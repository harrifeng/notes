<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-07-07 Thu 16:32 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>tic</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="harrifeng@outlook.com" />
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">tic</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org1e99ebf">1. Introduction to this book</a>
<ul>
<li><a href="#org5f5df7a">1.1. What is linear algebra and why learn it?</a></li>
<li><a href="#org5a50094">1.2. About this book</a></li>
<li><a href="#orgbfc3f14">1.3. Prerequisites</a></li>
<li><a href="#org05f6f4b">1.4. Practice, exercises and code challenges</a></li>
<li><a href="#org05bae25">1.5. Online and other resources</a></li>
</ul>
</li>
<li><a href="#orgb3ddf0e">2. Vectors</a>
<ul>
<li><a href="#orga6bf5ac">2.1. Scalars</a></li>
<li><a href="#orgb0412d4">2.2. Vectors: geometry and algebra</a></li>
<li><a href="#orgbd93deb">2.3. Transpose operation</a></li>
<li><a href="#orgc86e02f">2.4. Vector addition and subtraction</a></li>
<li><a href="#org978e201">2.5. Vector-scalar multiplication</a></li>
</ul>
</li>
<li><a href="#org702a1d8">3. Vector multiplications</a>
<ul>
<li><a href="#org86edde5">3.1. Vector dot product: Algebra</a></li>
<li><a href="#org2ee7df3">3.2. Dot product properties</a>
<ul>
<li><a href="#orgdfe3694">3.2.1. vector product和scalar的结合律</a></li>
<li><a href="#org0037d8d">3.2.2. vector product和vector的结合律</a></li>
<li><a href="#orgfce358f">3.2.3. commutative property</a></li>
<li><a href="#org62077f0">3.2.4. Distributive property</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org1e99ebf" class="outline-2">
<h2 id="org1e99ebf"><span class="section-number-2">1</span> Introduction to this book</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org5f5df7a" class="outline-3">
<h3 id="org5f5df7a"><span class="section-number-3">1.1</span> What is linear algebra and why learn it?</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>线性代数是数学中关于vector和matrix的分支</li>
<li>在现代,线性代数的重要性得到加强,因为很多数据都是以matrix的形势存储的,比如:
<ul class="org-ul">
<li>统计学</li>
<li>机器学习</li>
<li>计算机图形学</li>
<li>压缩算法</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org5a50094" class="outline-3">
<h3 id="org5a50094"><span class="section-number-3">1.2</span> About this book</h3>
<div class="outline-text-3" id="text-1-2">
<ul class="org-ul">
<li>本书对机器学习爱好者很有益处</li>
<li>本书仅仅需要高中数学知识</li>
<li>对于希望了解了线性代数之后进行深度学习,统计学的人来说,太过于抽象的线性代数学习比较浪费时间</li>
<li>本书注重实践,而不是理论</li>
<li>本书是一本数学书,所以请不要奇怪书中有公式.但是数学不仅仅是公式:
<ul class="org-ul">
<li>在我看来,数学的目的是理解概念</li>
<li>公式是展示概念的一种方式</li>
<li>但是文章,图片,甚至是代码都非常重要</li>
</ul></li>
<li>公式和其他表现形式有个微妙的平衡:
<ul class="org-ul">
<li>公式提供了正规而严格的表现形式,但是无法提供直觉力</li>
<li>其他表达形式(文章,类比,图表,代码)提供了直觉力,但是不够严格和正规</li>
</ul></li>
<li>本书的公式按照重要性分为三个等级:
<ol class="org-ol">
<li>简单的,或者是为了回忆之前讨论过的公式.那么就是优先度最低的公式,他们会和文本在一块,比如 \(x(yz) = (xy)z\)</li>
<li><p>
更加重要的公式,会有自己单独的行
</p>
\begin{equation}
\sigma = x(yz) = (xy)z\tag{1.1}
\end{equation}</li>
<li>最最重要的公式会有自己的区域来说明
<ul class="org-ul">
<li><p>
公式1.2
</p>
\begin{equation}
\sigma = x(yz) = (xy)z\tag{1.2}
\end{equation}</li>
<li>这个公式的要点1</li>
<li>这个公式的要点2</li>
</ul></li>
</ol></li>
<li>线性代数的很多概念可以使用如下两种数学分支的公式来表示:
<ul class="org-ul">
<li>Geometric: 几何方法,优点是提供图形化的直观展示,缺点是人类只能理解2D和3D的图像</li>
<li>Algebraic: 代数方法,优点是严谨的证明和计算机的介入,可以非常容易的扩展到N维</li>
</ul></li>
<li>注意,并不是所有的线性代数概念都可以使用几何和代数法来展示</li>
</ul>
</div>
</div>
<div id="outline-container-orgbfc3f14" class="outline-3">
<h3 id="orgbfc3f14"><span class="section-number-3">1.3</span> Prerequisites</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li>需要有学习线性代数的主动性</li>
<li>需要有高中数学基础</li>
<li>不需要有微积分知识</li>
<li>不需要任何线性代数知识,知道矩阵的计算肯定有好处</li>
<li>在计算机发明以前,数学里面的高阶概念,通常都是天才们依靠自己"能够把公式想象成图像"的能力来理解的,
现在有了计算机,我们可以享受到天才们的超能力了</li>
<li>本书使用Matlab(Octave)和Python来解决问题,其中Matlab更为容易实现线性代数</li>
</ul>
</div>
</div>
<div id="outline-container-org05f6f4b" class="outline-3">
<h3 id="org05f6f4b"><span class="section-number-3">1.4</span> Practice, exercises and code challenges</h3>
<div class="outline-text-3" id="text-1-4">
<ul class="org-ul">
<li>为了真正理解线性代数,必须做题</li>
<li>本书习题不多,目的是希望你全部都做完</li>
<li>本书习题分为三类:
<ul class="org-ul">
<li>Practice problem: 在subsection之后的,easy级别,答案就在后面,如果做不出来,
那么不需要继续向前读</li>
<li>Exercise: 在chapter之后的,中等难度,答案就在后面,需要手算,而不是用计算机算</li>
<li>Codechallenges: 需要使用计算机编程来实现的,比较难,也有答案</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org05bae25" class="outline-3">
<h3 id="org05bae25"><span class="section-number-3">1.5</span> Online and other resources</h3>
<div class="outline-text-3" id="text-1-5">
<ul class="org-ul">
<li>本书中的解释如果你理解不了,可以从网络上搜索从其他角度的解释来让你明白</li>
<li>本书有配套网络课程,喜欢网络课程学习方法的可以关注</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgb3ddf0e" class="outline-2">
<h2 id="orgb3ddf0e"><span class="section-number-2">2</span> Vectors</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-orga6bf5ac" class="outline-3">
<h3 id="orga6bf5ac"><span class="section-number-3">2.1</span> Scalars</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>我们不是从向量(vector)开始,而是从标量(scalar)开始</li>
<li>所谓标量(scalar)就是一个单独的数字,比如4或者-17.3等等</li>
<li>在数学的其他领域,标量有时候会被称之为常量(constant)</li>
<li>标量虽然简单,但是在线性代数里面却扮演者很多重要的角色:
<ul class="org-ul">
<li>subspaces</li>
<li>linear combination</li>
<li>eigendecomposition</li>
</ul></li>
<li>标量的名字(scalar)是scale的名词形式:
<ul class="org-ul">
<li>scale就有伸展,拉长的意思</li>
<li>scalar就有伸展拉长vector和metrix,并且不改变他们的方向(direction)</li>
</ul></li>
<li>标量在图上线上就是线上的一个空心的point,比如下图中的scalar就是一个1.5</li>
<li>注意:本书中标量都使用希腊小写字母( \(\lambda, \alpha, \gamma\) ),以便和vector和matrix区分</li>
<li><p>
使用python来表示标量,就是一个变量
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #FFB8D1;">aScalar</span> = 5
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-orgb0412d4" class="outline-3">
<h3 id="orgb0412d4"><span class="section-number-3">2.2</span> Vectors: geometry and algebra</h3>
<div class="outline-text-3" id="text-2-2">
<ul class="org-ul">
<li><b>Geometry</b> vector是一个line,由两个属性决定:
<ul class="org-ul">
<li>magnitude(长度)</li>
<li>direction(方向)</li>
</ul></li>
<li>line可以在任意维度存在(1维,2维,3维,&#x2026;N维)</li>
<li>如图
<ul class="org-ul">
<li><p>
图2-2
</p>

<div id="org8835a19" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/tic/2-2.png" alt="2-2.png" />
</p>
<p><span class="figure-number">Figure 1: </span>tic/2-2.png</p>
</div></li>
<li>上图左边是在2维空间的vector[2,3]</li>
<li>上图右边是在3维空间的vector[2,3,5]</li>
</ul></li>
<li>需要注意的是,vector的定义不包含它的起止位置(position)的,这是和坐标系不同的地方</li>
<li>在坐标系里面,每个坐标都是在空间中唯一的</li>
<li>从另外一个角度上讲,如果假设vector是从[0,0]开的话,那么vector和coordinate就是同一回事了.</li>
<li><p>
所以,起点(英文叫tail,注意是尾巴的意思,英文认为终点的是箭头,起点是尾巴)为[0,0]的vector被叫做在他
的standard position
</p>
<pre class="example" id="orgce8d84e">
A vector with its tail at the origin is said to be in its standard position
</pre></li>
<li>如图
<ul class="org-ul">
<li><p>
图2-3
</p>

<div id="org1114ae5" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/tic/2-3.png" alt="2-3.png" />
</p>
<p><span class="figure-number">Figure 2: </span>tic/2-3.png</p>
</div></li>
<li>上图中三个vector(line)都是相同的,因为他们的长度和方向都一样</li>
<li>上图中的三个坐标(圆圈)都是不相同的,因为坐标本来就全局唯一,没有两个一样的坐标</li>
<li>比较黑的line就是vector in its standard position. 这种情况下的vector[1,-2]的head和坐标[1,-2]相重叠</li>
</ul></li>
<li><p>
使用如下代码画vector
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #96CBFE; font-style: italic;">import</span> numpy <span style="color: #96CBFE; font-style: italic;">as</span> np
<span style="color: #96CBFE; font-style: italic;">import</span> matplotlib.pyplot <span style="color: #96CBFE; font-style: italic;">as</span> plt

<span style="color: #FFB8D1;">v</span> = np.array<span style="color: #55b3cc;">(</span><span style="color: #FFB8D1;">[</span>2, -1<span style="color: #FFB8D1;">]</span><span style="color: #55b3cc;">)</span>
plt.plot<span style="color: #55b3cc;">(</span><span style="color: #FFB8D1;">[</span>0, v<span style="color: #C2FFDF;">[</span>0<span style="color: #C2FFDF;">]</span><span style="color: #FFB8D1;">]</span>, <span style="color: #FFB8D1;">[</span>0, v<span style="color: #C2FFDF;">[</span>1<span style="color: #C2FFDF;">]</span><span style="color: #FFB8D1;">]</span><span style="color: #55b3cc;">)</span>
plt.axis<span style="color: #55b3cc;">(</span><span style="color: #FFB8D1;">[</span>-3, 3, -3, 3<span style="color: #FFB8D1;">]</span><span style="color: #55b3cc;">)</span>
plt.show<span style="color: #55b3cc;">()</span>
</pre>
</div></li>
<li><b>Algebra</b> 从代数的角度上说,vector就是一个ordered list(成员是number)</li>
<li>一个vector内部number的数量就叫做vector的dimensionality,比如:
<ul class="org-ul">
<li><p>
2D的vector例子
</p>
<pre class="example" id="orgbf79e01">
[1 -2], [4 1], [10000 0]
</pre></li>
<li><p>
3D的vector例子
</p>
<pre class="example" id="org8598977">
[3.14 e 0], [3 1 4], [2 -7 8]
</pre></li>
</ul></li>
<li>vector内部number的顺序是非常重要的,不同的顺序代表不同的vector,比如下面两个vector就不同,虽然他们
的dimensionality一样,数据也一样:
<ul class="org-ul">
<li>[3 1]</li>
<li>[1 3]</li>
</ul></li>
<li><b>Brackets</b> vector可以使用square bracket(方括号)或者是parentheses(园括号)</li>
<li>我个人认为方括号更加优雅,也不容易混淆,所以一直用方括号</li>
<li>但是有些情况下,你可能会遇到使用圆括号来代替方括号,比如下面两者在这种情况下是等价的:
<ul class="org-ul">
<li>[2 5 5]</li>
<li>(2 5 5)</li>
</ul></li>
<li>vector的几何表示,在2D表达中非常有用,在3D表达中也马马虎虎,但是更多维度就不行了</li>
<li><p>
vector的代数表示,却可以让我们在任何维度上,扩展vector,比如下面的公式就非常清晰的解释了什么是6D vector
</p>
<pre class="example" id="org7b73728">
[3 4 6 1 -4 5]
</pre></li>
<li><p>
vector成员也不仅限于number,其成员还可以是function,比如下面的例子
</p>
\begin{equation}
\mathbf{v} = [\cos(t)\; \sin(t)\; t]
\end{equation}</li>
<li>本书不讨论上面的情况,本书中vector的所有成员都是普通number</li>
<li><b>Vector orientation</b> vector可以"站着",也可以"躺着":
<ul class="org-ul">
<li><p>
站着的vector被叫做column vector,如下
</p>
\begin{equation}
\left[ {\begin{array}{cccc}
7 \\
3 \\
5 \\
0 \\
\end{array} } \right]
\end{equation}</li>
<li><p>
躺着的vector被叫做row vector,如下
</p>
\begin{equation}
[0 \;1 \;3]
\end{equation}</li>
</ul></li>
<li><b>IMPORTANT</b> 默认情况下,vector是column orientation的,原因可能是在和matrix进行相乘的时候,vector在
matrix右边(作为被乘matrix,一个某个方向上只有一维的matrix)才有意义, 一般matrix都是MxN的大小,那么
在matrix右边,必须是Nx1,而不能是1xN的形状</li>
<li><p>
在matrix中,使用空格分离是row vector, 使用`;`分离,是column vector
</p>
<pre class="example" id="orge937409">
v1 = [2 5 4 7] % row vector
v2 = [2; 5; 4; 7] % column vector
</pre></li>
<li><p>
在python中, list(以及numpy array)没有默认的orientation,所以在某些情况下一定要指定orientation的
时候,numpy要用比较麻烦的方式实现
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #FFB8D1;">v1</span> = <span style="color: #55b3cc;">[</span>2, 5, 4, 7<span style="color: #55b3cc;">]</span>               <span style="color: #E6C000;"># </span><span style="color: #E6C000;">list</span>
<span style="color: #FFB8D1;">v2</span> = np.array<span style="color: #55b3cc;">(</span><span style="color: #FFB8D1;">[</span>2, 5, 4, 7<span style="color: #FFB8D1;">]</span><span style="color: #55b3cc;">)</span>     <span style="color: #E6C000;"># </span><span style="color: #E6C000;">array, no orientation</span>
<span style="color: #FFB8D1;">v3</span> = np.array<span style="color: #55b3cc;">(</span><span style="color: #FFB8D1;">[</span><span style="color: #C2FFDF;">[</span>2<span style="color: #C2FFDF;">]</span>, <span style="color: #C2FFDF;">[</span>5<span style="color: #C2FFDF;">]</span>, <span style="color: #C2FFDF;">[</span>4<span style="color: #C2FFDF;">]</span>, <span style="color: #C2FFDF;">[</span>7<span style="color: #C2FFDF;">]</span><span style="color: #FFB8D1;">]</span><span style="color: #55b3cc;">)</span> <span style="color: #E6C000;"># </span><span style="color: #E6C000;">column vector</span>
<span style="color: #FFB8D1;">v4</span> = np.array<span style="color: #55b3cc;">(</span><span style="color: #FFB8D1;">[</span><span style="color: #C2FFDF;">[</span>2, 5, 4, 7<span style="color: #C2FFDF;">]</span><span style="color: #FFB8D1;">]</span><span style="color: #55b3cc;">)</span>       <span style="color: #E6C000;"># </span><span style="color: #E6C000;">row vector</span>
</pre>
</div></li>
<li><b>Notation</b> 在书面书写中,我们只需要boldface字母就可以表示vector了,比如 \(\mathbf{v}\), 但是如果是论
文中,我们一定需要在vector上面加上剪头,比如 \(\vec{\mathbf{v}}\)</li>
<li>为了表达vector里面的一个特定成员,我们会使用下标,比如 \(\mathbf{v} = [4\;0\;2]\), 的第二个成员表示
为 \(v_2 = 0\), 第ith个表示为 \(v_i\) ,注意这里的小写字母没有加粗</li>
<li><p>
如果小写字母加粗的下划线加i,也就是 \(\mathbf{v_i}\) 那么表示相关的如下vectors
</p>
\begin{equation}
(\mathbf{v_1},\mathbf{v_2},...,\mathbf{v_i})
\end{equation}</li>
<li><b>Zeros vector</b>, 所有成员都是0的vector叫做zeros vector,注意是所有成员,缺一个都不叫zeros vector</li>
<li>zeros vector有一些特殊的地方,比如:
<ul class="org-ul">
<li>zeros 没有direction, 我的意思不是说它的direction为0,我是说它的direction未知(undefined),因为
zeros vector的magnitude为0,讨论一个magnitude为0的vector的direction是没有意义的</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgbd93deb" class="outline-3">
<h3 id="orgbd93deb"><span class="section-number-3">2.3</span> Transpose operation</h3>
<div class="outline-text-3" id="text-2-3">
<ul class="org-ul">
<li>把vector在column vector和row vector之间相互转换的操作,叫做transpose</li>
<li>transpose只更改orientation,其他的element内容和排序都不变</li>
<li>我们使用一个上标T来代表这个操作,那么就有如下三个例子:
<ul class="org-ul">
<li><p>
row vector转换成 column vector
</p>
\begin{equation}
 [7\;3\;5]^T  = \left[ {\begin{array}{cccc}
7 \\
3 \\
5 \\
\end{array} } \right]
\end{equation}</li>
<li><p>
column vector转换成 row vector
</p>
\begin{equation}
\left[ {\begin{array}{cccc}
7 \\
3 \\
5 \\
\end{array} } \right]^T = [7\;3\;5]
\end{equation}</li>
<li><p>
两次TT操作,可以抵消
</p>
\begin{equation}
[7\;3\;5]^{TT}=[7\;3\;5]
\end{equation}</li>
</ul></li>
<li>我们之前说过,我们assume, vector是column vector,所以:
<ul class="org-ul">
<li>\(\mathbf{v}\) 就是column vector</li>
<li>\(\mathbf{v}^T\) 就是row vector</li>
</ul></li>
<li>在印刷书籍中,在文字间写column vector非常不方便,所以文字书籍中往往是把column vector写成row vector
的转置形式,比如 \(\mathbf{w} = [1\;2\;3]^T\)</li>
<li><p>
在代码中转置很方便
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #96CBFE; font-style: italic;">import</span> numpy <span style="color: #96CBFE; font-style: italic;">as</span> np

<span style="color: #FFB8D1;">v1</span> = np.array<span style="color: #55b3cc;">(</span><span style="color: #FFB8D1;">[</span><span style="color: #C2FFDF;">[</span>2, 5, 4, 7<span style="color: #C2FFDF;">]</span><span style="color: #FFB8D1;">]</span><span style="color: #55b3cc;">)</span>  <span style="color: #E6C000;"># </span><span style="color: #E6C000;">row vector</span>
<span style="color: #FFB8D1;">v2</span> = v1.T  <span style="color: #E6C000;"># </span><span style="color: #E6C000;">column vector</span>
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-orgc86e02f" class="outline-3">
<h3 id="orgc86e02f"><span class="section-number-3">2.4</span> Vector addition and subtraction</h3>
<div class="outline-text-3" id="text-2-4">
<ul class="org-ul">
<li>*Geometry*我们主要通过下面的四个图来理解vector的加和减
<ul class="org-ul">
<li><p>
图2-5
</p>

<div id="org68cafde" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/tic/2-5.png" alt="2-5.png" />
</p>
<p><span class="figure-number">Figure 3: </span>tic/2-5.png</p>
</div></li>
<li>第一幅图是介绍我们这次加减法的两个成员:
<ol class="org-ol">
<li>v1: [0 2]</li>
<li>v2: [1 1]</li>
</ol></li>
<li>第二幅图是介绍如何计算加法: 把v2的起点从standard position移动到v1的终点,那么从v1的起点到v2的终
点,就是新的vector</li>
<li>第三幅图是介绍减法的第一种做法,就把v2乘以-1,变成[-1,-1], 那么v1-v2就成了v1 + (-1 * v2),加法计算
方法和图二一致</li>
<li>第四幅图是介绍减法的第二种做法,就是从被减数的终点(作为起点)引出一条vector,终点是减数的终点,其
实就是v2 - v1 = v3 转换成v2 = v1 + v3</li>
</ul></li>
<li><p>
vector的加法满足交换律,也就是说
</p>
\begin{equation}
\mathbf{a}  + \mathbf{b} = \mathbf{b} + \mathbf{a}
\end{equation}</li>
<li><b>Algebra</b> 加法和减法的代数解释那就简单了,就是相对应的element进行加或者减:
<ul class="org-ul">
<li><p>
比如
</p>
\begin{equation}
[1\;2] + [3\;4] = [4\;6]
\end{equation}</li>
<li><p>
用公式来解释就是
</p>
\begin{equation}
\mathbf{c} = \mathbf{a} + \mathbf{b} = [a_1 + b_1 \; a_2 + b_2 \;...\; a_n + b_n]^T
\end{equation}</li>
</ul></li>
<li><b>Important</b> 加法和减法有意义的前提是参与运算的两个vector有同样的维度</li>
</ul>
</div>
</div>
<div id="outline-container-org978e201" class="outline-3">
<h3 id="org978e201"><span class="section-number-3">2.5</span> Vector-scalar multiplication</h3>
<div class="outline-text-3" id="text-2-5">
<ul class="org-ul">
<li><b>Geometry</b> Scaling一个vector,就是:
<ul class="org-ul">
<li>增加或者减少这个vector的长度</li>
<li>并且不改变这个vector的angle</li>
</ul></li>
<li>scalar multiplication也不会改变原始的orientation</li>
<li>当然,如果scalar为0的话,最后的结果全部变成0,但是这种情况下,vector转换成了一个point,我们不能说point
有任何的的angle</li>
<li><b>Algebra</b> Scalar-vector的乘法,就是把vector的每个成员都乘以scalar</li>
<li><p>
对于scalar \(\lambda\) 和 vector \(\mathbf{v}\) , 我们有如下的公式
</p>
\begin{equation}
\lambda \mathbf{v} = [\lambda \mathbf{v}_1 \; \lambda \mathbf{v}_2 \; ... \; \lambda \mathbf{v}_n]^T \tag{2.3}
\end{equation}</li>
<li><p>
一个简单的例子如下
</p>
<pre class="example" id="orge96a1ed">
3 [-1 3 0 2] = [-3 9 0 6]
</pre></li>
<li><p>
scalar-vector multipleication满足交换律,也就是说
</p>
\begin{equation}
\lambda \mathbf{v} =  \mathbf{v} \lambda
\end{equation}</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org702a1d8" class="outline-2">
<h2 id="org702a1d8"><span class="section-number-2">3</span> Vector multiplications</h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li>有四种方法来对两个vector进行乘法:
<ul class="org-ul">
<li>dot product</li>
<li>outer product</li>
<li>element-wise multiplication</li>
<li>cross product</li>
</ul></li>
<li>其中最重要的也是我们讲的最多的,就是dot product</li>
</ul>
</div>
<div id="outline-container-org86edde5" class="outline-3">
<h3 id="org86edde5"><span class="section-number-3">3.1</span> Vector dot product: Algebra</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li>dot product也叫做inner product, 是线性代数里面最重要的操作</li>
<li>dot product是如下高级操作的基础:
<ul class="org-ul">
<li>convolution(卷积)</li>
<li>correlation</li>
<li>Fourier transform</li>
<li>matrix multiplication</li>
<li>signal filtering</li>
</ul></li>
<li>dot product是使用一个number来提供两个vector之间relationship的方法</li>
<li><p>
由于两个vector的dot product结果是一个scalar, 所以dot product又称之为scalar product
</p>
<pre class="example" id="orgf24432f">
注意,是scalar product,而不是scalar-vector product
</pre></li>
<li>至于inner product,这是在"非欧几里得空间"里面对dot product的命名,在欧几里何空间,我们可以认为inner
product和dot product等价.</li>
<li>inner product和dot product(scalar product)的实际关系如下</li>
<li>本书只使用dot product这一个称呼</li>
<li>从几何角度上来说,计算dot product,只需要如下两步:
<ul class="org-ul">
<li>把两个vector对应的N个element相乘,得到N个数字</li>
<li>把这N个数字相加</li>
</ul></li>
<li><p>
dot product的过程可以使用如下公式表达,注意,公式中中间三个是对dot product的三种表达方式(我们经常
使用的是 \(\mathbf{a}^T\mathbf{b}\),因为这个体现了矩阵乘法的原理)
</p>
\begin{equation}
\alpha = \mathbf{a} \cdot \mathbf{b} = \left \langle \mathbf{a}, \mathbf{b} \right \rangle =\mathbf{a}^T \mathbf{b} = \sum_{i=1}^n a_i b_i \tag{3.1}
\end{equation}</li>
<li><p>
我们举个例子来计算一下
</p>
<pre class="example" id="org02ae23a">
[1 2 3 4] * [5 6 7 8] = 1*5 + 2*6 + 3*7 + 4*8
                      = 5 + 12 + 21 + 32
                      = 70
</pre></li>
<li>由于dot product计算过程的特性,那么我们需要dot product参与的两个vector都是相同的dimensionality</li>
<li>vector和它自己的dimensionality肯定是相同的,所以,我们可以计算vector和它自己的dot product
<ul class="org-ul">
<li><p>
这个操作可以在公式3.2中显示
</p>
\begin{equation}
\mathbf{a}^T\mathbf{a} = \left \| \mathbf{a} \right \|^2 = \sum_{i=1}^n a_i a_i = \sum_{i=1}^n a_i^2 \tag{3.2}
\end{equation}</li>
<li>\(\left \| \mathbf{a} \right \|\) 叫做 vector \(\matbf{a}\) 的length, magnitude或者是norm</li>
<li>vector自己和自己dot product的结果是\(\left \| \mathbf{a}^2 \right \|\) , 其实就是 vector的length-squared,
magnitude-squared或者是sauared-norm</li>
</ul></li>
<li><p>
使用如下代码计算dot product
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #FFB8D1;">v1</span> = np.array<span style="color: #55b3cc;">(</span><span style="color: #FFB8D1;">[</span>2, 5, 4, 7<span style="color: #FFB8D1;">]</span><span style="color: #55b3cc;">)</span>
<span style="color: #FFB8D1;">v2</span> = np.array<span style="color: #55b3cc;">(</span><span style="color: #FFB8D1;">[</span>4, 1, 0, 2<span style="color: #FFB8D1;">]</span><span style="color: #55b3cc;">)</span>
<span style="color: #FFB8D1;">dp</span> = np.dot<span style="color: #55b3cc;">(</span>v1, v2<span style="color: #55b3cc;">)</span>
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-org2ee7df3" class="outline-3">
<h3 id="org2ee7df3"><span class="section-number-3">3.2</span> Dot product properties</h3>
<div class="outline-text-3" id="text-3-2">
<ul class="org-ul">
<li><b>Associative property</b> 我们想看看结合律是否在dot production上面适用,需要从两个角度看,必须两个角
度都满足才能说dot production 满足结合律</li>
</ul>
</div>
<div id="outline-container-orgdfe3694" class="outline-4">
<h4 id="orgdfe3694"><span class="section-number-4">3.2.1</span> vector product和scalar的结合律</h4>
<div class="outline-text-4" id="text-3-2-1">
<ul class="org-ul">
<li>这种情况其实就是scalar-vector multiplication嵌套在dot product里面</li>
<li>这种情况下显然满足结合律,因为scalar和每个vector的结果都是"维度不变(长度变化)的新vector"</li>
<li><p>
用公式表达,就是公式3.3是成立的.
</p>
\begin{equation}
\gamma(\mathbf{u}^T \mathbf{v}) = (\gamma \mathbf{u}^T) \mathbf{v} = \mathbf{u}^T (\gamma \mathbf{v}) = (\mathbf{u}^T \mathbf{v})\gamma \tag{3.3}
\end{equation}</li>
</ul>
</div>
</div>
<div id="outline-container-org0037d8d" class="outline-4">
<h4 id="org0037d8d"><span class="section-number-4">3.2.2</span> vector product和vector的结合律</h4>
<div class="outline-text-4" id="text-3-2-2">
<ul class="org-ul">
<li>先说结论,这种情况下的结合律是不满足的</li>
<li><p>
用公式表达,就是公式3.4是不成立的!
</p>
\begin{equation}
\mathbf{u}^T(\mathbf{v}^T \mathbf{w}) = (\mathbf{u}^T\mathbf{v})^T \mathbf{w}
\end{equation}</li>
<li>要想理解这个不可能,我们可以从很多方向来理解:
<ul class="org-ul">
<li>我们首先假设三个vector的维度相同,那么我们会发现,上面公式的左右两边甚至都不是dot product,因为
<ol class="org-ol">
<li>左边是row vector \(\mathbf{u}^T\) 和一个scalar(两个vector相乘得到的)相乘, 所以左边是一个row vector</li>
<li>右边是一个scalr(两个vector相乘得到的)和一个column vector相乘,所以右边是一个 column vector(注
意对于scalar来说 \(4^T = 4\)</li>
<li><p>
其实不仅仅是row vector和column vector的不一样,他们的成员其实也有可能是不一样的,比如下面的例子
</p>
\begin{equation}
\mathbf{u} = \begin{bmatrix}
             1 \\
             2 \\
             \end{bmatrix} ,
\mathbf{v} = \begin{bmatrix}
             1 \\
             3 \\
             \end{bmatrix} ,
\mathbf{w} = \begin{bmatrix}
             2 \\
             3 \\
             \end{bmatrix}
\end{equation}</li>
<li><p>
左边的结果为
</p>
\begin{equation}
\mathbf{u}^T(\mathbf{v}^T \mathbf{w}) =
             \begin{bmatrix}
             1 \; 2 \\
             \end{bmatrix}
             \left(
             \begin{bmatrix}
             1 \; 3 \\
             \end{bmatrix}
             \begin{bmatrix}
             2 \\
             3 \\
             \end{bmatrix}
             \right)
             =
             \begin{bmatrix}
             11 \; 22 \\
             \end{bmatrix} \tag{3.5}
\end{equation}</li>
<li><p>
右边的结果为,可见,显然和左边的不一样,不仅orientation不一样,element维度也不一样
</p>
 \begin{equation}
( \mathbf{u}^T\mathbf{v})^T \mathbf{w} =
              \left(
              \begin{bmatrix}
              1 \; 2 \\
              \end{bmatrix}
              \begin{bmatrix}
              1 \\ 3 \\
              \end{bmatrix}
              \right)^T
              \begin{bmatrix}
              2 \\
              3 \\
              \end{bmatrix}
              =
              \begin{bmatrix}
              14 \\ 21 \\
              \end{bmatrix} \tag{3.6}
 \end{equation}</li>
</ol></li>
<li>如果这三个vector的维度不同,那么甚至有一边的计算都是invalid的,都不用考虑是否相等了</li>
</ul></li>
<li>综上所述,我们可以得到结论,就是vector dot product不遵守结合律.(但是,matrix的乘法遵守结合律,所以
后面不要和这里混淆)</li>
</ul>
</div>
</div>
<div id="outline-container-orgfce358f" class="outline-4">
<h4 id="orgfce358f"><span class="section-number-4">3.2.3</span> commutative property</h4>
<div class="outline-text-4" id="text-3-2-3">
<ul class="org-ul">
<li><p>
dot product 满足交换律,用公式表达如下
</p>
\begin{equation}
\mathbf{a}^T \mathbf{b} = \mathbf{b} \mathbf{a}^T \tag{3.7}
\end{equation}</li>
<li><p>
dot product 满足交换律是很显然的事情,因为dot production是在element维度完成的,两element的相乘,
其实就是两个scalar的乘积,而scalar乘法是符合交换律的(如公式3.8),那么我们也可以说dot product也是
符合交换律的
</p>
\begin{equation}
\sum_{i=1}^na_ib_i = \sum_{i=1}^nb_ia_i \tag{3.8}
\end{equation}</li>
</ul>
</div>
</div>
<div id="outline-container-org62077f0" class="outline-4">
<h4 id="org62077f0"><span class="section-number-4">3.2.4</span> Distributive property</h4>
<div class="outline-text-4" id="text-3-2-4">
<ul class="org-ul">
<li>首先抛出结论: dot product是符合分配率的,符合分配率这件事情能让"代数表达"和"几何表达"联系起来</li>
<li><p>
分配率可以用如下公式解释:(当然了,这里的vector必须维度相同)
</p>
\begin{equation}
\mathbf{w}^T (\mathbf{u} + \mathbf{v}) = \mathbf{w}^T \mathbf{u} + \mathbf{w}^T \mathbf{v} \tag{3.9}
\end{equation}</li>
<li>分配率说的是这么一个事儿:我们可以把一个dot product分成两个dot product的和,只需要把那个vector拆
成两个就好了</li>
<li>当然了也可以反过来用,假设两个vector都和同一个vector相乘,而这两vector的维度一样,那么就可以先把
这两个vector加起来</li>
<li>我们可以用一个例子来加深我们的理解:
<ul class="org-ul">
<li><p>
假设三个vector如下
</p>
\begin{equation}
\mathbf{u} = \begin{bmatrix}
             1 \\
             2 \\
             \end{bmatrix} ,
\mathbf{v} = \begin{bmatrix}
             1 \\
             3 \\
             \end{bmatrix} ,
\mathbf{w} = \begin{bmatrix}
             2 \\
             3 \\
             \end{bmatrix}
\end{equation}</li>
<li><p>
公式左边的计算结果是19
</p>
\begin{equation}
\mathbf{w}^T(\mathbf{u} + \mathbf{v}) =
             \begin{bmatrix}
             2 \; 3 \\
             \end{bmatrix}
             \left(
             \begin{bmatrix}
             1 \\ 2 \\
             \end{bmatrix}
+
              \begin{bmatrix}
              1 \\
              3 \\
              \end{bmatrix}
              \right)
              =
              \begin{bmatrix}
              2 \; 3 \\
              \end{bmatrix}
              \times
              \begin{bmatrix}
              2 \\
              5 \\
              \end{bmatrix}
              = 19
              \tag{3.11}
\end{equation}</li>
<li><p>
公式右边的计算结果也是19
</p>
\begin{equation}
\mathbf{w}^T \mathbf{u} + \mathbf{w}^T \mathbf{v} =
             \begin{bmatrix}
             2 \; 3 \\
             \end{bmatrix}
             \begin{bmatrix}
             1 \\ 2 \\
             \end{bmatrix}
+
              \begin{bmatrix}
              2 \; 3 \\
              \end{bmatrix}
              \begin{bmatrix}
              1 \\
              3 \\
              \end{bmatrix}
              =
              8 + 11
              = 19
              \tag{3.12}
\end{equation}</li>
</ul></li>
<li>下面我们把结合律应用到一种特殊的情况,那就是vector自己分成两个sub_vector, 然后这两个sub_vector再
乘以自己.</li>
<li><p>
由于分配率的存在,我们可以得到如下的等式
</p>
\begin{gather}
\begin{align}
(\mathbf{u} + \mathbf{v})^T(\mathbf{u} + \mathbf{v}) &= \| \mathbf{u} + \mathbf{v} \|^2 \\
                                                     &= \mathbf{u}^T\mathbf{u} + 2\mathbf{u}^T\mathbf{v} + \mathbf{v}^T\mathbf{v} \\
                                                     &= \| \mathbf{u} \|^2 + \| \mathbf{v} \|^2 + 2\mathbf{u}^T\mathbf{v}
\end{align}
\end{gather}</li>
<li>上述公式是连接"代数解释"和"几何解释"之间的桥梁</li>
<li><p>
<b>Cauchy-Schwarz inqauality</b> 柯西-斯瓦茨不等式提供了两个vector进行dot product的上限,,不等式如下
</p>
\begin{equation}
| \mathbf{v}^T \mathbf{w} | \leq \| v \| \| w \| \tag{3.14}
\end{equation}</li>
<li><p>
用英语来说,上面的不等式就是说
</p>
<pre class="example" id="org48998af">
两个vector的dot product的magnitude不会比这两个vector magitude的product值大
</pre></li>
<li>这个不等式的等于会在下面的情况下得到满足的时候,出现:
<ul class="org-ul">
<li>一个vector是另外一个vector的scaled version,也就是说 \(\mathbf{v} = \lambda \mathbf{w}\)</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: harrifeng@outlook.com</p>
<p class="date">Created: 2022-07-07 Thu 16:32</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
