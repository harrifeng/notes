<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-01-14 Tue 19:43 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>dlfs</title>
<meta name="author" content="harrifeng@outlook.com" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="src/readtheorg_theme/css/readtheorg.css"/>
<script type="text/javascript" src="src/lib/js/jquery.min.js"></script>
<script type="text/javascript" src="src/lib/js/bootstrap.min.js"></script>
<script type="text/javascript" src="src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="src/readtheorg_theme/js/readtheorg.js"></script>
<script id="MathJax-script" async src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">dlfs</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org2c2696b">1. Python 入门</a>
<ul>
<li><a href="#org27e28b7">1.1. Python是什么</a></li>
<li><a href="#orge31b682">1.2. Python的安装</a>
<ul>
<li><a href="#orgbc624df">1.2.1. Python版本</a></li>
<li><a href="#orge5e4d5a">1.2.2. 使用的外部库</a></li>
<li><a href="#org032d2ea">1.2.3. Anaconda发行版</a></li>
</ul>
</li>
<li><a href="#orgf39f09d">1.3. Python解释器</a>
<ul>
<li><a href="#org025c640">1.3.1. 算术计算</a></li>
<li><a href="#org893c235">1.3.2. 数据类型</a></li>
<li><a href="#org3b7e1e2">1.3.3. 变量</a></li>
<li><a href="#org9e90ac7">1.3.4. 列表</a></li>
<li><a href="#orgb772a3f">1.3.5. 字典</a></li>
<li><a href="#org29292ae">1.3.6. 布尔型</a></li>
<li><a href="#orgcaa2952">1.3.7. if 语句</a></li>
<li><a href="#org3dd5af0">1.3.8. for 语句</a></li>
<li><a href="#org04c1d84">1.3.9. 函数</a></li>
</ul>
</li>
<li><a href="#org471fe62">1.4. Python脚本文件</a>
<ul>
<li><a href="#org59a8893">1.4.1. 保存为文件</a></li>
<li><a href="#org7291ce9">1.4.2. 类</a></li>
</ul>
</li>
<li><a href="#org882ea65">1.5. NumPy</a>
<ul>
<li><a href="#org99ac31c">1.5.1. 导入NumPy</a></li>
<li><a href="#org5fe19a1">1.5.2. 生成NumPy数组</a></li>
<li><a href="#org23f9e83">1.5.3. NumPy的算术运算</a></li>
<li><a href="#orgc53abca">1.5.4. NumPy的N维数组</a></li>
<li><a href="#orgf5dd532">1.5.5. 广播</a></li>
<li><a href="#org203b513">1.5.6. 访问元素</a></li>
</ul>
</li>
<li><a href="#org5869137">1.6. Matplotlib</a>
<ul>
<li><a href="#orgf09892c">1.6.1. 绘制简单图形</a></li>
<li><a href="#org9f080cd">1.6.2. pyplot的功能</a></li>
<li><a href="#orga16fc8f">1.6.3. 显示图像</a></li>
</ul>
</li>
<li><a href="#org5af06c8">1.7. Understanding Broadcasting in NumPy</a>
<ul>
<li><a href="#orge69b740">1.7.1. What is Broadcasting?</a></li>
<li><a href="#orgadcf672">1.7.2. The Broadcasting Rules</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org68e7eb9">2. 感知机</a>
<ul>
<li><a href="#orgde9f0c3">2.1. 感知机是什么</a></li>
<li><a href="#org007df60">2.2. 简单的逻辑电路</a>
<ul>
<li><a href="#org2e02e14">2.2.1. 与门</a></li>
<li><a href="#org3476e63">2.2.2. 与非门和或门</a></li>
</ul>
</li>
<li><a href="#orgc22caf6">2.3. 感知机的实现</a>
<ul>
<li><a href="#org065312c">2.3.1. 简单的实现</a></li>
<li><a href="#org05a0a91">2.3.2. 导入权重和偏置</a></li>
<li><a href="#orgeef523e">2.3.3. 使用权重和偏置的实现</a></li>
</ul>
</li>
<li><a href="#org9af7e8b">2.4. 感知机的局限性</a>
<ul>
<li><a href="#org3185ab1">2.4.1. 异或门</a></li>
<li><a href="#org906b068">2.4.2. 线性和非线性</a></li>
</ul>
</li>
<li><a href="#org2493eee">2.5. 多层感知机</a>
<ul>
<li><a href="#orgb303916">2.5.1. 已有门电路组合</a></li>
<li><a href="#orgf3e4156">2.5.2. 异或门的实现</a></li>
</ul>
</li>
<li><a href="#orge4696b4">2.6. 从与非门到计算机</a></li>
</ul>
</li>
<li><a href="#orgcbd4d07">3. 神经网络</a>
<ul>
<li><a href="#orgfc8c3ed">3.1. 从感知机到神经网络</a>
<ul>
<li><a href="#orgd672310">3.1.1. 神经网路的例子</a></li>
<li><a href="#org4b440dc">3.1.2. 复习感知机</a></li>
<li><a href="#org2f71100">3.1.3. 激活函数登场</a></li>
</ul>
</li>
<li><a href="#org9eded81">3.2. 激活函数</a>
<ul>
<li><a href="#orge1f4478">3.2.1. sigmoid函数</a></li>
<li><a href="#org68cde32">3.2.2. 阶跃函数的实现</a></li>
<li><a href="#org82bdca7">3.2.3. 阶跃函数的图形</a></li>
<li><a href="#orgcf9c4bc">3.2.4. sigmoid 函数的实现</a></li>
<li><a href="#org47bb858">3.2.5. sigmoid函数和阶跃函数的比较</a></li>
<li><a href="#org3232734">3.2.6. 非线性函数</a></li>
<li><a href="#org3f43631">3.2.7. ReLU函数</a></li>
</ul>
</li>
<li><a href="#org496c960">3.3. 多维数组的运算</a>
<ul>
<li><a href="#orga0e3242">3.3.1. 多维数组</a></li>
<li><a href="#orgb093f49">3.3.2. 矩阵乘法</a></li>
<li><a href="#org328530a">3.3.3. 神经网络的内积</a></li>
</ul>
</li>
<li><a href="#org3c556be">3.4. 3层神经网络的实现</a>
<ul>
<li><a href="#orgcb14ff7">3.4.1. 符号确认</a></li>
<li><a href="#org4fd87eb">3.4.2. 各层间信号传递的实现</a></li>
<li><a href="#orgf4045a1">3.4.3. 代码现小结</a></li>
</ul>
</li>
<li><a href="#org331b1f1">3.5. 输出层的设计</a>
<ul>
<li><a href="#org7b69fb6">3.5.1. 恒等函数和softmax函数</a></li>
<li><a href="#org4f3123d">3.5.2. 实现softmax函数时的注意事项</a></li>
<li><a href="#org9f7d230">3.5.3. softmax函数的特征</a></li>
<li><a href="#org7b62e00">3.5.4. 输出层的神经元数量</a></li>
</ul>
</li>
<li><a href="#orga32ed8f">3.6. 手写数字识别</a>
<ul>
<li><a href="#org1b784d8">3.6.1. MNIST数据集</a></li>
<li><a href="#org10acdd2">3.6.2. 神经网络的推理处理</a></li>
<li><a href="#orgd824b97">3.6.3. 批处理</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgb9f8c41">4. 神经网络的学习</a>
<ul>
<li><a href="#orge4d453f">4.1. 从数据中学习</a>
<ul>
<li><a href="#orgb85e4b4">4.1.1. 数据驱动</a></li>
<li><a href="#org95d0c56">4.1.2. 训练数据和测试数据</a></li>
</ul>
</li>
<li><a href="#org9d639d1">4.2. 损失函数</a>
<ul>
<li><a href="#orgd20acf1">4.2.1. 均方误差</a></li>
<li><a href="#org3a56e8f">4.2.2. 交叉熵误差</a></li>
<li><a href="#orgcbddaa8">4.2.3. mini-batch学习</a></li>
<li><a href="#org5a4f3e0">4.2.4. mini-batch版交叉熵误差的实现</a></li>
<li><a href="#orgb52f9a3">4.2.5. 为何要设定损失函数</a></li>
</ul>
</li>
<li><a href="#org1a6ff99">4.3. 数值微分</a>
<ul>
<li><a href="#org8bc1ba5">4.3.1. 导数</a></li>
<li><a href="#org9cb7b80">4.3.2. 数值微分的例子</a></li>
<li><a href="#org5a086f1">4.3.3. 偏导数</a></li>
</ul>
</li>
<li><a href="#org61522e0">4.4. 梯度</a>
<ul>
<li><a href="#org0c6dc29">4.4.1. 梯度法</a></li>
<li><a href="#org8287132">4.4.2. 神经网络的梯度</a></li>
</ul>
</li>
<li><a href="#org808dade">4.5. 学习算法的实现</a>
<ul>
<li><a href="#orge59a953">4.5.1. 2层神经网络的类</a></li>
<li><a href="#org19f7abb">4.5.2. mini-batch的实现</a></li>
<li><a href="#orgdc8e62c">4.5.3. 基于测试数据的评价</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org54d3ebd">5. 误差反向传播法</a>
<ul>
<li><a href="#org662491b">5.1. 计算图</a>
<ul>
<li><a href="#org0c84cdf">5.1.1. 用计算图求解</a></li>
<li><a href="#orgf2c1521">5.1.2. 局部计算</a></li>
<li><a href="#orga1af80a">5.1.3. 为何用计算图解题</a></li>
</ul>
</li>
<li><a href="#org4a63b09">5.2. 链式法则</a>
<ul>
<li><a href="#org2c9a88f">5.2.1. 计算图的反向传播</a></li>
<li><a href="#org2d83f1d">5.2.2. 什么是链式法则</a></li>
<li><a href="#org5cba86c">5.2.3. 链式法则和计算图</a></li>
</ul>
</li>
<li><a href="#org8731f9f">5.3. 反向传播</a>
<ul>
<li><a href="#orgb563d48">5.3.1. 加法节点的反向传播</a></li>
<li><a href="#org828d928">5.3.2. 乘法节点的反向传播</a></li>
<li><a href="#org8059b7c">5.3.3. 苹果的例子</a></li>
</ul>
</li>
<li><a href="#org55d61ad">5.4. 简单层的实现</a>
<ul>
<li><a href="#org1c24775">5.4.1. 乘法层的实现</a></li>
<li><a href="#orgad8c2b6">5.4.2. 加法层的实现</a></li>
</ul>
</li>
<li><a href="#orgf5f99b1">5.5. 激活函数层的实现</a>
<ul>
<li><a href="#org6fdc5f7">5.5.1. ReLU层</a></li>
<li><a href="#org978daaf">5.5.2. Sigmoid层</a></li>
</ul>
</li>
<li><a href="#orgea2f217">5.6. Affine/Softmax层的实现</a>
<ul>
<li><a href="#org51e4b43">5.6.1. Affine层</a></li>
<li><a href="#orge040c4c">5.6.2. 批版本的Affine层</a></li>
<li><a href="#org6899955">5.6.3. Softmax-with-Loss层</a></li>
</ul>
</li>
<li><a href="#org35cea52">5.7. 误差反向传播法的实现</a>
<ul>
<li><a href="#orgfe1c7b1">5.7.1. 神经网络学习的全貌图</a></li>
<li><a href="#org34f3b3a">5.7.2. 对应误差反向传播法的神经网络实现</a></li>
<li><a href="#org9009266">5.7.3. 误差反向传播法的梯度确认</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orga8f5870">6. 与学习相关的技巧</a></li>
<li><a href="#org90f52a5">7. 卷积神经网络</a></li>
<li><a href="#orgedd65d7">8. 深度学习</a></li>
</ul>
</div>
</div>
<div id="outline-container-org2c2696b" class="outline-2">
<h2 id="org2c2696b"><span class="section-number-2">1.</span> Python 入门</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org27e28b7" class="outline-3">
<h3 id="org27e28b7"><span class="section-number-3">1.1.</span> Python是什么</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>Python是机器学习事实上的默认语言</li>
</ul>
</div>
</div>
<div id="outline-container-orge31b682" class="outline-3">
<h3 id="orge31b682"><span class="section-number-3">1.2.</span> Python的安装</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-orgbc624df" class="outline-4">
<h4 id="orgbc624df"><span class="section-number-4">1.2.1.</span> Python版本</h4>
<div class="outline-text-4" id="text-1-2-1">
<ul class="org-ul">
<li>本书使用Python3.x版本</li>
</ul>
</div>
</div>
<div id="outline-container-orge5e4d5a" class="outline-4">
<h4 id="orge5e4d5a"><span class="section-number-4">1.2.2.</span> 使用的外部库</h4>
<div class="outline-text-4" id="text-1-2-2">
<ul class="org-ul">
<li>本书目标是从零实现深度学习,所以只会依赖如下两个库:
<ul class="org-ul">
<li>NumPy: 便利我们进行科学技术和矩阵计算</li>
<li>Matplotlib: 用来画图的库</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org032d2ea" class="outline-4">
<h4 id="org032d2ea"><span class="section-number-4">1.2.3.</span> Anaconda发行版</h4>
<div class="outline-text-4" id="text-1-2-3">
<ul class="org-ul">
<li>推荐安装Anaconda发行版,这个发行版侧重于数据分析,已经包含了前面讲的,本书依赖的两个库NumPy和Matplotlib</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgf39f09d" class="outline-3">
<h3 id="orgf39f09d"><span class="section-number-3">1.3.</span> Python解释器</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li><p>
使用如下代码确认安装的python版本
</p>
<div class="org-src-container">
<pre class="src src-shell">$ python --version
Python 3.10.8
</pre>
</div></li>
<li><p>
python是动态语言,这种语言一般都会有REPL(Read-Eval-Print-Loop),可以实时查看运行结果
</p>
<div class="org-src-container">
<pre class="src src-shell">$ python -i
Python 3.10.8 <span style="color: #3a81c3;">(</span>main, Nov 24 2022, 08:08:27<span style="color: #3a81c3;">)</span> <span style="color: #3a81c3;">[</span>Clang 14.0.6 <span style="color: #3a81c3;">]</span> on darwin
Type <span style="color: #2d9574;">"help"</span>, <span style="color: #2d9574;">"copyright"</span>, <span style="color: #2d9574;">"credits"</span> or <span style="color: #2d9574;">"license"</span> for more information.
&gt;&gt;&gt; 1 + 2
3
</pre>
</div></li>
</ul>
</div>
<div id="outline-container-org025c640" class="outline-4">
<h4 id="org025c640"><span class="section-number-4">1.3.1.</span> 算术计算</h4>
<div class="outline-text-4" id="text-1-3-1">
<ul class="org-ul">
<li><p>
一些简单的计算可用直接在REPL中进行
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; 1 - 2
-1
&gt;&gt;&gt; 4 * 5
20
&gt;&gt;&gt; 7 / 5
1.4
&gt;&gt;&gt; 3 ** 2
9
</pre>
</div></li>
<li>需要注意的是python3整数除以整数得到的是浮点数</li>
</ul>
</div>
</div>
<div id="outline-container-org893c235" class="outline-4">
<h4 id="org893c235"><span class="section-number-4">1.3.2.</span> 数据类型</h4>
<div class="outline-text-4" id="text-1-3-2">
<ul class="org-ul">
<li><p>
Python中可以使用type来判断数据的类型
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; type<span style="color: #3a81c3;">(</span>10<span style="color: #3a81c3;">)</span>
&lt;class <span style="color: #2d9574;">'int'</span>&gt;
&gt;&gt;&gt; type<span style="color: #3a81c3;">(</span>2.718<span style="color: #3a81c3;">)</span>
&lt;class <span style="color: #2d9574;">'float'</span>&gt;
&gt;&gt;&gt; type<span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"hello"</span><span style="color: #3a81c3;">)</span>
&lt;class <span style="color: #2d9574;">'str'</span>&gt;
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-org3b7e1e2" class="outline-4">
<h4 id="org3b7e1e2"><span class="section-number-4">1.3.3.</span> 变量</h4>
<div class="outline-text-4" id="text-1-3-3">
<ul class="org-ul">
<li><p>
Python中变量例子如下
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; x = 10
&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
10
&gt;&gt;&gt; x = 100
&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
100
&gt;&gt;&gt; y = 3.14
&gt;&gt;&gt; x * y
314.0
&gt;&gt;&gt; type<span style="color: #3a81c3;">(</span>x*y<span style="color: #3a81c3;">)</span>
&lt;class <span style="color: #2d9574;">'float'</span>&gt;
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-org9e90ac7" class="outline-4">
<h4 id="org9e90ac7"><span class="section-number-4">1.3.4.</span> 列表</h4>
<div class="outline-text-4" id="text-1-3-4">
<ul class="org-ul">
<li><p>
列表是Python当中非常重要的类型,而且支持slicing,非常好用
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; a = <span style="color: #3a81c3;">[</span>1, 2, 3, 4,5<span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>a<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span>1, 2, 3, 4, 5<span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; len<span style="color: #3a81c3;">(</span>a<span style="color: #3a81c3;">)</span>
5
&gt;&gt;&gt; a<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span>
1
&gt;&gt;&gt; a<span style="color: #3a81c3;">[</span>0:2<span style="color: #3a81c3;">]</span>
<span style="color: #3a81c3;">[</span>1, 2<span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; a<span style="color: #3a81c3;">[</span>1:<span style="color: #3a81c3;">]</span>
<span style="color: #3a81c3;">[</span>2, 3, 4, 5<span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; a<span style="color: #3a81c3;">[</span>:-2<span style="color: #3a81c3;">]</span>
<span style="color: #3a81c3;">[</span>1, 2, 3<span style="color: #3a81c3;">]</span>
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-orgb772a3f" class="outline-4">
<h4 id="orgb772a3f"><span class="section-number-4">1.3.5.</span> 字典</h4>
<div class="outline-text-4" id="text-1-3-5">
<ul class="org-ul">
<li><p>
python中的哈希表叫做字典,字典基本是最常用数据结构了
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; me = <span style="color: #3a81c3;">{</span><span style="color: #2d9574;">"height"</span>: 180<span style="color: #3a81c3;">}</span>
&gt;&gt;&gt; me<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"height"</span><span style="color: #3a81c3;">]</span>
180
&gt;&gt;&gt; me<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"weight"</span><span style="color: #3a81c3;">]</span> = 70
&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>me<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">{</span><span style="color: #2d9574;">'height'</span>: 180, <span style="color: #2d9574;">'weight'</span>: 70<span style="color: #3a81c3;">}</span>
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-org29292ae" class="outline-4">
<h4 id="org29292ae"><span class="section-number-4">1.3.6.</span> 布尔型</h4>
<div class="outline-text-4" id="text-1-3-6">
<ul class="org-ul">
<li>Python中的bool值为首字母大写的True和False</li>
<li>针对bool类型运算符有:
<ul class="org-ul">
<li>and</li>
<li>or</li>
<li>not</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgcaa2952" class="outline-4">
<h4 id="orgcaa2952"><span class="section-number-4">1.3.7.</span> if 语句</h4>
<div class="outline-text-4" id="text-1-3-7">
<ul class="org-ul">
<li>if语句为级别逻辑语句</li>
</ul>
</div>
</div>
<div id="outline-container-org3dd5af0" class="outline-4">
<h4 id="org3dd5af0"><span class="section-number-4">1.3.8.</span> for 语句</h4>
<div class="outline-text-4" id="text-1-3-8">
<ul class="org-ul">
<li>for语句为级别循环语句</li>
</ul>
</div>
</div>
<div id="outline-container-org04c1d84" class="outline-4">
<h4 id="org04c1d84"><span class="section-number-4">1.3.9.</span> 函数</h4>
<div class="outline-text-4" id="text-1-3-9">
<ul class="org-ul">
<li>python中使用def来定义函数</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org471fe62" class="outline-3">
<h3 id="org471fe62"><span class="section-number-3">1.4.</span> Python脚本文件</h3>
<div class="outline-text-3" id="text-1-4">
</div>
<div id="outline-container-org59a8893" class="outline-4">
<h4 id="org59a8893"><span class="section-number-4">1.4.1.</span> 保存为文件</h4>
<div class="outline-text-4" id="text-1-4-1">
<ul class="org-ul">
<li>前面都是在解释器里面运行,但是真正的Python代码一般是保存在一个文件里面(一般以py结尾),然后运行</li>
</ul>
</div>
</div>
<div id="outline-container-org7291ce9" class="outline-4">
<h4 id="org7291ce9"><span class="section-number-4">1.4.2.</span> 类</h4>
<div class="outline-text-4" id="text-1-4-2">
<ul class="org-ul">
<li>Python中使用class来定义新的类型</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org882ea65" class="outline-3">
<h3 id="org882ea65"><span class="section-number-3">1.5.</span> NumPy</h3>
<div class="outline-text-3" id="text-1-5">
</div>
<div id="outline-container-org99ac31c" class="outline-4">
<h4 id="org99ac31c"><span class="section-number-4">1.5.1.</span> 导入NumPy</h4>
<div class="outline-text-4" id="text-1-5-1">
<ul class="org-ul">
<li><p>
numpy是事实上的科学计算标准,但是它不再python的标注库里面,我们通常以如下代码引入numpy
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; import numpy as np
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-org5fe19a1" class="outline-4">
<h4 id="org5fe19a1"><span class="section-number-4">1.5.2.</span> 生成NumPy数组</h4>
<div class="outline-text-4" id="text-1-5-2">
<ul class="org-ul">
<li><p>
Python的数组我们前面讲过了,叫做列表. 而NumPy的数组就叫NumPy数组,它需要使用list作为参数创建(当然也有
其他创建方式)
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; x = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1.0,2.0,3.0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span>1. 2. 3.<span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; type<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
&lt;class <span style="color: #2d9574;">'numpy.ndarray'</span>&gt;
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-org23f9e83" class="outline-4">
<h4 id="org23f9e83"><span class="section-number-4">1.5.3.</span> NumPy的算术运算</h4>
<div class="outline-text-4" id="text-1-5-3">
<ul class="org-ul">
<li>NumPy的运算都是element-wise的:
<ul class="org-ul">
<li><p>
如果两个numpy array进行运算,那么就是对应位置的element相互进行运算
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; x = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1.0, 2.0, 3.0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; y = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>2.0, 4.0, 6.0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; x + y
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>3., 6., 9.<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; x * y
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span> 2.,  8., 18.<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; x / y
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.5, 0.5, 0.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li><p>
如果一个numpy array和一个数值(标量)进行运算,那么就是array的每个element和标量进行运算
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; x = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1.0, 2.0, 3.0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; x / 2.0
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.5, 1. , 1.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgc53abca" class="outline-4">
<h4 id="orgc53abca"><span class="section-number-4">1.5.4.</span> NumPy的N维数组</h4>
<div class="outline-text-4" id="text-1-5-4">
<ul class="org-ul">
<li>NumPy还可以生成多维数组,比如下面是一个二维数组的例子
<ul class="org-ul">
<li><p>
例子如下
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; A = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>1,2<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>3,4<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>A<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span><span style="color: #6c3163;">[</span>1 2<span style="color: #6c3163;">]</span>
 <span style="color: #6c3163;">[</span>3 4<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; A.shape
<span style="color: #3a81c3;">(</span>2, 2<span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; A.dtype
<span style="color: #6c3163; font-weight: bold;">dtype</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">'int64'</span><span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li><p>
我们可以使用shape来查看矩阵的形状, 如果是一维数组,那么只有一个维度的长度
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; a = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1, 2, 3<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; a
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1, 2, 3<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; a.shape
<span style="color: #3a81c3;">(</span>3,<span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li>我们还可以使用dtype查看成员的数据类型(这里就需要numpy array的所有成员的类型一致)</li>
</ul></li>
<li>和一维数组的是运算一样, 多维NumPy数组的运算也是element-wise的:
<ul class="org-ul">
<li><p>
一个多维数组和一个维度相同的多维数组运算和一位数组相同
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>A<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span><span style="color: #6c3163;">[</span>1 2<span style="color: #6c3163;">]</span>
 <span style="color: #6c3163;">[</span>3 4<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; B = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>3,0<span style="color: #2d9574;">]</span>,<span style="color: #2d9574;">[</span>0,6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; A + B
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span> 4,  2<span style="color: #2d9574;">]</span>,
       <span style="color: #2d9574;">[</span> 3, 10<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; A * B
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span> 3,  0<span style="color: #2d9574;">]</span>,
       <span style="color: #2d9574;">[</span> 0, 24<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li><p>
一个多维数组和一个标量进行运算也和一维数组相同
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>A<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span><span style="color: #6c3163;">[</span>1 2<span style="color: #6c3163;">]</span>
 <span style="color: #6c3163;">[</span>3 4<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; A * 10
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>10, 20<span style="color: #2d9574;">]</span>,
       <span style="color: #2d9574;">[</span>30, 40<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
</pre>
</div></li>
</ul></li>
<li>数学上,会有一些特别的名字,比如:
<ul class="org-ul">
<li>单一的数值叫做: 标量(scalar)</li>
<li>一维数组叫做: 向量(vector)</li>
<li>二维数组叫做: 矩阵(matrix)</li>
<li>三维及以上数组叫做: 张量(tensor)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgf5dd532" class="outline-4">
<h4 id="orgf5dd532"><span class="section-number-4">1.5.5.</span> 广播</h4>
<div class="outline-text-4" id="text-1-5-5">
<ul class="org-ul">
<li><p>
之前我们看到过,一维或者多维数组都可以和自己维度不同的标量进行乘(除)法运算(加减法不行),其原理是NumPy
把标量扩展成了对应的形状.比如下面的例子,标量10就被扩展成了2*2的形状
</p>

<div id="org34ce6a3" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/1-1.png" alt="1-1.png" />
</p>
<p><span class="figure-number">Figure 1: </span>dlfs/1-1.png</p>
</div></li>
<li>这种把乘数扩展后再和被乘数进行乘法(除法)计算的方法,就叫做广播(broadcast)</li>
<li>广播定义之所以是把"乘数"扩展,而不是把标量扩展,是因为广播还支持非标量
<ul class="org-ul">
<li><p>
比如如下代码乘数是一维vector,也是支持广播操作的
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; A = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>1,2<span style="color: #2d9574;">]</span>,<span style="color: #2d9574;">[</span>3,4<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; B = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>10,20<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; A * B
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>10, 40<span style="color: #2d9574;">]</span>,
       <span style="color: #2d9574;">[</span>30, 80<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li><p>
我们可以从下图看到,一维vector是如何被扩展的
</p>

<div id="org6f12057" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/1-2.png" alt="1-2.png" />
</p>
<p><span class="figure-number">Figure 2: </span>dlfs/1-2.png</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org203b513" class="outline-4">
<h4 id="org203b513"><span class="section-number-4">1.5.6.</span> 访问元素</h4>
<div class="outline-text-4" id="text-1-5-6">
<ul class="org-ul">
<li><p>
numpy数组也是从0开始,对于多维数组的访问,也是多增加几次的[]操作
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; X = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>51,55<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>14,19<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0, 4<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>X<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span><span style="color: #6c3163;">[</span>51 55<span style="color: #6c3163;">]</span>
 <span style="color: #6c3163;">[</span>14 19<span style="color: #6c3163;">]</span>
 <span style="color: #6c3163;">[</span> 0  4<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; X<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span>
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>51, 55<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; X<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">][</span>1<span style="color: #3a81c3;">]</span>
55
</pre>
</div></li>
<li>numpy的`[]`里面还可以放置其他的非int值,比如:
<ul class="org-ul">
<li><p>
可以放置一个numpy 数组,比如这里我们要取第1, 3, 5位的数据
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; a = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0, 10, 20, 30, 40, 50<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>a<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span> 0 10 20 30 40 50<span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; a<span style="color: #3a81c3;">[</span>np.array<span style="color: #6c3163;">(</span><span style="color: #2d9574;">[</span>1, 3, 5<span style="color: #2d9574;">]</span><span style="color: #6c3163;">)</span><span style="color: #3a81c3;">]</span>
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>10, 30, 50<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li><p>
可以放置一个bool数组,我们只取其中为True的部分
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; a<span style="color: #3a81c3;">[</span>np.array<span style="color: #6c3163;">(</span><span style="color: #2d9574;">[</span>True, True, False, False, False, True<span style="color: #2d9574;">]</span><span style="color: #6c3163;">)</span><span style="color: #3a81c3;">]</span>
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span> 0, 10, 50<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org5869137" class="outline-3">
<h3 id="org5869137"><span class="section-number-3">1.6.</span> Matplotlib</h3>
<div class="outline-text-3" id="text-1-6">
</div>
<div id="outline-container-orgf09892c" class="outline-4">
<h4 id="orgf09892c"><span class="section-number-4">1.6.1.</span> 绘制简单图形</h4>
<div class="outline-text-4" id="text-1-6-1">
<ul class="org-ul">
<li>最简答的绘制sin函数曲线的例子
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
<span style="color: #3a81c3; font-weight: bold;">import</span> matplotlib.pyplot <span style="color: #3a81c3; font-weight: bold;">as</span> plt


<span style="color: #715ab1;">x</span> = np.arange<span style="color: #3a81c3;">(</span>0, 6, 0.1<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">y</span> = np.sin<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
plt.plot<span style="color: #3a81c3;">(</span>x, y<span style="color: #3a81c3;">)</span>
plt.show<span style="color: #3a81c3;">()</span>
</pre>
</div></li>
<li><p>
结果如下
</p>

<div id="org3195acf" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/1-3.png" alt="1-3.png" />
</p>
<p><span class="figure-number">Figure 3: </span>dlfs/1-3.png</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org9f080cd" class="outline-4">
<h4 id="org9f080cd"><span class="section-number-4">1.6.2.</span> pyplot的功能</h4>
<div class="outline-text-4" id="text-1-6-2">
<ul class="org-ul">
<li>我们还可以在上图中加上一些标题,x轴签名等等
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
<span style="color: #3a81c3; font-weight: bold;">import</span> matplotlib.pyplot <span style="color: #3a81c3; font-weight: bold;">as</span> plt


<span style="color: #715ab1;">x</span> = np.arange<span style="color: #3a81c3;">(</span>0, 6, 0.1<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">y1</span> = np.sin<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">y2</span> = np.cos<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
plt.plot<span style="color: #3a81c3;">(</span>x, y1, label=<span style="color: #2d9574;">"sin"</span><span style="color: #3a81c3;">)</span>
plt.plot<span style="color: #3a81c3;">(</span>x, y2, linestyle=<span style="color: #2d9574;">"--"</span>, label=<span style="color: #2d9574;">"cos"</span><span style="color: #3a81c3;">)</span>
plt.xlabel<span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"x"</span><span style="color: #3a81c3;">)</span>
plt.ylabel<span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"y"</span><span style="color: #3a81c3;">)</span>
plt.show<span style="color: #3a81c3;">()</span>
</pre>
</div></li>
<li><p>
结果如下
</p>

<div id="org53619b0" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/1-4.png" alt="1-4.png" />
</p>
<p><span class="figure-number">Figure 4: </span>dlfs/1-4.png</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orga16fc8f" class="outline-4">
<h4 id="orga16fc8f"><span class="section-number-4">1.6.3.</span> 显示图像</h4>
<div class="outline-text-4" id="text-1-6-3">
<ul class="org-ul">
<li>matplotlib还可以使用imread()方法读入图像</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org5af06c8" class="outline-3">
<h3 id="org5af06c8"><span class="section-number-3">1.7.</span> Understanding Broadcasting in NumPy</h3>
<div class="outline-text-3" id="text-1-7">
</div>
<div id="outline-container-orge69b740" class="outline-4">
<h4 id="orge69b740"><span class="section-number-4">1.7.1.</span> What is Broadcasting?</h4>
<div class="outline-text-4" id="text-1-7-1">
<ul class="org-ul">
<li>从本质上说, broadcasting是NumPy的一种在算术计算的过程中,扩展"较小array"到"较大array"的能力.这种能力
使得我们不必在计算之前,手动的对array进行reshape.</li>
<li>注意本节所有的array都是指的NumPy array</li>
</ul>
</div>
</div>
<div id="outline-container-orgadcf672" class="outline-4">
<h4 id="orgadcf672"><span class="section-number-4">1.7.2.</span> The Broadcasting Rules</h4>
<div class="outline-text-4" id="text-1-7-2">
<ul class="org-ul">
<li>Broadcasting Rules总结起来有如下五点:
<ol class="org-ol">
<li>Dimension Matching: NumPy在Broadcasting之前首先比较array的shape(我们可以认为shape是一个元组,而元
组的每个成员是dimension),顺序是从最右边的dimension开始,依次向左</li>
<li>Compatibility: 两个dimension被认为是相等的情况是:
<ul class="org-ul">
<li>要么两者相等</li>
<li>要么两者不相等,但是其中一个是1</li>
</ul></li>
<li>Broadcastig Axis: 如果"两者不相等,但是其中一个是1"的情况出现,那么较小的dimension自动增长为较大的
dimension相同的值</li>
<li>Rank Adjustment: 所谓rank是指dimension的数目,如果两个array的rank都不相同,那么从右到左比较的过程
当中,会为缺失的array补齐一个wrapper dimension,数值为1(这个dimension 1后面会根据对应的dimension
进行增长或保持不变)</li>
<li>ValueError: 如果上面的过程不能进行下去,那么Broadcasting过程失败,NumPy会抛出ValueError异常</li>
</ol></li>
<li>下面我们详细的讲解上面的过程</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org2db52d2"></a>Dimension Matching<br />
<div class="outline-text-5" id="text-1-7-2-1">
<ul class="org-ul">
<li><p>
我们首先看一个例子
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np

<span style="color: #715ab1;">arr1</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>1, 2, 3<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>4, 4, 6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|arr1.shape|=&gt;"""</span>, arr1.shape<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">arr2</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>10, 20, 30<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|arr2.shape|=&gt;"""</span>, arr2.shape<span style="color: #3a81c3;">)</span>


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|arr1.shape|=&gt; (2, 3)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|arr2.shape|=&gt; (3,)</span>
</pre>
</div></li>
<li>Dimension Matching(也可以理解为Broadcasting Check)上面例子的步骤如下:
<ol class="org-ol">
<li><p>
我们比较两个shape, (2, 3)和(3,),从最后的dimension开始比较,两者相同,都是3.
</p>
<pre class="example" id="orgc701cef">
注意(3,)这是元组为为了和set进行区分而发明的一个写法:元组即便是一个元素也要加个','在最后
</pre></li>
<li>我们左移一位,继续比较shape的倒数第二个dimension,这时候我们发现arr2没有倒数第二位,那么NumPy就自动
添加一位数值为1的dimension,那么arr2的shape变成了(1,3)</li>
<li>arr2改变shape之后,进行比较arr1的2和arr2的1是通过了check的.Broadcasting check通过. 如果上面的过程
中Broadcasting Check没有通过,那么会抛出ValueError异常</li>
</ol></li>
<li><p>
一旦Broadcasting check成功,那么就要开始真正的进行Broadcasting了,上面这个例子中NumPy会把arr2的第一
row进行复制.复制后的计算过程如上
</p>
<pre class="example" id="orge66b628">
[[1, 2, 3],    +    [[10, 20, 30],      = [[11, 22, 33],
 [4, 5, 6],          [10, 20, 30]]         [14, 25, 36]]
</pre></li>
<li>其实复制的过程也很容易理解,特别是你知道其实自己是从(1,3)扩展到(2,3),那么很显然是把第一个维度的数据
复制,比较难的,是理解NumPy把array从(3,)扩展成(1,3)</li>
</ul>
</div>
</li>
<li><a id="org2862f04"></a>Rank Adjustment<br />
<div class="outline-text-5" id="text-1-7-2-2">
<ul class="org-ul">
<li><p>
我们再来看一个例子,这个例子更加复杂
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np

<span style="color: #715ab1;">arr1</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1, 2, 3<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|arr1.shape|=&gt;"""</span>, arr1.shape<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">arr2</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>4<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>5<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|arr2.shape|=&gt;"""</span>, arr2.shape<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">result</span> = arr1 + arr2

<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|result.shape|=&gt;"""</span>, result.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|result|=&gt;"""</span>, result<span style="color: #3a81c3;">)</span>


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|arr1.shape|=&gt; (3,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|arr2.shape|=&gt; (2, 1)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|result.shape|=&gt; (2, 3)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|result|=&gt; [[5 6 7]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[6 7 8]]</span>
</pre>
</div></li>
<li>我们按照上一个例子的步骤来进行一下Broadcasting Check
<ol class="org-ol">
<li>我们比较两个shape, (3,)和(2,1), 从最后的dimension开始比较,两虽然不相等,但是其中一个是1,所以较小
的dimension升级(通过Broadcasting Axis),也就是说(2,1)=&gt;(2,3)</li>
<li>我们左移一位,会发现arr1已经没有dimension了,所以添加一个位数为1的dimension(通过Rank Adjustment),所以
arr1变成了(1,3)</li>
<li>我比较arr1的最左dimension(数值为1)和arr2的最左dimension(数组为2),我们发现两种虽然不相等,但是其中
一个是1,所以较小的dimension升级(通过Broadcasting Axis),也就是说(1,3)=&gt;(2,3)</li>
<li>经过上面的步骤arr1和arr2都进行了扩充,最后都扩充到了(2,3).</li>
<li><p>
很显然(3,)要水平方向复制(2,1)要竖着方向复制,总体的过程如下
</p>
<pre class="example" id="org48d9f5e">
arr1:         [1, 2, 3]      -&gt;   [[1, 2, 3],         (broadcast along axis 0)
                                   [1, 2, 3]]
+
arr2:         [[4],          -&gt;   [[4, 4, 4],         (broadcast along axis 1)
               [5]]                [5, 5, 5]]

result:       [[5, 6, 7],
               [5, 7, 8]]
</pre></li>
</ol></li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org68e7eb9" class="outline-2">
<h2 id="org68e7eb9"><span class="section-number-2">2.</span> 感知机</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-orgde9f0c3" class="outline-3">
<h3 id="orgde9f0c3"><span class="section-number-3">2.1.</span> 感知机是什么</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>所谓感知机,是指接收多个输入信号,输出一个信号.</li>
<li>这里的信号可以想象成电流或者河流那样具备"流动性"的东西.和实际的电流不同,感知机的信号只有"流/不流"两
种取值,本书中:
<ul class="org-ul">
<li>0对应"不传递信号"</li>
<li>1对应"传递信号"</li>
</ul></li>
<li>下图是一个感知机接收两个输入信号的例子:
<ul class="org-ul">
<li><p>
图2-1
</p>

<div id="org4915092" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/2-1.png" alt="2-1.png" />
</p>
<p><span class="figure-number">Figure 5: </span>dlfs/2-1.png</p>
</div></li>
<li>x1,x2是输入信号</li>
<li>y是输出信号</li>
<li>w1,w2是权重(w是weight的首字母). 感知机的多个输入信号都有各自固有的权重,权重越大,对应该权重的信号
重要性就越高</li>
<li>图中的圆形为"神经元"或者"节点"</li>
<li>输入信号被送往神经元的时候会被乘以固定的权重(w1x1,w2x2), 神经元会计算传过来的信号的总和,当这个总
和超过某个界限(称之为阈值)时,才会输出1.输出1也被称之为"神经元被激活"</li>
<li><p>
我们把上面的图用公式表达出来就是
</p>
\begin{equation}
y =
   \begin{cases}
    0 & (w_1 x_1 + w_2 x_2 \leqslant \theta) \\
    1 & (w_1 x_1 + w_2 x_2 > \theta) \tag{2.1}
   \end{cases}
\end{equation}</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org007df60" class="outline-3">
<h3 id="org007df60"><span class="section-number-3">2.2.</span> 简单的逻辑电路</h3>
<div class="outline-text-3" id="text-2-2">
</div>
<div id="outline-container-org2e02e14" class="outline-4">
<h4 id="org2e02e14"><span class="section-number-4">2.2.1.</span> 与门</h4>
<div class="outline-text-4" id="text-2-2-1">
<ul class="org-ul">
<li>我们先考虑用感知机来解决简单的问题,比如我们用感知机来实现一下逻辑电路的与门(AND gate)</li>
<li><p>
所谓与门,是指两个输入都为1的情况下,输出为1,其他情况下输入都是0, 如下图
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">x1</th>
<th scope="col" class="org-right">x2</th>
<th scope="col" class="org-right">y</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">1</td>
<td class="org-right">1</td>
</tr>
</tbody>
</table></li>
<li>从我们的公式2.1分析,我们其实只要设置好 \(w_1, w_2,\theta\) 的值就可以.</li>
<li>实际上,我们肉眼就能找到很多这样的值,比如:
<ul class="org-ul">
<li>\((w_1, w_2,\theta) = (0.5,0.5,0.7)\)</li>
<li>\((w_1, w_2,\theta) = (0.5,0.5,0.8)\)</li>
<li>\((w_1, w_2,\theta) = (1.0,1.0,1.0)\)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org3476e63" class="outline-4">
<h4 id="org3476e63"><span class="section-number-4">2.2.2.</span> 与非门和或门</h4>
<div class="outline-text-4" id="text-2-2-2">
<ul class="org-ul">
<li><p>
我们再来看看另外的逻辑电路,比如与非门(NAND gate), 与非门,就是"结果颠倒了的与门",如图
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">x1</th>
<th scope="col" class="org-right">x2</th>
<th scope="col" class="org-right">y</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
</tr>
</tbody>
</table></li>
<li>对应的\(w_1, w_2,\theta\) 的值也很容易选(其实把与门的参数取反就可以),比如:
<ul class="org-ul">
<li>\((w_1, w_2,\theta) = (-0.5,-0.5,-0.7)\)</li>
<li>\((w_1, w_2,\theta) = (-0.5,-0.5,-0.8)\)</li>
<li>\((w_1, w_2,\theta) = (-1.0,-1.0,-1.0)\)</li>
</ul></li>
<li><p>
同样的,我们还可以设置或门(OR gate),其为两个输入都是0的情况下,才返回0,其他情况都返回1
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">x1</th>
<th scope="col" class="org-right">x2</th>
<th scope="col" class="org-right">y</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">1</td>
<td class="org-right">1</td>
</tr>
</tbody>
</table></li>
<li>实际上,我们肉眼就也能找到很多这样的值,比如:
<ul class="org-ul">
<li>\((w_1, w_2,\theta) = (0.5,0.5,-0.2)\)</li>
<li>\((w_1, w_2,\theta) = (0.5,0.5,-0.3)\)</li>
<li>\((w_1, w_2,\theta) = (1.0,1.0,-0.9)\)</li>
</ul></li>
<li>我们不厌其烦的展示了三种逻辑电路,就是想说明:
<ul class="org-ul">
<li>这三种逻辑电路的感知机构造是一样的</li>
<li>我们只需要适当的调整参数,就能把一个感知机改造成不同的角色: 与门,与非门,或门</li>
</ul></li>
<li>提前剧透一下,感知机和机器学习的不同:
<ul class="org-ul">
<li>感知机是"人类"通过看真值表,确定感知器参数</li>
<li>机器学习是让"计算机"自动的决定这些参数.所谓"学习",就是确定这是参数的过程</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc22caf6" class="outline-3">
<h3 id="orgc22caf6"><span class="section-number-3">2.3.</span> 感知机的实现</h3>
<div class="outline-text-3" id="text-2-3">
</div>
<div id="outline-container-org065312c" class="outline-4">
<h4 id="org065312c"><span class="section-number-4">2.3.1.</span> 简单的实现</h4>
<div class="outline-text-4" id="text-2-3-1">
<ul class="org-ul">
<li><p>
我们先用代码来实现一下刚才的与门
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">AND</span><span style="color: #3a81c3;">(</span>x1, x2<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">w1</span>, <span style="color: #715ab1;">w2</span>, <span style="color: #715ab1;">theta</span> = 0.5, 0.5, 0.7
    <span style="color: #715ab1;">tmp</span> = x1 * w1 + x2 * w2
    <span style="color: #3a81c3; font-weight: bold;">if</span> tmp &lt;= theta:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 0
    <span style="color: #3a81c3; font-weight: bold;">elif</span> tmp &gt; theta:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 1


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>AND<span style="color: #6c3163;">(</span>0, 0<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>AND<span style="color: #6c3163;">(</span>1, 0<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>AND<span style="color: #6c3163;">(</span>0, 1<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>AND<span style="color: #6c3163;">(</span>1, 1<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">1</span>
</pre>
</div></li>
<li>与非门和或门的实现是类似的,区别只是权重参数的值.不过我们为了更好的抽象问题,我们准备改一下我们的公
式,也顺便改一下我们的实现</li>
</ul>
</div>
</div>
<div id="outline-container-org05a0a91" class="outline-4">
<h4 id="org05a0a91"><span class="section-number-4">2.3.2.</span> 导入权重和偏置</h4>
<div class="outline-text-4" id="text-2-3-2">
<ul class="org-ul">
<li>我们为了更好的抽象问题,把 \(\theta\) 换成 \(-b\)
<ul class="org-ul">
<li><p>
于是得到公式2.2
</p>
\begin{equation}
y =
   \begin{cases}
    0 & (b + w_1 x_1 + w_2 x_2 \leqslant 0) \\
    1 & (b + w_1 x_1 + w_2 x_2 > 0) \tag{2.2}
   \end{cases}
\end{equation}</li>
<li>公式2.2和公式2.1虽然有一个符号不同,但是表单是内容却是完全相同的</li>
<li>这里的b称之为偏置(bias). 偏置的值决定了神经元被激活的容易程度,比如-0.1的bias肯定比-20的bias更容易激活</li>
<li>w1,w2称之为权重(weight). 权重的值控制不同输入信号的重要性</li>
<li><b>NOTE</b> 有些上下文会把b,w1,w2统称为权重</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgeef523e" class="outline-4">
<h4 id="orgeef523e"><span class="section-number-4">2.3.3.</span> 使用权重和偏置的实现</h4>
<div class="outline-text-4" id="text-2-3-3">
<ul class="org-ul">
<li>更改了公式的同时,我们也使用NumPy来实现感知机
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">AND</span><span style="color: #3a81c3;">(</span>x1, x2<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>x1, x2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">w</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.5, 0.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">b</span> = -0.7
    <span style="color: #715ab1;">tmp</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>w * x<span style="color: #3a81c3;">)</span> + b
    <span style="color: #3a81c3; font-weight: bold;">if</span> tmp &lt;= 0:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 0
    <span style="color: #3a81c3; font-weight: bold;">else</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 1


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>AND<span style="color: #6c3163;">(</span>0, 0<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>AND<span style="color: #6c3163;">(</span>1, 0<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>AND<span style="color: #6c3163;">(</span>0, 1<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>AND<span style="color: #6c3163;">(</span>1, 1<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">1</span>
</pre>
</div></li>
<li>这里权重和参数都是numpy array,他们相乘就是element-wise的相乘</li>
<li>相乘结果再用np.sum把结果累加,就实现了之前2-1中x1 * w1 + x2 * w2的效果</li>
<li>最后加上偏置,再和0比大小即可</li>
</ul></li>
<li><p>
我们用同样的方式可以创建成功与非门
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">NAND</span><span style="color: #3a81c3;">(</span>x1, x2<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>x1, x2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">w</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>-0.5, -0.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">b</span> = 0.7
    <span style="color: #715ab1;">tmp</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>w * x<span style="color: #3a81c3;">)</span> + b
    <span style="color: #3a81c3; font-weight: bold;">if</span> tmp &lt;= 0:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 0
    <span style="color: #3a81c3; font-weight: bold;">else</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 1


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>NAND<span style="color: #6c3163;">(</span>0, 0<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>NAND<span style="color: #6c3163;">(</span>1, 0<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>NAND<span style="color: #6c3163;">(</span>0, 1<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>NAND<span style="color: #6c3163;">(</span>1, 1<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">1</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">1</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">1</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0</span>
</pre>
</div></li>
<li><p>
最后是同样的方式创建好或门
</p>
<div class="org-src-container">
<pre class="src src-python">
<span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">OR</span><span style="color: #3a81c3;">(</span>x1, x2<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>x1, x2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">w</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.5, 0.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">b</span> = -0.2
    <span style="color: #715ab1;">tmp</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>w * x<span style="color: #3a81c3;">)</span> + b
    <span style="color: #3a81c3; font-weight: bold;">if</span> tmp &lt;= 0:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 0
    <span style="color: #3a81c3; font-weight: bold;">else</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 1


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>OR<span style="color: #6c3163;">(</span>0, 0<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>OR<span style="color: #6c3163;">(</span>1, 0<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>OR<span style="color: #6c3163;">(</span>0, 1<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>OR<span style="color: #6c3163;">(</span>1, 1<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">1</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">1</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">1</span>
</pre>
</div></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9af7e8b" class="outline-3">
<h3 id="org9af7e8b"><span class="section-number-3">2.4.</span> 感知机的局限性</h3>
<div class="outline-text-3" id="text-2-4">
<ul class="org-ul">
<li>到目前为止,我们已经知道,感知机可以实现与门,与非门,或门,三种逻辑,现在我们考虑下异或门</li>
</ul>
</div>
<div id="outline-container-org3185ab1" class="outline-4">
<h4 id="org3185ab1"><span class="section-number-4">2.4.1.</span> 异或门</h4>
<div class="outline-text-4" id="text-2-4-1">
<ul class="org-ul">
<li><p>
所谓异或门,是指仅当x1或x2中一方为1时,才会输出1,如表格
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">x1</th>
<th scope="col" class="org-right">x2</th>
<th scope="col" class="org-right">y</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
</tr>
</tbody>
</table></li>
<li><p>
我们再次尝试使用之前的方法来寻找一个权重和偏移的组合,我们发现我们找不到这样一个组合,实际的情况是
</p>
<pre class="example" id="orge43b9f0">
用感知机是无法实现异或门的
</pre></li>
<li>为什么感知机无法实现异或门,我们可以用下面的例子来讲解一下
<ul class="org-ul">
<li><p>
我们首先将或门具体化,我们把一组可行的权重参数(b,w1,w2)=(-0.5,1.0,1.0) 带入到公式2.2,得到公式2.3
</p>
\begin{equation}
y =
   \begin{cases}
    0 & (-0.5 + w_1 x_1 + w_2 x_2 \leqslant 0) \\
    1 & (-0.5 + w_1 x_1 + w_2 x_2 > 0) \tag{2.3}
   \end{cases}
\end{equation}</li>
<li><p>
我们如果把x2看成是y的话,我们会得到这么一条直线y=-x+0.5,如图
</p>

<div id="orgd7069d5" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/2-6.png" alt="2-6.png" />
</p>
<p><span class="figure-number">Figure 6: </span>dlfs/2-6.png</p>
</div></li>
<li>这条直线把整个平面分成了两个部分:
<ol class="org-ol">
<li>灰色部分是感知机输出0的区域,我们看到(0,0)也在这个位置(圆圈)</li>
<li>白色部分是感知机输出1的区域,我们看到(0,1),(1,0),(1,1)都在这个区域(三角形)</li>
</ol></li>
<li><p>
我们来如法炮制,把异或门需要分开的四个点(两个圆圈,两个三角)也列在下图,我们会发现,我们找不到一个直
线能欧分割图中的圆圈和三角
</p>

<div id="org213c02f" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/2-7.png" alt="2-7.png" />
</p>
<p><span class="figure-number">Figure 7: </span>dlfs/2-7.png</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org906b068" class="outline-4">
<h4 id="org906b068"><span class="section-number-4">2.4.2.</span> 线性和非线性</h4>
<div class="outline-text-4" id="text-2-4-2">
<ul class="org-ul">
<li><p>
图2-7是无法用一个直线来分割圆圈和三角,但是将"直线"这个限制去掉,就可以实现了,比如下图,我们使用曲线
来完成了这个区分
</p>

<div id="org1a5f7fd" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/2-8.png" alt="2-8.png" />
</p>
<p><span class="figure-number">Figure 8: </span>dlfs/2-8.png</p>
</div></li>
<li>上图这种由曲线分割的区域就叫做非线性空间.之前用直线分割的区域自然就叫线性空间啦</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org2493eee" class="outline-3">
<h3 id="org2493eee"><span class="section-number-3">2.5.</span> 多层感知机</h3>
<div class="outline-text-3" id="text-2-5">
<ul class="org-ul">
<li><p>
感知机无法表示异或门让人遗憾,但是感知机可以通过"叠加层"来完成这个任务
</p>
<pre class="example" id="orge284647">
准确的是说,应该是"单层感知机"无法表示异或门
</pre></li>
<li>我们下面通过电路来理解一下,什么是叠加层</li>
</ul>
</div>
<div id="outline-container-orgb303916" class="outline-4">
<h4 id="orgb303916"><span class="section-number-4">2.5.1.</span> 已有门电路组合</h4>
<div class="outline-text-4" id="text-2-5-1">
<ul class="org-ul">
<li>异或门有很多种制作方法,其中最经典的做法是组合我们前面学到的三种门:与门,与非门和或门
<ul class="org-ul">
<li><p>
我们首先以下图来表示与门,与非门和或门
</p>

<div id="org79d35be" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/2-9.png" alt="2-9.png" />
</p>
<p><span class="figure-number">Figure 9: </span>dlfs/2-9.png</p>
</div></li>
<li><p>
异或门就可以使用上面的元器件,如下进行组合配置,最终实现异或门
</p>

<div id="org7732e75" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/2-11.png" alt="2-11.png" />
</p>
<p><span class="figure-number">Figure 10: </span>dlfs/2-11.png</p>
</div></li>
<li><p>
我们可以使用如下的真值表来确认我们的配置正确.
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">x1</th>
<th scope="col" class="org-right">x2</th>
<th scope="col" class="org-right">s1</th>
<th scope="col" class="org-right">s2</th>
<th scope="col" class="org-right">y</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">1</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">1</td>
<td class="org-right">1</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
</tr>
</tbody>
</table></li>
<li>上表中:x1,x2与非得到s1, x1,x2或得到s2, s1,s2与得到y</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgf3e4156" class="outline-4">
<h4 id="orgf3e4156"><span class="section-number-4">2.5.2.</span> 异或门的实现</h4>
<div class="outline-text-4" id="text-2-5-2">
<ul class="org-ul">
<li><p>
我们使用代码来实现2-11所示的异或门
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">AND</span><span style="color: #3a81c3;">(</span>x1, x2<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>x1, x2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">w</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.5, 0.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">b</span> = -0.7
    <span style="color: #715ab1;">tmp</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>w * x<span style="color: #3a81c3;">)</span> + b
    <span style="color: #3a81c3; font-weight: bold;">if</span> tmp &lt;= 0:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 0
    <span style="color: #3a81c3; font-weight: bold;">else</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 1


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">NAND</span><span style="color: #3a81c3;">(</span>x1, x2<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>x1, x2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">w</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>-0.5, -0.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">b</span> = 0.7
    <span style="color: #715ab1;">tmp</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>w * x<span style="color: #3a81c3;">)</span> + b
    <span style="color: #3a81c3; font-weight: bold;">if</span> tmp &lt;= 0:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 0
    <span style="color: #3a81c3; font-weight: bold;">else</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 1


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">OR</span><span style="color: #3a81c3;">(</span>x1, x2<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>x1, x2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">w</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.5, 0.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">b</span> = -0.2
    <span style="color: #715ab1;">tmp</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>w * x<span style="color: #3a81c3;">)</span> + b
    <span style="color: #3a81c3; font-weight: bold;">if</span> tmp &lt;= 0:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 0
    <span style="color: #3a81c3; font-weight: bold;">else</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 1


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">XOR</span><span style="color: #3a81c3;">(</span>x1, x2<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">s1</span> = NAND<span style="color: #3a81c3;">(</span>x1, x2<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">s2</span> = OR<span style="color: #3a81c3;">(</span>x1, x2<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">y</span> = AND<span style="color: #3a81c3;">(</span>s1, s2<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> y


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>XOR<span style="color: #6c3163;">(</span>0, 0<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>XOR<span style="color: #6c3163;">(</span>1, 0<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>XOR<span style="color: #6c3163;">(</span>0, 1<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>XOR<span style="color: #6c3163;">(</span>1, 1<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">1</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">1</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0</span>
</pre>
</div></li>
<li>我们试着把电路图转换为感知机来表示
<ul class="org-ul">
<li><p>
如图2-13
</p>

<div id="org99bdea2" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/2-13.png" alt="2-13.png" />
</p>
<p><span class="figure-number">Figure 11: </span>dlfs/2-13.png</p>
</div></li>
<li><p>
上图和前面的与门,与非门,或门的感知机图不同.事实上之前的图都是单层感知机,而异或门是2层感知机
</p>
<pre class="example" id="org795bd6d">
也有文献把这个叫做3层感知机, 这取决于如何看待最后y是不是一层
</pre></li>
<li>这种2层感知机可以看做是流水线的组装作业.第一层的工人对传送过来的零件进行加工,完成后再传送给第二层
的工人.第二层的工作对第一层工人传递过来的零件进行加工,完成后出货(输出)</li>
<li><p>
通过这样的2层结构,感知机得以实现异或门.换句话说,就是
</p>
<pre class="example" id="org0ab907c">
单层感知机无法表达的东西,通过增加一层就可以解决.也就是说,通过增加层,感知机能进行更加灵活的表示
</pre></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orge4696b4" class="outline-3">
<h3 id="orge4696b4"><span class="section-number-3">2.6.</span> 从与非门到计算机</h3>
<div class="outline-text-3" id="text-2-6">
<ul class="org-ul">
<li>人们通常认为计算机很复杂,但是令人惊讶的是,仅仅通过与非门(NAND)一个逻辑电路的不同组合,就能实现.</li>
<li>这也就说明理论上,感知机(多层)也可以表示计算机.我们只需要记住这个结论就好</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgcbd4d07" class="outline-2">
<h2 id="orgcbd4d07"><span class="section-number-2">3.</span> 神经网络</h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li>上一章我们学习了感知机,关于感知机既有好消息,也有坏消息:
<ul class="org-ul">
<li>好消息是: 即便对于复杂函数,感知机也是可以通过增加层的方式来表达出来</li>
<li>坏消息是: 设定权重的工作,还是由人工进行的</li>
</ul></li>
<li>神经网络的出现,就是Eileen解决刚才的坏消息.具体来说就是,神经网络可以自动的从数据中学习到合适的权重
参数</li>
</ul>
</div>
<div id="outline-container-orgfc8c3ed" class="outline-3">
<h3 id="orgfc8c3ed"><span class="section-number-3">3.1.</span> 从感知机到神经网络</h3>
<div class="outline-text-3" id="text-3-1">
</div>
<div id="outline-container-orgd672310" class="outline-4">
<h4 id="orgd672310"><span class="section-number-4">3.1.1.</span> 神经网路的例子</h4>
<div class="outline-text-4" id="text-3-1-1">
<ul class="org-ul">
<li>我们用图来表示神经网路
<ul class="org-ul">
<li><p>
图3-1
</p>

<div id="org4523cd8" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-1.png" alt="3-1.png" />
</p>
<p><span class="figure-number">Figure 12: </span>dlfs/3-1.png</p>
</div></li>
<li>上图中最左边一层是输入层.本书称之为第0层</li>
<li>最右边一层是输出层.本书称之为第2层</li>
<li>中间一层是隐藏层,"隐藏"一词的意思是,隐藏层中的神经元(和输入层,输出层不同)肉眼看不到.本书称之为第1层</li>
<li>上图中一共有三层神经网络构成,但是只有两层神经网络有权重,所以我们本书称之为"2层网络",本书之后都是
这种做法: 根据实质上拥有权重的层数来确定名称(也就是,输入层,隐藏层,输出层总数减去1)</li>
<li><b>Note</b> 有些书会把上图的叫做"3层网络"</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org4b440dc" class="outline-4">
<h4 id="org4b440dc"><span class="section-number-4">3.1.2.</span> 复习感知机</h4>
<div class="outline-text-4" id="text-3-1-2">
<ul class="org-ul">
<li>在观察神经网络中信号的传递方法之前,我们先复习一下感知机
<ul class="org-ul">
<li><p>
感知机如图
</p>

<div id="orgbd9ead7" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-2.png" alt="3-2.png" />
</p>
<p><span class="figure-number">Figure 13: </span>dlfs/3-2.png</p>
</div></li>
<li><p>
图中的感知机公式如下
</p>
\begin{equation}
y =
   \begin{cases}
    0 & (b + w_1 x_1 + w_2 x_2 \leqslant 0) \\
    1 & (b + w_1 x_1 + w_2 x_2 > 0) \tag{3.1}
   \end{cases}
\end{equation}</li>
<li>w1,w2是权重参数,b是偏置参数</li>
<li><p>
在图3-2中,并没有画出偏置b,如果要画出b,可以向下图一样,让b和w1,w2一个地位, 1和x1,x2一个地址
</p>

<div id="org6c4c593" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-3.png" alt="3-3.png" />
</p>
<p><span class="figure-number">Figure 14: </span>dlfs/3-3.png</p>
</div></li>
</ul></li>
<li>公式3.1有两个条件,看起来不够直观(主要是 \(b+w_1x_1+w_2x_2\) 重复了两次. 现在我们把公式3.1改写一下,改
成如下两个公式:
<ul class="org-ul">
<li><p>
公式3.2,重复部分写到一块
</p>
\begin{equation}
y = h(b+w_1x_1+w_2x_2) \tag{3.2}
\end{equation}</li>
<li><p>
公式3.3, x指代 \(b+w_1x_1+w_2x_2\)
</p>
\begin{equation}
h(x) =
   \begin{cases}
    0 & (x \leqslant 0) \\
    1 & (x > 0) \tag{3.3}
   \end{cases}
\end{equation}</li>
<li>一个公式转换为两个公式的理解非常重要,这里我们其实是想让y从一个公式出来(这个公式就是最后的激活公式,
也就是h函数).我们可以在h函数定义的时候,写成两个来源,这种两个来源的函数也就是激活函数.后面我们就会
知道,提取出这个激活函数是多么的重要(因为激活函数不同,就分成了感知机和神经网络),公式3-3明显是一个
突然变化很强烈的函数,我们叫做阶跃函数,是感知机常用的激活函数</li>
<li>总结一句就是之所以多次将一个函数拆成两个,是为了引出激活函数这个重要概念</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org2f71100" class="outline-4">
<h4 id="org2f71100"><span class="section-number-4">3.1.3.</span> 激活函数登场</h4>
<div class="outline-text-4" id="text-3-1-3">
<ul class="org-ul">
<li>刚才登场的函数h(x)会将输入信号的总和转换为输出信号,这种函数一般称之为激活函数(activation function)</li>
<li>我们把上面的公式3.2再次进行拆分,得到如下两个公式:
<ul class="org-ul">
<li><p>
公式3.2的右边拆分得到公式3.4
</p>
\begin{equation}
a = b + w_1 x_1 + w_2 x_2 \tag{3.4}
\end{equation}</li>
<li><p>
公式3.2的左边拆分得到公式3.5
</p>
\begin{equation}
y = h(a) \tag{3.5}
\end{equation}</li>
<li>改成两个公式后我们可以证明理解: 权重和偏置总和记为a(3.4), 然后h()函数将a输出为y.h()函数是针对于a
的函数(而不是针对于w或者x)</li>
<li><p>
有了公式3.4和和3.5后,我们的神经元内部也可以画出内容来了,如下
</p>

<div id="org10f32e3" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-4.png" alt="3-4.png" />
</p>
<p><span class="figure-number">Figure 15: </span>dlfs/3-4.png</p>
</div></li>
<li><p>
下图是神经元前后两种画法的对比,下面的图告诉我们,神经元不一定是最后一个才有这种h()函数,作为中间神经元也可以
</p>

<div id="orge53f54c" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-5.png" alt="3-5.png" />
</p>
<p><span class="figure-number">Figure 16: </span>dlfs/3-5.png</p>
</div></li>
</ul></li>
<li>下一节我们会详细介绍激活函数.激活函数是链接感知机和神经网络的桥梁:
<ul class="org-ul">
<li>感知机这个词,绝大多数情况下是指的"朴素感知机",其特点是是单层网络,且使用"阶跃函数"(突然发生跳变的
函数,比如公式3.3)作为激活函数</li>
<li>而使用多层网络,并且使用"sigmoid函数"作为激活函数的多层感知机,绝大多数情况下会使用"神经网络"这个词</li>
</ul></li>
<li><p>
我们再多提一句,上一节介绍的多层网络,其激活函数还是普通"阶跃函数". 这种多层感知机是为了理解让我们理
解如下概念,其实不具有实用性
</p>
<pre class="example" id="org849575f">
多层感知机能够进行非线性表示
</pre></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9eded81" class="outline-3">
<h3 id="org9eded81"><span class="section-number-3">3.2.</span> 激活函数</h3>
<div class="outline-text-3" id="text-3-2">
<ul class="org-ul">
<li><p>
上一章说到,朴素感知机使用的激活函数为阶跃函数(公式3.3就是一个阶跃函数), 所谓阶跃函数, 其定义如下.
</p>
<pre class="example" id="org293cad9">
阶跃函数，指函数值突然发生跳变的函数。例如从0突然变成100，从0突然变成正无穷，
从负无穷突然变成正无穷，都可以叫阶跃函数。
</pre></li>
<li>朴素感知机如果使用了其他函数作为激活函数会怎样? 从定义看来,如果使用了非阶跃函数作为激活函数,那么就
不能再叫朴素感知机了,而是应该叫神经网络了(当然如果层数在多一层,神经网络的名字,就更准确了)</li>
<li>作为激活函数的非阶跃函数,最出名的,就是sigmoid函数了</li>
</ul>
</div>
<div id="outline-container-orge1f4478" class="outline-4">
<h4 id="orge1f4478"><span class="section-number-4">3.2.1.</span> sigmoid函数</h4>
<div class="outline-text-4" id="text-3-2-1">
<ul class="org-ul">
<li>神经网络中最经常使用的一个激活函数就是sigmoid函数:
<ul class="org-ul">
<li><p>
公式如下
</p>
\begin{equation}
h(x) = \frac{1}{1 + \exp(-x)} \tag{3.6}
\end{equation}</li>
<li>公式中的 \(\exp(-x)\) 是 \(e^{-x}\) 的意思</li>
<li>e是纳皮尔常数2.7182&#x2026;</li>
</ul></li>
<li>好了,作者这里介绍了神经网络的激活函数sigmoid,然后马上,开始实现神经网络的激活函数(阶跃函数),之后才又
实现sigmoid函数,整个过程跳跃有点过快,需要大家精力集中,不要被带到沟里.</li>
</ul>
</div>
</div>
<div id="outline-container-org68cde32" class="outline-4">
<h4 id="org68cde32"><span class="section-number-4">3.2.2.</span> 阶跃函数的实现</h4>
<div class="outline-text-4" id="text-3-2-2">
<ul class="org-ul">
<li><p>
前面已经说了,公式3.3就是阶跃函数,我们可以使用python很容易的实现这个阶跃函数
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">step_function</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">if</span> x &gt; 0:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 1
    <span style="color: #3a81c3; font-weight: bold;">else</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span> 0
</pre>
</div></li>
<li>我们后面要把激活函数打印出来,那么输入就必须要支持数组(这里是numpy数组),所以我们要升级下我们的函数
让它支持numpy数组作为参数.当然输出也就是相同长度的numpy数组啦
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">step_function</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">y</span> = x &gt; 0
    <span style="color: #3a81c3; font-weight: bold;">return</span> y.astype<span style="color: #3a81c3;">(</span>np.int64<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #715ab1;">x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>-1.0, 1.0, 2.0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|x|=&gt;"""</span>, x<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">y</span> = x &gt; 0
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|y|=&gt;"""</span>, y<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">z</span> = y.astype<span style="color: #3a81c3;">(</span>np.int64<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|z|=&gt;"""</span>, z<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|step_function(x)|=&gt;"""</span>, step_function<span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|x|=&gt; [-1.  1.  2.]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|y|=&gt; [False  True  True]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|z|=&gt; [0 1 1]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|step_function(x)|=&gt; [0 1 1]</span>
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org82bdca7" class="outline-4">
<h4 id="org82bdca7"><span class="section-number-4">3.2.3.</span> 阶跃函数的图形</h4>
<div class="outline-text-4" id="text-3-2-3">
<ul class="org-ul">
<li>我们现在就使用matplotlib库来打印阶跃函数的图形(刚才的支持numpy array输入就起到作用了)
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
<span style="color: #3a81c3; font-weight: bold;">import</span> matplotlib.pyplot <span style="color: #3a81c3; font-weight: bold;">as</span> plt


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">step_function</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> np.array<span style="color: #3a81c3;">(</span>x &gt; 0, dtype=np.int64<span style="color: #3a81c3;">)</span>


<span style="color: #715ab1;">x</span> = np.arange<span style="color: #3a81c3;">(</span>-5.0, 5.0, 0.1<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">y</span> = step_function<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
plt.plot<span style="color: #3a81c3;">(</span>x, y<span style="color: #3a81c3;">)</span>
plt.ylim<span style="color: #3a81c3;">(</span>-0.1, 1.1<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">range for y-axis</span>
plt.show<span style="color: #3a81c3;">()</span>
</pre>
</div></li>
<li><p>
图形如下
</p>

<div id="org6f0eb32" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-6.png" alt="3-6.png" />
</p>
<p><span class="figure-number">Figure 17: </span>dlfs/3-6.png</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgcf9c4bc" class="outline-4">
<h4 id="orgcf9c4bc"><span class="section-number-4">3.2.4.</span> sigmoid 函数的实现</h4>
<div class="outline-text-4" id="text-3-2-4">
<ul class="org-ul">
<li>我们还可以使用类似代码来完成sigmod的图形
<ul class="org-ul">
<li><p>
代码如下,注意标量和numpy array无论进行加法还是除法都可以"先把标量扩展成向量"在和向量进行计算.
这是numpy库的广播特性其了作用(第一章里面详细介绍了广播)
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
<span style="color: #3a81c3; font-weight: bold;">import</span> matplotlib.pyplot <span style="color: #3a81c3; font-weight: bold;">as</span> plt


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sigmoid</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 1 / <span style="color: #3a81c3;">(</span>1 + np.exp<span style="color: #6c3163;">(</span>-x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #715ab1;">x</span> = np.arange<span style="color: #3a81c3;">(</span>-5.0, 5.0, 0.1<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">y</span> = sigmoid<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
plt.plot<span style="color: #3a81c3;">(</span>x, y<span style="color: #3a81c3;">)</span>
plt.ylim<span style="color: #3a81c3;">(</span>-0.1, 1.1<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">range for y-axis</span>
plt.show<span style="color: #3a81c3;">()</span>
</pre>
</div></li>
<li><p>
图形如下
</p>

<div id="orgd38d914" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-7.png" alt="3-7.png" />
</p>
<p><span class="figure-number">Figure 18: </span>dlfs/3-7.png</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org47bb858" class="outline-4">
<h4 id="org47bb858"><span class="section-number-4">3.2.5.</span> sigmoid函数和阶跃函数的比较</h4>
<div class="outline-text-4" id="text-3-2-5">
<ul class="org-ul">
<li>我们现在比较一下sigmod函数和阶跃函数
<ul class="org-ul">
<li><p>
把两者的图放到同一个坐标后如下
</p>

<div id="org8949661" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-8.png" alt="3-8.png" />
</p>
<p><span class="figure-number">Figure 19: </span>dlfs/3-8.png</p>
</div></li>
<li>首先注意到的是,两者的"平滑性"不同:
<ul class="org-ul">
<li>阶跃函数以0为界,输出发生剧烈变化</li>
<li>sigmoid函数是一条平滑的曲线,输出随着输入发生连续性的变化. sigmoid函数的平滑性对于神经网络的学
习有重要的意义</li>
</ul></li>
<li>两者另外的不同在于返回值:
<ol class="org-ol">
<li>阶跃函数只能返回1,0,使用 <b>阶跃函数的感知机</b> 中神经元之间流动的是二元信号(0,1)</li>
<li>sigmoid函数能够返回0.731, 0.880等实数,使用 <b>sigmoid的神经网络</b> 中神经元之间流动的就是连续的实
数的信号</li>
</ol></li>
<li>两者的共同点有:
<ol class="org-ol">
<li><p>
两者的第一个共同点在于其形状相似,两者都能做到
</p>
<pre class="example" id="org356b247">
输入小时,输出接近0(为0), 随着输入增大,输出像1靠近(变成1)
</pre></li>
<li>两者的第二个共同点是不管输入信号多大或者多小,输出信号的值都在0和1之间</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org3232734" class="outline-4">
<h4 id="org3232734"><span class="section-number-4">3.2.6.</span> 非线性函数</h4>
<div class="outline-text-4" id="text-3-2-6">
<ul class="org-ul">
<li>阶跃函数和sigmoid函数的最重要相同点,是他们都是非线性函数</li>
<li><p>
我们定义一下线性函数,那么为什么阶跃函数和sigmoid函数都是非线性函数就很明显了
</p>
<pre class="example" id="org2aee57f">
所谓线性函数,就是输出值是输入值的常数倍,比如人h(x)=cx.因此线性函数是一条笔直的直线
</pre></li>
<li>由于阶跃函数和sigmoid函数都没有像线性函数一样"呈现出一条直线",所以他们都是非线性函数</li>
<li>神经网络的激活函数必须使用非线性函数,换句话说,在神经网络里,激活函数不能使用线性函数</li>
<li>为什么会有这个规定呢?
<ul class="org-ul">
<li>首先神经网络的定义,就是必须要多层的感知机,一层的是朴素感知机(朴素感知机是可以使用线性函数的)</li>
<li>多层肯定是为了表达能力更强,但是如果使用了线性函数的话,加深神经网络的层数就没有意义了</li>
</ul></li>
<li>为什么使用了线性函数加深网络层数就没有意义了呢?
<ul class="org-ul">
<li>我们举个反例,假设把线性函数 \(h(x) = cx\) 作为激活函数,把 \(y(x)=h(h(h(x)))\) 运算,对应3层神经网络,
这个就相当于 \(y(x) = c \times c \times c \times x\) , 那其实就是 \(y(x)=ax (a = c^3)\)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org3f43631" class="outline-4">
<h4 id="org3f43631"><span class="section-number-4">3.2.7.</span> ReLU函数</h4>
<div class="outline-text-4" id="text-3-2-7">
<ul class="org-ul">
<li>神经网络的发展史上,早期使用sigmoid函数比较多,而最近则主要使用ReLU函数</li>
<li>ReLU函数在输入大于0的时候,直接输出该值,在输入小于等于0的时候,输出0
<ul class="org-ul">
<li><p>
其公式如下
</p>
\begin{equation}
h(x) =
   \begin{cases}
    x & (x > 0) \\
    0 & (x \leqslant 0) \tag{3.7}
   \end{cases}
\end{equation}</li>
<li><p>
其python实现如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">relu</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> np.maximum<span style="color: #3a81c3;">(</span>0, x<span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li><p>
其绘图如下
</p>

<div id="orgdb7e5ac" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-9.png" alt="3-9.png" />
</p>
<p><span class="figure-number">Figure 20: </span>dlfs/3-9.png</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org496c960" class="outline-3">
<h3 id="org496c960"><span class="section-number-3">3.3.</span> 多维数组的运算</h3>
<div class="outline-text-3" id="text-3-3">
<ul class="org-ul">
<li>numpy的多维数组运算能够高效的实现神经网络,所以我们这里停下来先学习一下numpy多维数组的运算</li>
</ul>
</div>
<div id="outline-container-orga0e3242" class="outline-4">
<h4 id="orga0e3242"><span class="section-number-4">3.3.1.</span> 多维数组</h4>
<div class="outline-text-4" id="text-3-3-1">
<ul class="org-ul">
<li>超过1维的数组就是多维数组.但是为了实现的一致性,从1维到n维,numpy的接口都是一样的,比如:
<ul class="org-ul">
<li>都有shape函数,返回一个tuple,来获取多维数组在某个维度上面成员的数目,对于一维数组也是返回元祖,只不
过,这个元祖只有一个成员</li>
<li>都有可以通过np.ndim()函数(或者ndim成员变量)获取其维度</li>
<li><p>
一维数组例子如下
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; A = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1, 2, 3, 4<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>A<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span>1 2 3 4<span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; A.ndim
1
&gt;&gt;&gt; np.ndim<span style="color: #3a81c3;">(</span>A<span style="color: #3a81c3;">)</span>
1
&gt;&gt;&gt; A.shape
<span style="color: #3a81c3;">(</span>4,<span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; A.shape<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span>
4
</pre>
</div></li>
<li><p>
二维数组的例子如下
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; B = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>1, 2<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>3, 4<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>5, 6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>B<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span><span style="color: #6c3163;">[</span>1 2<span style="color: #6c3163;">]</span>
 <span style="color: #6c3163;">[</span>3 4<span style="color: #6c3163;">]</span>
 <span style="color: #6c3163;">[</span>5 6<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; np.ndim<span style="color: #3a81c3;">(</span>B<span style="color: #3a81c3;">)</span>
2
&gt;&gt;&gt; B.ndim
2
&gt;&gt;&gt; B.shape
<span style="color: #3a81c3;">(</span>3, 2<span style="color: #3a81c3;">)</span>&gt;&gt;&gt; B = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>1, 2<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>3, 4<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>5, 6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; print<span style="color: #3a81c3;">(</span>B<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span><span style="color: #6c3163;">[</span>1 2<span style="color: #6c3163;">]</span>
 <span style="color: #6c3163;">[</span>3 4<span style="color: #6c3163;">]</span>
 <span style="color: #6c3163;">[</span>5 6<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; np.ndim<span style="color: #3a81c3;">(</span>B<span style="color: #3a81c3;">)</span>
2
&gt;&gt;&gt; B.ndim
2
&gt;&gt;&gt; B.shape
<span style="color: #3a81c3;">(</span>3, 2<span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li>这里生成了一个 \(3 \times 2\) 的数组. \(3 \times 2\) 的数组表示第一个维度有3个成员,第二个维度有2个成
员.</li>
<li><p>
二维数组也称为矩阵(matrix),横向为行(row),纵向为列(column),如下图
</p>

<div id="org499a60e" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-10.png" alt="3-10.png" />
</p>
<p><span class="figure-number">Figure 21: </span>dlfs/3-10.png</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgb093f49" class="outline-4">
<h4 id="orgb093f49"><span class="section-number-4">3.3.2.</span> 矩阵乘法</h4>
<div class="outline-text-4" id="text-3-3-2">
<ul class="org-ul">
<li>下面我们来介绍矩阵(也就是专指二维数组)的乘法
<ul class="org-ul">
<li><p>
如图3-11,就是两个 \(2 \times 2\) 的矩阵相乘
</p>

<div id="orgc960da1" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-11.png" alt="3-11.png" />
</p>
<p><span class="figure-number">Figure 22: </span>dlfs/3-11.png</p>
</div></li>
<li>本书中矩阵使用黑色斜体大写表示,比如矩阵 \(\boldsymbol{A}\) 和矩阵 \(\boldsymbol{B}\)</li>
<li>matrix乘法的第M行第N列是由 \(\boldsymbol{A}\) 的第M行乘以 \(\boldsymbol{B}\) 的第N列得到的结果.比如
\(\boldsymbol{A}\) 的第2行和 \(\boldsymbol{B}\) 的第1列相乘,就是新矩阵的第2行第1列的元素</li>
<li><p>
上述过程用python表示如下
</p>
<div class="org-src-container">
<pre class="src src-shell">Type <span style="color: #2d9574;">"help"</span>, <span style="color: #2d9574;">"copyright"</span>, <span style="color: #2d9574;">"credits"</span> or <span style="color: #2d9574;">"license"</span> for more information.
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; A = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>1, 2<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>3, 4<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; A.shape
<span style="color: #3a81c3;">(</span>2, 2<span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; B = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>5, 6<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>7,8<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; B.shape
<span style="color: #3a81c3;">(</span>2, 2<span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; np.dot<span style="color: #3a81c3;">(</span>A,B<span style="color: #3a81c3;">)</span>
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>19, 22<span style="color: #2d9574;">]</span>,
       <span style="color: #2d9574;">[</span>43, 50<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt;
</pre>
</div></li>
</ul></li>
<li>上面的例子是相乘的两个矩阵的shape完全一致的情况,但是很多时候相乘的矩阵的shape是不一致的.不一样shape
的两个矩阵只有一种情况可以相乘: 那就是第一个矩阵Shape的最后一个维度,要和下一个矩阵的第一个维度相同
<ul class="org-ul">
<li><p>
矩阵A是 \(3 \times 2\), 矩阵B是 \(2 \times 3\), AB可以相乘
</p>

<div id="orgaeb20eb" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-12.png" alt="3-12.png" />
</p>
<p><span class="figure-number">Figure 23: </span>dlfs/3-12.png</p>
</div></li>
<li>矩阵A是 \(3 \times 2\), 矩阵B是 \(2 \times 3\), BA不可以相乘!</li>
</ul></li>
<li>上述要求(第一个shape的最后一位等于第二个shape的第一位)这种要求在numpy层面有两个特例,那就是:
<ul class="org-ul">
<li><p>
Matrix(狭义) 和 Column Vector相乘, 比如shape为(2,3)的和shape为(3,)的相乘.结果为(2,)
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np

<span style="color: #715ab1;">A</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #3a81c3;">range</span><span style="color: #6c3163;">(</span>1, 7<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">A</span> = A.reshape<span style="color: #3a81c3;">(</span>2, 3<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|A|=&gt;"""</span>, A<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|A.shape|=&gt;"""</span>, A.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"-"</span> * 60<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">B</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1, 2, 3<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|B|=&gt;"""</span>, B<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|B.shape|=&gt;"""</span>, B.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"-"</span> * 60<span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">X</span> = np.dot<span style="color: #3a81c3;">(</span>A, B<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|X|=&gt;"""</span>, X<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|X.shape|=&gt;"""</span>, X.shape<span style="color: #3a81c3;">)</span>


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|A|=&gt; [[1 2 3]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[4 5 6]]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|A.shape|=&gt; (2, 3)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">------------------------------------------------------------</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|B|=&gt; [1 2 3]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|B.shape|=&gt; (3,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">------------------------------------------------------------</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|X|=&gt; [14 32]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|X.shape|=&gt; (2,)</span>
</pre>
</div></li>
<li><p>
Row Vector 和 Matrix(狭义)相乘,比如shape为(2,)的和shape为(2,3)的相乘.结果为(3,)
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np

<span style="color: #715ab1;">A</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #3a81c3;">range</span><span style="color: #6c3163;">(</span>1, 7<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">A</span> = A.reshape<span style="color: #3a81c3;">(</span>2, 3<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|A|=&gt;"""</span>, A<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|A.shape|=&gt;"""</span>, A.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"-"</span> * 60<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">B</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1, 2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|B|=&gt;"""</span>, B<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|B.shape|=&gt;"""</span>, B.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"-"</span> * 60<span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">X</span> = np.dot<span style="color: #3a81c3;">(</span>B, A<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|X|=&gt;"""</span>, X<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|X.shape|=&gt;"""</span>, X.shape<span style="color: #3a81c3;">)</span>


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|A|=&gt; [[1 2 3]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[4 5 6]]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|A.shape|=&gt; (2, 3)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">------------------------------------------------------------</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|B|=&gt; [1 2]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|B.shape|=&gt; (2,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">------------------------------------------------------------</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|X|=&gt; [ 9 12 15]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|X.shape|=&gt; (3,)</span>
</pre>
</div></li>
</ul></li>
<li>我们上面特地写了"狭义",也就是说这个特性是只给matrix准备的. 总结起来就是numpy给了我们一个特例,那就是
我们的二维数组(matrix)可以和一维数组相乘(两者维度都不一样),但是只要:
<ul class="org-ul">
<li><p>
一维数组再右边的时候,被识别为column vector,只需要matrix的第1位和一维数组的第0位相同即可.如果我们
右边是一维数组,左边是N维数组,那么N维数组的后两位作为matrix来进行验证满足即可.比如(4,3,2)只看(3,2)
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np

<span style="color: #715ab1;">A</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #3a81c3;">range</span><span style="color: #6c3163;">(</span>1, 25<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">A</span> = A.reshape<span style="color: #3a81c3;">(</span>4, 3, 2<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|A|=&gt;"""</span>, A<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|A.shape|=&gt;"""</span>, A.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"-"</span> * 60<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">B</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1, 2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|B|=&gt;"""</span>, B<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|B.shape|=&gt;"""</span>, B.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"-"</span> * 60<span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">X</span> = np.dot<span style="color: #3a81c3;">(</span>A, B<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|X|=&gt;"""</span>, X<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|X.shape|=&gt;"""</span>, X.shape<span style="color: #3a81c3;">)</span>


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|A|=&gt; [[[ 1  2]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#   </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[ 3  4]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#   </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[ 5  6]]</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[[ 7  8]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#   </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[ 9 10]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#   </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[11 12]]</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[[13 14]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#   </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[15 16]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#   </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[17 18]]</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[[19 20]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#   </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[21 22]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#   </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[23 24]]]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|A.shape|=&gt; (4, 3, 2)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">------------------------------------------------------------</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|B|=&gt; [1 2]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|B.shape|=&gt; (2,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">------------------------------------------------------------</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|X|=&gt; [[ 5 11 17]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[23 29 35]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[41 47 53]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[59 65 71]]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|X.shape|=&gt; (4, 3)</span>
</pre>
</div></li>
<li><p>
一维数组再左边的时候,被识别为row vector,只需要一维数组的第0位和matrix的第0位相同即可.如果我们做边
是一维数组,右边是N维数组,那么N维数组的后两位作为matrix来进行验证满足即可.比如(2,3,4)只看(3,4)
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np

<span style="color: #715ab1;">A</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #3a81c3;">range</span><span style="color: #6c3163;">(</span>1, 25<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">A</span> = A.reshape<span style="color: #3a81c3;">(</span>2, 3, 4<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|A|=&gt;"""</span>, A<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|A.shape|=&gt;"""</span>, A.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"-"</span> * 60<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">B</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1, 2, 3<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|B|=&gt;"""</span>, B<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|B.shape|=&gt;"""</span>, B.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"-"</span> * 60<span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">X</span> = np.dot<span style="color: #3a81c3;">(</span>B, A<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|X|=&gt;"""</span>, X<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|X.shape|=&gt;"""</span>, X.shape<span style="color: #3a81c3;">)</span>


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|A|=&gt; [[[ 1  2  3  4]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#   </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[ 5  6  7  8]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#   </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[ 9 10 11 12]]</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[[13 14 15 16]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#   </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[17 18 19 20]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#   </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[21 22 23 24]]]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|A.shape|=&gt; (2, 3, 4)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">------------------------------------------------------------</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|B|=&gt; [1 2 3]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|B.shape|=&gt; (3,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">------------------------------------------------------------</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|X|=&gt; [[ 38  44  50  56]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[110 116 122 128]]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|X.shape|=&gt; (2, 4)</span>
</pre>
</div></li>
</ul></li>
<li>上面的特例是numpy为vector准备的福利,让vector(一维数组)能够参与到多维数组运算.这个特例其实是让我的
vector拥有了超能力:
<ul class="org-ul">
<li>在dot运算的右边自动被识别成column vector</li>
<li>在dot运算的左边自动被识别成是row vector</li>
</ul></li>
<li>为了让我们的特例不至于影响正常的多维数组之间的dot运算,我们的matrix(二维)和vector(一维)的运算结果总
是一维的(把相同的shape值消掉).当然了,如果是N维和vector进行dot运算,那么结果是N-1维的.</li>
</ul>
</div>
</div>
<div id="outline-container-org328530a" class="outline-4">
<h4 id="org328530a"><span class="section-number-4">3.3.3.</span> 神经网络的内积</h4>
<div class="outline-text-4" id="text-3-3-3">
<ul class="org-ul">
<li>理解了numpy的特例机制,那么如何使用numpy来实现神经网络就非常轻松了</li>
<li>下面的例子省略了偏置和激活函数,主要为了让大家理解如何将 \(x_n\) 和 \(w_n\) 进行匹配的
<ul class="org-ul">
<li><p>
如图
</p>

<div id="orge4aefd7" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-14.png" alt="3-14.png" />
</p>
<p><span class="figure-number">Figure 24: </span>dlfs/3-14.png</p>
</div></li>
<li>我们注意到矩阵X的shape是(2,), 而且它在公式左边,那么它这里就是作为row vector,而W是一个二维数组(matrix),
shape是(2,3),两者dot得到的shape就是(3,)</li>
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; X = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1,2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; X.shape
<span style="color: #3a81c3;">(</span>2,<span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; W = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>1, 3, 5<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>2, 4, 6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; W
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>1, 3, 5<span style="color: #2d9574;">]</span>,
       <span style="color: #2d9574;">[</span>2, 4, 6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; W.shape
<span style="color: #3a81c3;">(</span>2, 3<span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; Y = np.dot<span style="color: #3a81c3;">(</span>X, W<span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; Y
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span> 5, 11, 17<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; Y.shape
<span style="color: #3a81c3;">(</span>3,<span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li>通过上面的例子我们知道,即便矩阵Y有一千个元素,那么仅仅通过一次运算也就算出来了.这极大的简化了运算</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org3c556be" class="outline-3">
<h3 id="org3c556be"><span class="section-number-3">3.4.</span> 3层神经网络的实现</h3>
<div class="outline-text-3" id="text-3-4">
<ul class="org-ul">
<li>神经网络问题(或者更广义上的机器学习问题),可以分成如下两个阶段:
<ul class="org-ul">
<li>学习:首先,在学习阶段,就是进行模型的学习. 所谓模型的学习,就是使用已知的训练数据自动调参得到无数浮
点参数组成的模型</li>
<li>推理:然后,在推理阶段,用学到的模型对未知的数据进行推理(回归或者分类)</li>
</ul></li>
<li>本章我们先了解一下"推理"阶段,这个阶段理解起来比较直接."推理"阶段在"学习"阶段之后,自然我们是已经在
已知数据上面习得了新的模型(浮点数参数集合).</li>
<li>新的模型存储在numpy数组里面,我们要推理的数据,也在numpy数组里面,通过我们上节学到的numpy数组的计算,
最终得到推理的结果(回归或者分类)</li>
<li>我们的例子是一个三层神经网络
<ul class="org-ul">
<li><p>
如图
</p>

<div id="orgab60ca4" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-15.png" alt="3-15.png" />
</p>
<p><span class="figure-number">Figure 25: </span>dlfs/3-15.png</p>
</div></li>
</ul></li>
</ul>
</div>
<div id="outline-container-orgcb14ff7" class="outline-4">
<h4 id="orgcb14ff7"><span class="section-number-4">3.4.1.</span> 符号确认</h4>
<div class="outline-text-4" id="text-3-4-1">
<ul class="org-ul">
<li>为了能够清晰的理解推理过程,我们给参数进行了一些特殊定义:
<ul class="org-ul">
<li><p>
如图
</p>

<div id="orga07e862" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-16.png" alt="3-16.png" />
</p>
<p><span class="figure-number">Figure 26: </span>dlfs/3-16.png</p>
</div></li>
<li>权重(w)和隐藏层神经元的右上角有一个"(1)", 这个表示权重(w)和神经元的层号</li>
<li>权重的右下角有两个数组: 第一个是后一层神经元的index, 第二个是前一层神经元的index,比如 \(w_{12}^{(1)}\)
表示前一层的第2个神经元 \(x_2\) 到 后一层第1个神经元 \(a_1^{(1)}\) 的权重</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org4fd87eb" class="outline-4">
<h4 id="org4fd87eb"><span class="section-number-4">3.4.2.</span> 各层间信号传递的实现</h4>
<div class="outline-text-4" id="text-3-4-2">
<ul class="org-ul">
<li>我们现在看一下从输入层到第一层第一个神经元的信号传递过程
<ul class="org-ul">
<li><p>
如图
</p>

<div id="orgcbda9ba" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-17.png" alt="3-17.png" />
</p>
<p><span class="figure-number">Figure 27: </span>dlfs/3-17.png</p>
</div></li>
<li>图中增加了表示偏置(bias)的神经元"1", 注意偏置的右下角只有一个标记(也就是目的地), 因为偏置神经元(神经
元"1")只有一个</li>
<li>上面偏置右下角只有一个标记,这也就解释了为什么权重要把目的地写前面了(一般目的地都写后面)&#x2013;因为偏置
只有目的地, 为了偏置和权重使用一套符号,所以把目的地写第一个位置</li>
<li><p>
上图所谓的第一层第一个神经元,用我们的符号表示的话,其实就是 \(a_1^{(1)}\), 我们使用数学公式来表达下
计算第一层第一个神经元的公式
</p>
\begin{equation}
a_1^{(1)} = w_{11}^{(1)} x_1 + w_{12}^{(1)} x_2 + b_1^{(1)} \tag{3.8}
\end{equation}</li>
</ul></li>
<li>有了第一层第一个神经元的计算公式,我们可以进一步把第一层的计算方式列出来:
<ul class="org-ul">
<li><p>
总体公式如下
</p>
\begin{equation}
\boldsymbol{A}^{(1)} = \boldsymbol{X} \boldsymbol{W}^{(1)} + \boldsymbol{B}^{(1)} \tag{3.9}
\end{equation}</li>
<li><p>
其中 \(\boldsymbol{A}^{(1)}\) 如下
</p>
\begin{equation}
\boldsymbol{A}^{(1)} = \left(a_1^{(1)} \; a_2^{(1)} \; a_3^{(1)} \right) \notag
\end{equation}</li>
<li><p>
其中 \(\boldsymbol{X}\) 如下
</p>
\begin{equation}
\boldsymbol{X} = \left( x_1, x_2 \right) \notag
\end{equation}</li>
<li><p>
其中 \(\boldsymbol{B}^{(1)}\) 如下
</p>
\begin{equation}
\boldsymbol{B}^{(1)} = \left(b_1^{(1)} \; b_2^{(1)} \; b_3^{(1)} \right) \notag
\end{equation}</li>
<li><p>
其中 \(\boldsymbol{W}^{(1)}\) 如下
</p>
\begin{equation}
\boldsymbol{W}^{(1)} = \begin{pmatrix}
                           w_{11}^{(1)} & w_{21}^{(1)} & w_{31}^{(1)} \\
                           w_{12}^{(1)} & w_{22}^{(1)} & w_{32}^{(1)}
                       \end{pmatrix} \notag
\end{equation}</li>
<li><p>
最后,我们使用numpy多维数组来实现公式3.9,其中权重,偏置,X值都是随机的
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np

<span style="color: #715ab1;">X</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1.0, 0.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">W1</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>0.1, 0.3, 0.5<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.2, 0.4, 0.6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">B1</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.1, 0.2, 0.3<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>W1.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>X.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>B1.shape<span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">A1</span> = np.dot<span style="color: #3a81c3;">(</span>X, W1<span style="color: #3a81c3;">)</span> + B1
</pre>
</div></li>
</ul></li>
<li>下面我们来看看激活过程
<ul class="org-ul">
<li><p>
如图
</p>

<div id="org5b8af61" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-18.png" alt="3-18.png" />
</p>
<p><span class="figure-number">Figure 28: </span>dlfs/3-18.png</p>
</div></li>
<li>隐藏层的加权和(加权信号和偏置的总和)用a表示</li>
<li>被激活函数转换后的信号用z表示</li>
<li><p>
\(h()\) 表示激活函数,我们这里使用的是sigmoid函数,从输入到激活成功的总体代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sigmoid</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 1 / <span style="color: #3a81c3;">(</span>1 + np.exp<span style="color: #6c3163;">(</span>-x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #715ab1;">X</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1.0, 0.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">W1</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>0.1, 0.3, 0.5<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.2, 0.4, 0.6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">B1</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.1, 0.2, 0.3<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>W1.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>X.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>B1.shape<span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">A1</span> = np.dot<span style="color: #3a81c3;">(</span>X, W1<span style="color: #3a81c3;">)</span> + B1
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>A1<span style="color: #3a81c3;">)</span>


<span style="color: #715ab1;">Z1</span> = sigmoid<span style="color: #3a81c3;">(</span>A1<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>Z1<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(2, 3)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(2,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(3,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[0.3 0.7 1.1]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[0.57444252 0.66818777 0.75026011]</span>
</pre>
</div></li>
</ul></li>
<li>下面再来看看第一层到第二层的信号传递
<ul class="org-ul">
<li><p>
如图
</p>

<div id="orgff2727e" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-19.png" alt="3-19.png" />
</p>
<p><span class="figure-number">Figure 29: </span>dlfs/3-19.png</p>
</div></li>
<li><p>
代码和前面只有些许不同, 把一层的输出Z作为了第二层的输入
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sigmoid</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 1 / <span style="color: #3a81c3;">(</span>1 + np.exp<span style="color: #6c3163;">(</span>-x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #715ab1;">X</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1.0, 0.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">W1</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>0.1, 0.3, 0.5<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.2, 0.4, 0.6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">B1</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.1, 0.2, 0.3<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>


<span style="color: #715ab1;">A1</span> = np.dot<span style="color: #3a81c3;">(</span>X, W1<span style="color: #3a81c3;">)</span> + B1
<span style="color: #715ab1;">Z1</span> = sigmoid<span style="color: #3a81c3;">(</span>A1<span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">W2</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>0.1, 0.4<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.2, 0.5<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.3, 0.6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">B2</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.1, 0.2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>Z1.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>W2.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>B2.shape<span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">A2</span> = np.dot<span style="color: #3a81c3;">(</span>Z1, W2<span style="color: #3a81c3;">)</span> + B2
<span style="color: #715ab1;">Z2</span> = sigmoid<span style="color: #3a81c3;">(</span>A2<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>A2<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>Z2<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(3,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(3, 2)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(2,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[0.51615984 1.21402696]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[0.62624937 0.7710107 ]</span>
</pre>
</div></li>
</ul></li>
<li>最后一步是第2层到输出层的信号传递
<ul class="org-ul">
<li><p>
如图
</p>

<div id="orgc639fc3" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-20.png" alt="3-20.png" />
</p>
<p><span class="figure-number">Figure 30: </span>dlfs/3-20.png</p>
</div></li>
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sigmoid</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 1 / <span style="color: #3a81c3;">(</span>1 + np.exp<span style="color: #6c3163;">(</span>-x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #715ab1;">X</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1.0, 0.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">W1</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>0.1, 0.3, 0.5<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.2, 0.4, 0.6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">B1</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.1, 0.2, 0.3<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>


<span style="color: #715ab1;">A1</span> = np.dot<span style="color: #3a81c3;">(</span>X, W1<span style="color: #3a81c3;">)</span> + B1
<span style="color: #715ab1;">Z1</span> = sigmoid<span style="color: #3a81c3;">(</span>A1<span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">W2</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>0.1, 0.4<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.2, 0.5<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.3, 0.6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">B2</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.1, 0.2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>Z1.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>W2.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>B2.shape<span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">A2</span> = np.dot<span style="color: #3a81c3;">(</span>Z1, W2<span style="color: #3a81c3;">)</span> + B2
<span style="color: #715ab1;">Z2</span> = sigmoid<span style="color: #3a81c3;">(</span>A2<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>A2<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>Z2<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">identity_function</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> x

<span style="color: #715ab1;">W3</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>0.1, 0.3<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.2, 0.4<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">B3</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.1, 0.2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">A3</span> = np.dot<span style="color: #3a81c3;">(</span>Z2, W3<span style="color: #3a81c3;">)</span> + B3
<span style="color: #715ab1;">Y</span> = identity_function<span style="color: #3a81c3;">(</span>A3<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(3,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(3, 2)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(2,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[0.51615984 1.21402696]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[0.62624937 0.7710107 ]</span>
</pre>
</div></li>
<li>这里Z2是输入</li>
<li>我们这里定义了identity_function()函数,并且作为输出层的激活函数.这个函数其实什么都没干,我们也只是
为了和之前的流程保持一致,所以加了这个函数.</li>
<li>输出层所用的激活函数,要根据求解问题的性质决定:
<ol class="org-ol">
<li>回归问题可以用恒等函数,因为回顾问题本来就是求一个浮点数</li>
<li>二元分类问题可以使用sigmoid函数</li>
<li>多元分类问题可以使用softmax函数</li>
</ol></li>
<li>identity_function()这个函数对应于图3-20中的 \(\sigma()\)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgf4045a1" class="outline-4">
<h4 id="orgf4045a1"><span class="section-number-4">3.4.3.</span> 代码现小结</h4>
<div class="outline-text-4" id="text-3-4-3">
<ul class="org-ul">
<li>我们可以把前面几个步骤重新整理一下
<ul class="org-ul">
<li><p>
完整的代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sigmoid</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 1 / <span style="color: #3a81c3;">(</span>1 + np.exp<span style="color: #6c3163;">(</span>-x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">identity_function</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> x


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">init_network</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #715ab1;">network</span> = <span style="color: #3a81c3;">{}</span>
    <span style="color: #715ab1;">network</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>0.1, 0.3, 0.5<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.2, 0.4, 0.6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">network</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.1, 0.2, 0.3<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">network</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>0.1, 0.4<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.2, 0.5<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.3, 0.6<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">network</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.1, 0.2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">network</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W3"</span><span style="color: #3a81c3;">]</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>0.1, 0.3<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.2, 0.4<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">network</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b3"</span><span style="color: #3a81c3;">]</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.1, 0.2<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> network


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">forward</span><span style="color: #3a81c3;">(</span>network, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">W1</span>, <span style="color: #715ab1;">W2</span>, <span style="color: #715ab1;">W3</span> = network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W3"</span><span style="color: #3a81c3;">]</span>
    <span style="color: #715ab1;">b1</span>, <span style="color: #715ab1;">b2</span>, <span style="color: #715ab1;">b3</span> = network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b3"</span><span style="color: #3a81c3;">]</span>

    <span style="color: #715ab1;">a1</span> = np.dot<span style="color: #3a81c3;">(</span>x, W1<span style="color: #3a81c3;">)</span> + b1
    <span style="color: #715ab1;">z1</span> = sigmoid<span style="color: #3a81c3;">(</span>a1<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">a2</span> = np.dot<span style="color: #3a81c3;">(</span>z1, W2<span style="color: #3a81c3;">)</span> + b2
    <span style="color: #715ab1;">z2</span> = sigmoid<span style="color: #3a81c3;">(</span>a2<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">a3</span> = np.dot<span style="color: #3a81c3;">(</span>z2, W3<span style="color: #3a81c3;">)</span> + b3
    <span style="color: #715ab1;">y</span> = identity_function<span style="color: #3a81c3;">(</span>a3<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> y


<span style="color: #715ab1;">network</span> = init_network<span style="color: #3a81c3;">()</span>
<span style="color: #715ab1;">x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1.0, 0.5<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">y</span> = forward<span style="color: #3a81c3;">(</span>network, x<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>y<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[0.31682708 0.69627909]</span>
</pre>
</div></li>
<li>我们这里引入了init_network()函数来初始化权重和偏置</li>
<li>这里的forward()函数则封装了将输入信号转换为输出信号的过程. forward的前项,指的是从输入到输出方向的
传递处理.后面在介绍"训练"阶段的时候,我们将介绍backward(后向:从输出到输入)的处理</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org331b1f1" class="outline-3">
<h3 id="org331b1f1"><span class="section-number-3">3.5.</span> 输出层的设计</h3>
<div class="outline-text-3" id="text-3-5">
<ul class="org-ul">
<li>神经网络可以用在如下两种问题上:
<ul class="org-ul">
<li>回归问题(比如区分图形中的人是男性还是女性): 一般使用恒等函数</li>
<li>分类问题(根据一个人的图像预测这个人的体重): 一般使用softmax函数</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org7b69fb6" class="outline-4">
<h4 id="org7b69fb6"><span class="section-number-4">3.5.1.</span> 恒等函数和softmax函数</h4>
<div class="outline-text-4" id="text-3-5-1">
<ul class="org-ul">
<li>恒等函数就非常直接了,在输出层使用恒等函数的时候,输入信号会原封不动地被输出
<ul class="org-ul">
<li><p>
如图
</p>

<div id="orge4a83d1" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-21.png" alt="3-21.png" />
</p>
<p><span class="figure-number">Figure 31: </span>dlfs/3-21.png</p>
</div></li>
<li>上图的 \(\sigma()\) 就是恒等函数.我们可以看到恒等函数转换的时候 \(y_n\) 只跟 \(a_n\) 有关系(两者通过箭
头相连,表示转换的时候有关系)</li>
</ul></li>
<li>分类问题使用的softmax函数可以用下面的公式表示
<ul class="org-ul">
<li><p>
公式如下
</p>
\begin{equation}
 y_k = \frac{\exp(a_k)}{  \displaystyle \sum_{i=1}^{n} \exp(a_i) } \tag{3.10}
\end{equation}</li>
<li>\(\exp(x)\) 是表示 \(\mathrm{e}^x\) 的指数函数( \(\mathrm{e}\) 是纳皮尔常数2.7182&#x2026;)</li>
<li>上述公式表示假设输出层有n个神经元,计算第k个神经元的输出 \(y_k\)</li>
<li>softmax函数的分子是输入信号 \(a_k\) 的指数函数,分母是所有输入信号的指数函数的和</li>
<li><p>
用图表示如下
</p>

<div id="org02f0d9a" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-22.png" alt="3-22.png" />
</p>
<p><span class="figure-number">Figure 32: </span>dlfs/3-22.png</p>
</div></li>
<li>这里箭头还是和图3-21一样表示计算时候有关联,那么我们可以看到:图3-22输出层每个神经元都受到所有输入信号的影响</li>
</ul></li>
<li>我们使用python来实现一遍softmax函数
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np

<span style="color: #715ab1;">a</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.3, 2.9, 4.0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">exp_a</span> = np.exp<span style="color: #3a81c3;">(</span>a<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|exp_a|=&gt;"""</span>, exp_a<span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">sum_exp_a</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>exp_a<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|sum_exp_a|=&gt;"""</span>, sum_exp_a<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">y</span> = exp_a / sum_exp_a
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|y|=&gt;"""</span>, y<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|exp_a|=&gt; [ 1.34985881 18.17414537 54.59815003]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|sum_exp_a|=&gt; 74.1221542101633</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|y|=&gt; [0.01821127 0.24519181 0.73659691]</span>
</pre>
</div></li>
<li>我们可以看到,softmax的数组结果加起来为1</li>
<li><p>
考虑到后面还要使用这段代码，我们把函数实现总结如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">softmax</span><span style="color: #3a81c3;">(</span>a<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">exp_a</span> = np.exp<span style="color: #3a81c3;">(</span>a<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">sum_exp_a</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>exp_a<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">y</span> = exp_a / sum_exp_a
    <span style="color: #3a81c3; font-weight: bold;">return</span> y
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org4f3123d" class="outline-4">
<h4 id="org4f3123d"><span class="section-number-4">3.5.2.</span> 实现softmax函数时的注意事项</h4>
<div class="outline-text-4" id="text-3-5-2">
<ul class="org-ul">
<li>上面的softmax函数的实现虽然正确的描述了公式3.10, 但是在计算的时候有一定的缺陷,因为函数的中间值可能
会变的非常大,比如:
<ul class="org-ul">
<li><p>
np.exp(10)就会超过2000
</p>
<div class="org-src-container">
<pre class="src src-python">&gt;&gt;&gt; np.exp<span style="color: #3a81c3;">(</span>10<span style="color: #3a81c3;">)</span>
22026.465794806718
</pre>
</div></li>
<li><p>
np.exp(100)会变成有40多个0 的超大值
</p>
<div class="org-src-container">
<pre class="src src-python">&gt;&gt;&gt; np.exp<span style="color: #3a81c3;">(</span>100<span style="color: #3a81c3;">)</span>
2.6881171418161356e+43
</pre>
</div></li>
<li><p>
np.exp(1000) 的结果会溢出
</p>
<div class="org-src-container">
<pre class="src src-python">&gt;&gt;&gt; np.exp<span style="color: #3a81c3;">(</span>1000<span style="color: #3a81c3;">)</span>
&lt;stdin&gt;:1: <span style="color: #ba2f59; font-weight: bold;">RuntimeWarning</span>: overflow encountered <span style="color: #3a81c3; font-weight: bold;">in</span> exp
inf
</pre>
</div></li>
</ul></li>
<li>为了让我们的计算过程中间值不要出现溢出(或者超大值,因为超大值之间的计算也可能出现问题),我们需要对公
式3.10进行改造
<ul class="org-ul">
<li><p>
新公式如下
</p>
\begin{align}
y_k    = \frac{\exp(a_k)}{\displaystyle \sum_{i=1}^{n} \exp(a_i)} &= \frac{\mathrm{C} \exp(a_k)}{\mathrm{C} \displaystyle \sum_{i=1}^{n} \exp(a_i)} \notag \\
     &  =  \frac{ \exp(a_k + \mathrm{log \;C})}{ \displaystyle \sum_{i=1}^{n} \exp(a_i + \mathrm{log \; C})} \notag \\
     &  =  \frac{ \exp(a_k + \mathrm{C'})}{ \displaystyle \sum_{i=1}^{n} \exp(a_i + \mathrm{C'})} \tag{3.11}
\end{align}</li>
<li>分子分母都乘以常数C,结果不变</li>
<li>把C移动到指数函数exp中,记作logC(也就是C')</li>
<li>公式3.11说明,在进行softmax函数计算的时候,加上或者减去一个常数不会改变结果,并且C'可以是任意值</li>
<li><p>
虽然C'可以是任意值,通常情况下,为了防止再出现溢出,我们会选择输入vector中最大的值来作为C'(这样np.exp
的参数最大的只可能是0),例子如下
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; a = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>1010, 1000, 990<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; np.exp<span style="color: #3a81c3;">(</span>a<span style="color: #3a81c3;">)</span> / np.sum<span style="color: #3a81c3;">(</span>np.exp<span style="color: #6c3163;">(</span>a<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
&lt;stdin&gt;:1: RuntimeWarning: invalid value encountered<span style="color: #3a81c3; font-weight: bold;"> in</span> divide
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>nan, nan, nan<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; c = np.max<span style="color: #3a81c3;">(</span>a<span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; c
1010
&gt;&gt;&gt; a - c
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>  0, -10, -20<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; np.exp<span style="color: #3a81c3;">(</span>a-c<span style="color: #3a81c3;">)</span> / np.sum<span style="color: #3a81c3;">(</span>np.exp<span style="color: #6c3163;">(</span>a-c<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #6c3163; font-weight: bold;">array</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>9.99954600e-01, 4.53978686e-05, 2.06106005e-09<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li><p>
公式3.11对应的代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">softmax</span><span style="color: #3a81c3;">(</span>a<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">c</span> = np.<span style="color: #3a81c3;">max</span><span style="color: #3a81c3;">(</span>a<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">exp_a</span> = np.exp<span style="color: #3a81c3;">(</span>a - c<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">sum_exp_a</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>exp_a<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">y</span> = exp_a / sum_exp_a
    <span style="color: #3a81c3; font-weight: bold;">return</span> y
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org9f7d230" class="outline-4">
<h4 id="org9f7d230"><span class="section-number-4">3.5.3.</span> softmax函数的特征</h4>
<div class="outline-text-4" id="text-3-5-3">
<ul class="org-ul">
<li>我们模拟一个输入[0.3, 2.9, 4.0], 看看softmax函数的输出有什么特点
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python">&gt;&gt;&gt; a = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.3, 2.9, 4.0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; y = softmax<span style="color: #3a81c3;">(</span>a<span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>y<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span>0.01821127 0.24519181 0.73659691<span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>y<span style="color: #3a81c3;">)</span>
1.0
</pre>
</div></li>
<li>如上所述,softmax函数的输出是0.0到1.0之间的实数</li>
<li><p>
softmax函数的输出值总和是1."输出值总和为1"是softmax函数的重要特征,正因为有了这个特征,我们才可以
把softmax邯郸的输出解释为"概率",比如上面的例子就可以从概率的角度解释为
</p>
<pre class="example" id="org42296f9">
有74%的概率是第2个类别,有25%的概率是第一个类别,有1%的概率是第0个类别
</pre></li>
<li>这里需要注意的是,即便使用了softmax函数,各个元素之间的大小关系也不会改变,因为指数函数( \(y = \exp(x)\) )
是单调递增函数. 比如上个例子中输入(也就是a)中最大的是第2个,输出(也就是y)中最大的也是第2个</li>
<li>一般而言,神经网络只把输出值最大的神经元所对应的类别作为识别结果,比如上面数组a就已经说明第2个元素
最大了,softmax计算过后选出来的还是第2个元素,那么再耗费计算资源去计算softmax就没有意义了.所以,我们
说:
<ol class="org-ol">
<li>在(模型已经创建好后)再进行分类,回归等"推理"阶段的时候,我们不计算softmax,因为没有意义</li>
<li>在(模型还在探索的)"学习"阶段,我们是要使用softmax函数的,具体信息我们后面会看到</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org7b62e00" class="outline-4">
<h4 id="org7b62e00"><span class="section-number-4">3.5.4.</span> 输出层的神经元数量</h4>
<div class="outline-text-4" id="text-3-5-4">
<ul class="org-ul">
<li><p>
输出层神经元的数量要根据待解决的问题来定:
</p>
<pre class="example" id="orgeaa5c0b">
对于分类问题,输出层的神经元数量一般设定为类别的数量
</pre></li>
<li>比如对于某个输入图像,预测图中数字是0-9中哪个数字的问题,我们将输出层神经元设定为10个
<ul class="org-ul">
<li><p>
如图
</p>

<div id="org2d97656" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-23.png" alt="3-23.png" />
</p>
<p><span class="figure-number">Figure 33: </span>dlfs/3-23.png</p>
</div></li>
<li>上图中神经元从上到下以此对应数字0-9</li>
<li>图中输出层神经元的值用不同灰度表示,颜色越深,输出值越大.上图中y2的颜色最深,表示这个神经元预测手写
输入的结果是y2对应的类别,也就是"2"</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orga32ed8f" class="outline-3">
<h3 id="orga32ed8f"><span class="section-number-3">3.6.</span> 手写数字识别</h3>
<div class="outline-text-3" id="text-3-6">
<ul class="org-ul">
<li><p>
我们本节来看一个神经网络的例子. 这个例子假设神经网络的"学习阶段"已经完成(也就是模型参数也存储下来了),
我们利用存储下来的模型参数来进行"推理阶段",推理一个模型没见过的新的输入.
</p>
<pre class="example" id="orgff56c58">
已知模型参数,对位置问题进行推理的过程,也被称为神经网络的前向传播(forward progagation)
</pre></li>
</ul>
</div>
<div id="outline-container-org1b784d8" class="outline-4">
<h4 id="org1b784d8"><span class="section-number-4">3.6.1.</span> MNIST数据集</h4>
<div class="outline-text-4" id="text-3-6-1">
<ul class="org-ul">
<li>MNIST数据集是由0到9的数字图像构成,其中:
<ul class="org-ul">
<li>训练图像有6万张</li>
<li>测试图像有1万张</li>
</ul></li>
<li>MNIST的图像数据是28像素*28像素的灰度图像,灰阶力度在0-255之间</li>
<li><p>
每个数据都相应的标记了"7","2", "1"等标签,如下图
</p>

<div id="orgd2f1ea9" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-24.png" alt="3-24.png" />
</p>
<p><span class="figure-number">Figure 34: </span>dlfs/3-24.png</p>
</div></li>
<li>本书提供了一个脚本下载mnist数据
<ul class="org-ul">
<li><p>
例子如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">try</span>:
    <span style="color: #3a81c3; font-weight: bold;">import</span> urllib.request
<span style="color: #3a81c3; font-weight: bold;">except</span> <span style="color: #ba2f59; font-weight: bold;">ImportError</span>:
    <span style="color: #3a81c3; font-weight: bold;">raise</span> <span style="color: #ba2f59; font-weight: bold;">ImportError</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"You should use Python 3.x"</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3; font-weight: bold;">import</span> os.path
<span style="color: #3a81c3; font-weight: bold;">import</span> gzip
<span style="color: #3a81c3; font-weight: bold;">import</span> pickle
<span style="color: #3a81c3; font-weight: bold;">import</span> os
<span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #715ab1;">url_base</span> = <span style="color: #2d9574;">"http://yann.lecun.com/exdb/mnist/"</span>
<span style="color: #715ab1;">key_file</span> = <span style="color: #3a81c3;">{</span>
    <span style="color: #2d9574;">"train_img"</span>: <span style="color: #2d9574;">"train-images-idx3-ubyte.gz"</span>,
    <span style="color: #2d9574;">"train_label"</span>: <span style="color: #2d9574;">"train-labels-idx1-ubyte.gz"</span>,
    <span style="color: #2d9574;">"test_img"</span>: <span style="color: #2d9574;">"t10k-images-idx3-ubyte.gz"</span>,
    <span style="color: #2d9574;">"test_label"</span>: <span style="color: #2d9574;">"t10k-labels-idx1-ubyte.gz"</span>,
<span style="color: #3a81c3;">}</span>

<span style="color: #715ab1;">dataset_dir</span> = os.path.dirname<span style="color: #3a81c3;">(</span>os.path.abspath<span style="color: #6c3163;">(</span>__file__<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">save_file</span> = dataset_dir + <span style="color: #2d9574;">"/mnist.pkl"</span>

<span style="color: #715ab1;">train_num</span> = 60000
<span style="color: #715ab1;">test_num</span> = 10000
<span style="color: #715ab1;">img_dim</span> = <span style="color: #3a81c3;">(</span>1, 28, 28<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">img_size</span> = 784


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_download</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3; font-weight: bold;">if</span> os.path.exists<span style="color: #3a81c3;">(</span>file_path<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span>

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Downloading "</span> + file_name + <span style="color: #2d9574;">" ... "</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">headers</span> = <span style="color: #3a81c3;">{</span>
        <span style="color: #2d9574;">"User-Agent"</span>: <span style="color: #2d9574;">"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0"</span>
    <span style="color: #3a81c3;">}</span>
    <span style="color: #715ab1;">request</span> = urllib.request.Request<span style="color: #3a81c3;">(</span>url_base + file_name, headers=headers<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">response</span> = urllib.request.urlopen<span style="color: #3a81c3;">(</span>request<span style="color: #3a81c3;">)</span>.read<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, mode=<span style="color: #2d9574;">"wb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        f.write<span style="color: #3a81c3;">(</span>response<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">download_mnist</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3; font-weight: bold;">for</span> v <span style="color: #3a81c3; font-weight: bold;">in</span> key_file.values<span style="color: #3a81c3;">()</span>:
        _download<span style="color: #3a81c3;">(</span>v<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_load_label</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Converting "</span> + file_name + <span style="color: #2d9574;">" to NumPy Array ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> gzip.<span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">labels</span> = np.frombuffer<span style="color: #3a81c3;">(</span>f.read<span style="color: #6c3163;">()</span>, np.uint8, offset=8<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> labels


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_load_img</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Converting "</span> + file_name + <span style="color: #2d9574;">" to NumPy Array ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> gzip.<span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">data</span> = np.frombuffer<span style="color: #3a81c3;">(</span>f.read<span style="color: #6c3163;">()</span>, np.uint8, offset=16<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">data</span> = data.reshape<span style="color: #3a81c3;">(</span>-1, img_size<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> data


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_convert_numpy</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #715ab1;">dataset</span> = <span style="color: #3a81c3;">{}</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #3a81c3;">]</span> = _load_img<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #3a81c3;">]</span> = _load_label<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">]</span> = _load_img<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #3a81c3;">]</span> = _load_label<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> dataset


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">init_mnist</span><span style="color: #3a81c3;">()</span>:
    download_mnist<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">dataset</span> = _convert_numpy<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Creating pickle file ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>save_file, <span style="color: #2d9574;">"wb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        pickle.dump<span style="color: #3a81c3;">(</span>dataset, f, -1<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done!"</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_change_one_hot_label</span><span style="color: #3a81c3;">(</span>X<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">T</span> = np.zeros<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">(</span>X.size, 10<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">for</span> idx, row <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">enumerate</span><span style="color: #3a81c3;">(</span>T<span style="color: #3a81c3;">)</span>:
        row<span style="color: #3a81c3;">[</span>X<span style="color: #6c3163;">[</span>idx<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">]</span> = 1

    <span style="color: #3a81c3; font-weight: bold;">return</span> T


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">load_mnist</span><span style="color: #3a81c3;">(</span>normalize=<span style="color: #4e3163;">True</span>, flatten=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">False</span><span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">not</span> os.path.exists<span style="color: #3a81c3;">(</span>save_file<span style="color: #3a81c3;">)</span>:
        init_mnist<span style="color: #3a81c3;">()</span>

    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>save_file, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">dataset</span> = pickle.load<span style="color: #3a81c3;">(</span>f<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> normalize:
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train_img"</span>, <span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">)</span>:
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> = dataset<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>.astype<span style="color: #3a81c3;">(</span>np.float32<span style="color: #3a81c3;">)</span>
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> /= 255.0

    <span style="color: #3a81c3; font-weight: bold;">if</span> one_hot_label:
        <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #3a81c3;">]</span> = _change_one_hot_label<span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #3a81c3;">]</span> = _change_one_hot_label<span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">not</span> flatten:
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train_img"</span>, <span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">)</span>:
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> = dataset<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>.reshape<span style="color: #3a81c3;">(</span>-1, 1, 28, 28<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #6c3163;">]</span>, dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span>
        dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #6c3163;">]</span>,
        dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span>,
    <span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #3a81c3;">(</span>x_train, t_train<span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span><span style="color: #715ab1;">x_test</span>, <span style="color: #715ab1;">t_test</span><span style="color: #3a81c3;">)</span> = load_mnist<span style="color: #3a81c3;">(</span>flatten=<span style="color: #4e3163;">True</span>, normalize=<span style="color: #4e3163;">False</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>x_train.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>t_train.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>x_test.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>t_test.shape<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Downloading train-images-idx3-ubyte.gz ...</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Done</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Downloading train-labels-idx1-ubyte.gz ...</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Done</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Downloading t10k-images-idx3-ubyte.gz ...</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Done</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Downloading t10k-labels-idx1-ubyte.gz ...</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Done</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Converting train-images-idx3-ubyte.gz to NumPy Array ...</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Done</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Converting train-labels-idx1-ubyte.gz to NumPy Array ...</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Done</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Converting t10k-images-idx3-ubyte.gz to NumPy Array ...</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Done</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Done</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Creating pickle file ...</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Done!</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(60000, 784)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(60000,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(10000, 784)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(10000,)</span>
</pre>
</div></li>
<li>我们的load_mnist有三个参数:
<ol class="org-ol">
<li>normalize=True, 默认参数要正则化，也就是说图像像素数组（无论是一维还是二维）不再是0-255,而是0.0-1.0, 我们选择不要正则化</li>
<li>flattern=True, 默认图像数组是打扁的，也就是一维数组成员是784个，成员数据为0-255或者是0.0-1.0</li>
<li>one_hot_label=False，默认标签是不要one-hot的，而是7,2这种数字</li>
</ol></li>
<li>由于我们选择了flatten为true，所以我们的结果是一个打扁了的图像文件总像素是784</li>
<li><p>
这个例子第一次会下载数据到本地，也就是如下几个压缩文件
</p>
<pre class="example" id="org6084377">
t10k-images-idx3-ubyte.gz
t10k-labels-idx1-ubyte.gz
train-images-idx3-ubyte.gz
train-labels-idx1-ubyte.gz
</pre></li>
<li><p>
然后，程序还会把这些压缩文件存储到pickle文件（这是python默认的二进制导出文件）
</p>
<pre class="example" id="orgad5ab43">
mnist.pkl
</pre></li>
</ul></li>
<li>我们下面为了体验一下数据，选择训练集的第一个数据，打印出来
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">try</span>:
    <span style="color: #3a81c3; font-weight: bold;">import</span> urllib.request
<span style="color: #3a81c3; font-weight: bold;">except</span> <span style="color: #ba2f59; font-weight: bold;">ImportError</span>:
    <span style="color: #3a81c3; font-weight: bold;">raise</span> <span style="color: #ba2f59; font-weight: bold;">ImportError</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"You should use Python 3.x"</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3; font-weight: bold;">import</span> os.path
<span style="color: #3a81c3; font-weight: bold;">import</span> gzip
<span style="color: #3a81c3; font-weight: bold;">import</span> pickle
<span style="color: #3a81c3; font-weight: bold;">import</span> os
<span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #715ab1;">url_base</span> = <span style="color: #2d9574;">"http://yann.lecun.com/exdb/mnist/"</span>
<span style="color: #715ab1;">key_file</span> = <span style="color: #3a81c3;">{</span>
    <span style="color: #2d9574;">"train_img"</span>: <span style="color: #2d9574;">"train-images-idx3-ubyte.gz"</span>,
    <span style="color: #2d9574;">"train_label"</span>: <span style="color: #2d9574;">"train-labels-idx1-ubyte.gz"</span>,
    <span style="color: #2d9574;">"test_img"</span>: <span style="color: #2d9574;">"t10k-images-idx3-ubyte.gz"</span>,
    <span style="color: #2d9574;">"test_label"</span>: <span style="color: #2d9574;">"t10k-labels-idx1-ubyte.gz"</span>,
<span style="color: #3a81c3;">}</span>

<span style="color: #715ab1;">dataset_dir</span> = os.path.dirname<span style="color: #3a81c3;">(</span>os.path.abspath<span style="color: #6c3163;">(</span>__file__<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">save_file</span> = dataset_dir + <span style="color: #2d9574;">"/mnist.pkl"</span>

<span style="color: #715ab1;">train_num</span> = 60000
<span style="color: #715ab1;">test_num</span> = 10000
<span style="color: #715ab1;">img_dim</span> = <span style="color: #3a81c3;">(</span>1, 28, 28<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">img_size</span> = 784


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_download</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3; font-weight: bold;">if</span> os.path.exists<span style="color: #3a81c3;">(</span>file_path<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span>

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Downloading "</span> + file_name + <span style="color: #2d9574;">" ... "</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">headers</span> = <span style="color: #3a81c3;">{</span>
        <span style="color: #2d9574;">"User-Agent"</span>: <span style="color: #2d9574;">"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0"</span>
    <span style="color: #3a81c3;">}</span>
    <span style="color: #715ab1;">request</span> = urllib.request.Request<span style="color: #3a81c3;">(</span>url_base + file_name, headers=headers<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">response</span> = urllib.request.urlopen<span style="color: #3a81c3;">(</span>request<span style="color: #3a81c3;">)</span>.read<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, mode=<span style="color: #2d9574;">"wb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        f.write<span style="color: #3a81c3;">(</span>response<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">download_mnist</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3; font-weight: bold;">for</span> v <span style="color: #3a81c3; font-weight: bold;">in</span> key_file.values<span style="color: #3a81c3;">()</span>:
        _download<span style="color: #3a81c3;">(</span>v<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_load_label</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Converting "</span> + file_name + <span style="color: #2d9574;">" to NumPy Array ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> gzip.<span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">labels</span> = np.frombuffer<span style="color: #3a81c3;">(</span>f.read<span style="color: #6c3163;">()</span>, np.uint8, offset=8<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> labels


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_load_img</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Converting "</span> + file_name + <span style="color: #2d9574;">" to NumPy Array ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> gzip.<span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">data</span> = np.frombuffer<span style="color: #3a81c3;">(</span>f.read<span style="color: #6c3163;">()</span>, np.uint8, offset=16<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">data</span> = data.reshape<span style="color: #3a81c3;">(</span>-1, img_size<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> data


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_convert_numpy</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #715ab1;">dataset</span> = <span style="color: #3a81c3;">{}</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #3a81c3;">]</span> = _load_img<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #3a81c3;">]</span> = _load_label<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">]</span> = _load_img<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #3a81c3;">]</span> = _load_label<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> dataset


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">init_mnist</span><span style="color: #3a81c3;">()</span>:
    download_mnist<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">dataset</span> = _convert_numpy<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Creating pickle file ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>save_file, <span style="color: #2d9574;">"wb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        pickle.dump<span style="color: #3a81c3;">(</span>dataset, f, -1<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done!"</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_change_one_hot_label</span><span style="color: #3a81c3;">(</span>X<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">T</span> = np.zeros<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">(</span>X.size, 10<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">for</span> idx, row <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">enumerate</span><span style="color: #3a81c3;">(</span>T<span style="color: #3a81c3;">)</span>:
        row<span style="color: #3a81c3;">[</span>X<span style="color: #6c3163;">[</span>idx<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">]</span> = 1

    <span style="color: #3a81c3; font-weight: bold;">return</span> T


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">load_mnist</span><span style="color: #3a81c3;">(</span>normalize=<span style="color: #4e3163;">True</span>, flatten=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">False</span><span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">not</span> os.path.exists<span style="color: #3a81c3;">(</span>save_file<span style="color: #3a81c3;">)</span>:
        init_mnist<span style="color: #3a81c3;">()</span>

    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>save_file, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">dataset</span> = pickle.load<span style="color: #3a81c3;">(</span>f<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> normalize:
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train_img"</span>, <span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">)</span>:
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> = dataset<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>.astype<span style="color: #3a81c3;">(</span>np.float32<span style="color: #3a81c3;">)</span>
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> /= 255.0

    <span style="color: #3a81c3; font-weight: bold;">if</span> one_hot_label:
        <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #3a81c3;">]</span> = _change_one_hot_label<span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #3a81c3;">]</span> = _change_one_hot_label<span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">not</span> flatten:
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train_img"</span>, <span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">)</span>:
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> = dataset<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>.reshape<span style="color: #3a81c3;">(</span>-1, 1, 28, 28<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #6c3163;">]</span>, dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span>
        dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #6c3163;">]</span>,
        dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span>,
    <span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">img_show</span><span style="color: #3a81c3;">(</span>img<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">from</span> PIL <span style="color: #3a81c3; font-weight: bold;">import</span> Image

    <span style="color: #715ab1;">pil_img</span> = Image.fromarray<span style="color: #3a81c3;">(</span>np.uint8<span style="color: #6c3163;">(</span>img<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    pil_img.show<span style="color: #3a81c3;">()</span>


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #3a81c3;">(</span>x_train, t_train<span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span><span style="color: #715ab1;">x_test</span>, <span style="color: #715ab1;">t_test</span><span style="color: #3a81c3;">)</span> = load_mnist<span style="color: #3a81c3;">(</span>flatten=<span style="color: #4e3163;">True</span>, normalize=<span style="color: #4e3163;">False</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">img</span> = x_train<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span>
    <span style="color: #715ab1;">label</span> = t_train<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>label<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>img.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">img</span> = img.reshape<span style="color: #3a81c3;">(</span>28, 28<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>img.shape<span style="color: #3a81c3;">)</span>
    img_show<span style="color: #3a81c3;">(</span>img<span style="color: #3a81c3;">)</span>


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;"># &lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">5</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(784,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(28, 28)</span>
</pre>
</div></li>
<li>我们从训练集的label可以看到，这个图的正确结果是一个5</li>
<li>我们想打印这个数据，但是因为我们flattern过，所以我们要reshape之后，再打印，我们在命令行运行会看到
一个图像5</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org10acdd2" class="outline-4">
<h4 id="org10acdd2"><span class="section-number-4">3.6.2.</span> 神经网络的推理处理</h4>
<div class="outline-text-4" id="text-3-6-2">
<ul class="org-ul">
<li>我们下面对这个MNIST数据集进行推理处理:
<ul class="org-ul">
<li>首先还是要注意,推理处理是在已经学习到"参数"的情况下进行的,我们的代码使用了之前已经学习好的参数,
并且把他们存储在了sample_weight.pkl</li>
<li>识别一个MNIST图像,就要把图像分解成像素.我们这里把输入的像素打平成一维数组,长度是784,那么我们的神
经网络的输入层就是有784个神经元</li>
<li>而我们识别的目的是0-9这个十个数字,所以我们的输出层就是有10个神经元</li>
<li>因为我们使用了已有的"参数"(存储在sample_weight.pkl),这个"参数"为整个神经网络设计了两个隐藏层:
<ol class="org-ol">
<li>第一个隐藏层有50个神经元</li>
<li>第二个隐藏层有100个单元</li>
</ol></li>
<li>设计几个隐藏层,每层有多少个神经元是一个玄学,我们称之为"超参"</li>
<li><p>
整个过程的全部代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> urllib.request
<span style="color: #3a81c3; font-weight: bold;">import</span> gzip
<span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
<span style="color: #3a81c3; font-weight: bold;">import</span> os
<span style="color: #3a81c3; font-weight: bold;">import</span> pickle

<span style="color: #715ab1;">url_base</span> = <span style="color: #2d9574;">"http://yann.lecun.com/exdb/mnist/"</span>
<span style="color: #715ab1;">key_file</span> = <span style="color: #3a81c3;">{</span>
    <span style="color: #2d9574;">"train_img"</span>: <span style="color: #2d9574;">"train-images-idx3-ubyte.gz"</span>,
    <span style="color: #2d9574;">"train_label"</span>: <span style="color: #2d9574;">"train-labels-idx1-ubyte.gz"</span>,
    <span style="color: #2d9574;">"test_img"</span>: <span style="color: #2d9574;">"t10k-images-idx3-ubyte.gz"</span>,
    <span style="color: #2d9574;">"test_label"</span>: <span style="color: #2d9574;">"t10k-labels-idx1-ubyte.gz"</span>,
<span style="color: #3a81c3;">}</span>

<span style="color: #715ab1;">dataset_dir</span> = os.path.dirname<span style="color: #3a81c3;">(</span>os.path.abspath<span style="color: #6c3163;">(</span>__file__<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">save_file</span> = dataset_dir + <span style="color: #2d9574;">"/mnist.pkl"</span>

<span style="color: #715ab1;">train_num</span> = 60000
<span style="color: #715ab1;">test_num</span> = 10000
<span style="color: #715ab1;">img_dim</span> = <span style="color: #3a81c3;">(</span>1, 28, 28<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">img_size</span> = 784


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_download</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3; font-weight: bold;">if</span> os.path.exists<span style="color: #3a81c3;">(</span>file_path<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span>

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Downloading "</span> + file_name + <span style="color: #2d9574;">" ... "</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">headers</span> = <span style="color: #3a81c3;">{</span>
        <span style="color: #2d9574;">"User-Agent"</span>: <span style="color: #2d9574;">"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0"</span>
    <span style="color: #3a81c3;">}</span>
    <span style="color: #715ab1;">request</span> = urllib.request.Request<span style="color: #3a81c3;">(</span>url_base + file_name, headers=headers<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">response</span> = urllib.request.urlopen<span style="color: #3a81c3;">(</span>request<span style="color: #3a81c3;">)</span>.read<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, mode=<span style="color: #2d9574;">"wb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        f.write<span style="color: #3a81c3;">(</span>response<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">download_mnist</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3; font-weight: bold;">for</span> v <span style="color: #3a81c3; font-weight: bold;">in</span> key_file.values<span style="color: #3a81c3;">()</span>:
        _download<span style="color: #3a81c3;">(</span>v<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_load_label</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Converting "</span> + file_name + <span style="color: #2d9574;">" to NumPy Array ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> gzip.<span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">labels</span> = np.frombuffer<span style="color: #3a81c3;">(</span>f.read<span style="color: #6c3163;">()</span>, np.uint8, offset=8<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> labels


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_load_img</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Converting "</span> + file_name + <span style="color: #2d9574;">" to NumPy Array ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> gzip.<span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">data</span> = np.frombuffer<span style="color: #3a81c3;">(</span>f.read<span style="color: #6c3163;">()</span>, np.uint8, offset=16<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">data</span> = data.reshape<span style="color: #3a81c3;">(</span>-1, img_size<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> data


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_convert_numpy</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #715ab1;">dataset</span> = <span style="color: #3a81c3;">{}</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #3a81c3;">]</span> = _load_img<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #3a81c3;">]</span> = _load_label<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">]</span> = _load_img<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #3a81c3;">]</span> = _load_label<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> dataset


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">init_mnist</span><span style="color: #3a81c3;">()</span>:
    download_mnist<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">dataset</span> = _convert_numpy<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Creating pickle file ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>save_file, <span style="color: #2d9574;">"wb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        pickle.dump<span style="color: #3a81c3;">(</span>dataset, f, -1<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done!"</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_change_one_hot_label</span><span style="color: #3a81c3;">(</span>X<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">T</span> = np.zeros<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">(</span>X.size, 10<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">for</span> idx, row <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">enumerate</span><span style="color: #3a81c3;">(</span>T<span style="color: #3a81c3;">)</span>:
        row<span style="color: #3a81c3;">[</span>X<span style="color: #6c3163;">[</span>idx<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">]</span> = 1

    <span style="color: #3a81c3; font-weight: bold;">return</span> T


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">load_mnist</span><span style="color: #3a81c3;">(</span>normalize=<span style="color: #4e3163;">True</span>, flatten=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">False</span><span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">not</span> os.path.exists<span style="color: #3a81c3;">(</span>save_file<span style="color: #3a81c3;">)</span>:
        init_mnist<span style="color: #3a81c3;">()</span>

    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>save_file, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">dataset</span> = pickle.load<span style="color: #3a81c3;">(</span>f<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> normalize:
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train_img"</span>, <span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">)</span>:
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> = dataset<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>.astype<span style="color: #3a81c3;">(</span>np.float32<span style="color: #3a81c3;">)</span>
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> /= 255.0

    <span style="color: #3a81c3; font-weight: bold;">if</span> one_hot_label:
        <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #3a81c3;">]</span> = _change_one_hot_label<span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #3a81c3;">]</span> = _change_one_hot_label<span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">not</span> flatten:
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train_img"</span>, <span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">)</span>:
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> = dataset<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>.reshape<span style="color: #3a81c3;">(</span>-1, 1, 28, 28<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #6c3163;">]</span>, dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span>
        dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #6c3163;">]</span>,
        dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span>,
    <span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sigmoid</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 1 / <span style="color: #3a81c3;">(</span>1 + np.exp<span style="color: #6c3163;">(</span>-x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">softmax</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = x - np.<span style="color: #3a81c3;">max</span><span style="color: #3a81c3;">(</span>x, axis=-1, keepdims=<span style="color: #4e3163;">True</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> np.exp<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span> / np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>np.exp<span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span>, axis=-1, keepdims=<span style="color: #4e3163;">True</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">get_data</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3;">(</span>x_train, t_train<span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span><span style="color: #715ab1;">x_test</span>, <span style="color: #715ab1;">t_test</span><span style="color: #3a81c3;">)</span> = load_mnist<span style="color: #3a81c3;">(</span>
        normalize=<span style="color: #4e3163;">True</span>, flatten=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">False</span>
    <span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> x_test, t_test


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">init_network</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"sample_weight.pkl"</span>, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">network</span> = pickle.load<span style="color: #3a81c3;">(</span>f<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> network


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">predict</span><span style="color: #3a81c3;">(</span>network, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">W1</span>, <span style="color: #715ab1;">W2</span>, <span style="color: #715ab1;">W3</span> = network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W3"</span><span style="color: #3a81c3;">]</span>
    <span style="color: #715ab1;">b1</span>, <span style="color: #715ab1;">b2</span>, <span style="color: #715ab1;">b3</span> = network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b3"</span><span style="color: #3a81c3;">]</span>

    <span style="color: #715ab1;">a1</span> = np.dot<span style="color: #3a81c3;">(</span>x, W1<span style="color: #3a81c3;">)</span> + b1
    <span style="color: #715ab1;">z1</span> = sigmoid<span style="color: #3a81c3;">(</span>a1<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">a2</span> = np.dot<span style="color: #3a81c3;">(</span>z1, W2<span style="color: #3a81c3;">)</span> + b2
    <span style="color: #715ab1;">z2</span> = sigmoid<span style="color: #3a81c3;">(</span>a2<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">a3</span> = np.dot<span style="color: #3a81c3;">(</span>z2, W3<span style="color: #3a81c3;">)</span> + b3
    <span style="color: #715ab1;">y</span> = softmax<span style="color: #3a81c3;">(</span>a3<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> y


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #715ab1;">x</span>, <span style="color: #715ab1;">t</span> = get_data<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">network</span> = init_network<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">accuracy_cnt</span> = 0
    <span style="color: #3a81c3; font-weight: bold;">for</span> i <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">range</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3;">len</span><span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">y</span> = predict<span style="color: #3a81c3;">(</span>network, x<span style="color: #6c3163;">[</span>i<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">p</span> = np.argmax<span style="color: #3a81c3;">(</span>y<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">if</span> p == t<span style="color: #3a81c3;">[</span>i<span style="color: #3a81c3;">]</span>:
            <span style="color: #715ab1;">accuracy_cnt</span> += 1

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Accuracy:"</span> + <span style="color: #3a81c3;">str</span><span style="color: #6c3163;">(</span><span style="color: #3a81c3;">float</span><span style="color: #2d9574;">(</span>accuracy_cnt<span style="color: #2d9574;">)</span> / <span style="color: #3a81c3;">len</span><span style="color: #2d9574;">(</span>x<span style="color: #2d9574;">)</span><span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Accuracy:0.9352</span>
</pre>
</div></li>
<li><p>
"推理"一个图像属于哪个数字的代码如下(输入是一个长度为784的数组,输出是一个长度为10的数组,表明图像是0-9的概率)
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">get_data</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3;">(</span>x_train, t_train<span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span><span style="color: #715ab1;">x_test</span>, <span style="color: #715ab1;">t_test</span><span style="color: #3a81c3;">)</span> = load_mnist<span style="color: #3a81c3;">(</span>
        normalize=<span style="color: #4e3163;">True</span>, flatten=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">False</span>
    <span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> x_test, t_test


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">init_network</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"sample_weight.pkl"</span>, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">network</span> = pickle.load<span style="color: #3a81c3;">(</span>f<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> network


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">predict</span><span style="color: #3a81c3;">(</span>network, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">W1</span>, <span style="color: #715ab1;">W2</span>, <span style="color: #715ab1;">W3</span> = network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W3"</span><span style="color: #3a81c3;">]</span>
    <span style="color: #715ab1;">b1</span>, <span style="color: #715ab1;">b2</span>, <span style="color: #715ab1;">b3</span> = network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b3"</span><span style="color: #3a81c3;">]</span>

    <span style="color: #715ab1;">a1</span> = np.dot<span style="color: #3a81c3;">(</span>x, W1<span style="color: #3a81c3;">)</span> + b1
    <span style="color: #715ab1;">z1</span> = sigmoid<span style="color: #3a81c3;">(</span>a1<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">a2</span> = np.dot<span style="color: #3a81c3;">(</span>z1, W2<span style="color: #3a81c3;">)</span> + b2
    <span style="color: #715ab1;">z2</span> = sigmoid<span style="color: #3a81c3;">(</span>a2<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">a3</span> = np.dot<span style="color: #3a81c3;">(</span>z2, W3<span style="color: #3a81c3;">)</span> + b3
    <span style="color: #715ab1;">y</span> = softmax<span style="color: #3a81c3;">(</span>a3<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> y
</pre>
</div></li>
<li><p>
"参数"并不是我们训练的,我们只是用这个"参数"来进行"推理",判定这个"参数"好不好的标志,就是看看这个
参数判断100个(没见过的)图像能判断对几个.首先获取"没见过的图像"
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">get_data</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3;">(</span>x_train, t_train<span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span><span style="color: #715ab1;">x_test</span>, <span style="color: #715ab1;">t_test</span><span style="color: #3a81c3;">)</span> = load_mnist<span style="color: #3a81c3;">(</span>
        normalize=<span style="color: #4e3163;">True</span>, flatten=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">False</span>
    <span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> x_test, t_test
</pre>
</div></li>
<li><p>
然后我们在main函数里面就是判定"参数"能够在"没见过"的图像里面,正确的认识几个:通过 np.argmax(y) 获
取到概率最大的数字,并且和标签t[i]进行比较,相等算"推理"成功一个
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #715ab1;">x</span>, <span style="color: #715ab1;">t</span> = get_data<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">network</span> = init_network<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">accuracy_cnt</span> = 0
    <span style="color: #3a81c3; font-weight: bold;">for</span> i <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">range</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3;">len</span><span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">y</span> = predict<span style="color: #3a81c3;">(</span>network, x<span style="color: #6c3163;">[</span>i<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">p</span> = np.argmax<span style="color: #3a81c3;">(</span>y<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">if</span> p == t<span style="color: #3a81c3;">[</span>i<span style="color: #3a81c3;">]</span>:
            <span style="color: #715ab1;">accuracy_cnt</span> += 1

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Accuracy:"</span> + <span style="color: #3a81c3;">str</span><span style="color: #6c3163;">(</span><span style="color: #3a81c3;">float</span><span style="color: #2d9574;">(</span>accuracy_cnt<span style="color: #2d9574;">)</span> / <span style="color: #3a81c3;">len</span><span style="color: #2d9574;">(</span>x<span style="color: #2d9574;">)</span><span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Accuracy:0.9352</span>
</pre>
</div></li>
<li><p>
还有一点,我们在load_mnist的时候把normalize设置成了True,这就意味着数组的784个成员,每个都是0-1.0,
像这样吧数据限定到某个范围内的处理称之为正规化(normalization),正规化能够提高深度学习模型的性能
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3;">(</span>x_train, t_train<span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span><span style="color: #715ab1;">x_test</span>, <span style="color: #715ab1;">t_test</span><span style="color: #3a81c3;">)</span> = load_mnist<span style="color: #3a81c3;">(</span>
    normalize=<span style="color: #4e3163;">True</span>, flatten=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">False</span>
<span style="color: #3a81c3;">)</span>
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgd824b97" class="outline-4">
<h4 id="orgd824b97"><span class="section-number-4">3.6.3.</span> 批处理</h4>
<div class="outline-text-4" id="text-3-6-3">
<ul class="org-ul">
<li>上述是一次性处理一个image的情况,最终的输出是一个一维数组,长度是10,分别代表image为0-9的概率
<ul class="org-ul">
<li><p>
一次性处理一个image的参数列表如下
</p>

<div id="orge3cf6bc" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-26.png" alt="3-26.png" />
</p>
<p><span class="figure-number">Figure 35: </span>dlfs/3-26.png</p>
</div></li>
<li>我们可以看到,我们的输入参数可以理解为1*784,输出是1*10</li>
<li><p>
那么如果我们每次传入100张图片呢?其实就是输入变成了100*784,我们的"参数"完全不用更改,最后的结果也
变了,变成了100*10,如下图
</p>

<div id="org3cd53b1" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/3-27.png" alt="3-27.png" />
</p>
<p><span class="figure-number">Figure 36: </span>dlfs/3-27.png</p>
</div></li>
<li>输入变成一百个,输出也相应变成100个,这得益于矩阵的特性.这种打包式的输入称之为批(batch)</li>
</ul></li>
<li>批处理只会更改部分代码
<ul class="org-ul">
<li><p>
总体代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> urllib.request
<span style="color: #3a81c3; font-weight: bold;">import</span> gzip
<span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
<span style="color: #3a81c3; font-weight: bold;">import</span> os
<span style="color: #3a81c3; font-weight: bold;">import</span> pickle

<span style="color: #715ab1;">url_base</span> = <span style="color: #2d9574;">"http://yann.lecun.com/exdb/mnist/"</span>
<span style="color: #715ab1;">key_file</span> = <span style="color: #3a81c3;">{</span>
    <span style="color: #2d9574;">"train_img"</span>: <span style="color: #2d9574;">"train-images-idx3-ubyte.gz"</span>,
    <span style="color: #2d9574;">"train_label"</span>: <span style="color: #2d9574;">"train-labels-idx1-ubyte.gz"</span>,
    <span style="color: #2d9574;">"test_img"</span>: <span style="color: #2d9574;">"t10k-images-idx3-ubyte.gz"</span>,
    <span style="color: #2d9574;">"test_label"</span>: <span style="color: #2d9574;">"t10k-labels-idx1-ubyte.gz"</span>,
<span style="color: #3a81c3;">}</span>

<span style="color: #715ab1;">dataset_dir</span> = os.path.dirname<span style="color: #3a81c3;">(</span>os.path.abspath<span style="color: #6c3163;">(</span>__file__<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">save_file</span> = dataset_dir + <span style="color: #2d9574;">"/mnist.pkl"</span>

<span style="color: #715ab1;">train_num</span> = 60000
<span style="color: #715ab1;">test_num</span> = 10000
<span style="color: #715ab1;">img_dim</span> = <span style="color: #3a81c3;">(</span>1, 28, 28<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">img_size</span> = 784


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_download</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3; font-weight: bold;">if</span> os.path.exists<span style="color: #3a81c3;">(</span>file_path<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span>

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Downloading "</span> + file_name + <span style="color: #2d9574;">" ... "</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">headers</span> = <span style="color: #3a81c3;">{</span>
        <span style="color: #2d9574;">"User-Agent"</span>: <span style="color: #2d9574;">"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0"</span>
    <span style="color: #3a81c3;">}</span>
    <span style="color: #715ab1;">request</span> = urllib.request.Request<span style="color: #3a81c3;">(</span>url_base + file_name, headers=headers<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">response</span> = urllib.request.urlopen<span style="color: #3a81c3;">(</span>request<span style="color: #3a81c3;">)</span>.read<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, mode=<span style="color: #2d9574;">"wb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        f.write<span style="color: #3a81c3;">(</span>response<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">download_mnist</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3; font-weight: bold;">for</span> v <span style="color: #3a81c3; font-weight: bold;">in</span> key_file.values<span style="color: #3a81c3;">()</span>:
        _download<span style="color: #3a81c3;">(</span>v<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_load_label</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Converting "</span> + file_name + <span style="color: #2d9574;">" to NumPy Array ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> gzip.<span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">labels</span> = np.frombuffer<span style="color: #3a81c3;">(</span>f.read<span style="color: #6c3163;">()</span>, np.uint8, offset=8<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> labels


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_load_img</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Converting "</span> + file_name + <span style="color: #2d9574;">" to NumPy Array ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> gzip.<span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">data</span> = np.frombuffer<span style="color: #3a81c3;">(</span>f.read<span style="color: #6c3163;">()</span>, np.uint8, offset=16<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">data</span> = data.reshape<span style="color: #3a81c3;">(</span>-1, img_size<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> data


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_convert_numpy</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #715ab1;">dataset</span> = <span style="color: #3a81c3;">{}</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #3a81c3;">]</span> = _load_img<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #3a81c3;">]</span> = _load_label<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">]</span> = _load_img<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #3a81c3;">]</span> = _load_label<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> dataset


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">init_mnist</span><span style="color: #3a81c3;">()</span>:
    download_mnist<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">dataset</span> = _convert_numpy<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Creating pickle file ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>save_file, <span style="color: #2d9574;">"wb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        pickle.dump<span style="color: #3a81c3;">(</span>dataset, f, -1<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done!"</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_change_one_hot_label</span><span style="color: #3a81c3;">(</span>X<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">T</span> = np.zeros<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">(</span>X.size, 10<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">for</span> idx, row <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">enumerate</span><span style="color: #3a81c3;">(</span>T<span style="color: #3a81c3;">)</span>:
        row<span style="color: #3a81c3;">[</span>X<span style="color: #6c3163;">[</span>idx<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">]</span> = 1

    <span style="color: #3a81c3; font-weight: bold;">return</span> T


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">load_mnist</span><span style="color: #3a81c3;">(</span>normalize=<span style="color: #4e3163;">True</span>, flatten=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">False</span><span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">not</span> os.path.exists<span style="color: #3a81c3;">(</span>save_file<span style="color: #3a81c3;">)</span>:
        init_mnist<span style="color: #3a81c3;">()</span>

    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>save_file, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">dataset</span> = pickle.load<span style="color: #3a81c3;">(</span>f<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> normalize:
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train_img"</span>, <span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">)</span>:
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> = dataset<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>.astype<span style="color: #3a81c3;">(</span>np.float32<span style="color: #3a81c3;">)</span>
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> /= 255.0

    <span style="color: #3a81c3; font-weight: bold;">if</span> one_hot_label:
        <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #3a81c3;">]</span> = _change_one_hot_label<span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #3a81c3;">]</span> = _change_one_hot_label<span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">not</span> flatten:
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train_img"</span>, <span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">)</span>:
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> = dataset<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>.reshape<span style="color: #3a81c3;">(</span>-1, 1, 28, 28<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #6c3163;">]</span>, dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span>
        dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #6c3163;">]</span>,
        dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span>,
    <span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sigmoid</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 1 / <span style="color: #3a81c3;">(</span>1 + np.exp<span style="color: #6c3163;">(</span>-x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">softmax</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = x - np.<span style="color: #3a81c3;">max</span><span style="color: #3a81c3;">(</span>x, axis=-1, keepdims=<span style="color: #4e3163;">True</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> np.exp<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span> / np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>np.exp<span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span>, axis=-1, keepdims=<span style="color: #4e3163;">True</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">get_data</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3;">(</span>x_train, t_train<span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span><span style="color: #715ab1;">x_test</span>, <span style="color: #715ab1;">t_test</span><span style="color: #3a81c3;">)</span> = load_mnist<span style="color: #3a81c3;">(</span>
        normalize=<span style="color: #4e3163;">True</span>, flatten=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">False</span>
    <span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> x_test, t_test


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">init_network</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"sample_weight.pkl"</span>, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">network</span> = pickle.load<span style="color: #3a81c3;">(</span>f<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> network


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">predict</span><span style="color: #3a81c3;">(</span>network, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">W1</span>, <span style="color: #715ab1;">W2</span>, <span style="color: #715ab1;">W3</span> = network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W3"</span><span style="color: #3a81c3;">]</span>
    <span style="color: #715ab1;">b1</span>, <span style="color: #715ab1;">b2</span>, <span style="color: #715ab1;">b3</span> = network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span>, network<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b3"</span><span style="color: #3a81c3;">]</span>

    <span style="color: #715ab1;">a1</span> = np.dot<span style="color: #3a81c3;">(</span>x, W1<span style="color: #3a81c3;">)</span> + b1
    <span style="color: #715ab1;">z1</span> = sigmoid<span style="color: #3a81c3;">(</span>a1<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">a2</span> = np.dot<span style="color: #3a81c3;">(</span>z1, W2<span style="color: #3a81c3;">)</span> + b2
    <span style="color: #715ab1;">z2</span> = sigmoid<span style="color: #3a81c3;">(</span>a2<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">a3</span> = np.dot<span style="color: #3a81c3;">(</span>z2, W3<span style="color: #3a81c3;">)</span> + b3
    <span style="color: #715ab1;">y</span> = softmax<span style="color: #3a81c3;">(</span>a3<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> y


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #715ab1;">x</span>, <span style="color: #715ab1;">t</span> = get_data<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">network</span> = init_network<span style="color: #3a81c3;">()</span>

    <span style="color: #715ab1;">batch_size</span> = 100
    <span style="color: #715ab1;">accuracy_cnt</span> = 0

    <span style="color: #3a81c3; font-weight: bold;">for</span> i <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">range</span><span style="color: #3a81c3;">(</span>0, <span style="color: #3a81c3;">len</span><span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span>, batch_size<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">x_batch</span> = x<span style="color: #3a81c3;">[</span>i : i + batch_size<span style="color: #3a81c3;">]</span>
        <span style="color: #715ab1;">y_batch</span> = predict<span style="color: #3a81c3;">(</span>network, x_batch<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">p</span> = np.argmax<span style="color: #3a81c3;">(</span>y_batch, axis=1<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">accuracy_cnt</span> += np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>p == t<span style="color: #6c3163;">[</span>i : i + batch_size<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Accuracy:"</span> + <span style="color: #3a81c3;">str</span><span style="color: #6c3163;">(</span><span style="color: #3a81c3;">float</span><span style="color: #2d9574;">(</span>accuracy_cnt<span style="color: #2d9574;">)</span> / <span style="color: #3a81c3;">len</span><span style="color: #2d9574;">(</span>x<span style="color: #2d9574;">)</span><span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Accuracy:0.9352</span>

</pre>
</div></li>
<li><p>
和之前代码不一样的地方如下
</p>
<div class="org-src-container">
<pre class="src src-diff"> if __name__ == "__main__":
     x, t = get_data()
     network = init_network()
<span style="color: #67b11d;">+</span>
<span style="color: #67b11d;">+</span><span style="color: #67b11d;">    batch_size = 100</span>
     accuracy_cnt = 0
<span style="color: #f2241f;">-</span><span style="color: #f2241f;">    for i in range(len(x)):</span>
<span style="color: #f2241f;">-</span><span style="color: #f2241f;">        y = predict(network, x[i])</span>
<span style="color: #f2241f;">-</span><span style="color: #f2241f;">        p = np.argmax(y)</span>
<span style="color: #f2241f;">-</span><span style="color: #f2241f;">        if p == t[i]:</span>
<span style="color: #f2241f;">-</span><span style="color: #f2241f;">            accuracy_cnt += 1</span>
<span style="color: #67b11d;">+</span>
<span style="color: #67b11d;">+</span><span style="color: #67b11d;">    for i in range(0, len(x), batch_size):</span>
<span style="color: #67b11d;">+</span><span style="color: #67b11d;">        x_batch = x[i : i + batch_size]</span>
<span style="color: #67b11d;">+</span><span style="color: #67b11d;">        y_batch = predict(network, x_batch)</span>
<span style="color: #67b11d;">+</span><span style="color: #67b11d;">        p = np.argmax(y_batch, axis=1)</span>
<span style="color: #67b11d;">+</span><span style="color: #67b11d;">        accuracy_cnt += np.sum(p == t[i : i + batch_size])</span>

     print("Accuracy:" + str(float(accuracy_cnt) / len(x)))
</pre>
</div></li>
<li><p>
其中的range()函数加了第三个参数是step,这样每次循环的开始位置会不一样
</p>
<div class="org-src-container">
<pre class="src src-shell"> &gt;&gt;&gt; list<span style="color: #3a81c3;">(</span>range<span style="color: #6c3163;">(</span>0, 10<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span>0, 1, 2, 3, 4, 5, 6, 7, 8, 9<span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; list<span style="color: #3a81c3;">(</span>range<span style="color: #6c3163;">(</span>0, 10, 3<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span>0, 3, 6, 9<span style="color: #3a81c3;">]</span>
</pre>
</div></li>
<li><p>
agrmax()这里也多了一个参数axis=1,也就是要沿着第1维的方向找到最大index(也就是每个子数组的最大index)
</p>
<div class="org-src-container">
<pre class="src src-python">&gt;&gt;&gt; <span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
&gt;&gt;&gt; x = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>0.1, 0.8, 0.1<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.3, 0.1, 0.6<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.2, 0.5, 0.3<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>0.8, 0.1, 0.1<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; y = np.argmax<span style="color: #3a81c3;">(</span>x, axis=1<span style="color: #3a81c3;">)</span>
&gt;&gt;&gt; <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>y<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">[</span>1 2 1 0<span style="color: #3a81c3;">]</span>
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-orgb9f8c41" class="outline-2">
<h2 id="orgb9f8c41"><span class="section-number-2">4.</span> 神经网络的学习</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-orge4d453f" class="outline-3">
<h3 id="orge4d453f"><span class="section-number-3">4.1.</span> 从数据中学习</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li>神经网络的特征就是可以从数据中学习.所谓"从数据中学习",是指可以由数据自动决定"参数"</li>
<li>如果由人来决定"参数"的话,是典型的statistical learning(也叫机器学习),而神经网络是让数据自己来决定参
数.比机器学习更"深",所以叫"深度学习"</li>
</ul>
</div>
<div id="outline-container-orgb85e4b4" class="outline-4">
<h4 id="orgb85e4b4"><span class="section-number-4">4.1.1.</span> 数据驱动</h4>
<div class="outline-text-4" id="text-4-1-1">
<ul class="org-ul">
<li>我们要解决的问题是识别图片:
<ul class="org-ul">
<li>对于人来说,我们可以简单的识别出5,但是却很难明确说出是基于何种规律而识别出了5</li>
<li>利用数据来解决这个问题的话,就会有两个思路:
<ol class="org-ol">
<li>机器学习</li>
<li>深度学习</li>
</ol></li>
</ul></li>
<li>机器学习和深度学习都是使用数据来让计算机判断图片,但是两者却有着很大的差别:
<ul class="org-ul">
<li><p>
如图
</p>

<div id="orgcace244" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/4-2.png" alt="4-2.png" />
</p>
<p><span class="figure-number">Figure 37: </span>dlfs/4-2.png</p>
</div></li>
<li>白色部分是需要人参与的, 灰色的部分是计算机自动可以完成的</li>
<li>我们可以看到机器学习方法是介于"纯人工"和"纯自动化"之间的一种方法:虽然SVM,KNN等分类器可以自动学得
参数,但是这些分类器的"向量"确是需要通过经验来选取特点的方法(SIFT,HOG等)把image转换后获得</li>
<li>深度学习则是完全"自动化的",连重要的特征量也是有机器来学习的</li>
<li>神经网络的优点是对所有的问题都可以使用同样的流程来解决,比如不管要求求解的问题是识别5,还是识别狗,
神经网络都是通过不断地学习所提供的数据,尝试发现待求解问题的模式.换句话说,神经网络可以将数据直接
作为原始数据,进行"端对端"的学习,而与待处理的问题无关</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org95d0c56" class="outline-4">
<h4 id="org95d0c56"><span class="section-number-4">4.1.2.</span> 训练数据和测试数据</h4>
<div class="outline-text-4" id="text-4-1-2">
<ul class="org-ul">
<li>机器学习中,一般将数据分为如下两个部分:
<ul class="org-ul">
<li>训练数据:首先使用训练数据进行学习,寻找最优的"参数"</li>
<li>测试数据:然后使用测试数据评价"参数"的实际能力</li>
</ul></li>
<li>为什么要将数据分成训练数据和测试数据:
<ul class="org-ul">
<li>因为我们追求的是模型的泛化能力,只有划分中训练数据和测试数据,才能正确评价模型的泛化能力</li>
<li>所谓"泛化能力",是指处理未被观察过的数据(也就是训练时候没有见过的数据)的能力</li>
<li>训练数据页可以称之为监督数据(所谓监督,是在训练模型的时候才需要监督)</li>
<li>对某个数据集过度拟合的状态称之为过拟合(overfitting),避免过拟合也是机器学习的一个重要课题</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9d639d1" class="outline-3">
<h3 id="org9d639d1"><span class="section-number-3">4.2.</span> 损失函数</h3>
<div class="outline-text-3" id="text-4-2">
<ul class="org-ul">
<li>如果有人问你现在有多幸福
<ul class="org-ul">
<li>一般人可能回答"还可以吧", "很幸福"等笼统的回答</li>
<li>如果有人用数值来评判自己的幸福程度(比如"我现在的幸福指数是10.23"),那么可能会把人吓一跳,因为他用
数值来评价自己的幸福程度</li>
<li><p>
其实神经网络就是在做同样的事情:
</p>
<pre class="example" id="orgec5df16">
通过某个指标来表示当前的状态,然后,以这个指标为基准,寻找最优权重参数
</pre></li>
<li>神经网络的"某个指标",其实是一个损失函数(loss function), 通常使用如下两种函数:
<ol class="org-ol">
<li>均方误差</li>
<li>交叉熵误差</li>
</ol></li>
</ul></li>
<li>损失函数是表示神经网络性能的"恶劣程度"的指标,也就是说当前的神经网络对监督数据在多大程度上不拟合,在
多大程度上不一致(注意是监督数据,我们关于训练,所有的数据都是监督数据,没有测试数据什么事)</li>
<li>以"性能的恶劣程度"为指标可能让人感觉不自然,但是我们如果给损失函数乘以一个-1,那么就可以解释为"性能
的优秀程度",也就是"性能有多好"</li>
<li>损失函数可以使用任意函数,但一般使用均方误差和交叉熵误差等函数</li>
</ul>
</div>
<div id="outline-container-orgd20acf1" class="outline-4">
<h4 id="orgd20acf1"><span class="section-number-4">4.2.1.</span> 均方误差</h4>
<div class="outline-text-4" id="text-4-2-1">
<ul class="org-ul">
<li>损失函数中最有名的就是均方误差(mean sauared error)
<ul class="org-ul">
<li><p>
其公式如下
</p>
\begin{equation}
E = \frac{1}{2} \sum_{k} \left( y_{k} - t_{k} \right)^{2}
\end{equation}</li>
<li>\(y_k\) 表示神经网络的输出</li>
<li>\(t_k\) 表示监督数据</li>
<li>\(k\) 表示数据的维度</li>
</ul></li>
<li>比如,上一章最后的手写识别项目中:
<ul class="org-ul">
<li><p>
\(y_k\) 如下: 表示当前图像为0的概率是0.1, 为1的概率是0.05, 为2的概率是0.6,等等
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #715ab1;">y</span> = <span style="color: #3a81c3;">[</span>0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0<span style="color: #3a81c3;">]</span>
</pre>
</div></li>
<li><p>
\(t_k\) 如下: 表示正确的结果应该是2(只有第2位是1, 这种将正确标签表示为1,其他为0的方法称之为one-hot表示)
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #715ab1;">t</span> = <span style="color: #3a81c3;">[</span>0, 0, 1, 0, 0, 0, 0, 0, 0, 0<span style="color: #3a81c3;">]</span>
</pre>
</div></li>
<li>\(k\) 就是10</li>
</ul></li>
<li>我们使用numpy能够非常容易的计算均方差
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">mean_squared_error</span><span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 0.5 * np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">(</span>y - t<span style="color: #6c3163;">)</span> ** 2<span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li><p>
我们的标签是不变的
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #715ab1;">t</span> = <span style="color: #3a81c3;">[</span>0, 0, 1, 0, 0, 0, 0, 0, 0, 0<span style="color: #3a81c3;">]</span>
</pre>
</div></li>
<li><p>
一个和标签比较吻合的结果("2"的概率最高的情况),得到的均方差值较小
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; y = <span style="color: #3a81c3;">[</span>0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0<span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; mean_squared_error<span style="color: #3a81c3;">(</span>np.array<span style="color: #6c3163;">(</span>y<span style="color: #6c3163;">)</span>, np.array<span style="color: #6c3163;">(</span>t<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
0.09750000000000003
</pre>
</div></li>
<li><p>
一个和标签不太吻合的结果("7"的概率最高的情况),得到的均方差值较大
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt;&gt;&gt; y2 = <span style="color: #3a81c3;">[</span>0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0<span style="color: #3a81c3;">]</span>
&gt;&gt;&gt; mean_squared_error<span style="color: #3a81c3;">(</span>np.array<span style="color: #6c3163;">(</span>y2<span style="color: #6c3163;">)</span>, np.array<span style="color: #6c3163;">(</span>t<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
0.5975
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org3a56e8f" class="outline-4">
<h4 id="org3a56e8f"><span class="section-number-4">4.2.2.</span> 交叉熵误差</h4>
<div class="outline-text-4" id="text-4-2-2">
<ul class="org-ul">
<li>除了均方误差外,交叉熵误差(cross entropy error)也经常被用作损失函数:
<ul class="org-ul">
<li><p>
其公式如下
</p>
\begin{equation}
E = - \sum_{k} t_{k} \log y_{k}, \tag{4.2}
\end{equation}</li>
<li>这里log表示以e为底的自然对数</li>
<li>\(y_k\) 是神经网络的输出</li>
<li>\(t_k\) 是正确解标签,其中只有正确解标签的索引为1,其他都是0(one-hot表示),所以上述式4-2实际上只计算
正确解标签的输出的自然对数</li>
<li><p>
举例,假设正确解标签的索引值是2(也就是图像其实是2,index2的 \(t_k\) 值为1, 其他全部都是0),index2对应的神经网络输出值 \(y_k\)
为0.6,则交叉熵误差是-log0.6=0.51
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #715ab1;">t</span> = <span style="color: #3a81c3;">[</span>0, 0, 1, 0, 0, 0, 0, 0, 0, 0<span style="color: #3a81c3;">]</span>
<span style="color: #715ab1;">y</span> = <span style="color: #3a81c3;">[</span>0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0<span style="color: #3a81c3;">]</span>
</pre>
</div></li>
<li><p>
举例,假设正确解标签的索引值是2(也就是图像其实是2,index2的 \(t_k\) 值为1, 其他全部都是0),index2对应的神经网络输出值 \(y_k\)
为0.1,则交叉熵误差是-log0.1=2.30
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #715ab1;">t</span> = <span style="color: #3a81c3;">[</span>0, 0, 1, 0, 0, 0, 0, 0, 0, 0<span style="color: #3a81c3;">]</span>
<span style="color: #715ab1;">y2</span> = <span style="color: #3a81c3;">[</span>0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0<span style="color: #3a81c3;">]</span>
</pre>
</div></li>
</ul></li>
<li>通过上面的例子我们很自然想到,如果正确的index值对应的概率越接近1,那么交叉熵误差就越接近0,效果也就是越好
<ul class="org-ul">
<li><p>
如下图
</p>

<div id="orgaa9b91b" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/4-3.png" alt="4-3.png" />
</p>
<p><span class="figure-number">Figure 38: </span>dlfs/4-3.png</p>
</div></li>
<li>当x等于1的时候,y等于0(效果最好)</li>
<li>随着x向0靠近,y逐渐变小(效果越来越差)</li>
</ul></li>
<li>下面我们来实现一下交叉熵误差:
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">cross_entropy_error</span><span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">delta</span> = 1e-7
    <span style="color: #3a81c3; font-weight: bold;">return</span> -np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>t * np.log<span style="color: #6c3163;">(</span>y + delta<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li>这里的参数y和t是numpy数组</li>
<li>在计算np.log时,加上了一个微小的delta,这是防止出现np.log(0),这会导致一个无限大的-inf</li>
<li><p>
我们把上一章的标签和数据集拿来使用cross_entropy_error计算后得到的结果如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">cross_entropy_error</span><span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">delta</span> = 1e-7
    <span style="color: #3a81c3; font-weight: bold;">return</span> -np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>t * np.log<span style="color: #6c3163;">(</span>y + delta<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #715ab1;">t</span> = <span style="color: #3a81c3;">[</span>0, 0, 1, 0, 0, 0, 0, 0, 0, 0<span style="color: #3a81c3;">]</span>
<span style="color: #715ab1;">y</span> = <span style="color: #3a81c3;">[</span>0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0<span style="color: #3a81c3;">]</span>
<span style="color: #715ab1;">y2</span> = <span style="color: #3a81c3;">[</span>0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0<span style="color: #3a81c3;">]</span>

<span style="color: #715ab1;">v1</span> = cross_entropy_error<span style="color: #3a81c3;">(</span>np.array<span style="color: #6c3163;">(</span>y<span style="color: #6c3163;">)</span>, np.array<span style="color: #6c3163;">(</span>t<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|v1|=&gt;"""</span>, v1<span style="color: #3a81c3;">)</span>

<span style="color: #715ab1;">v2</span> = cross_entropy_error<span style="color: #3a81c3;">(</span>np.array<span style="color: #6c3163;">(</span>y2<span style="color: #6c3163;">)</span>, np.array<span style="color: #6c3163;">(</span>t<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|v2|=&gt;"""</span>, v2<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|v1|=&gt; 0.510825457099338</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|v2|=&gt; 2.302584092994546</span>
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgcbddaa8" class="outline-4">
<h4 id="orgcbddaa8"><span class="section-number-4">4.2.3.</span> mini-batch学习</h4>
<div class="outline-text-4" id="text-4-2-3">
<ul class="org-ul">
<li>机器学习使用训练数据进行学习,损失函数也应该是将所有的训练数据作为对象,也就是说,如果训练数据有100个
的话,我们要把这100个损失函数的总和作为学习的指标</li>
<li>上一节的例子是拿一个数据来计算损失的.如果是要求所有训练数据的损失函数的总和,那么:
<ul class="org-ul">
<li><p>
公式应该如下
</p>
\begin{equation}
E = - \frac{1}{N} \sum_{n} \sum_{k} t_{nk} \log y_{nk}, \tag{4.3}
\end{equation}</li>
<li>这里假设数据有N个</li>
<li>式子虽然复杂,但是,其实就是把式4-2扩大了N倍,最终再除以N进行正规化</li>
</ul></li>
<li><p>
当数据集比较小的时候,我们把数据整体的损失算出来再除以N还能接受,如果遇到大数据,数据量会有百万千万级,
这种情况下以全部数据为对象计算损失函数是不现实的.这种情况下我们的应对方案是
</p>
<pre class="example" id="org3c21d80">
从全部数据中选出一部分,作为全部数据的"近似"
</pre></li>
<li>从训练数据中选出小批量的数据进行学习,就叫做mini-batch学习,因为mini-batch就是小批量的意思
<ul class="org-ul">
<li><p>
下面的代码就是从训练数据中随机选择指定个数数据进行mini-batch学习的代码
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #715ab1;">batch_mask</span> = np.random.choice<span style="color: #3a81c3;">(</span>train_size, batch_size<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">x_batch</span> = x_train<span style="color: #3a81c3;">[</span>batch_mask<span style="color: #3a81c3;">]</span>
<span style="color: #715ab1;">t_batch</span> = t_train<span style="color: #3a81c3;">[</span>batch_mask<span style="color: #3a81c3;">]</span>
</pre>
</div></li>
<li><p>
这段代码的核心就是np.random.choice,它能从第一个参数确定的区间里面,随机获得N个数字(N为第一个参数
设置)
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np

<span style="color: #715ab1;">ret</span> = np.random.choice<span style="color: #3a81c3;">(</span>6000, 10<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|ret|=&gt;"""</span>, ret<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|ret|=&gt; [1952 5938 1093  456 2108 5936  596 3343 1663 3691]</span>
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org5a4f3e0" class="outline-4">
<h4 id="org5a4f3e0"><span class="section-number-4">4.2.4.</span> mini-batch版交叉熵误差的实现</h4>
<div class="outline-text-4" id="text-4-2-4">
<ul class="org-ul">
<li>为了能够实现mini-batch的交叉熵误差,我们需要改良一下之前的代码:
<ul class="org-ul">
<li><p>
改良之前的代码:只支持ndim为1的y和t
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">cross_entropy_error</span><span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">delta</span> = 1e-7
    <span style="color: #3a81c3; font-weight: bold;">return</span> -np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>t * np.log<span style="color: #6c3163;">(</span>y + delta<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li><p>
改良之后的代码,支持ndim为任意值的y和t. 如果ye和t的ndim还是1的话,要把这两个的ndim扩展成2,也就是
shape为(1,size)的格式,方便后面用同样的逻辑进行计算
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">cross_entropy_error</span><span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">if</span> y.ndim == 1:
        <span style="color: #715ab1;">t</span> = t.reshape<span style="color: #3a81c3;">(</span>1, t.size<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">y</span> = y.reshape<span style="color: #3a81c3;">(</span>1, y.size<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">batch_size</span> = y.shape<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> -np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>t * np.log<span style="color: #6c3163;">(</span>y + 1e-7<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span> / batch_size
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgb52f9a3" class="outline-4">
<h4 id="orgb52f9a3"><span class="section-number-4">4.2.5.</span> 为何要设定损失函数</h4>
<div class="outline-text-4" id="text-4-2-5">
<ul class="org-ul">
<li><p>
我们之所以要设计损失函数,是因为识别精度不能作为指标,总结起来就是
</p>
<pre class="example" id="org78795b5">
在进行神经网络的学习时,不能将识别精度作为指标,因为如果以识别精度为指标,
则参数的导数在大多数地方都会变为0
</pre></li>
<li>神经网络的学习同样不能以阶跃函数作为激活函数.
<ul class="org-ul">
<li><p>
如下图. 阶跃函数的导数在绝大多数地方均为0
</p>

<div id="orga7d56bd" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/4-4.png" alt="4-4.png" />
</p>
<p><span class="figure-number">Figure 39: </span>dlfs/4-4.png</p>
</div></li>
<li>换句话说,如果使用了阶跃函数,那么即便将损失函数作为指标,参数的微小变化也会被阶跃函数抹杀,导致损失
函数的值不会产生任何变化</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org1a6ff99" class="outline-3">
<h3 id="org1a6ff99"><span class="section-number-3">4.3.</span> 数值微分</h3>
<div class="outline-text-3" id="text-4-3">
</div>
<div id="outline-container-org8bc1ba5" class="outline-4">
<h4 id="org8bc1ba5"><span class="section-number-4">4.3.1.</span> 导数</h4>
<div class="outline-text-4" id="text-4-3-1">
<ul class="org-ul">
<li>加入你是全程马拉松选手,在最开始的十分钟内跑了两千米,我们想计算速度,那就是2/10=0.2[千米/分]</li>
<li>严格的讲,刚才的计算得出的结果是一个10分钟内的平均速度.而如果我们想要知道某个瞬间的速度,那么就要用到导数
<ul class="org-ul">
<li><p>
导数的定义如下
</p>
\begin{equation}
\frac{df(x)}{dx} = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h}, \tag{4.4}
\end{equation}</li>
<li>左边的 \(\frac{df(x)}{dx}\) 表示 f(x) 关于x的导数, 即f(x)相对于x的变化程度</li>
<li>右边的h是一个无线趋近于0的数字,表示为 \(\lim_{h \to 0}\),在h趋近于0的情况下f(x+h)-fx(x)除以h,就是
这个瞬间的速度</li>
</ul></li>
<li>接下来,我们想计算一下公式4-4,这里就有一些要说的故事:
<ul class="org-ul">
<li>我们曾经都学过导数,在高等数学里面,我们是可以通过一系列公式来计算导数的.比如 \(y=x^2\) 的导数就是2x</li>
<li>但是,在计算机的世界里面,很多情况下不是这么计算导数的.这是因为:
<ol class="org-ol">
<li>在计算机世界(特别是深度学习世界)我们很难得到 \(y=x^2\) 这种清晰的函数</li>
<li>就算得到了较为清晰的函数,比起真的给一个"极小值"去计算,使用公式获得"完美"导数的情况,也会更加的消耗cpu</li>
</ol></li>
</ul></li>
<li>所以,在计算机世界(准确的说是深度学习世界),我们是代入一个"极小值"来计算导数的
<ul class="org-ul">
<li><p>
比如下面的例子
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_diff</span><span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">h</span> = 10e-50
    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>f<span style="color: #6c3163;">(</span>x + h<span style="color: #6c3163;">)</span> - f<span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span> / h
</pre>
</div></li>
<li>函数numerical_diff的名字就是数值微分的英文</li>
<li>numerical_diff有两个参数:
<ol class="org-ol">
<li>函数f</li>
<li>函数f的参数x</li>
</ol></li>
</ul></li>
<li>这个例子有两个问题:
<ul class="org-ul">
<li><p>
第一个就是"极小值"(1e-50)太小了,在python里面会产生摄入误差,最终在python里面就是0.0了,这里我们要
把极小值改成10e-4就够了
</p>
<div class="org-src-container">
<pre class="src src-python">&gt;&gt;&gt; np.float32<span style="color: #3a81c3;">(</span>1e-50<span style="color: #3a81c3;">)</span>
np.float32<span style="color: #3a81c3;">(</span>0.0<span style="color: #3a81c3;">)</span>
</pre>
</div></li>
<li><p>
第二个问题是我们能提高计算的"导数"的精度:我们计算的导数其实是有误差的,如下图
</p>

<div id="orgc36acc9" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/4-5.png" alt="4-5.png" />
</p>
<p><span class="figure-number">Figure 40: </span>dlfs/4-5.png</p>
</div></li>
<li>"真的导数"对应函数在x处的斜率(真的切线),但是我们计算出来的是那个"近似切线",所以我们有误差,如果想
缩小这个误差,那么通过一系列的数学证明(证明略),我们可以使用"中心差值法",来减小误差</li>
<li><p>
所谓"中心差值法",就是"以x为中心,计算它左右两边的差分",代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_diff</span><span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">h</span> = 1e-4
    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>f<span style="color: #6c3163;">(</span>x + h<span style="color: #6c3163;">)</span> - f<span style="color: #6c3163;">(</span>x - h<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">(</span>2 * h<span style="color: #3a81c3;">)</span>
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org9cb7b80" class="outline-4">
<h4 id="org9cb7b80"><span class="section-number-4">4.3.2.</span> 数值微分的例子</h4>
<div class="outline-text-4" id="text-4-3-2">
<ul class="org-ul">
<li>我们通过一个例子来加深一下"使用python来计算导数"这件事的印象:
<ul class="org-ul">
<li>首先,我们使用代码来实现一个函数,并且打印出来</li>
<li><p>
打印出来的图像如下
</p>

<div id="orga082054" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/4-6.png" alt="4-6.png" />
</p>
<p><span class="figure-number">Figure 41: </span>dlfs/4-6.png</p>
</div></li>
<li><p>
我们再结合上节的数值微分的代码,计算在x=5和x=10两个点的导数
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_diff</span><span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">h</span> = 1e-4
    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>f<span style="color: #6c3163;">(</span>x + h<span style="color: #6c3163;">)</span> - f<span style="color: #6c3163;">(</span>x - h<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">(</span>2 * h<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">function_1</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 0.01 * x**2 + 0.1 * x


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">derivative on 5</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|numerical_diff(function_1, 5)|=&gt;"""</span>, numerical_diff<span style="color: #6c3163;">(</span>function_1, 5<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">derivative on 10</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|numerical_diff(function_1, 10)|=&gt;"""</span>, numerical_diff<span style="color: #6c3163;">(</span>function_1, 10<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|numerical_diff(function_1, 5)|=&gt; 0.1999999999990898</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|numerical_diff(function_1, 10)|=&gt; 0.2999999999986347</span>
</pre>
</div></li>
<li><p>
我们的原始函数使用公式表达如下
</p>
\begin{equation}
y = 0.01x^2 + 0.1x \tag{4.5}
\end{equation}</li>
<li><p>
由于这个公式非常简单,我们可以通过"导数计算公式"得到它的导数解析值如下
</p>
\begin{equation}
\frac{\mathrm{d} f(x)}{\mathrm{d} x} = 0.02x + 0.1 \notag
\end{equation}</li>
<li>我们由此可以计算出在x=5和x=10两点的导数:
<ol class="org-ol">
<li>x = 5时真实导数为0.2: 我们计算值为:0.1999999999990898,误差小到可以认为是相等</li>
<li>x = 10时真实导数为0.3: 我们计算值为0.2999999999986347,误差小到可以认为是相等</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org5a086f1" class="outline-4">
<h4 id="org5a086f1"><span class="section-number-4">4.3.3.</span> 偏导数</h4>
<div class="outline-text-4" id="text-4-3-3">
<ul class="org-ul">
<li>所谓偏导数,是指"多个变量函数的导数"</li>
<li>先看一个"多个变量的函数"的例子
<ul class="org-ul">
<li><p>
公式如下
</p>
\begin{equation}
f(x_0, x_1) = x_0^2 + x_1^2 \tag{4.6}
\end{equation}</li>
<li><p>
使用代码表示如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
<span style="color: #3a81c3; font-weight: bold;">import</span> matplotlib.pyplot <span style="color: #3a81c3; font-weight: bold;">as</span> plt
<span style="color: #3a81c3; font-weight: bold;">from</span> mpl_toolkits.mplot3d <span style="color: #3a81c3; font-weight: bold;">import</span> Axes3D


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#23450;&#20041;&#20989;&#25968; function_2</span>
<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">function_2</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> x<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span> ** 2 + x<span style="color: #3a81c3;">[</span>1<span style="color: #3a81c3;">]</span> ** 2


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#21019;&#24314; x &#21644; y &#30340;&#32593;&#26684;</span>
<span style="color: #715ab1;">x</span> = np.linspace<span style="color: #3a81c3;">(</span>-10, 10, 400<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">y</span> = np.linspace<span style="color: #3a81c3;">(</span>-10, 10, 400<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">X</span>, <span style="color: #715ab1;">Y</span> = np.meshgrid<span style="color: #3a81c3;">(</span>x, y<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#35745;&#31639;&#27599;&#20010;&#32593;&#26684;&#28857;&#30340;&#20989;&#25968;&#20540;</span>
<span style="color: #715ab1;">Z</span> = function_2<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>X, Y<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#20351;&#29992; matplotlib &#30011;&#20986;&#19977;&#32500;&#22270;&#20687;</span>
<span style="color: #715ab1;">fig</span> = plt.figure<span style="color: #3a81c3;">()</span>
<span style="color: #715ab1;">ax</span> = fig.add_subplot<span style="color: #3a81c3;">(</span>111, projection=<span style="color: #2d9574;">"3d"</span><span style="color: #3a81c3;">)</span>
ax.plot_surface<span style="color: #3a81c3;">(</span>X, Y, Z, cmap=<span style="color: #2d9574;">"viridis"</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#28155;&#21152;&#26631;&#39064;&#21644;&#36724;&#26631;&#31614;</span>
ax.set_title<span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"3D plot of function_2"</span><span style="color: #3a81c3;">)</span>
ax.set_xlabel<span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"x0"</span><span style="color: #3a81c3;">)</span>
ax.set_ylabel<span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"x1"</span><span style="color: #3a81c3;">)</span>
ax.set_zlabel<span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"f(x)"</span><span style="color: #3a81c3;">)</span>

plt.show<span style="color: #3a81c3;">()</span>
</pre>
</div></li>
<li><p>
用python打印出来的三维图像如下
</p>

<div id="org4389c5f" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/4-8.png" alt="4-8.png" />
</p>
<p><span class="figure-number">Figure 42: </span>dlfs/4-8.png</p>
</div></li>
</ul></li>
<li>了解完"多个变量的函数"之后,我们来试着给"多个变量的函数"求导,因为公式4-6有两个变量,所以有必要区分对
哪个变量求导(也就是针对 \(x_0\) 还是 \(x_1\) 求导),在数学上,我们这样区分:
<ul class="org-ul">
<li>对 \(x_0\) 的求导,可以写成 \(\frac{\partial f}{\partial x_0}\)</li>
<li>对 \(x_1\) 的求导,可以写成 \(\frac{\partial f}{\partial x_1}\)</li>
</ul></li>
<li>在计算机领域,我们计算偏导数,只需要把一个变量看做常量得到一个新的函数,然后用上节课讲的numerical_diff
来计算这个新函数的导数就可以了:
<ul class="org-ul">
<li><p>
比如,我们可以计算 \(x_0 =3, x_1 = 4\) 时候的关于 \(x_0\) 的偏导(这个时候 \(x_1\) 就应该先看成常量), 我
们用代码求出来的偏导数为6.00000000000378,实际值为6
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_diff</span><span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">h</span> = 1e-4
    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>f<span style="color: #6c3163;">(</span>x + h<span style="color: #6c3163;">)</span> - f<span style="color: #6c3163;">(</span>x - h<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">(</span>2 * h<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">function_tmp1</span><span style="color: #3a81c3;">(</span>x0<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> x0 * x0 + 4.0**2.0


<span style="color: #715ab1;">nd1</span> = numerical_diff<span style="color: #3a81c3;">(</span>function_tmp1, 3.0<span style="color: #3a81c3;">)</span>

<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|nd1|=&gt;"""</span>, nd1<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|nd1|=&gt; 6.00000000000378</span>
</pre>
</div></li>
<li><p>
比如,我们可以计算 \(x_0 =3, x_1 = 4\) 时候的关于 \(x_1\) 的偏导(这个时候 \(x_0\) 就应该先看成常量), 我
们用代码求出来的偏导数为7.999999999999119,实际值为8
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_diff</span><span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">h</span> = 1e-4
    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>f<span style="color: #6c3163;">(</span>x + h<span style="color: #6c3163;">)</span> - f<span style="color: #6c3163;">(</span>x - h<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">(</span>2 * h<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">function_tmp2</span><span style="color: #3a81c3;">(</span>x1<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 3.0**2 + x1 * x1


<span style="color: #715ab1;">nd2</span> = numerical_diff<span style="color: #3a81c3;">(</span>function_tmp2, 4.0<span style="color: #3a81c3;">)</span>

<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|nd2|=&gt;"""</span>, nd2<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|nd2|=&gt; 7.999999999999119</span>
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org61522e0" class="outline-3">
<h3 id="org61522e0"><span class="section-number-3">4.4.</span> 梯度</h3>
<div class="outline-text-3" id="text-4-4">
<ul class="org-ul">
<li>本节我们学习梯度,梯度是建立在偏导数上的一个新的概念
<ul class="org-ul">
<li><p>
其定义如下:
</p>
<pre class="example" id="org33f015f">
所谓梯度(gradient),是指由全部变量的偏导数汇总而成的向量
</pre></li>
<li>比如上一节我们研究的函数 \(f(x_0, x_1) = x_0^2 + x_1^2\), 其有两个变量 \(x_0, x_1\), 我们把这两个变
量的偏导数组合起来,得到的向量 \((\frac{\partial f}{\partial x_0},\frac{\partial f}{\partial x_1})\) 就称之为梯度</li>
</ul></li>
<li><p>
注意,梯度是一个向量(vector),那既然是一个向量,就包含长度和方向.其中方向对于梯度来说意义更大,那是因为有一个结论
</p>
<pre class="example" id="org1af14be">
梯度的方向是函数增加最快的方向
</pre></li>
<li>这个结论非常重要,我们想要记住这个结论,最好的方式是通过不同维度进行解释和证明:
<ol class="org-ol">
<li>几何解释:
<ul class="org-ul">
<li>梯度向量垂直于等高线(二维),或者等值线(高维)</li>
<li>沿着梯度方向运动是直接离开等高线(等值线)最快的路径,因此是函数增加最快的路径</li>
</ul></li>
<li>线性近似解释:
<ul class="org-ul">
<li>在某一点附近,函数的变化值可以近似为一个线性变化.比如y=ax+b</li>
<li>梯度是这个线性近似的系数(也就是a),它决定了函数值变化的速度和方向</li>
</ul></li>
<li>直观解释:
<ul class="org-ul">
<li>可以想象在一个山坡上,梯度指向的是上坡最陡的方向</li>
<li>如果你想尽快爬到山顶,沿着梯度方向走是最有效的</li>
</ul></li>
</ol></li>
<li>我们用python来实现一下梯度
<ul class="org-ul">
<li><p>
代码如下:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#23450;&#20041;&#20989;&#25968; function_2</span>
<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">function_2</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> x<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span> ** 2 + x<span style="color: #3a81c3;">[</span>1<span style="color: #3a81c3;">]</span> ** 2


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_gradient</span><span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">h</span> = 1e-4
    <span style="color: #715ab1;">grad</span> = np.zeros_like<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">for</span> idx <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">range</span><span style="color: #3a81c3;">(</span>x.size<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">tmp_val</span> = x<span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span>
        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x+h)</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val + h
        <span style="color: #715ab1;">fxh1</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x-h)</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val - h
        <span style="color: #715ab1;">fxh2</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">grad</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = <span style="color: #3a81c3;">(</span>fxh1 - fxh2<span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">(</span>2 * h<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val
    <span style="color: #3a81c3; font-weight: bold;">return</span> grad


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>numerical_gradient<span style="color: #6c3163;">(</span>function_2, np.array<span style="color: #2d9574;">(</span><span style="color: #67b11d;">[</span>3.0, 4.0<span style="color: #67b11d;">]</span><span style="color: #2d9574;">)</span><span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>numerical_gradient<span style="color: #6c3163;">(</span>function_2, np.array<span style="color: #2d9574;">(</span><span style="color: #67b11d;">[</span>0.0, 2.0<span style="color: #67b11d;">]</span><span style="color: #2d9574;">)</span><span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>numerical_gradient<span style="color: #6c3163;">(</span>function_2, np.array<span style="color: #2d9574;">(</span><span style="color: #67b11d;">[</span>3.0, 0.0<span style="color: #67b11d;">]</span><span style="color: #2d9574;">)</span><span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[6. 8.]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[0. 4.]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[6. 0.]</span>
</pre>
</div></li>
</ul></li>
</ul>
</div>
<div id="outline-container-org0c6dc29" class="outline-4">
<h4 id="org0c6dc29"><span class="section-number-4">4.4.1.</span> 梯度法</h4>
<div class="outline-text-4" id="text-4-4-1">
<ul class="org-ul">
<li>神经网络必须在学校的时候找到最优参数,这里说的最优参数是指损失函数取得最小值时的参数
<ul class="org-ul">
<li><p>
那么我们的目标就很明确了
</p>
<pre class="example" id="org2d10a80">
利用梯度指明的"方向的反方向"前进,"力争"找到函数的最小值
</pre></li>
<li>这个目标中,我们前进的方向是梯度的反方向,是因为我们的目标是最小值,梯度vector的方向,可能函数最大值
的方向,那么梯度vector的反方向就可能是函数最小值的方向</li>
<li>我们上面的描述又用了"可能",这是以为梯度vector的反方向,最终寻找的是梯度为0的地方,但是这种地方有三种可能:
<ol class="org-ol">
<li>最小值:整个函数的min值</li>
<li>极小值:局部最小值</li>
<li>鞍点: 从某个方向上看是极大值,从另一个方向上看则是极小值</li>
</ol></li>
<li>所以,朝着梯度vector的反方向,只是"可能"找到最小值,但是因为这是唯一的可能,所以我们也只能朝这个方向走.</li>
</ul></li>
<li>我们明确了必须按照梯度vector的反方向走(当前唯一的线索),那么我们就可以介绍这个策略对应的方法了:梯度法:
<ul class="org-ul">
<li>随机一组数据作为初始化值</li>
<li>初始化值沿着梯度vector的反方向前进一个lr(learning rate)的举例,获得新的一组值</li>
<li>新的一组值在新的位置重新求梯度,然后沿着新梯度vector的反方向继续前进.反复重复上述步骤</li>
</ul></li>
<li>上面的步骤中,每次更新的数值,叫做学习率(learning rate),其值是一个超参,需要提前设定.
<ul class="org-ul">
<li>所谓超参是为了区别于权重参数(权重和偏置)的一个性质不同的参数</li>
<li>权重参数是通过训练自动获得的.</li>
<li>超参(比如学习率)是人工设定的,一般来说,超参需要尝试多个值以便找到一种最佳值.所谓"联单调参工程师"调
的就是这个参数</li>
</ul></li>
<li>我们使用代码来模拟下梯度法
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#23450;&#20041;&#20989;&#25968; function_2</span>
<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">function_2</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> x<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span> ** 2 + x<span style="color: #3a81c3;">[</span>1<span style="color: #3a81c3;">]</span> ** 2


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_gradient</span><span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">h</span> = 1e-4
    <span style="color: #715ab1;">grad</span> = np.zeros_like<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">for</span> idx <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">range</span><span style="color: #3a81c3;">(</span>x.size<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">tmp_val</span> = x<span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span>
        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x+h)</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val + h
        <span style="color: #715ab1;">fxh1</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x-h)</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val - h
        <span style="color: #715ab1;">fxh2</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">grad</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = <span style="color: #3a81c3;">(</span>fxh1 - fxh2<span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">(</span>2 * h<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val
    <span style="color: #3a81c3; font-weight: bold;">return</span> grad


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">gradient_descent</span><span style="color: #3a81c3;">(</span>f, init_x, lr=0.01, step_num=100<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = init_x
    <span style="color: #3a81c3; font-weight: bold;">for</span> i <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">range</span><span style="color: #3a81c3;">(</span>step_num<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">grad</span> = numerical_gradient<span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">x</span> -= lr * grad

    <span style="color: #3a81c3; font-weight: bold;">return</span> x


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #715ab1;">init_x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>-3.0, 4.0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">ret</span> = gradient_descent<span style="color: #3a81c3;">(</span>function_2, init_x=init_x, lr=0.1, step_num=100<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|ret|=&gt;"""</span>, ret<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|ret|=&gt; [-6.11110793e-10  8.14814391e-10]</span>
</pre>
</div></li>
<li>我们这里初始值(-3.0, 4.0)可以理解为一个随机初始值</li>
<li>重复梯度法100次之后(每次移动0.1),最后得到的最小值是(-6.11110793e-10  8.14814391e-10)和真正的最小
值(0,0)非常接近</li>
<li><p>
前面说过超参lr过大或者过小都不好,这里我们试验一下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#23450;&#20041;&#20989;&#25968; function_2</span>
<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">function_2</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> x<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span> ** 2 + x<span style="color: #3a81c3;">[</span>1<span style="color: #3a81c3;">]</span> ** 2


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_gradient</span><span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">h</span> = 1e-4
    <span style="color: #715ab1;">grad</span> = np.zeros_like<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">for</span> idx <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">range</span><span style="color: #3a81c3;">(</span>x.size<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">tmp_val</span> = x<span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span>
        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x+h)</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val + h
        <span style="color: #715ab1;">fxh1</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x-h)</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val - h
        <span style="color: #715ab1;">fxh2</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">grad</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = <span style="color: #3a81c3;">(</span>fxh1 - fxh2<span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">(</span>2 * h<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val
    <span style="color: #3a81c3; font-weight: bold;">return</span> grad


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">gradient_descent</span><span style="color: #3a81c3;">(</span>f, init_x, lr=0.01, step_num=100<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = init_x
    <span style="color: #3a81c3; font-weight: bold;">for</span> i <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">range</span><span style="color: #3a81c3;">(</span>step_num<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">grad</span> = numerical_gradient<span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">x</span> -= lr * grad

    <span style="color: #3a81c3; font-weight: bold;">return</span> x


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #715ab1;">init_x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>-3.0, 4.0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>gradient_descent<span style="color: #6c3163;">(</span>function_2, init_x=init_x, lr=10.0, step_num=100<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">init_x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>-3.0, 4.0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>gradient_descent<span style="color: #6c3163;">(</span>function_2, init_x=init_x, lr=1e-10, step_num=100<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;"># &lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[-2.58983747e+13 -1.29524862e+12]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[-2.99999994  3.99999992]</span>
</pre>
</div></li>
<li>可以看到:
<ol class="org-ol">
<li>lr过大的话,会发散成一个很大的值</li>
<li>lr过小的话,基本上没怎么更新就结束了</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org8287132" class="outline-4">
<h4 id="org8287132"><span class="section-number-4">4.4.2.</span> 神经网络的梯度</h4>
<div class="outline-text-4" id="text-4-4-2">
<ul class="org-ul">
<li>我们刚才看到的是一个一维数组求梯度,其实上面的数组换成N维数组也可以求梯度,只不过梯度的shape和输入数
组的shape是一样的.
<ul class="org-ul">
<li>比如我们有一个形状为2*3的权重为W的神经网络</li>
<li>这个网络的损失函数用L表示的话,梯度可以用表示</li>
<li><p>
W神经网络如下
</p>
\begin{equation}
\boldsymbol{W} =
\begin{pmatrix}
w_{11} & w_{12} & w_{13} \\
w_{21} & w_{22} & w_{23} \\
\end{pmatrix} \notag
\end{equation}</li>
<li><p>
梯度如下
</p>
\begin{equation}
\frac{\partial L}{\partial \boldsymbol{W}} =
\begin{pmatrix}
\frac{\partial L}{\partial w_{11}} & \frac{\partial L}{\partial w_{12}} & \frac{\partial L}{\partial w_{13}} \\
\frac{\partial L}{\partial w_{21}} & \frac{\partial L}{\partial w_{22}} & \frac{\partial L}{\partial w_{23}} \\
\end{pmatrix} \notag
\end{equation}</li>
</ul></li>
<li>我们下面使用代码来表示上述过程
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">softmax</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = x - np.<span style="color: #3a81c3;">max</span><span style="color: #3a81c3;">(</span>x, axis=-1, keepdims=<span style="color: #4e3163;">True</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> np.exp<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span> / np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>np.exp<span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span>, axis=-1, keepdims=<span style="color: #4e3163;">True</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">cross_entropy_error</span><span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">delta</span> = 1e-7
    <span style="color: #3a81c3; font-weight: bold;">return</span> -np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>t * np.log<span style="color: #6c3163;">(</span>y + delta<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_gradient</span><span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">h</span> = 1e-4  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.0001</span>
    <span style="color: #715ab1;">grad</span> = np.zeros_like<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

    <span style="color: #715ab1;">it</span> = np.nditer<span style="color: #3a81c3;">(</span>x, flags=<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"multi_index"</span><span style="color: #6c3163;">]</span>, op_flags=<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"readwrite"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">while</span> <span style="color: #3a81c3; font-weight: bold;">not</span> it.finished:
        <span style="color: #715ab1;">idx</span> = it.multi_index
        <span style="color: #715ab1;">tmp_val</span> = x<span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val + h
        <span style="color: #715ab1;">fxh1</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x+h)</span>

        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val - h
        <span style="color: #715ab1;">fxh2</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x-h)</span>
        <span style="color: #715ab1;">grad</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = <span style="color: #3a81c3;">(</span>fxh1 - fxh2<span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">(</span>2 * h<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val
        it.iternext<span style="color: #3a81c3;">()</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> grad


<span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">simpleNet</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span><span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">W</span> = np.array<span style="color: #3a81c3;">(</span>
            <span style="color: #6c3163;">[</span>
                <span style="color: #2d9574;">[</span>0.47355232, 0.9977393, 0.84668094<span style="color: #2d9574;">]</span>,
                <span style="color: #2d9574;">[</span>0.85557411, 0.03563661, 0.69422093<span style="color: #2d9574;">]</span>,
            <span style="color: #6c3163;">]</span>
        <span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">predict</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span> np.dot<span style="color: #3a81c3;">(</span>x, <span style="color: #3a81c3; font-weight: bold;">self</span>.W<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">loss</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">z</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.predict<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">y</span> = softmax<span style="color: #3a81c3;">(</span>z<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">loss</span> = cross_entropy_error<span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">return</span> loss


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #715ab1;">net</span> = simpleNet<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|net.W|=&gt;"""</span>, net.W<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0.6, 0.9<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">p</span> = net.predict<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|p|=&gt;"""</span>, p<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|np.argmax(p)|=&gt;"""</span>, np.argmax<span style="color: #6c3163;">(</span>p<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">t</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span>0, 0, 1<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|net.loss(x, t)|=&gt;"""</span>, net.loss<span style="color: #6c3163;">(</span>x, t<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">f</span> = <span style="color: #3a81c3; font-weight: bold;">lambda</span> w: net.loss<span style="color: #3a81c3;">(</span>x, t<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dW</span> = numerical_gradient<span style="color: #3a81c3;">(</span>f, net.W<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|dW|=&gt;"""</span>, dW<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|net.W|=&gt; [[0.47355232 0.9977393  0.84668094]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[0.85557411 0.03563661 0.69422093]]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|p|=&gt; [1.05414809 0.63071653 1.1328074 ]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|np.argmax(p)|=&gt; 2</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|net.loss(x, t)|=&gt; 0.9280682857864075</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|dW|=&gt; [[ 0.21924757  0.14356243 -0.36281   ]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[ 0.32887136  0.21534364 -0.544215  ]]</span>
</pre>
</div></li>
<li>这个版本的numerical_gradient和上个版本的numerical_gradient不一样的地方,在于loop的方法,新版本兼顾
了多维数组</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org808dade" class="outline-3">
<h3 id="org808dade"><span class="section-number-3">4.5.</span> 学习算法的实现</h3>
<div class="outline-text-3" id="text-4-5">
<ul class="org-ul">
<li>我们现在总结一下神经网络"学习"的步骤:
<ol class="org-ol">
<li>mini-batch: 从训练数据中随机挑选中一部分数据,这部分数据称之为mini-batch,我们的目标是减小mini-batch的损失函数的值</li>
<li>计算梯度: 为了减小mini-batch的损失函数的值,需要求出各个权重参数的梯度(梯度shape和权重参数一致).
因为梯度vector的反方向是损失函数减小最多的方向</li>
<li>更新参数: 将权重,按着梯度vector的反方向进行微小更新</li>
<li>重复步骤1,2,3</li>
</ol></li>
<li>上面的步骤通过"梯度下降"法更新参数,同时又由于这里不是全量更新,而是随机选择的mini batch数据, 所以上
述算法全名是随机梯度下降法(stochastic gradient descent)</li>
</ul>
</div>
<div id="outline-container-orge59a953" class="outline-4">
<h4 id="orge59a953"><span class="section-number-4">4.5.1.</span> 2层神经网络的类</h4>
<div class="outline-text-4" id="text-4-5-1">
<ul class="org-ul">
<li>前面我们首先介绍了一个一维数组求梯度的例子,后面又学习了多维数组求梯度的例子</li>
<li>本节,我们是更进一步,求2层神经网络梯度的例子. 所谓2层神经网络,其实就是两个多维数组求梯度
<ul class="org-ul">
<li><p>
详细代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sigmoid</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 1 / <span style="color: #3a81c3;">(</span>1 + np.exp<span style="color: #6c3163;">(</span>-x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">softmax</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = x - np.<span style="color: #3a81c3;">max</span><span style="color: #3a81c3;">(</span>x, axis=-1, keepdims=<span style="color: #4e3163;">True</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> np.exp<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span> / np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>np.exp<span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span>, axis=-1, keepdims=<span style="color: #4e3163;">True</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">cross_entropy_error</span><span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">delta</span> = 1e-7
    <span style="color: #3a81c3; font-weight: bold;">return</span> -np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>t * np.log<span style="color: #6c3163;">(</span>y + delta<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_gradient</span><span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">h</span> = 1e-4  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.0001</span>
    <span style="color: #715ab1;">grad</span> = np.zeros_like<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

    <span style="color: #715ab1;">it</span> = np.nditer<span style="color: #3a81c3;">(</span>x, flags=<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"multi_index"</span><span style="color: #6c3163;">]</span>, op_flags=<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"readwrite"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">while</span> <span style="color: #3a81c3; font-weight: bold;">not</span> it.finished:
        <span style="color: #715ab1;">idx</span> = it.multi_index
        <span style="color: #715ab1;">tmp_val</span> = x<span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val + h
        <span style="color: #715ab1;">fxh1</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x+h)</span>

        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val - h
        <span style="color: #715ab1;">fxh2</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x-h)</span>
        <span style="color: #715ab1;">grad</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = <span style="color: #3a81c3;">(</span>fxh1 - fxh2<span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">(</span>2 * h<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val
        it.iternext<span style="color: #3a81c3;">()</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> grad


<span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">TwoLayerNet</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, input_size, hidden_size, output_size, weight_init_std=0.01<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span> = <span style="color: #3a81c3;">{}</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span> = weight_init_std * np.random.randn<span style="color: #3a81c3;">(</span>input_size, hidden_size<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span> = np.zeros<span style="color: #3a81c3;">(</span>hidden_size<span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span> = weight_init_std * np.random.randn<span style="color: #3a81c3;">(</span>hidden_size, output_size<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span> = np.zeros<span style="color: #3a81c3;">(</span>output_size<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">predict</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">W1</span>, <span style="color: #715ab1;">W2</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span>, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span>
        <span style="color: #715ab1;">b1</span>, <span style="color: #715ab1;">b2</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span>, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span>

        <span style="color: #715ab1;">a1</span> = np.dot<span style="color: #3a81c3;">(</span>x, W1<span style="color: #3a81c3;">)</span> + b1
        <span style="color: #715ab1;">z1</span> = sigmoid<span style="color: #3a81c3;">(</span>a1<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">a2</span> = np.dot<span style="color: #3a81c3;">(</span>z1, W2<span style="color: #3a81c3;">)</span> + b2
        <span style="color: #715ab1;">y</span> = softmax<span style="color: #3a81c3;">(</span>a2<span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">return</span> y

    <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">x: input, t: supervisory data</span>
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">loss</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">y</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.predict<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">return</span> cross_entropy_error<span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">accuracy</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">y</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.predict<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">y</span> = np.argmax<span style="color: #3a81c3;">(</span>y, axis=1<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">t</span> = np.argmax<span style="color: #3a81c3;">(</span>t, axis=1<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">accuracy</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>y == t<span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">float</span><span style="color: #3a81c3;">(</span>x.shape<span style="color: #6c3163;">[</span>0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">return</span> accuracy

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_gradient</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:

        <span style="color: #715ab1;">loss_W</span> = <span style="color: #3a81c3; font-weight: bold;">lambda</span> W: <span style="color: #3a81c3; font-weight: bold;">self</span>.loss<span style="color: #3a81c3;">(</span>x, t<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">grads</span> = <span style="color: #3a81c3;">{}</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span> = numerical_gradient<span style="color: #3a81c3;">(</span>loss_W, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span> = numerical_gradient<span style="color: #3a81c3;">(</span>loss_W, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span> = numerical_gradient<span style="color: #3a81c3;">(</span>loss_W, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span> = numerical_gradient<span style="color: #3a81c3;">(</span>loss_W, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">return</span> grads


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:

    <span style="color: #715ab1;">net</span> = TwoLayerNet<span style="color: #3a81c3;">(</span>input_size=784, hidden_size=100, output_size=10<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>net.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #6c3163;">]</span>.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>net.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #6c3163;">]</span>.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>net.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #6c3163;">]</span>.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>net.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #6c3163;">]</span>.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">x</span> = np.random.rand<span style="color: #3a81c3;">(</span>100, 784<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">t</span> = np.random.rand<span style="color: #3a81c3;">(</span>100, 10<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">grads</span> = net.numerical_gradient<span style="color: #3a81c3;">(</span>x, t<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>grads<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #6c3163;">]</span>.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>grads<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #6c3163;">]</span>.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>grads<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #6c3163;">]</span>.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>grads<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #6c3163;">]</span>.shape<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(784, 100)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(100,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(100, 10)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(10,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(784, 100)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(100,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(100, 10)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(10,)</span>
</pre>
</div></li>
<li>params这个字典,保存的是两层的权重.比如params['W1']是第一层权重, params['b2']是第二层偏置</li>
<li>grads这个字典,保存的是两层的梯度.比如grads['W1']是第一层权重的梯度, grads['b2']是第二层偏置的梯度</li>
<li>input_size是784,这是由输入参数的图像大小(28*28)决定的</li>
<li>output_size是10,这是由我们最终判定的图形种类决定的</li>
<li>hidden_size属于超参,可以由用户经过经验设定</li>
<li>我们这里的权重初始化使用的是"符合高斯分布的随机数进行初始化",偏置使用0初始化</li>
<li>本节的梯度使用的是数值微分的计算方法,这种方法很慢,所以我们的结果要好久才算出来. 下一章我们会介绍
一种高速的计算梯度的方法,叫做误差反向传播</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org19f7abb" class="outline-4">
<h4 id="org19f7abb"><span class="section-number-4">4.5.2.</span> mini-batch的实现</h4>
<div class="outline-text-4" id="text-4-5-2">
<ul class="org-ul">
<li>上一节的例子,就是计算训练集中一个成员的计算梯度的过程(权重是随机初始化的)</li>
<li>如果要得到有意义的权重,那么算一次梯度是没有意义的,因为权重要不停的根据梯度进行更新.算一次梯度,更新
了之后的权重变动很小(因为learning_rate数值就不会大),没有实际意义</li>
<li>最有意义的,恐怕是计算的时候每次计算都把训练集所有的成员都利用一遍,但是这个方法的缺点是太耗费计算资源</li>
<li>mini-batch学习,成功的将上面两个例子的优点结合起来,其核心就是随机选一部数据(也就是多维数组的一部分)
计算梯度(而不是所有有的梯度都计算). 这样既能算出有意义的权重,也不会太耗费资源
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> sys, os

sys.path.append<span style="color: #3a81c3;">(</span>os.pardir<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
<span style="color: #3a81c3; font-weight: bold;">import</span> matplotlib.pyplot <span style="color: #3a81c3; font-weight: bold;">as</span> plt
<span style="color: #3a81c3; font-weight: bold;">import</span> urllib.request
<span style="color: #3a81c3; font-weight: bold;">import</span> gzip
<span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
<span style="color: #3a81c3; font-weight: bold;">import</span> os
<span style="color: #3a81c3; font-weight: bold;">import</span> pickle

<span style="color: #715ab1;">url_base</span> = <span style="color: #2d9574;">"http://yann.lecun.com/exdb/mnist/"</span>
<span style="color: #715ab1;">key_file</span> = <span style="color: #3a81c3;">{</span>
    <span style="color: #2d9574;">"train_img"</span>: <span style="color: #2d9574;">"train-images-idx3-ubyte.gz"</span>,
    <span style="color: #2d9574;">"train_label"</span>: <span style="color: #2d9574;">"train-labels-idx1-ubyte.gz"</span>,
    <span style="color: #2d9574;">"test_img"</span>: <span style="color: #2d9574;">"t10k-images-idx3-ubyte.gz"</span>,
    <span style="color: #2d9574;">"test_label"</span>: <span style="color: #2d9574;">"t10k-labels-idx1-ubyte.gz"</span>,
<span style="color: #3a81c3;">}</span>

<span style="color: #715ab1;">dataset_dir</span> = os.path.dirname<span style="color: #3a81c3;">(</span>os.path.abspath<span style="color: #6c3163;">(</span>__file__<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">save_file</span> = dataset_dir + <span style="color: #2d9574;">"/mnist.pkl"</span>

<span style="color: #715ab1;">train_num</span> = 60000
<span style="color: #715ab1;">test_num</span> = 10000
<span style="color: #715ab1;">img_dim</span> = <span style="color: #3a81c3;">(</span>1, 28, 28<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">img_size</span> = 784


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_download</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3; font-weight: bold;">if</span> os.path.exists<span style="color: #3a81c3;">(</span>file_path<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span>

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Downloading "</span> + file_name + <span style="color: #2d9574;">" ... "</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">headers</span> = <span style="color: #3a81c3;">{</span>
        <span style="color: #2d9574;">"User-Agent"</span>: <span style="color: #2d9574;">"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0"</span>
    <span style="color: #3a81c3;">}</span>
    <span style="color: #715ab1;">request</span> = urllib.request.Request<span style="color: #3a81c3;">(</span>url_base + file_name, headers=headers<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">response</span> = urllib.request.urlopen<span style="color: #3a81c3;">(</span>request<span style="color: #3a81c3;">)</span>.read<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, mode=<span style="color: #2d9574;">"wb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        f.write<span style="color: #3a81c3;">(</span>response<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">download_mnist</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3; font-weight: bold;">for</span> v <span style="color: #3a81c3; font-weight: bold;">in</span> key_file.values<span style="color: #3a81c3;">()</span>:
        _download<span style="color: #3a81c3;">(</span>v<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_load_label</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Converting "</span> + file_name + <span style="color: #2d9574;">" to NumPy Array ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> gzip.<span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">labels</span> = np.frombuffer<span style="color: #3a81c3;">(</span>f.read<span style="color: #6c3163;">()</span>, np.uint8, offset=8<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> labels


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_load_img</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Converting "</span> + file_name + <span style="color: #2d9574;">" to NumPy Array ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> gzip.<span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">data</span> = np.frombuffer<span style="color: #3a81c3;">(</span>f.read<span style="color: #6c3163;">()</span>, np.uint8, offset=16<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">data</span> = data.reshape<span style="color: #3a81c3;">(</span>-1, img_size<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> data


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_convert_numpy</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #715ab1;">dataset</span> = <span style="color: #3a81c3;">{}</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #3a81c3;">]</span> = _load_img<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #3a81c3;">]</span> = _load_label<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">]</span> = _load_img<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #3a81c3;">]</span> = _load_label<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> dataset


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">init_mnist</span><span style="color: #3a81c3;">()</span>:
    download_mnist<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">dataset</span> = _convert_numpy<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Creating pickle file ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>save_file, <span style="color: #2d9574;">"wb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        pickle.dump<span style="color: #3a81c3;">(</span>dataset, f, -1<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done!"</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_change_one_hot_label</span><span style="color: #3a81c3;">(</span>X<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">T</span> = np.zeros<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">(</span>X.size, 10<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">for</span> idx, row <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">enumerate</span><span style="color: #3a81c3;">(</span>T<span style="color: #3a81c3;">)</span>:
        row<span style="color: #3a81c3;">[</span>X<span style="color: #6c3163;">[</span>idx<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">]</span> = 1

    <span style="color: #3a81c3; font-weight: bold;">return</span> T


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">load_mnist</span><span style="color: #3a81c3;">(</span>normalize=<span style="color: #4e3163;">True</span>, flatten=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">False</span><span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">not</span> os.path.exists<span style="color: #3a81c3;">(</span>save_file<span style="color: #3a81c3;">)</span>:
        init_mnist<span style="color: #3a81c3;">()</span>

    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>save_file, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">dataset</span> = pickle.load<span style="color: #3a81c3;">(</span>f<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> normalize:
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train_img"</span>, <span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">)</span>:
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> = dataset<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>.astype<span style="color: #3a81c3;">(</span>np.float32<span style="color: #3a81c3;">)</span>
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> /= 255.0

    <span style="color: #3a81c3; font-weight: bold;">if</span> one_hot_label:
        <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #3a81c3;">]</span> = _change_one_hot_label<span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #3a81c3;">]</span> = _change_one_hot_label<span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">not</span> flatten:
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train_img"</span>, <span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">)</span>:
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> = dataset<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>.reshape<span style="color: #3a81c3;">(</span>-1, 1, 28, 28<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #6c3163;">]</span>, dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span>
        dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #6c3163;">]</span>,
        dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span>,
    <span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sigmoid</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 1 / <span style="color: #3a81c3;">(</span>1 + np.exp<span style="color: #6c3163;">(</span>-x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sigmoid_grad</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>1.0 - sigmoid<span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span> * sigmoid<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">softmax</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = x - np.<span style="color: #3a81c3;">max</span><span style="color: #3a81c3;">(</span>x, axis=-1, keepdims=<span style="color: #4e3163;">True</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> np.exp<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span> / np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>np.exp<span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span>, axis=-1, keepdims=<span style="color: #4e3163;">True</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">cross_entropy_error</span><span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">delta</span> = 1e-7
    <span style="color: #3a81c3; font-weight: bold;">return</span> -np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>t * np.log<span style="color: #6c3163;">(</span>y + delta<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_gradient</span><span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">h</span> = 1e-4  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.0001</span>
    <span style="color: #715ab1;">grad</span> = np.zeros_like<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

    <span style="color: #715ab1;">it</span> = np.nditer<span style="color: #3a81c3;">(</span>x, flags=<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"multi_index"</span><span style="color: #6c3163;">]</span>, op_flags=<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"readwrite"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">while</span> <span style="color: #3a81c3; font-weight: bold;">not</span> it.finished:
        <span style="color: #715ab1;">idx</span> = it.multi_index
        <span style="color: #715ab1;">tmp_val</span> = x<span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val + h
        <span style="color: #715ab1;">fxh1</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x+h)</span>

        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val - h
        <span style="color: #715ab1;">fxh2</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x-h)</span>
        <span style="color: #715ab1;">grad</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = <span style="color: #3a81c3;">(</span>fxh1 - fxh2<span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">(</span>2 * h<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val
        it.iternext<span style="color: #3a81c3;">()</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> grad


<span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">TwoLayerNet</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, input_size, hidden_size, output_size, weight_init_std=0.01<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span> = <span style="color: #3a81c3;">{}</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span> = weight_init_std * np.random.randn<span style="color: #3a81c3;">(</span>input_size, hidden_size<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span> = np.zeros<span style="color: #3a81c3;">(</span>hidden_size<span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span> = weight_init_std * np.random.randn<span style="color: #3a81c3;">(</span>hidden_size, output_size<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span> = np.zeros<span style="color: #3a81c3;">(</span>output_size<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">predict</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">W1</span>, <span style="color: #715ab1;">W2</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span>, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span>
        <span style="color: #715ab1;">b1</span>, <span style="color: #715ab1;">b2</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span>, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span>

        <span style="color: #715ab1;">a1</span> = np.dot<span style="color: #3a81c3;">(</span>x, W1<span style="color: #3a81c3;">)</span> + b1
        <span style="color: #715ab1;">z1</span> = sigmoid<span style="color: #3a81c3;">(</span>a1<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">a2</span> = np.dot<span style="color: #3a81c3;">(</span>z1, W2<span style="color: #3a81c3;">)</span> + b2
        <span style="color: #715ab1;">y</span> = softmax<span style="color: #3a81c3;">(</span>a2<span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">return</span> y

    <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">x: input, t: supervisory data</span>
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">loss</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">y</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.predict<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">return</span> cross_entropy_error<span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">accuracy</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">y</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.predict<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">y</span> = np.argmax<span style="color: #3a81c3;">(</span>y, axis=1<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">t</span> = np.argmax<span style="color: #3a81c3;">(</span>t, axis=1<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">accuracy</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>y == t<span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">float</span><span style="color: #3a81c3;">(</span>x.shape<span style="color: #6c3163;">[</span>0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">return</span> accuracy

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_gradient</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:

        <span style="color: #715ab1;">loss_W</span> = <span style="color: #3a81c3; font-weight: bold;">lambda</span> W: <span style="color: #3a81c3; font-weight: bold;">self</span>.loss<span style="color: #3a81c3;">(</span>x, t<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">grads</span> = <span style="color: #3a81c3;">{}</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span> = numerical_gradient<span style="color: #3a81c3;">(</span>loss_W, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span> = numerical_gradient<span style="color: #3a81c3;">(</span>loss_W, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span> = numerical_gradient<span style="color: #3a81c3;">(</span>loss_W, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span> = numerical_gradient<span style="color: #3a81c3;">(</span>loss_W, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">return</span> grads

    <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">will introduce this method in chapter 5</span>
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">gradient</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">W1</span>, <span style="color: #715ab1;">W2</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span>, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span>
        <span style="color: #715ab1;">b1</span>, <span style="color: #715ab1;">b2</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span>, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span>
        <span style="color: #715ab1;">grads</span> = <span style="color: #3a81c3;">{}</span>

        <span style="color: #715ab1;">batch_num</span> = x.shape<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span>

        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">forward</span>
        <span style="color: #715ab1;">a1</span> = np.dot<span style="color: #3a81c3;">(</span>x, W1<span style="color: #3a81c3;">)</span> + b1
        <span style="color: #715ab1;">z1</span> = sigmoid<span style="color: #3a81c3;">(</span>a1<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">a2</span> = np.dot<span style="color: #3a81c3;">(</span>z1, W2<span style="color: #3a81c3;">)</span> + b2
        <span style="color: #715ab1;">y</span> = softmax<span style="color: #3a81c3;">(</span>a2<span style="color: #3a81c3;">)</span>

        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">backward</span>
        <span style="color: #715ab1;">dy</span> = <span style="color: #3a81c3;">(</span>y - t<span style="color: #3a81c3;">)</span> / batch_num
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span> = np.dot<span style="color: #3a81c3;">(</span>z1.T, dy<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>dy, axis=0<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">dz1</span> = np.dot<span style="color: #3a81c3;">(</span>dy, W2.T<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">da1</span> = sigmoid_grad<span style="color: #3a81c3;">(</span>a1<span style="color: #3a81c3;">)</span> * dz1
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span> = np.dot<span style="color: #3a81c3;">(</span>x.T, da1<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>da1, axis=0<span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">return</span> grads


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #3a81c3;">(</span>x_train, t_train<span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span><span style="color: #715ab1;">x_test</span>, <span style="color: #715ab1;">t_test</span><span style="color: #3a81c3;">)</span> = load_mnist<span style="color: #3a81c3;">(</span>
        normalize=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">True</span>
    <span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"-"</span> * 100<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|x_train.shape|=&gt;"""</span>, x_train.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">network</span> = TwoLayerNet<span style="color: #3a81c3;">(</span>input_size=784, hidden_size=50, output_size=10<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">iters_num</span> = 10000
    <span style="color: #715ab1;">train_size</span> = x_train.shape<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span>
    <span style="color: #715ab1;">batch_size</span> = 100
    <span style="color: #715ab1;">learning_rate</span> = 0.1

    <span style="color: #715ab1;">train_loss_list</span> = <span style="color: #3a81c3;">[]</span>
    <span style="color: #715ab1;">train_acc_list</span> = <span style="color: #3a81c3;">[]</span>
    <span style="color: #715ab1;">test_acc_list</span> = <span style="color: #3a81c3;">[]</span>

    <span style="color: #715ab1;">iter_per_epoch</span> = <span style="color: #3a81c3;">max</span><span style="color: #3a81c3;">(</span>train_size / batch_size, 1<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">for</span> i <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">range</span><span style="color: #3a81c3;">(</span>iters_num<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">batch_mask</span> = np.random.choice<span style="color: #3a81c3;">(</span>train_size, batch_size<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|batch_mask|=&gt;"""</span>, batch_mask<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">x_batch</span> = x_train<span style="color: #3a81c3;">[</span>batch_mask<span style="color: #3a81c3;">]</span>
        <span style="color: #715ab1;">t_batch</span> = t_train<span style="color: #3a81c3;">[</span>batch_mask<span style="color: #3a81c3;">]</span>

        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">grad = network.numerical_gradient(x_batch, t_batch)</span>
        <span style="color: #715ab1;">grad</span> = network.gradient<span style="color: #3a81c3;">(</span>x_batch, t_batch<span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"W1"</span>, <span style="color: #2d9574;">"b1"</span>, <span style="color: #2d9574;">"W2"</span>, <span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">)</span>:
            network.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> -= learning_rate * grad<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>

        <span style="color: #715ab1;">loss</span> = network.loss<span style="color: #3a81c3;">(</span>x_batch, t_batch<span style="color: #3a81c3;">)</span>
        train_loss_list.append<span style="color: #3a81c3;">(</span>loss<span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">if</span> i % iter_per_epoch == 0:
            <span style="color: #715ab1;">train_acc</span> = network.accuracy<span style="color: #3a81c3;">(</span>x_train, t_train<span style="color: #3a81c3;">)</span>
            <span style="color: #715ab1;">test_acc</span> = network.accuracy<span style="color: #3a81c3;">(</span>x_test, t_test<span style="color: #3a81c3;">)</span>
            train_acc_list.append<span style="color: #3a81c3;">(</span>train_acc<span style="color: #3a81c3;">)</span>
            test_acc_list.append<span style="color: #3a81c3;">(</span>test_acc<span style="color: #3a81c3;">)</span>
            <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train acc, test acc | "</span> + <span style="color: #3a81c3;">str</span><span style="color: #6c3163;">(</span>train_acc<span style="color: #6c3163;">)</span> + <span style="color: #2d9574;">", "</span> + <span style="color: #3a81c3;">str</span><span style="color: #6c3163;">(</span>test_acc<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

    <span style="color: #715ab1;">markers</span> = <span style="color: #3a81c3;">{</span><span style="color: #2d9574;">"train"</span>: <span style="color: #2d9574;">"o"</span>, <span style="color: #2d9574;">"test"</span>: <span style="color: #2d9574;">"s"</span><span style="color: #3a81c3;">}</span>
    <span style="color: #715ab1;">x</span> = np.arange<span style="color: #3a81c3;">(</span><span style="color: #3a81c3;">len</span><span style="color: #6c3163;">(</span>train_acc_list<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    plt.plot<span style="color: #3a81c3;">(</span>x, train_acc_list, label=<span style="color: #2d9574;">"train acc"</span><span style="color: #3a81c3;">)</span>
    plt.plot<span style="color: #3a81c3;">(</span>x, test_acc_list, label=<span style="color: #2d9574;">"test acc"</span>, linestyle=<span style="color: #2d9574;">"--"</span><span style="color: #3a81c3;">)</span>
    plt.xlabel<span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"epochs"</span><span style="color: #3a81c3;">)</span>
    plt.ylabel<span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"accuracy"</span><span style="color: #3a81c3;">)</span>
    plt.ylim<span style="color: #3a81c3;">(</span>0, 1.0<span style="color: #3a81c3;">)</span>
    plt.legend<span style="color: #3a81c3;">(</span>loc=<span style="color: #2d9574;">"lower right"</span><span style="color: #3a81c3;">)</span>
    plt.show<span style="color: #3a81c3;">()</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|batch_mask|=&gt; [55042 57580 26353 35980 13656 43434 18767 40423 34832 54980 23740  6243</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">16157 34436   599 20722 14811  3251 10143 59768 13611  5878 42315 51881</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">50937   430 48309 46010 12334 59681 32248 11051 57513 40803 53210 52054</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">59240 51198 41928 46019 27908 18878 52678 54914  1086 16767 41548 18964</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">16539 11742 33476 29459 55901  3382  1806  7439 50428 21073 20977 52301</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">16353 42163  6298 28517 44204 56918 31428 30217 39793 37299 15000 37104</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">37632 19522 24223 52476 16756  5223 18282 29389  6028 45843 47634 44335</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">20943  1030 25547 35279 37407  8161 35126 26345  6441 55142 26255 20225</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">48168 17079 12869  3795]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">...</span>
</pre>
</div></li>
<li><p>
上例最后还会画出一个图,如下
</p>

<div id="org4dd780b" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/4-12.png" alt="4-12.png" />
</p>
<p><span class="figure-number">Figure 43: </span>dlfs/4-12.png</p>
</div></li>
<li>我们可以看到iteration还是不能变的,我们还要循环足够多的次数(这里是10000次)才能得到比较好的权重,但
是每次循环就不需要所有的成员都参加了.我们每次精选100个成员参加,但是每次都是不同的一百个.换句话说
就是:还是训练10000次,但是每次训练规模从60000个784*50的规模,变成了100个784*50的规模</li>
<li>我们这个例子用了误差反向传播,没有用数值微分,因为数值微分计算实在是太慢了.</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgdc8e62c" class="outline-4">
<h4 id="orgdc8e62c"><span class="section-number-4">4.5.3.</span> 基于测试数据的评价</h4>
<div class="outline-text-4" id="text-4-5-3">
<ul class="org-ul">
<li>神经网络学习的目的是掌握泛化能力,要评价神经网络的泛化能力,就必须使用不包含在训练数据中的数据.常用
的办法,就是使用新的权重去测试数据集里面计算准确率.</li>
<li>我们上面的例子中,每过一个epoch会计算一次准确率.
<ul class="org-ul">
<li><p>
epoch的定义是
</p>
<pre class="example" id="orgd1223c4">
所有训练数据都被使用过一次,要用到多少次循环
</pre></li>
<li>比如上面的例子,我们训练集有60000个数据,每次随机选100个,那么我可以(从期望上)认为每600次就用完了所
有的训练集内容.这个100次就是一个epoch</li>
<li>我们的最终结果是打印训练集和测试集中随着epoch而变化的训练集的accuracy和测试集accuracy的对比,我们
发现两者几乎是同一条线,说明我们这次学习没有发生过拟合的现象</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org54d3ebd" class="outline-2">
<h2 id="org54d3ebd"><span class="section-number-2">5.</span> 误差反向传播法</h2>
<div class="outline-text-2" id="text-5">
<ul class="org-ul">
<li>上一章,我们介绍了神经网络的学习,并且通过数值微分计算了神经网络的权重参数的梯度</li>
<li>数值微分虽然简单,也容易实现,但是缺点的计算比较费时间.本章我们将学习一个能够高效计算权重梯度的方法-误差反向传播法</li>
<li>本章使用Computational Graph(计算图)的方法来理解误差反向传播法</li>
</ul>
</div>
<div id="outline-container-org662491b" class="outline-3">
<h3 id="org662491b"><span class="section-number-3">5.1.</span> 计算图</h3>
<div class="outline-text-3" id="text-5-1">
<ul class="org-ul">
<li>计算图是将计算过程用图形表示出来.这里的图形是数据结构图,我们先用一些简单的例子来入门</li>
</ul>
</div>
<div id="outline-container-org0c84cdf" class="outline-4">
<h4 id="org0c84cdf"><span class="section-number-4">5.1.1.</span> 用计算图求解</h4>
<div class="outline-text-4" id="text-5-1-1">
<ul class="org-ul">
<li><p>
下面的问题心算即可求解,但是我们用这些例子来引入计算图
</p>
<pre class="example" id="org0f950ea">
问题1: 在超市买了2个100元的苹果,消费税是10%,请计算支付金额
</pre></li>
<li>计算图通过节点和箭头表示计算过程:
<ul class="org-ul">
<li>节点用容器表示,其中是计算内容</li>
<li>计算的中间结果写在箭头的上方,各个节点的计算结果从左向右传递</li>
</ul></li>
<li>我们把问题1用计算图介绍一下
<ul class="org-ul">
<li><p>
问题1的计算图如下
</p>
<pre class="example" id="org308a392">
              +--------+              +--------+
     100      |        |     200      |        |      220
-------------&gt;|   *2   |-------------&gt;|  *1.1  |-------------&gt;
              |        |              |        |
              +--------+              +--------+
</pre></li>
<li>上面的例子把乘法和数字都放在了容器里面.这样让我们更容易先接受这个方式</li>
<li><p>
更加精确的计算图会把数字和符号分开.容器里面就是简单的计算方法.箭头上面都是数据.如下
</p>
<pre class="example" id="orgeee03d7">
               100    +-------+   200    +-------+    220
            ---------&gt;|   *   |---------&gt;|   *   |---------&gt;
                      +-------+          +-------+
                          ^                  ^
                2         |                  |
apple number--------------+                  |
                                             |
                     1.1                     |
      tax   ---------------------------------+
</pre></li>
</ul></li>
<li>问题2如下</li>
<li>还是用计算图来求解问题2
<ul class="org-ul">
<li><p>
问题2的计算图如下
</p>
<pre class="example" id="orgb144839">
                2
orange number-------------+
                          |
                          V
               100    +-------+    200
            ----------|   *   |----------+
                      +-------+          |
                                         V
                                     +-------+   650    +-------+    715
                                     |   +   |---------&gt;|   *   |---------&gt;
                                     +-------+          +-------+
                                         ^                  ^
               150    +-------+    450   |                  |
            ----------|   *   |----------+                  |
                      +-------+                             |
                          ^                                 |
                3         |                                 |
orange number-------------+                                 |
                                                            |
                                   1.1                      |
       tax  ------------------------------------------------+
</pre></li>
<li>这个例子新增了加法节点"+"来合并苹果和橘子的金额</li>
<li>构建了计算图后,从左向右进行计算,就像电路中的电流流动一样,计算结果从左向右传递,最终在最右边得到计算结果</li>
</ul></li>
<li>经过两个问题的了解之后,我们总结下用计算图解题的步骤:
<ol class="org-ol">
<li>构建计算图</li>
<li>在计算图上,从左向右进行计算</li>
</ol></li>
<li>上面的"从左向右进行计算",是一种正方向上的传播,简称为正向传播</li>
<li>正向传播是从计算图出发点到结束点的传播,既然有正向传播这个名称,那么就有对应的反向传播名称</li>
<li>所谓反向传播,就是从结束点到出发点(也就是上图从右到左)的传播</li>
</ul>
</div>
</div>
<div id="outline-container-orgf2c1521" class="outline-4">
<h4 id="orgf2c1521"><span class="section-number-4">5.1.2.</span> 局部计算</h4>
<div class="outline-text-4" id="text-5-1-2">
<ul class="org-ul">
<li>计算图的特点是可以通过"局部计算"获得最终结果.</li>
<li>所谓"局部计算"是指,无论全局发生了什么,我根据"与自己相关的信息",都能在局部进行一些计算,得出一些结果.
换言之,就是各个节点只需要根据输入和规则进行计算,不需要了解输入是怎么来的,相当于每个输入都是黑盒</li>
<li>我们用一个具体的例子来说明局部计算
<ul class="org-ul">
<li><p>
例子如下
</p>

<div id="org87e146a" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-4.png" alt="5-4.png" />
</p>
<p><span class="figure-number">Figure 44: </span>dlfs/5-4.png</p>
</div></li>
<li>上面的例子中,我们在超市买了2个苹果和其他很多东西</li>
<li>这个"其他很多东西",其实就是黑盒.我们在"其他很多东西"和苹果进行加运算的时候,并不关心这个4000块的
"其他很多东西"是如何计算而来的,只要把这两个数字相加就可以了.</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orga1af80a" class="outline-4">
<h4 id="orga1af80a"><span class="section-number-4">5.1.3.</span> 为何用计算图解题</h4>
<div class="outline-text-4" id="text-5-1-3">
<ul class="org-ul">
<li>截止到目前为止,我们总结下计算图已知的两个优点:
<ul class="org-ul">
<li>无论全局是多么复杂的计算,都可以通过局部计算使得各个节点致力于简单的计算,从而简化问题</li>
<li>利用计算图可以将中间计算结果全部保存起来,比如计算进行到两个苹果的时候金额是200元,加上消费税之前的金额是650元</li>
</ul></li>
<li><p>
但是仅仅这两个优点是不足以让我们使用计算图的,使用计算图的最大原因是:
</p>
<pre class="example" id="orgbcb4e32">
可以通过反向传播高效计算导数
</pre></li>
<li>为何计算图就能能高效计算导数.部分原因在于计算图存储了中间结果,让导数可以利用中间结果,而不是从头算.
我们以问题1来举例说明
<ul class="org-ul">
<li><p>
如图
</p>
<pre class="example" id="orgbf05961">
               100    +-------+   200    +-------+    220
            ---------&gt;|   *   |---------&gt;|   *   |---------&gt;
            &lt;---------|       |&lt;---------|       |&lt;---------
               2.2    +-------+   1.1    +-------+    1
                          ^                  ^
                2         |                  |
apple number--------------+                  |
                                             |
                     1.1                     |
      tax   ---------------------------------+
</pre></li>
<li>这里我们想知道苹果价格上涨在多大程度上会影响最终的支付金额,换句话说,就是"支付金额关于苹果价格的导
数".</li>
<li>设苹果价格为x,支付金额为L,则相当于求 \(\frac{\partial L}{\partial x}\) ,这个导数的值表示当苹果的价
格稍微上涨时,支付金额会增加多少</li>
<li>上图是直接把结果写出来了(使用从右向左的箭头表示),其实是通过"图的反向传播求导数"的方法计算得来的.这方法后面介绍</li>
<li>我们先看这个例子的具体值,反向传播从右向左传递导数的值为2.2&lt;-2-&lt;-1.注意这个值就是L相对于不同变量
的导数.那么我们就可以直观的看到L关于x的导数在最后,就是2.2</li>
<li>这就意味着如果苹果价格上涨1元,最终支付金额将增加2.2元</li>
<li>这里只求了关于苹果价格的导数.其实还可以求:
<ol class="org-ol">
<li>支付金额关于苹果个数的导数:我们算一下其实就是(1.1 * 200 / 2 = 110,注意这里就用到了中间结果).也
就是说,每增加一个苹果,支付金额多110元</li>
<li>支付金额关于消费税率的导数: 我们算一下其实就是(220/1.1=200),也就是说每增加1的税率,支付金额多200</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org4a63b09" class="outline-3">
<h3 id="org4a63b09"><span class="section-number-3">5.2.</span> 链式法则</h3>
<div class="outline-text-3" id="text-5-2">
<ul class="org-ul">
<li>前面我们介绍的计算图的正向传播,因为是我们日常接触到的计算方式,而且传递的是价格,所以理解起来比较自然.</li>
<li>但是反向传播是将"到目前为止的局部导数",按照反方向(从右到左)传递.这个方向看起来有点让人困惑.</li>
<li>这个传递能够成立的理论基础是链式法则(chain rule),我们这一节就介绍链式法则,并阐明它是如何对于国内计算图上的反向传播的</li>
</ul>
</div>
<div id="outline-container-org2c9a88f" class="outline-4">
<h4 id="org2c9a88f"><span class="section-number-4">5.2.1.</span> 计算图的反向传播</h4>
<div class="outline-text-4" id="text-5-2-1">
<ul class="org-ul">
<li>我们先来看一个计算图的反向传播的例子
<ul class="org-ul">
<li><p>
假设存在y=f(x)的计算,其反向传播图如下
</p>

<div id="org3ecdb2e" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-6.png" alt="5-6.png" />
</p>
<p><span class="figure-number">Figure 45: </span>dlfs/5-6.png</p>
</div></li>
<li>反向传播的计算顺序是,将信号E乘以节点的局部导数 \(\frac{\partial y}{\partial x}\) , 然后作为信号传
递给下一个(左边)的节点. 这里的局部导数是指正向传播中y=f(x)的导数</li>
</ul></li>
<li>这就是反向传播的计算顺序,可以看到,由于可以利用中间值,所以计算效率很高.但是为什么这样做的理论基础就
是我们接下来要介绍的链式法则</li>
</ul>
</div>
</div>
<div id="outline-container-org2d83f1d" class="outline-4">
<h4 id="org2d83f1d"><span class="section-number-4">5.2.2.</span> 什么是链式法则</h4>
<div class="outline-text-4" id="text-5-2-2">
<ul class="org-ul">
<li>要介绍链式法则,我们要先从复合函数说起.</li>
<li>复合函数是由多个函数构成的函数,比如 \(z = (x+y)^2\) 是由如下两个式子构成的:
<ul class="org-ul">
<li>\(z = t^2\)</li>
<li>\(t = x + y\)</li>
</ul></li>
<li><p>
链式法则是关于复合函数导数的性质,定义如下
</p>
<pre class="example" id="org7489e88">
如果某个函数由复合函数表示,则该复合函数的导数可以用构成复合函的各个函数的导数的乘积表示
</pre></li>
<li><p>
这句话说起来很复杂,三期用数学式表示的话,反而比较容易理解
</p>
\begin{equation}
\frac{\partial z}{\partial x} = \frac{\partial z}{\partial t} \frac{\partial t}{\partial x} \tag{5.2}
\end{equation}</li>
<li>由于 \(\partial t\) 可以相互抵消,所以记起来非常简单</li>
<li>我们使用链式法则试着求5.2的导数 \(\frac{\partial z}{\partial x}\) , 为此我们分三步:
<ol class="org-ol">
<li>求 \(\frac{\partial z}{\partial t} = 2t\)</li>
<li>求 \(\frac{\partial t}{\partial x} = 1\)</li>
<li><p>
两者相乘 \(2t*1 = 2t\) , 总结起来就是公式5-4
</p>
\begin{equation}
\frac{\partial z}{\partial x} = \frac{\partial z}{\partial t} \frac{\partial t}{\partial x} =2t \cdot 1 = 2(x+y) \tag{5.4}
\end{equation}</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org5cba86c" class="outline-4">
<h4 id="org5cba86c"><span class="section-number-4">5.2.3.</span> 链式法则和计算图</h4>
<div class="outline-text-4" id="text-5-2-3">
<ul class="org-ul">
<li>我们尝试将公式5-4的链式法则用计算图表示出来
<ul class="org-ul">
<li><p>
如图
</p>

<div id="orge1ed67a" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-7.png" alt="5-7.png" />
</p>
<p><span class="figure-number">Figure 46: </span>dlfs/5-7.png</p>
</div></li>
<li>最左边黑线只有一个偏导数,所以总体就是这个偏导数 \(\frac{\partial z}{\partial z}\) 也就是1</li>
<li>中间黑线表示z对t的偏导数. 两个偏导数的乘积 \(\frac{\partial z}{\partial z} \frac{\partial z}{\partial t}\)</li>
<li>左边和弦表示z对x的偏导, 链式法则就是上面两个偏导数的乘积再乘以t对x的偏导\(\frac{\partial z}{\partial z} \frac{\partial z}{\partial t} \frac{\partial t}{\partial x}\)</li>
<li><p>
我们把结果带入得到下图
</p></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org8731f9f" class="outline-3">
<h3 id="org8731f9f"><span class="section-number-3">5.3.</span> 反向传播</h3>
<div class="outline-text-3" id="text-5-3">
<ul class="org-ul">
<li>本节我们会以"+"和"*"的两个例子来截杀反向传播的结构</li>
</ul>
</div>
<div id="outline-container-orgb563d48" class="outline-4">
<h4 id="orgb563d48"><span class="section-number-4">5.3.1.</span> 加法节点的反向传播</h4>
<div class="outline-text-4" id="text-5-3-1">
<ul class="org-ul">
<li><p>
这里以z=x+y为对象,来观察它的反向传播. z=x+y的导数可以由下面两个公式计算出来
</p>
\begin{equation}
\begin{aligned}
\frac{\partial z}{\partial x} &= 1 \\
\frac{\partial z}{\partial y} &= 1
\end{aligned}
\tag{5.5}
\end{equation}</li>
<li>上面的公式可以用下图表示:
<ul class="org-ul">
<li><p>
如下图
</p>

<div id="org027a200" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-9.png" alt="5-9.png" />
</p>
<p><span class="figure-number">Figure 47: </span>dlfs/5-9.png</p>
</div></li>
<li>从右往左看,上游传过来的导数是 \(\frac{\partial L}{\partial z}\)</li>
<li>由于 \(\frac{\partial z}{\partial x}\) 和 \(\frac{\partial z}{\partial y}\) 都等于1,那么右图最左边两
个粗线必然也就只能乘以1. 换句话说,就是输入的值会原封不动的流向下一个节点</li>
<li><p>
上图的L,是我们假定的整个计算最终的输出值.我们的z=x+y计算位于这个计算的某个地方.如下图
</p>

<div id="orgcb24d2a" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-10.png" alt="5-10.png" />
</p>
<p><span class="figure-number">Figure 48: </span>dlfs/5-10.png</p>
</div></li>
<li>上图中最左上的一条斜线的值就是 \(\frac{\partial L}{\partial x}\) , 其计算方法就是 \(\frac{\partial L}{\partial z}\) 乘以 \(\frac{\partial z}{\partial x}\) (也就是1)</li>
<li>上图中最左下的一条斜线的值就是 \(\frac{\partial L}{\partial y}\) , 其计算方法就是 \(\frac{\partial L}{\partial z}\) 乘以 \(\frac{\partial z}{\partial y}\) (也就是1)</li>
</ul></li>
<li>最后,我们带入一个如下的公式来一个实际的例子:
<ul class="org-ul">
<li>z = 15</li>
<li>x = 10</li>
<li>y = 5</li>
<li>从最终结果传递过来的导数为1.3</li>
<li><p>
最终结果如图
</p>

<div id="org3e046e3" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-11.png" alt="5-11.png" />
</p>
<p><span class="figure-number">Figure 49: </span>dlfs/5-11.png</p>
</div></li>
<li>最终,左上的1.3和左下的1.3都继续向下传递</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org828d928" class="outline-4">
<h4 id="org828d928"><span class="section-number-4">5.3.2.</span> 乘法节点的反向传播</h4>
<div class="outline-text-4" id="text-5-3-2">
<ul class="org-ul">
<li><p>
这里以z=x+y为对象,来观察它的反向传播. z=x*y的导数可以由下面两个公式计算出来
</p>
\begin{equation}
\begin{aligned}
\frac{\partial z}{\partial x} &= y \\
\frac{\partial z}{\partial y} &= x
\end{aligned}
\tag{5.6}
\end{equation}</li>
<li>上面的公式可以用下图表示:
<ul class="org-ul">
<li><p>
如下图
</p>

<div id="org21df449" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/5-12.png" alt="5-12.png" />
</p>
<p><span class="figure-number">Figure 50: </span>5-12.png</p>
</div></li>
<li>从右往左看,上游传过来的导数是 \(\frac{\partial L}{\partial z}\)</li>
<li>由于 \(\frac{\partial z}{\partial x} = y\) 和 \(\frac{\partial z}{\partial y} = x\) ,那么传播的时候右
图左边的两个粗线乘以的值正好跟左图左边的两个细线上的字母相反.: 正向传入x,反向乘以y, 也就是
\(\frac{\partial L}{\partial z} \cdot y\) ; 正向传入y,反向乘以x 也就是 \(\frac{\partial L}{\partial z} \cdot x\) .</li>
</ul></li>
<li>最后,我们带入一个如下的公式来一个实际的例子:
<ul class="org-ul">
<li>z = 50</li>
<li>x = 10</li>
<li>y = 5</li>
<li>从最终结果传递过来的导数为1.3</li>
<li><p>
最终结果如图
</p>

<div id="orgcaf1718" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-13.png" alt="5-13.png" />
</p>
<p><span class="figure-number">Figure 51: </span>dlfs/5-13.png</p>
</div></li>
<li>左上的传递来10,但是乘以的是左下的5,所以左上是5*1.3= 6.5</li>
<li>左下的传递来5,但是乘以的是左上的10,所以左上是10*1.3= 13</li>
<li>这里就和加法不一样了,因为加法的导数是1,那么x,y的具体值其实不重要.但是乘法需要乘以"翻转值(x传进来乘以y)",所以,x和y的值都要记录</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org8059b7c" class="outline-4">
<h4 id="org8059b7c"><span class="section-number-4">5.3.3.</span> 苹果的例子</h4>
<div class="outline-text-4" id="text-5-3-3">
<ul class="org-ul">
<li>我们最后来看看购买苹果的例子(2个苹果和消费税)
<ul class="org-ul">
<li><p>
如图
</p>

<div id="orge9e4681" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-14.png" alt="5-14.png" />
</p>
<p><span class="figure-number">Figure 52: </span>dlfs/5-14.png</p>
</div></li>
<li>从前面的学习我们知道,乘法节点的反向传播会将输入信号翻转后传给下游.所以我们得到下面三个导数:
<ol class="org-ol">
<li>支付金额关于苹果价格的导数: 2.2. 也就是说苹果价格涨价1块钱,最终支付价格会涨价2.2块</li>
<li>支付金额关于苹果个数的导数: 110. 也就是说苹果个数增加一个,最终支付价格会涨价110块</li>
<li>支付金额关于消费税的导数:200. 也就是说消费税增加1(从1.1到2.1),最终支付价格会涨价200块</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org55d61ad" class="outline-3">
<h3 id="org55d61ad"><span class="section-number-3">5.4.</span> 简单层的实现</h3>
<div class="outline-text-3" id="text-5-4">
<ul class="org-ul">
<li>本节我们会使用Python来实现前面购买苹果的例子</li>
</ul>
</div>
<div id="outline-container-org1c24775" class="outline-4">
<h4 id="org1c24775"><span class="section-number-4">5.4.1.</span> 乘法层的实现</h4>
<div class="outline-text-4" id="text-5-4-1">
<ul class="org-ul">
<li>我们把层抽象成一个类,其有两个主要方法, forward()用来正向传播, backward()用来反向传播
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">MulLayer</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span><span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">x</span> = <span style="color: #4e3163;">None</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">y</span> = <span style="color: #4e3163;">None</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">forward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, y<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">x</span> = x
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">y</span> = y
        <span style="color: #715ab1;">out</span> = x * y
        <span style="color: #3a81c3; font-weight: bold;">return</span> out

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">backward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, dout<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">dx</span> = dout * <span style="color: #3a81c3; font-weight: bold;">self</span>.y  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#32763;&#36716;</span>
        <span style="color: #715ab1;">dy</span> = dout * <span style="color: #3a81c3; font-weight: bold;">self</span>.x

        <span style="color: #3a81c3; font-weight: bold;">return</span> dx, dy


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #715ab1;">apple</span> = 100
    <span style="color: #715ab1;">apple_num</span> = 2
    <span style="color: #715ab1;">tax</span> = 1.1

    <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">layer</span>
    <span style="color: #715ab1;">mul_apple_layer</span> = MulLayer<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">mul_tax_layer</span> = MulLayer<span style="color: #3a81c3;">()</span>

    <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">forward</span>
    <span style="color: #715ab1;">apple_price</span> = mul_apple_layer.forward<span style="color: #3a81c3;">(</span>apple, apple_num<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">price</span> = mul_tax_layer.forward<span style="color: #3a81c3;">(</span>apple_price, tax<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|price|=&gt;"""</span>, price<span style="color: #3a81c3;">)</span>

    <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">backward</span>
    <span style="color: #715ab1;">dprice</span> = 1
    <span style="color: #715ab1;">dapple_price</span>, <span style="color: #715ab1;">dtax</span> = mul_tax_layer.backward<span style="color: #3a81c3;">(</span>dprice<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dapple</span>, <span style="color: #715ab1;">dapple_num</span> = mul_apple_layer.backward<span style="color: #3a81c3;">(</span>dapple_price<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|dapple|=&gt;"""</span>, dapple<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|dapple_num|=&gt;"""</span>, dapple_num<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|dtax|=&gt;"""</span>, dtax<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|price|=&gt; 220.00000000000003</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|dapple|=&gt; 2.2</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|dapple_num|=&gt; 110.00000000000001</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|dtax|=&gt; 200</span>
</pre>
</div></li>
<li>注意,这里调用backward()和调用forward()的顺序相反.</li>
<li><p>
上面代码运行的效果等同于下图
</p>

<div id="orgb7b6ec9" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-16.png" alt="5-16.png" />
</p>
<p><span class="figure-number">Figure 53: </span>dlfs/5-16.png</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgad8c2b6" class="outline-4">
<h4 id="orgad8c2b6"><span class="section-number-4">5.4.2.</span> 加法层的实现</h4>
<div class="outline-text-4" id="text-5-4-2">
<ul class="org-ul">
<li>加法层本身比较简单,我们把加法层和乘法层结合起来实现买苹果和桔子的例子
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">MulLayer</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span><span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">x</span> = <span style="color: #4e3163;">None</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">y</span> = <span style="color: #4e3163;">None</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">forward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, y<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">x</span> = x
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">y</span> = y
        <span style="color: #715ab1;">out</span> = x * y
        <span style="color: #3a81c3; font-weight: bold;">return</span> out

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">backward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, dout<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">dx</span> = dout * <span style="color: #3a81c3; font-weight: bold;">self</span>.y  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#32763;&#36716;</span>
        <span style="color: #715ab1;">dy</span> = dout * <span style="color: #3a81c3; font-weight: bold;">self</span>.x

        <span style="color: #3a81c3; font-weight: bold;">return</span> dx, dy


<span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">AddLayer</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span><span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">pass</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">forward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, y<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">out</span> = x + y
        <span style="color: #3a81c3; font-weight: bold;">return</span> out

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">backward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, dout<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">dx</span> = dout * 1
        <span style="color: #715ab1;">dy</span> = dout * 1
        <span style="color: #3a81c3; font-weight: bold;">return</span> dx, dy


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #715ab1;">apple</span> = 100
    <span style="color: #715ab1;">apple_num</span> = 2
    <span style="color: #715ab1;">orange</span> = 150
    <span style="color: #715ab1;">orange_num</span> = 3
    <span style="color: #715ab1;">tax</span> = 1.1

    <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">layer</span>
    <span style="color: #715ab1;">mul_apple_layer</span> = MulLayer<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">mul_orange_layer</span> = MulLayer<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">add_apple_orange_layer</span> = AddLayer<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">mul_tax_layer</span> = MulLayer<span style="color: #3a81c3;">()</span>

    <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">forward</span>
    <span style="color: #715ab1;">apple_price</span> = mul_apple_layer.forward<span style="color: #3a81c3;">(</span>apple, apple_num<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(1)</span>
    <span style="color: #715ab1;">orange_price</span> = mul_orange_layer.forward<span style="color: #3a81c3;">(</span>orange, orange_num<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(2)</span>
    <span style="color: #715ab1;">all_price</span> = add_apple_orange_layer.forward<span style="color: #3a81c3;">(</span>apple_price, orange_price<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(3)</span>
    <span style="color: #715ab1;">price</span> = mul_tax_layer.forward<span style="color: #3a81c3;">(</span>all_price, tax<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(4)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|price|=&gt;"""</span>, price<span style="color: #3a81c3;">)</span>

    <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">backward</span>
    <span style="color: #715ab1;">dprice</span> = 1
    <span style="color: #715ab1;">dall_price</span>, <span style="color: #715ab1;">dtax</span> = mul_tax_layer.backward<span style="color: #3a81c3;">(</span>dprice<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(4)</span>
    <span style="color: #715ab1;">dapple_price</span>, <span style="color: #715ab1;">dorange_price</span> = add_apple_orange_layer.backward<span style="color: #3a81c3;">(</span>dall_price<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(3)</span>
    <span style="color: #715ab1;">dorange</span>, <span style="color: #715ab1;">dorange_num</span> = mul_orange_layer.backward<span style="color: #3a81c3;">(</span>dorange_price<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(2)</span>
    <span style="color: #715ab1;">dapple</span>, <span style="color: #715ab1;">dapple_num</span> = mul_apple_layer.backward<span style="color: #3a81c3;">(</span>dapple_price<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">(1)</span>

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|dapple_num|=&gt;"""</span>, dapple_num<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|dapple|=&gt;"""</span>, dapple<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|dorange_num|=&gt;"""</span>, dorange_num<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|dorange|=&gt;"""</span>, dorange<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|dtax|=&gt;"""</span>, dtax<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|price|=&gt; 715.0000000000001</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|dapple_num|=&gt; 110.00000000000001</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|dapple|=&gt; 2.2</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|dorange_num|=&gt; 165.0</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|dorange|=&gt; 3.3000000000000003</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|dtax|=&gt; 650</span>
</pre>
</div></li>
<li><p>
上面代码运行的效果等同于下图
</p>

<div id="org28a7935" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-17.png" alt="5-17.png" />
</p>
<p><span class="figure-number">Figure 54: </span>dlfs/5-17.png</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgf5f99b1" class="outline-3">
<h3 id="orgf5f99b1"><span class="section-number-3">5.5.</span> 激活函数层的实现</h3>
<div class="outline-text-3" id="text-5-5">
<ul class="org-ul">
<li>本节我们将计算图的思路应用到神经网络中,把神经网络的层实现为一个类.</li>
<li>先来看看不同激活函数的激活层:
<ul class="org-ul">
<li>ReLU层</li>
<li>Sigmoid层</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org6fdc5f7" class="outline-4">
<h4 id="org6fdc5f7"><span class="section-number-4">5.5.1.</span> ReLU层</h4>
<div class="outline-text-4" id="text-5-5-1">
<ul class="org-ul">
<li>对于ReLU(Recitified Linear Unit):
<ul class="org-ul">
<li><p>
其公式如下
</p>
\begin{align}
y = \begin{cases}
x & (x > 0) \\
0 & (x \leq 0)
\end{cases} \tag{5.7}
\end{align}</li>
<li><p>
对应的导数公式如下
</p>
\begin{align}
\frac{\partial y}{\partial x} = \begin{cases}
1 & (x > 0) \\
0 & (x \leq 0)
\end{cases} \tag{5.8}
\end{align}</li>
</ul></li>
<li>换句话说,对于ReLU:
<ul class="org-ul">
<li>如果正向传播时的输入x大于0,则反向传播将原封不动的传递给下游(乘以1)</li>
<li>如果整型传播时的输入x小于0,则反向传播的信号将停留在次数(乘以0)</li>
<li><p>
上面的过程可以如下图显示
</p>

<div id="org05762b5" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-18.png" alt="5-18.png" />
</p>
<p><span class="figure-number">Figure 55: </span>dlfs/5-18.png</p>
</div></li>
</ul></li>
<li>我们可以把上图总结为代码
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">Relu</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span><span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">mask</span> = <span style="color: #4e3163;">None</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">forward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">mask</span> = x &lt; 0
        <span style="color: #715ab1;">out</span> = x.copy<span style="color: #3a81c3;">()</span>
        <span style="color: #715ab1;">out</span><span style="color: #3a81c3;">[</span><span style="color: #3a81c3; font-weight: bold;">self</span>.mask<span style="color: #3a81c3;">]</span> = 0
        <span style="color: #3a81c3; font-weight: bold;">return</span> out

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">backward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, dout<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">dout</span><span style="color: #3a81c3;">[</span><span style="color: #3a81c3; font-weight: bold;">self</span>.mask<span style="color: #3a81c3;">]</span> = 0
        <span style="color: #715ab1;">dx</span> = dout
        <span style="color: #3a81c3; font-weight: bold;">return</span> dx
</pre>
</div></li>
<li>注意,这里的mask是一个由True/False组成的NumPy数组.正向传播时输入的x小于0的index位置为True,其他位置为False</li>
<li><p>
mask作为数组的[]的时候.作用就是所有为index为True的位置会发生变化.比如下面这句话就是把数组index为1,2的值设置为0
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np

<span style="color: #715ab1;">x</span> = np.array<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">[</span><span style="color: #2d9574;">[</span>1.0, -0.5<span style="color: #2d9574;">]</span>, <span style="color: #2d9574;">[</span>-2.0, 3.0<span style="color: #2d9574;">]</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|x|=&gt;"""</span>, x<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">mask</span> = x &lt;= 0
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|mask|=&gt;"""</span>, mask<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|x[mask]|=&gt;"""</span>, x<span style="color: #6c3163;">[</span>mask<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">x_copy</span> = x.copy<span style="color: #3a81c3;">()</span>
<span style="color: #715ab1;">x_copy</span><span style="color: #3a81c3;">[</span>mask<span style="color: #3a81c3;">]</span> = 0
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|x_copy|=&gt;"""</span>, x_copy<span style="color: #3a81c3;">)</span>


<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|x|=&gt; [[ 1.  -0.5]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[-2.   3. ]]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|mask|=&gt; [[False  True]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[ True False]]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|x[mask]|=&gt; [-0.5 -2. ]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|x_copy|=&gt; [[1. 0.]</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#  </span><span style="color: #2aa1ae; background-color: #ecf3ec;">[0. 3.]]</span>
</pre>
</div></li>
</ul></li>
<li>ReLU层的作用就像电路中的开关一样:
<ul class="org-ul">
<li>正向传播时,有电流通过的话,就将开关设置为ON; 没有电流通过的话,就将开关设置为OFF</li>
<li>反向传播时,开关为ON的话,电流会直接通过;开关为OFF的话,则不会有电流通过</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org978daaf" class="outline-4">
<h4 id="org978daaf"><span class="section-number-4">5.5.2.</span> Sigmoid层</h4>
<div class="outline-text-4" id="text-5-5-2">
<ul class="org-ul">
<li>接下来我们实现sigmoid函数
<ul class="org-ul">
<li><p>
sigmoid函数公式如下
</p>
\begin{equation}
y = \frac{1}{1 + \exp(-x)} \tag{5.9}
\end{equation}</li>
<li><p>
用计算图表示如图
</p>

<div id="org4182d9f" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-19.png" alt="5-19.png" />
</p>
<p><span class="figure-number">Figure 56: </span>dlfs/5-19.png</p>
</div></li>
<li>上图中的"exp"节点会进行y=exp(x)计算</li>
<li>上图中的"/"节点会进行y=1/x计算</li>
</ul></li>
<li>我们分步骤来进行反向传播的流程:</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org380918c"></a>步骤1<br />
<div class="outline-text-5" id="text-5-5-2-1">
<ul class="org-ul">
<li><p>
"/"节点表示y=1/x, 其导数可以解析为
</p>
\begin{equation}
\begin{aligned}
\frac{\partial y}{\partial x} &= -\frac{1}{x^2} \notag \\
&= -y^2
\end{aligned}
\tag{5.10}
\end{equation}</li>
<li><p>
根据公式5-10,反向传播时,会将上游值乘以 \(-y^2\) 后再传递给下游,如下图
</p>

<div id="org0657125" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-19-1.png" alt="5-19-1.png" />
</p>
<p><span class="figure-number">Figure 57: </span>dlfs/5-19-1.png</p>
</div></li>
</ul>
</div>
</li>
<li><a id="orgb954335"></a>步骤2<br />
<div class="outline-text-5" id="text-5-5-2-2">
<ul class="org-ul">
<li><p>
"+" 节点将上游的值原封不动地传递给下游,计算图如下所示
</p>

<div id="orgcc29ad7" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-19-2.png" alt="5-19-2.png" />
</p>
<p><span class="figure-number">Figure 58: </span>dlfs/5-19-2.png</p>
</div></li>
</ul>
</div>
</li>
<li><a id="org1f38765"></a>步骤3<br />
<div class="outline-text-5" id="text-5-5-2-3">
<ul class="org-ul">
<li><p>
"exp"节点表示y=exp(x), 它的倒数有如下公式表示
</p>
\begin{equation}
\frac{\partial y}{\partial x} = \exp(x) \tag{5.1}
\end{equation}</li>
<li><p>
在计算图中,上游值值乘以正向传播时候的输出(注意这里是exp(-x)),再传递给下游,如图
</p>

<div id="orgfea31d5" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-19-3.png" alt="5-19-3.png" />
</p>
<p><span class="figure-number">Figure 59: </span>dlfs/5-19-3.png</p>
</div></li>
</ul>
</div>
</li>
<li><a id="org64b8053"></a>步骤4<br />
<div class="outline-text-5" id="text-5-5-2-4">
<ul class="org-ul">
<li><p>
"*" 节点将正向传播时的值翻转后做乘法运算,因此这里要乘以-1
</p>

<div id="org16973f8" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-20.png" alt="5-20.png" />
</p>
<p><span class="figure-number">Figure 60: </span>dlfs/5-20.png</p>
</div></li>
</ul>
</div>
</li>
<li><a id="org46f8116"></a>总结<br />
<div class="outline-text-5" id="text-5-5-2-5">
<ul class="org-ul">
<li>上面所有的步骤综合起来
<ul class="org-ul">
<li><p>
我们把前面的步骤只留着头和尾就得到下面的图
</p>

<div id="org897eac0" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-21.png" alt="5-21.png" />
</p>
<p><span class="figure-number">Figure 61: </span>dlfs/5-21.png</p>
</div></li>
<li>我们可以看到总结起来sigmoid的反向传播值就是 \(\frac{\partial L}{\partial y} y^2 \exp(-x)\)</li>
<li><p>
我们还可以通过如下计算得到 \(\frac{\partial L}{\partial y} y^2 \exp(-x)\) 其实就是 \(\frac{\partial L}{\partial y} y (1-y)\).
整个公式的推导过程如下
</p>
\begin{equation}
\begin{aligned}
\frac{\partial L }{\partial y} y^2 \exp(-x) &= \frac{\partial L }{\partial y} \frac{1}{(1+\exp(-x))^2} \exp(-x) \\
                                            &=\frac{\partial L }{\partial y} \frac{1}{1+\exp(-x)} \frac{\exp(-x)}{1 + \exp(-x)} \\
                                            &=\frac{\partial L }{\partial y} \frac{1}{1+\exp(-x)} \frac{1+\exp(-x)-1}{1 + \exp(-x)} \\
                                            &=\frac{\partial L }{\partial y} \frac{1}{1+\exp(-x)} \frac{1+\exp(-x)}{1 + \exp(-x)} \frac{-1}{1 + \exp(-x)} \\
                                            &= \frac{\partial L }{\partial y} y(1-y)
\end{aligned}
\tag{5.12}
\end{equation}</li>
<li><p>
那么我们最终得到下图
</p>

<div id="orgd343ef9" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-21.png" alt="5-21.png" />
</p>
<p><span class="figure-number">Figure 62: </span>dlfs/5-21.png</p>
</div></li>
</ul></li>
<li><p>
有了这些实现以后,我们就可以使用python代码来实现sigmoid
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">Sigmoid</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span><span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">out</span> = <span style="color: #4e3163;">None</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">forward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">out</span> = 1 / <span style="color: #3a81c3;">(</span>1 + np.exp<span style="color: #6c3163;">(</span>-x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">out</span> = out
        <span style="color: #3a81c3; font-weight: bold;">return</span> out

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">backward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, dout<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">dx</span> = dout * <span style="color: #3a81c3;">(</span>1.0 - <span style="color: #3a81c3; font-weight: bold;">self</span>.out<span style="color: #3a81c3;">)</span> * <span style="color: #3a81c3; font-weight: bold;">self</span>.out
        <span style="color: #3a81c3; font-weight: bold;">return</span> dx
</pre>
</div></li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-orgea2f217" class="outline-3">
<h3 id="orgea2f217"><span class="section-number-3">5.6.</span> Affine/Softmax层的实现</h3>
<div class="outline-text-3" id="text-5-6">
</div>
<div id="outline-container-org51e4b43" class="outline-4">
<h4 id="org51e4b43"><span class="section-number-4">5.6.1.</span> Affine层</h4>
<div class="outline-text-4" id="text-5-6-1">
<ul class="org-ul">
<li>仿射变换(Affine Transformation)是几何学忠的一种线性变化.包括一次线性变换和一次平移,分别对应神经网络
的加权和运算,加偏置运算.所以处理仿射变换的处理我们叫做"Affine层"</li>
<li>神经网络的正向传播中,为了计算加权信号的总和,使用了矩阵乘法
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np

<span style="color: #715ab1;">X</span> = np.random.rand<span style="color: #3a81c3;">(</span>2<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">W</span> = np.random.rand<span style="color: #3a81c3;">(</span>2, 3<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">B</span> = np.random.rand<span style="color: #3a81c3;">(</span>3<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|X.shape|=&gt;"""</span>, X.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|W.shape|=&gt;"""</span>, W.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|B.shape|=&gt;"""</span>, B.shape<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|np.dot(X,W).shape|=&gt;"""</span>, np.dot<span style="color: #6c3163;">(</span>X, W<span style="color: #6c3163;">)</span>.shape<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">Y</span> = np.dot<span style="color: #3a81c3;">(</span>X, W<span style="color: #3a81c3;">)</span> + B
<span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|Y.shape|=&gt;"""</span>, Y.shape<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|X.shape|=&gt; (2,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|W.shape|=&gt; (2, 3)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|B.shape|=&gt; (3,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|np.dot(X,W).shape|=&gt; (3,)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|Y.shape|=&gt; (3,)</span>
</pre>
</div></li>
<li>Y就是神经元的加权值.这个加权值经过激活函数转换后,传递给下一层.</li>
<li><p>
整个计算过程中,X和W的维度必须能够适配才能进行相乘.如图
</p>

<div id="org2c62365" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-23.png" alt="5-23.png" />
</p>
<p><span class="figure-number">Figure 63: </span>dlfs/5-23.png</p>
</div></li>
</ul></li>
<li>下面,我们将上面的"矩阵乘积+偏置"的计算,用计算图表示出来
<ul class="org-ul">
<li><p>
如图
</p>

<div id="org9062a8a" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-24.png" alt="5-24.png" />
</p>
<p><span class="figure-number">Figure 64: </span>dlfs/5-24.png</p>
</div></li>
<li>其中矩阵乘积运算用dot表示</li>
<li>之前我们的计算图中,各个节点之间流动的是标量.而这里流动的X,W,B都是矩阵</li>
<li>另外在各个变量的上方标记了他们的shape</li>
</ul></li>
<li>我们把上面的计算图的反向传播再来组织一下
<ul class="org-ul">
<li><p>
首先,矩阵求导由于矩阵shape的关系,其和标量的求导公式有些许区别
</p>
\begin{align}
\frac{\partial L}{\partial \mathbf{X}} &= \frac{\partial L}{\partial \mathbf{Y}} \cdot \mathbf{W}^\top \\
\frac{\partial L}{\partial \mathbf{W}} &= \mathbf{X}^\top \cdot \frac{\partial L}{\partial \mathbf{Y}}
\end{align}</li>
<li>其中的 \(\mathbf{W}^\top\) 表示转置,转置操作会把(i,j)元素换成(j,i)</li>
<li><p>
下图就是上面计算图的反向传播
</p>

<div id="org6638fea" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-25.png" alt="5-25.png" />
</p>
<p><span class="figure-number">Figure 65: </span>dlfs/5-25.png</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orge040c4c" class="outline-4">
<h4 id="orge040c4c"><span class="section-number-4">5.6.2.</span> 批版本的Affine层</h4>
<div class="outline-text-4" id="text-5-6-2">
<ul class="org-ul">
<li>前面介绍的Affine层的输入矩阵X,每个成员都是单个数据.也就是说X是一个向量.</li>
<li>而真正计算的时候,是批量的算的的,也就是说X的每个成员都是向量,X自己是一个矩阵.这就是所谓的批版本的Affine层
<ul class="org-ul">
<li><p>
批版本的Affine层的计算图如下
</p>

<div id="orgdc0b30c" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-27.png" alt="5-27.png" />
</p>
<p><span class="figure-number">Figure 66: </span>dlfs/5-27.png</p>
</div></li>
<li><p>
批版本的代码实现如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np


<span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">Affine</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, W, b<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">W</span> = W
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">b</span> = b
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">x</span> = <span style="color: #4e3163;">None</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">dW</span> = <span style="color: #4e3163;">None</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">db</span> = <span style="color: #4e3163;">None</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">forward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">x</span> = x
        <span style="color: #715ab1;">out</span> = np.dot<span style="color: #3a81c3;">(</span>x, <span style="color: #3a81c3; font-weight: bold;">self</span>.W<span style="color: #3a81c3;">)</span> + <span style="color: #3a81c3; font-weight: bold;">self</span>.b

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">backward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, dout<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">dx</span> = np.dot<span style="color: #3a81c3;">(</span>dout, <span style="color: #3a81c3; font-weight: bold;">self</span>.W.T<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">dw</span> = np.dot<span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>.x.T, dout<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">db</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>dout, axis=0<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">return</span> dx
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org6899955" class="outline-4">
<h4 id="org6899955"><span class="section-number-4">5.6.3.</span> Softmax-with-Loss层</h4>
<div class="outline-text-4" id="text-5-6-3">
<ul class="org-ul">
<li>最后介绍一下输出层的softmax函数.
<ul class="org-ul">
<li>softmax函数会将输入值正规化之后再输出</li>
<li><p>
比如下图,就是手写数字识别时,softmax层的输出如下
</p>

<div id="orga9626dc" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-28.png" alt="5-28.png" />
</p>
<p><span class="figure-number">Figure 67: </span>dlfs/5-28.png</p>
</div></li>
<li>上图中"0"的得分是5.3,这个值经过softmax层转换后概率为0.8%.</li>
<li>上图中"2"的得分是10.1,这个值经过softmax层转换后概率为99.1%</li>
<li>softmax的定义就是把"输出值的和调整为1"之后再输出.这个例子就是把10个输出的值调整为1,然后输出</li>
</ul></li>
<li>神经网络中通常分成推理和学习两个阶段,通常只有学习阶段需要softmax层,推理阶段不需要softmax层</li>
<li>我们下面来实现softmax层
<ul class="org-ul">
<li><p>
因为这个也包含作为损失函数的交叉熵误差(Cross Entropy Error),如下图,所以我们统称为Softmax-with-Loss层
</p>

<div id="orgfb32384" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-29.png" alt="5-29.png" />
</p>
<p><span class="figure-number">Figure 68: </span>dlfs/5-29.png</p>
</div></li>
</ul></li>
<li>上图过于复杂,我们经过简化,能将上图转换为下图
<ul class="org-ul">
<li><p>
如图
</p>

<div id="org4304030" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/dlfs/5-30.png" alt="5-30.png" />
</p>
<p><span class="figure-number">Figure 69: </span>dlfs/5-30.png</p>
</div></li>
<li>上图中,Softmax层将输入(a1,a2,a3)正则化,输出(y1,y2,y3)</li>
<li>Cross Entropy Error层接收Softmax的输出(y1,y2,y3)和教师标签(t1,t2,t3),从这些数据中输出损失L</li>
<li>深色的黑色线条从右往左就是反向传播的结果.我们看到Softmax层的反向传播得到的结果都是非常漂亮的:(y1-t1,y2-t2,y3-t3)</li>
<li><p>
实际上,这样"漂亮"的结果并不是偶然,而是为了得到这样漂亮的结果,特意设计了交叉熵误差函数.换句话说
</p>
<pre class="example" id="org5940bb1">
使用"平方和误差"作为"恒等函数"的损失函数,反向传播才能得到(y1-t1,y2-t2,y3-t3)这样"漂亮"的结果
</pre></li>
<li>这里我们举个具体的例子:比如老师标签是(0,1,0), Softmax层的输出是(0.3,0.2,0.5),这种情况下,明细正确
标签出的概率是0.2(20%),也就是这时候神经网络没有正确识别,此时Softmax层的反向传播是(0.3, -0.8, 0.5)
这样一个大的误差.因为这个大的误差会向前面的层传播,所以Softmax层前面的层会从这个大的误差中学习到"大"
的内容</li>
</ul></li>
<li>最后我们来看看代码实现
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">SoftmaxWithLoss</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span><span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">loss</span> = <span style="color: #4e3163;">None</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">y</span> = <span style="color: #4e3163;">None</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">t</span> = <span style="color: #4e3163;">None</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">forward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">t</span> = t
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">y</span> = softmax<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">loss</span> = cross_entropy_error<span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>.y, <span style="color: #3a81c3; font-weight: bold;">self</span>.t<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3; font-weight: bold;">self</span>.loss

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">backward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, dout=1<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">batch_size</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.t.shape<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span>
        <span style="color: #715ab1;">dx</span> = <span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>.y - <span style="color: #3a81c3; font-weight: bold;">self</span>.t<span style="color: #3a81c3;">)</span> / batch_size
        <span style="color: #3a81c3; font-weight: bold;">return</span> dx
</pre>
</div></li>
<li>这里的实现非常简单,只需要注意反向传播时,将要传播的值除以batch_size后,传递给前面的层的是单个数据
的误差</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org35cea52" class="outline-3">
<h3 id="org35cea52"><span class="section-number-3">5.7.</span> 误差反向传播法的实现</h3>
<div class="outline-text-3" id="text-5-7">
</div>
<div id="outline-container-orgfe1c7b1" class="outline-4">
<h4 id="orgfe1c7b1"><span class="section-number-4">5.7.1.</span> 神经网络学习的全貌图</h4>
<div class="outline-text-4" id="text-5-7-1">
<ul class="org-ul">
<li>在进行具体的实现之前,我们再次来确认一下神经网络的学习全貌,步骤如下:
<ol class="org-ol">
<li>mini-batch: 从训练数据中随机选择一部分数据</li>
<li>计算梯度: 计算损失函数对于各个权重参数的梯度</li>
<li>更新参数: 将权重参数沿梯度方向进行微小的更新</li>
<li>重复步骤1,步骤2,步骤3</li>
</ol></li>
<li>上一章我们使用数值微分来进行第二步"计算梯度",数值微分的实现虽然简单,但是计算要耗费较多时间,更好的
办法是使用本章引入的"误差反向传播法"来替代"数值微分". 因为"误差反向传播算法"可以快速高效地计算梯度</li>
</ul>
</div>
</div>
<div id="outline-container-org34f3b3a" class="outline-4">
<h4 id="org34f3b3a"><span class="section-number-4">5.7.2.</span> 对应误差反向传播法的神经网络实现</h4>
<div class="outline-text-4" id="text-5-7-2">
<ul class="org-ul">
<li>下面是误差反向传播的神经网络实现.和第四章不一样的地方在于,这里使用了层.获得结果的predict,技术梯度
的gradient都是通过层实现的
<ul class="org-ul">
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
<span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
<span style="color: #3a81c3; font-weight: bold;">import</span> urllib.request
<span style="color: #3a81c3; font-weight: bold;">import</span> gzip
<span style="color: #3a81c3; font-weight: bold;">import</span> numpy <span style="color: #3a81c3; font-weight: bold;">as</span> np
<span style="color: #3a81c3; font-weight: bold;">import</span> os
<span style="color: #3a81c3; font-weight: bold;">import</span> pickle
<span style="color: #3a81c3; font-weight: bold;">from</span> collections <span style="color: #3a81c3; font-weight: bold;">import</span> OrderedDict


<span style="color: #715ab1;">url_base</span> = <span style="color: #2d9574;">"http://yann.lecun.com/exdb/mnist/"</span>
<span style="color: #715ab1;">key_file</span> = <span style="color: #3a81c3;">{</span>
    <span style="color: #2d9574;">"train_img"</span>: <span style="color: #2d9574;">"train-images-idx3-ubyte.gz"</span>,
    <span style="color: #2d9574;">"train_label"</span>: <span style="color: #2d9574;">"train-labels-idx1-ubyte.gz"</span>,
    <span style="color: #2d9574;">"test_img"</span>: <span style="color: #2d9574;">"t10k-images-idx3-ubyte.gz"</span>,
    <span style="color: #2d9574;">"test_label"</span>: <span style="color: #2d9574;">"t10k-labels-idx1-ubyte.gz"</span>,
<span style="color: #3a81c3;">}</span>

<span style="color: #715ab1;">dataset_dir</span> = os.path.dirname<span style="color: #3a81c3;">(</span>os.path.abspath<span style="color: #6c3163;">(</span>__file__<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">save_file</span> = dataset_dir + <span style="color: #2d9574;">"/mnist.pkl"</span>

<span style="color: #715ab1;">train_num</span> = 60000
<span style="color: #715ab1;">test_num</span> = 10000
<span style="color: #715ab1;">img_dim</span> = <span style="color: #3a81c3;">(</span>1, 28, 28<span style="color: #3a81c3;">)</span>
<span style="color: #715ab1;">img_size</span> = 784


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_download</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3; font-weight: bold;">if</span> os.path.exists<span style="color: #3a81c3;">(</span>file_path<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">return</span>

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Downloading "</span> + file_name + <span style="color: #2d9574;">" ... "</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">headers</span> = <span style="color: #3a81c3;">{</span>
        <span style="color: #2d9574;">"User-Agent"</span>: <span style="color: #2d9574;">"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0"</span>
    <span style="color: #3a81c3;">}</span>
    <span style="color: #715ab1;">request</span> = urllib.request.Request<span style="color: #3a81c3;">(</span>url_base + file_name, headers=headers<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">response</span> = urllib.request.urlopen<span style="color: #3a81c3;">(</span>request<span style="color: #3a81c3;">)</span>.read<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, mode=<span style="color: #2d9574;">"wb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        f.write<span style="color: #3a81c3;">(</span>response<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">download_mnist</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #3a81c3; font-weight: bold;">for</span> v <span style="color: #3a81c3; font-weight: bold;">in</span> key_file.values<span style="color: #3a81c3;">()</span>:
        _download<span style="color: #3a81c3;">(</span>v<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_load_label</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Converting "</span> + file_name + <span style="color: #2d9574;">" to NumPy Array ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> gzip.<span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">labels</span> = np.frombuffer<span style="color: #3a81c3;">(</span>f.read<span style="color: #6c3163;">()</span>, np.uint8, offset=8<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> labels


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_load_img</span><span style="color: #3a81c3;">(</span>file_name<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">file_path</span> = dataset_dir + <span style="color: #2d9574;">"/"</span> + file_name

    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Converting "</span> + file_name + <span style="color: #2d9574;">" to NumPy Array ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> gzip.<span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>file_path, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">data</span> = np.frombuffer<span style="color: #3a81c3;">(</span>f.read<span style="color: #6c3163;">()</span>, np.uint8, offset=16<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">data</span> = data.reshape<span style="color: #3a81c3;">(</span>-1, img_size<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done"</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> data


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_convert_numpy</span><span style="color: #3a81c3;">()</span>:
    <span style="color: #715ab1;">dataset</span> = <span style="color: #3a81c3;">{}</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #3a81c3;">]</span> = _load_img<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #3a81c3;">]</span> = _load_label<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">]</span> = _load_img<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #3a81c3;">]</span> = _load_label<span style="color: #3a81c3;">(</span>key_file<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> dataset


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">init_mnist</span><span style="color: #3a81c3;">()</span>:
    download_mnist<span style="color: #3a81c3;">()</span>
    <span style="color: #715ab1;">dataset</span> = _convert_numpy<span style="color: #3a81c3;">()</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Creating pickle file ..."</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>save_file, <span style="color: #2d9574;">"wb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        pickle.dump<span style="color: #3a81c3;">(</span>dataset, f, -1<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"Done!"</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">_change_one_hot_label</span><span style="color: #3a81c3;">(</span>X<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">T</span> = np.zeros<span style="color: #3a81c3;">(</span><span style="color: #6c3163;">(</span>X.size, 10<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">for</span> idx, row <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">enumerate</span><span style="color: #3a81c3;">(</span>T<span style="color: #3a81c3;">)</span>:
        row<span style="color: #3a81c3;">[</span>X<span style="color: #6c3163;">[</span>idx<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">]</span> = 1

    <span style="color: #3a81c3; font-weight: bold;">return</span> T


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">load_mnist</span><span style="color: #3a81c3;">(</span>normalize=<span style="color: #4e3163;">True</span>, flatten=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">False</span><span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">not</span> os.path.exists<span style="color: #3a81c3;">(</span>save_file<span style="color: #3a81c3;">)</span>:
        init_mnist<span style="color: #3a81c3;">()</span>

    <span style="color: #3a81c3; font-weight: bold;">with</span> <span style="color: #3a81c3;">open</span><span style="color: #3a81c3;">(</span>save_file, <span style="color: #2d9574;">"rb"</span><span style="color: #3a81c3;">)</span> <span style="color: #3a81c3; font-weight: bold;">as</span> f:
        <span style="color: #715ab1;">dataset</span> = pickle.load<span style="color: #3a81c3;">(</span>f<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> normalize:
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train_img"</span>, <span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">)</span>:
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> = dataset<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>.astype<span style="color: #3a81c3;">(</span>np.float32<span style="color: #3a81c3;">)</span>
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> /= 255.0

    <span style="color: #3a81c3; font-weight: bold;">if</span> one_hot_label:
        <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #3a81c3;">]</span> = _change_one_hot_label<span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #3a81c3;">]</span> = _change_one_hot_label<span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">not</span> flatten:
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"train_img"</span>, <span style="color: #2d9574;">"test_img"</span><span style="color: #3a81c3;">)</span>:
            <span style="color: #715ab1;">dataset</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> = dataset<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>.reshape<span style="color: #3a81c3;">(</span>-1, 1, 28, 28<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_img"</span><span style="color: #6c3163;">]</span>, dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"train_label"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span>
        dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_img"</span><span style="color: #6c3163;">]</span>,
        dataset<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"test_label"</span><span style="color: #6c3163;">]</span>,
    <span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">identity_function</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> x


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">step_function</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> np.array<span style="color: #3a81c3;">(</span>x &gt; 0, dtype=np.<span style="color: #3a81c3;">int</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sigmoid</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 1 / <span style="color: #3a81c3;">(</span>1 + np.exp<span style="color: #6c3163;">(</span>-x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sigmoid_grad</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3;">(</span>1.0 - sigmoid<span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span> * sigmoid<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">relu</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> np.maximum<span style="color: #3a81c3;">(</span>0, x<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">relu_grad</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">grad</span> = np.zeros_like<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">grad</span><span style="color: #3a81c3;">[</span>x &gt;= 0<span style="color: #3a81c3;">]</span> = 1
    <span style="color: #3a81c3; font-weight: bold;">return</span> grad


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">softmax</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">x</span> = x - np.<span style="color: #3a81c3;">max</span><span style="color: #3a81c3;">(</span>x, axis=-1, keepdims=<span style="color: #4e3163;">True</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> np.exp<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span> / np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>np.exp<span style="color: #6c3163;">(</span>x<span style="color: #6c3163;">)</span>, axis=-1, keepdims=<span style="color: #4e3163;">True</span><span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">sum_squared_error</span><span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">return</span> 0.5 * np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span><span style="color: #6c3163;">(</span>y - t<span style="color: #6c3163;">)</span> ** 2<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">cross_entropy_error</span><span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>:
    <span style="color: #3a81c3; font-weight: bold;">if</span> y.ndim == 1:
        <span style="color: #715ab1;">t</span> = t.reshape<span style="color: #3a81c3;">(</span>1, t.size<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">y</span> = y.reshape<span style="color: #3a81c3;">(</span>1, y.size<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">if</span> t.size == y.size:
        <span style="color: #715ab1;">t</span> = t.argmax<span style="color: #3a81c3;">(</span>axis=1<span style="color: #3a81c3;">)</span>

    <span style="color: #715ab1;">batch_size</span> = y.shape<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> -np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>np.log<span style="color: #6c3163;">(</span>y<span style="color: #2d9574;">[</span>np.arange<span style="color: #67b11d;">(</span>batch_size<span style="color: #67b11d;">)</span>, t<span style="color: #2d9574;">]</span> + 1e-7<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span> / batch_size


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">softmax_loss</span><span style="color: #3a81c3;">(</span>X, t<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">y</span> = softmax<span style="color: #3a81c3;">(</span>X<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">return</span> cross_entropy_error<span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>


<span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_gradient</span><span style="color: #3a81c3;">(</span>f, x<span style="color: #3a81c3;">)</span>:
    <span style="color: #715ab1;">h</span> = 1e-4  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.0001</span>
    <span style="color: #715ab1;">grad</span> = np.zeros_like<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

    <span style="color: #715ab1;">it</span> = np.nditer<span style="color: #3a81c3;">(</span>x, flags=<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"multi_index"</span><span style="color: #6c3163;">]</span>, op_flags=<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"readwrite"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3; font-weight: bold;">while</span> <span style="color: #3a81c3; font-weight: bold;">not</span> it.finished:
        <span style="color: #715ab1;">idx</span> = it.multi_index
        <span style="color: #715ab1;">tmp_val</span> = x<span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span>
        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val + h
        <span style="color: #715ab1;">fxh1</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x+h)</span>

        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val - h
        <span style="color: #715ab1;">fxh2</span> = f<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">f(x-h)</span>
        <span style="color: #715ab1;">grad</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = <span style="color: #3a81c3;">(</span>fxh1 - fxh2<span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">(</span>2 * h<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">x</span><span style="color: #3a81c3;">[</span>idx<span style="color: #3a81c3;">]</span> = tmp_val  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#20516;&#12434;&#20803;&#12395;&#25147;&#12377;</span>
        it.iternext<span style="color: #3a81c3;">()</span>

    <span style="color: #3a81c3; font-weight: bold;">return</span> grad


<span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">Affine</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, W, b<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">W</span> = W
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">b</span> = b

        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">x</span> = <span style="color: #4e3163;">None</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">original_x_shape</span> = <span style="color: #4e3163;">None</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">dW</span> = <span style="color: #4e3163;">None</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">db</span> = <span style="color: #4e3163;">None</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">forward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x<span style="color: #3a81c3;">)</span>:

        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">original_x_shape</span> = x.shape
        <span style="color: #715ab1;">x</span> = x.reshape<span style="color: #3a81c3;">(</span>x.shape<span style="color: #6c3163;">[</span>0<span style="color: #6c3163;">]</span>, -1<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">x</span> = x

        <span style="color: #715ab1;">out</span> = np.dot<span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>.x, <span style="color: #3a81c3; font-weight: bold;">self</span>.W<span style="color: #3a81c3;">)</span> + <span style="color: #3a81c3; font-weight: bold;">self</span>.b

        <span style="color: #3a81c3; font-weight: bold;">return</span> out

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">backward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, dout<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">dx</span> = np.dot<span style="color: #3a81c3;">(</span>dout, <span style="color: #3a81c3; font-weight: bold;">self</span>.W.T<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">dW</span> = np.dot<span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>.x.T, dout<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">db</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>dout, axis=0<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">dx</span> = dx.reshape<span style="color: #3a81c3;">(</span>*<span style="color: #3a81c3; font-weight: bold;">self</span>.original_x_shape<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">return</span> dx


<span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">Relu</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span><span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">mask</span> = <span style="color: #4e3163;">None</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">forward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">mask</span> = x &lt;= 0
        <span style="color: #715ab1;">out</span> = x.copy<span style="color: #3a81c3;">()</span>
        <span style="color: #715ab1;">out</span><span style="color: #3a81c3;">[</span><span style="color: #3a81c3; font-weight: bold;">self</span>.mask<span style="color: #3a81c3;">]</span> = 0

        <span style="color: #3a81c3; font-weight: bold;">return</span> out

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">backward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, dout<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">dout</span><span style="color: #3a81c3;">[</span><span style="color: #3a81c3; font-weight: bold;">self</span>.mask<span style="color: #3a81c3;">]</span> = 0
        <span style="color: #715ab1;">dx</span> = dout

        <span style="color: #3a81c3; font-weight: bold;">return</span> dx


<span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">SoftmaxWithLoss</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span><span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">loss</span> = <span style="color: #4e3163;">None</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">y</span> = <span style="color: #4e3163;">None</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">softmax&#12398;&#20986;&#21147;</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">t</span> = <span style="color: #4e3163;">None</span>  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#25945;&#24107;&#12487;&#12540;&#12479;</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">forward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">t</span> = t
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">y</span> = softmax<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">loss</span> = cross_entropy_error<span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>.y, <span style="color: #3a81c3; font-weight: bold;">self</span>.t<span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3; font-weight: bold;">self</span>.loss

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">backward</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, dout=1<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">batch_size</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.t.shape<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span>
        <span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3; font-weight: bold;">self</span>.t.size == <span style="color: #3a81c3; font-weight: bold;">self</span>.y.size:
            <span style="color: #715ab1;">dx</span> = <span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>.y - <span style="color: #3a81c3; font-weight: bold;">self</span>.t<span style="color: #3a81c3;">)</span> / batch_size
        <span style="color: #3a81c3; font-weight: bold;">else</span>:
            <span style="color: #715ab1;">dx</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.y.copy<span style="color: #3a81c3;">()</span>
            <span style="color: #715ab1;">dx</span><span style="color: #3a81c3;">[</span>np.arange<span style="color: #6c3163;">(</span>batch_size<span style="color: #6c3163;">)</span>, <span style="color: #3a81c3; font-weight: bold;">self</span>.t<span style="color: #3a81c3;">]</span> -= 1
            <span style="color: #715ab1;">dx</span> = dx / batch_size

        <span style="color: #3a81c3; font-weight: bold;">return</span> dx


<span style="color: #3a81c3; font-weight: bold;">class</span> <span style="color: #ba2f59; font-weight: bold;">TwoLayerNet</span>:
    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">__init__</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, input_size, hidden_size, output_size, weight_init_std=0.01<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span> = <span style="color: #3a81c3;">{}</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span> = weight_init_std * np.random.randn<span style="color: #3a81c3;">(</span>input_size, hidden_size<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span> = np.zeros<span style="color: #3a81c3;">(</span>hidden_size<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span> = weight_init_std * np.random.randn<span style="color: #3a81c3;">(</span>hidden_size, output_size<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span> = np.zeros<span style="color: #3a81c3;">(</span>output_size<span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">layers</span> = OrderedDict<span style="color: #3a81c3;">()</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">layers</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"Affine1"</span><span style="color: #3a81c3;">]</span> = Affine<span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #6c3163;">]</span>, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">layers</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"Relu1"</span><span style="color: #3a81c3;">]</span> = Relu<span style="color: #3a81c3;">()</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">layers</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"Affine2"</span><span style="color: #3a81c3;">]</span> = Affine<span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #6c3163;">]</span>, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">self</span>.<span style="color: #715ab1;">lastLayer</span> = SoftmaxWithLoss<span style="color: #3a81c3;">()</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">predict</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x<span style="color: #3a81c3;">)</span>:
        <span style="color: #3a81c3; font-weight: bold;">for</span> layer <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3; font-weight: bold;">self</span>.layers.values<span style="color: #3a81c3;">()</span>:
            <span style="color: #715ab1;">x</span> = layer.forward<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">return</span> x

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">loss</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">y</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.predict<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">return</span> <span style="color: #3a81c3; font-weight: bold;">self</span>.lastLayer.forward<span style="color: #3a81c3;">(</span>y, t<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">accuracy</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">y</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.predict<span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">y</span> = np.argmax<span style="color: #3a81c3;">(</span>y, axis=1<span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">if</span> t.ndim != 1:
            <span style="color: #715ab1;">t</span> = np.argmax<span style="color: #3a81c3;">(</span>t, axis=1<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">accuracy</span> = np.<span style="color: #3a81c3;">sum</span><span style="color: #3a81c3;">(</span>y == t<span style="color: #3a81c3;">)</span> / <span style="color: #3a81c3;">float</span><span style="color: #3a81c3;">(</span>x.shape<span style="color: #6c3163;">[</span>0<span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3; font-weight: bold;">return</span> accuracy

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">numerical_gradient</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">loss_W</span> = <span style="color: #3a81c3; font-weight: bold;">lambda</span> W: <span style="color: #3a81c3; font-weight: bold;">self</span>.loss<span style="color: #3a81c3;">(</span>x, t<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">grads</span> = <span style="color: #3a81c3;">{}</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span> = numerical_gradient<span style="color: #3a81c3;">(</span>loss_W, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span> = numerical_gradient<span style="color: #3a81c3;">(</span>loss_W, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span> = numerical_gradient<span style="color: #3a81c3;">(</span>loss_W, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span> = numerical_gradient<span style="color: #3a81c3;">(</span>loss_W, <span style="color: #3a81c3; font-weight: bold;">self</span>.params<span style="color: #6c3163;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #6c3163;">]</span><span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">return</span> grads

    <span style="color: #3a81c3; font-weight: bold;">def</span> <span style="color: #6c3163; font-weight: bold;">gradient</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>, x, t<span style="color: #3a81c3;">)</span>:
        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">forward</span>
        <span style="color: #3a81c3; font-weight: bold;">self</span>.loss<span style="color: #3a81c3;">(</span>x, t<span style="color: #3a81c3;">)</span>
        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">backward</span>
        <span style="color: #715ab1;">dout</span> = 1
        <span style="color: #715ab1;">dout</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.lastLayer.backward<span style="color: #3a81c3;">(</span>dout<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">layers</span> = <span style="color: #3a81c3;">list</span><span style="color: #3a81c3;">(</span><span style="color: #3a81c3; font-weight: bold;">self</span>.layers.values<span style="color: #6c3163;">()</span><span style="color: #3a81c3;">)</span>
        layers.reverse<span style="color: #3a81c3;">()</span>
        <span style="color: #3a81c3; font-weight: bold;">for</span> layer <span style="color: #3a81c3; font-weight: bold;">in</span> layers:
            <span style="color: #715ab1;">dout</span> = layer.backward<span style="color: #3a81c3;">(</span>dout<span style="color: #3a81c3;">)</span>

        <span style="color: #715ab1;">grads</span> = <span style="color: #3a81c3;">{}</span>
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W1"</span><span style="color: #3a81c3;">]</span>, <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b1"</span><span style="color: #3a81c3;">]</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.layers<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"Affine1"</span><span style="color: #3a81c3;">]</span>.dW, <span style="color: #3a81c3; font-weight: bold;">self</span>.layers<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"Affine1"</span><span style="color: #3a81c3;">]</span>.db
        <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"W2"</span><span style="color: #3a81c3;">]</span>, <span style="color: #715ab1;">grads</span><span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">]</span> = <span style="color: #3a81c3; font-weight: bold;">self</span>.layers<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"Affine2"</span><span style="color: #3a81c3;">]</span>.dW, <span style="color: #3a81c3; font-weight: bold;">self</span>.layers<span style="color: #3a81c3;">[</span><span style="color: #2d9574;">"Affine2"</span><span style="color: #3a81c3;">]</span>.db

        <span style="color: #3a81c3; font-weight: bold;">return</span> grads


<span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:

    <span style="color: #3a81c3;">(</span>x_train, t_train<span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span><span style="color: #715ab1;">x_test</span>, <span style="color: #715ab1;">t_test</span><span style="color: #3a81c3;">)</span> = load_mnist<span style="color: #3a81c3;">(</span>
        normalize=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">True</span>
    <span style="color: #3a81c3;">)</span>

    <span style="color: #715ab1;">network</span> = TwoLayerNet<span style="color: #3a81c3;">(</span>input_size=784, hidden_size=50, output_size=10<span style="color: #3a81c3;">)</span>

    <span style="color: #715ab1;">iters_num</span> = 10000
    <span style="color: #715ab1;">train_size</span> = x_train.shape<span style="color: #3a81c3;">[</span>0<span style="color: #3a81c3;">]</span>
    <span style="color: #715ab1;">batch_size</span> = 100
    <span style="color: #715ab1;">learning_rate</span> = 0.1

    <span style="color: #715ab1;">train_loss_list</span> = <span style="color: #3a81c3;">[]</span>
    <span style="color: #715ab1;">train_acc_list</span> = <span style="color: #3a81c3;">[]</span>
    <span style="color: #715ab1;">test_acc_list</span> = <span style="color: #3a81c3;">[]</span>

    <span style="color: #715ab1;">iter_per_epoch</span> = <span style="color: #3a81c3;">max</span><span style="color: #3a81c3;">(</span>train_size / batch_size, 1<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">for</span> i <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">range</span><span style="color: #3a81c3;">(</span>iters_num<span style="color: #3a81c3;">)</span>:
        <span style="color: #715ab1;">batch_mask</span> = np.random.choice<span style="color: #3a81c3;">(</span>train_size, batch_size<span style="color: #3a81c3;">)</span>
        <span style="color: #715ab1;">x_batch</span> = x_train<span style="color: #3a81c3;">[</span>batch_mask<span style="color: #3a81c3;">]</span>
        <span style="color: #715ab1;">t_batch</span> = t_train<span style="color: #3a81c3;">[</span>batch_mask<span style="color: #3a81c3;">]</span>

        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#21246;&#37197;</span>
        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">grad = network.numerical_gradient(x_batch, t_batch)</span>
        <span style="color: #715ab1;">grad</span> = network.gradient<span style="color: #3a81c3;">(</span>x_batch, t_batch<span style="color: #3a81c3;">)</span>

        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&#26356;&#26032;</span>
        <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> <span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"W1"</span>, <span style="color: #2d9574;">"b1"</span>, <span style="color: #2d9574;">"W2"</span>, <span style="color: #2d9574;">"b2"</span><span style="color: #3a81c3;">)</span>:
            network.<span style="color: #715ab1;">params</span><span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span> -= learning_rate * grad<span style="color: #3a81c3;">[</span>key<span style="color: #3a81c3;">]</span>

        <span style="color: #715ab1;">loss</span> = network.loss<span style="color: #3a81c3;">(</span>x_batch, t_batch<span style="color: #3a81c3;">)</span>
        train_loss_list.append<span style="color: #3a81c3;">(</span>loss<span style="color: #3a81c3;">)</span>

        <span style="color: #3a81c3; font-weight: bold;">if</span> i % iter_per_epoch == 0:
            <span style="color: #715ab1;">train_acc</span> = network.accuracy<span style="color: #3a81c3;">(</span>x_train, t_train<span style="color: #3a81c3;">)</span>
            <span style="color: #715ab1;">test_acc</span> = network.accuracy<span style="color: #3a81c3;">(</span>x_test, t_test<span style="color: #3a81c3;">)</span>
            train_acc_list.append<span style="color: #3a81c3;">(</span>train_acc<span style="color: #3a81c3;">)</span>
            test_acc_list.append<span style="color: #3a81c3;">(</span>test_acc<span style="color: #3a81c3;">)</span>
            <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>train_acc, test_acc<span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.19161666666666666 0.1895</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9035166666666666 0.9064</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9202333333333333 0.9193</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9349833333333334 0.9345</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9437833333333333 0.9421</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.94975 0.9469</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.95605 0.951</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9610333333333333 0.9565</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9641666666666666 0.9592</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9676666666666667 0.9593</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9709166666666667 0.9633</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9705666666666667 0.9644</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9735166666666667 0.9661</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9745 0.968</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9764 0.9672</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9767 0.9683</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">0.9791333333333333 0.9693</span>
</pre>
</div></li>
<li><p>
上述学习模型的例子和第四章比较著名的不同在于计算梯度,这里的梯度是误差反向法计算得来的
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #715ab1;">grad</span> = network.gradient<span style="color: #3a81c3;">(</span>x_batch, t_batch<span style="color: #3a81c3;">)</span>
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org9009266" class="outline-4">
<h4 id="org9009266"><span class="section-number-4">5.7.3.</span> 误差反向传播法的梯度确认</h4>
<div class="outline-text-4" id="text-5-7-3">
<ul class="org-ul">
<li>目前为止,我们介绍了两种计算梯度的方法:
<ul class="org-ul">
<li>基于数值微分的方法</li>
<li>误差反向传播法</li>
</ul></li>
<li>数值微分计算很耗费时间,但是有点是实现简单,一般不太容易出错. 而误差反向传播法实现复杂,容易出错.所以
我们这里写一个例子,比较数值微分和误差反向传播法的结果,以确认误差反向传播法的实现是否正确
<ul class="org-ul">
<li><p>
main函数代码如下,其他部分和上面模型学习的例子一样
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #3a81c3; font-weight: bold;">if</span> <span style="color: #3a81c3;">__name__</span> == <span style="color: #2d9574;">"__main__"</span>:
    <span style="color: #3a81c3;">(</span>x_train, t_train<span style="color: #3a81c3;">)</span>, <span style="color: #3a81c3;">(</span><span style="color: #715ab1;">x_test</span>, <span style="color: #715ab1;">t_test</span><span style="color: #3a81c3;">)</span> = load_mnist<span style="color: #3a81c3;">(</span>
        normalize=<span style="color: #4e3163;">True</span>, one_hot_label=<span style="color: #4e3163;">True</span>
    <span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"-"</span> * 100<span style="color: #3a81c3;">)</span>
    <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span><span style="color: #2d9574;">"""|x_train.shape|=&gt;"""</span>, x_train.shape<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">network</span> = TwoLayerNet<span style="color: #3a81c3;">(</span>input_size=784, hidden_size=50, output_size=10<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">x_batch</span> = x_train<span style="color: #3a81c3;">[</span>:3<span style="color: #3a81c3;">]</span>
    <span style="color: #715ab1;">t_batch</span> = t_train<span style="color: #3a81c3;">[</span>:3<span style="color: #3a81c3;">]</span>
    <span style="color: #715ab1;">grad_numerial</span> = network.numerical_gradient<span style="color: #3a81c3;">(</span>x_batch, t_batch<span style="color: #3a81c3;">)</span>
    <span style="color: #715ab1;">grad_backprop</span> = network.gradient<span style="color: #3a81c3;">(</span>x_batch, t_batch<span style="color: #3a81c3;">)</span>

    <span style="color: #3a81c3; font-weight: bold;">for</span> key <span style="color: #3a81c3; font-weight: bold;">in</span> grad_numerial.keys<span style="color: #3a81c3;">()</span>:
        <span style="color: #715ab1;">diff</span> = np.average<span style="color: #3a81c3;">(</span>np.<span style="color: #3a81c3;">abs</span><span style="color: #6c3163;">(</span>grad_backprop<span style="color: #2d9574;">[</span>key<span style="color: #2d9574;">]</span> - grad_numerial<span style="color: #2d9574;">[</span>key<span style="color: #2d9574;">]</span><span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>
        <span style="color: #3a81c3;">print</span><span style="color: #3a81c3;">(</span>key + <span style="color: #2d9574;">":"</span> + <span style="color: #3a81c3;">str</span><span style="color: #6c3163;">(</span>diff<span style="color: #6c3163;">)</span><span style="color: #3a81c3;">)</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;====================OUTPUT====================&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">|x_train.shape|=&gt; (60000, 784)</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">W1:5.275995153389141e-10</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">b1:3.377598751098769e-09</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">W2:5.891334917194579e-09</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">b2:1.4015139910839024e-07</span>
</pre>
</div></li>
<li>我们可以看到计算出来的误差都是非常的小(由于计算机的精度有限,两者计算的结果误差不太可能为0),这样
一来,我们就可以确认,自己实现的误差反向传播法是正确的.</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-orga8f5870" class="outline-2">
<h2 id="orga8f5870"><span class="section-number-2">6.</span> 与学习相关的技巧</h2>
</div>
<div id="outline-container-org90f52a5" class="outline-2">
<h2 id="org90f52a5"><span class="section-number-2">7.</span> 卷积神经网络</h2>
</div>
<div id="outline-container-orgedd65d7" class="outline-2">
<h2 id="orgedd65d7"><span class="section-number-2">8.</span> 深度学习</h2>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: harrifeng@outlook.com</p>
<p class="date">Created: 2025-01-14 Tue 19:43</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>