<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-08-29 ÖÜ¶ş 20:44 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>introduction-to-statistical-learning</title>
<meta name="author" content="harrifeng@outlook.com" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">introduction-to-statistical-learning</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org950cf20">1. Chapter 1: Introduction</a>
<ul>
<li><a href="#orgb5290f0">1.1. An Overview of Statistical Learning</a>
<ul>
<li><a href="#org143d397">1.1.1. Wage Data</a></li>
<li><a href="#org0d4371d">1.1.2. Stock Market Data</a></li>
<li><a href="#orgbe21d2b">1.1.3. Gene Expression Data</a></li>
</ul>
</li>
<li><a href="#org7d33c21">1.2. A Brief History of Statistical Learning</a></li>
<li><a href="#org6c56c3a">1.3. This Book</a></li>
<li><a href="#org66e0a75">1.4. Who Should Read This Book?</a></li>
<li><a href="#org0bc0a8c">1.5. Notation and Simple Matrix Algebra</a></li>
</ul>
</li>
<li><a href="#orgcccbc8c">2. Chapter 2: Statistical Learning</a>
<ul>
<li><a href="#orge8d037c">2.1. What Is Statistical Learning?</a>
<ul>
<li><a href="#org68f8152">2.1.1. Why Estimate f?</a></li>
<li><a href="#org90395e5">2.1.2. How Do We Estimate f?</a></li>
<li><a href="#org9fed118">2.1.3. The Trade-Off Between Prediction Accuracy and Model Interpretability</a></li>
<li><a href="#orgf6fc2b5">2.1.4. Supervised Versus Unsupervised Learning</a></li>
<li><a href="#org8294b2d">2.1.5. Regression Versus Classification Problems</a></li>
</ul>
</li>
<li><a href="#orge780837">2.2. Assessing Model Accuracy</a>
<ul>
<li><a href="#org61d67da">2.2.1. Measuring the Quality of Fit</a></li>
<li><a href="#orga2730fe">2.2.2. The Bias-Variance Trade-Off</a></li>
<li><a href="#org1630992">2.2.3. The Classification Setting</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org0260ce2">3. Chapter 3: Linear Regression</a>
<ul>
<li><a href="#org8a47d5c">3.1. Simple Linear Regression</a>
<ul>
<li><a href="#org849aad2">3.1.1. Estimating the Coefficients</a></li>
<li><a href="#org97dd9f3">3.1.2. Assessing the Accuracy of the Coefficient Estimates</a></li>
<li><a href="#orge4fd700">3.1.3. Assessing the Accuracy of the Model</a></li>
</ul>
</li>
<li><a href="#org0f973b6">3.2. Multiple Linear Regression</a>
<ul>
<li><a href="#orgc7964f6">3.2.1. Estimating the Regression Coefficients</a></li>
<li><a href="#org6833422">3.2.2. Some Important Questions</a></li>
</ul>
</li>
<li><a href="#org7212140">3.3. Other Considerations in the Regression Model</a>
<ul>
<li><a href="#orgb81cadd">3.3.1. Qualitative Predictors</a></li>
<li><a href="#orgc9f69d3">3.3.2. Predictors with Only Two Levels</a></li>
<li><a href="#org47f0cc4">3.3.3. Qualitative Predictors with More than Two Levels</a></li>
<li><a href="#orgf39078e">3.3.4. Extensions of the Linear Model</a></li>
<li><a href="#org973c2ae">3.3.5. Potential Problems</a></li>
</ul>
</li>
<li><a href="#orgc6e4926">3.4. The Marketing Plan</a>
<ul>
<li><a href="#org3b75b30">3.4.1. Is there a relationship between advertising sales and budget?</a></li>
<li><a href="#orgb646876">3.4.2. How strongis the relationship?</a></li>
<li><a href="#orgf4608f9">3.4.3. Which media contribute to sales?</a></li>
<li><a href="#org4bf462b">3.4.4. How large is the effect of each medium on seles?</a></li>
<li><a href="#org3a41324">3.4.5. How accurately can we predict future sales?</a></li>
<li><a href="#org8b95c7a">3.4.6. Is the relationship linear?</a></li>
<li><a href="#org9f6c31c">3.4.7. Is there synergy among the advertising media?</a></li>
</ul>
</li>
<li><a href="#org1d8f340">3.5. Comparison of Linear Regression</a></li>
<li><a href="#orgf70aba0">3.6. Lab: Linear Regression</a></li>
</ul>
</li>
<li><a href="#org52e8bc8">4. Chapter 4: Classification</a>
<ul>
<li><a href="#orgfe8ab59">4.1. An Overview of Classification</a></li>
<li><a href="#org8af2708">4.2. Why Not Linear Regression?</a></li>
<li><a href="#org92abfbc">4.3. Logistic Regression</a>
<ul>
<li><a href="#orgae2aae1">4.3.1. The Logistic Model</a></li>
<li><a href="#org91dcdec">4.3.2. Estimating the Regression Coefficients</a></li>
<li><a href="#org695d05f">4.3.3. Making Predictions</a></li>
<li><a href="#org59c16cd">4.3.4. Multiple Logistic Regression</a></li>
<li><a href="#orge8ea61f">4.3.5. Logistic Regression for &gt; 2 Response Classes</a></li>
</ul>
</li>
<li><a href="#orgf067726">4.4. Linear Discriminant Analysis</a>
<ul>
<li><a href="#orgb0aabbe">4.4.1. Using Bayes' Theorem for Classification</a></li>
<li><a href="#org9d21c72">4.4.2. Linear Discriminant Analysis for p = 1</a></li>
<li><a href="#orgc5cdef8">4.4.3. Linear Discriminant Analysis for p &gt; 1</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgbb6f844">5. Chapter 5: Resampling Method</a>
<ul>
<li><a href="#orgc4694ed">5.1. Cross-Validation</a>
<ul>
<li><a href="#org4d1102d">5.1.1. The Validation Set Approach</a></li>
<li><a href="#orgd0243c8">5.1.2. Leave-One-Out Cross-Validation</a></li>
<li><a href="#orga5282f7">5.1.3. K-Fold Cross-Validation</a></li>
<li><a href="#orgb27462f">5.1.4. Bias-Variance Trade-Off for k-Fold Cross-Validation</a></li>
<li><a href="#orgd309ba1">5.1.5. Cross-Validation on Classification Problems</a></li>
</ul>
</li>
<li><a href="#org1b78f4d">5.2. Bootstrap</a></li>
</ul>
</li>
<li><a href="#orgc44a234">6. Chapter 6: Linear Model Selection and Regularization</a>
<ul>
<li><a href="#org68214c6">6.1. Subset Selection</a>
<ul>
<li><a href="#org801cd93">6.1.1. Best Subset Selection</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org3571fbb">7. Chapter 8: Tree-Based Methods</a>
<ul>
<li><a href="#org6a084ee">7.1. The Basics of Decision Trees</a>
<ul>
<li><a href="#orgd8da673">7.1.1. Regression Trees</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org691844f">8. Chapter 9: Suppport Vector Machines</a>
<ul>
<li><a href="#orge58dcf1">8.1. Maximal Margin Classifier</a>
<ul>
<li><a href="#org673f552">8.1.1. What is a Hyperplane?</a></li>
<li><a href="#org2351863">8.1.2. Classification Using a Separating Hyperplane</a></li>
<li><a href="#orgd92b146">8.1.3. The Maximal Margin Classifier</a></li>
<li><a href="#orgf04de60">8.1.4. Construction of the Maximal Margin Classifier</a></li>
<li><a href="#orga5df7f8">8.1.5. The Non-separable Case</a></li>
</ul>
</li>
<li><a href="#orgb858ba5">8.2. Support Vector Classifiers</a>
<ul>
<li><a href="#org603c340">8.2.1. Overview of the Support Vector Classifier</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org950cf20" class="outline-2">
<h2 id="org950cf20"><span class="section-number-2">1.</span> Chapter 1: Introduction</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-orgb5290f0" class="outline-3">
<h3 id="orgb5290f0"><span class="section-number-3">1.1.</span> An Overview of Statistical Learning</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>statistical learning ä»£è¡¨ä¸€ç³»åˆ—ç†è§£æ•°æ®çš„å·¥å…·,è¿™äº›å·¥å…·å¯ä»¥åˆ†ä¸º:
<ul class="org-ul">
<li>supervised</li>
<li>unsupervised</li>
</ul></li>
<li>ä¸€èˆ¬æ¥è¯´,supervised statistical learningåŒ…å«åˆ›å»ºä¸€ä¸ªstatistical modelç”¨æ¥:
<ul class="org-ul">
<li>åŸºäºä¸€ä¸ªæˆ–è€…å¤šä¸ªinputæ¥predicting output</li>
<li>åŸºäºä¸€ä¸ªæˆ–è€…å¤šä¸ªinputæ¥estimating output</li>
</ul></li>
<li>å¯¹äºunsupervised statistical learningæ¥è¯´,ä»–ä»¬æœ‰inputä½†æ˜¯æ²¡æœ‰supervisingçš„output
ä½†æ˜¯æˆ‘ä»¬å¯ä»¥ä»è¿™ç§æ•°æ®ä¸­å­¦ä¹ relationshipå’Œstructure</li>
<li>ä¸ºäº†æˆ‘ä»¬çš„è®²è¿°æ›´åŠ çš„å®¹æ˜“ç†è§£,æˆ‘ä»¬ç®€çŸ­çš„ä»‹ç»ä¸‹å®é™…ç”Ÿæ´»çš„ä¸‰ä¸ªdata set</li>
</ul>
</div>
<div id="outline-container-org143d397" class="outline-4">
<h4 id="org143d397"><span class="section-number-4">1.1.1.</span> Wage Data</h4>
<div class="outline-text-4" id="text-1-1-1">
<ul class="org-ul">
<li>åœ¨è¿™æœ¬ä¹¦é‡Œé¢,æˆ‘ä»¬ä¼šæŠŠè¿™ä¸ªä¾‹å­å«æˆæ˜¯Wage data set</li>
<li>Wage data setæ˜¯ç ”ç©¶ç¾å›½å¤§è¥¿æ´‹åŒºåŸŸçš„ä¸€äº›ç”·æ€§å·¥èµ„,å·²ç»å½±å“å·¥èµ„çš„å› ç´ ,æ¯”å¦‚:å¹´é¾„,æ•™è‚²æ°´å¹³,å·¥ä½œç»éªŒå¯¹å·¥èµ„çš„å½±å“</li>
<li>å›¾1-1ä»‹ç»äº†Wage data:
<ul class="org-ul">
<li><p>
å›¾1-1:
</p>

<div id="org40c93d5" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/1-1.png" alt="1-1.png" />
</p>
<p><span class="figure-number">Figure 1: </span>isl/1-1.png</p>
</div></li>
<li>å·¦è¾¹,ä¸Šé¢æ˜¯å±•ç¤ºäº†æ¯ä¸ªå¹´é¾„çš„wage,æˆ‘ä»¬å¯ä»¥çœ‹åˆ°,éšç€å¹´é¾„çš„å¢é•¿å·¥èµ„å¢é•¿</li>
<li>ä½†æ˜¯å¢é•¿åœç•™åœ¨60å²,ä¹‹åå·¥èµ„æ˜¯éšç€å¹´é¾„æ˜¯ä¸‹æ»‘çš„</li>
<li>å›¾å·¦è¾¹ä¸­çš„è“è‰²çº¿æ˜¯é¢„æµ‹wageå’Œageå…³ç³»çš„,è®©æˆ‘ä»¬æŠŠtrendçœ‹çš„æ›´æ¸…æ¥š</li>
<li>ç»™æˆ‘ä»¬é›‡å‘˜çš„age,æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªcurveæ¥é¢„æµ‹ä»–çš„å·¥èµ„,ä½†æ˜¯æˆ‘ä»¬ä¹Ÿä»å›¾1-1ä¸­çŸ¥é“</li>
<li>å…¶å®å¾ˆå¤švariabilityéƒ½å’Œwageç›¸å…³,ä»…ä»…ä½¿ç”¨ageç®—å‡ºæ¥çš„é¢„æµ‹ç»“æœå¹¶ä¸å‡†ç¡®</li>
<li>å›¾1-1çš„ä¸­é—´æ˜¯å·¥èµ„å’Œå¹´ä»½çš„å…³ç³»</li>
<li>å›¾1-1çš„å³è¾¹æ˜¯å·¥èµ„å’Œæ•™è‚²æ°´å¹³çš„å…³ç³»</li>
<li>è¿™ä¸¤ä¸ªå°å›¾ä¹Ÿè¯æ˜,å·¥èµ„å’Œå¹´ä»½ä»¥åŠæ•™è‚²æ°´å¹³ä¹Ÿæœ‰å…³ç³»</li>
</ul></li>
<li>å¾ˆæ˜æ˜¾çš„,å¯¹wageæœ€ç²¾ç¡®çš„predictionå¿…é¡»åŒ…å«age,educationå’Œyear:
<ul class="org-ul">
<li>ç¬¬ä¸‰ç« ä¼šä»‹ç»åŒ…å«age,education,yearæ¥é¢„æµ‹wageçš„linear regression</li>
<li>ç¬¬ä¸ƒç« ä¼šä»‹ç»non-linearçš„å…³ç³»</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org0d4371d" class="outline-4">
<h4 id="org0d4371d"><span class="section-number-4">1.1.2.</span> Stock Market Data</h4>
<div class="outline-text-4" id="text-1-1-2">
<ul class="org-ul">
<li>Wage dataåŒ…å«é¢„æµ‹å¦‚ä¸‹ä¸¤ç§value, è¿™äº›é—®é¢˜ä¹Ÿè¢«ç§°ä¹‹ä¸ºå›å½’é—®é¢˜(regression problem):
<ul class="org-ul">
<li>continuous output value</li>
<li>quantitative output value</li>
</ul></li>
<li>å¦å¤–ä¸€äº›æƒ…å†µä¸‹,æˆ‘ä»¬å¸Œæœ›é¢„æµ‹non-numerical vaue,ä¹Ÿå°±æ˜¯åˆ†ç±»é—®é¢˜(categorical problem):
<ul class="org-ul">
<li>qualitative output</li>
</ul></li>
<li>ç¬¬å››ç« æˆ‘ä»¬ä¼šåˆ†æä¸€ä¸ªstock market data set,è¿™ä¸ªdata setåŒ…å«2001åˆ°2005å¹´S&amp;Pçš„
daily movement,è¿™å°±æ˜¯ä¸€ä¸ªnon-numericalçš„åˆ†ç±»é—®é¢˜,å› ä¸ºæˆ‘ä»¬åªéœ€è¦é¢„æµ‹æŒ‡æ•°:
<ul class="org-ul">
<li>increase</li>
<li>è¿˜æ˜¯decrease</li>
</ul></li>
<li>å›¾1-2æè¿°çš„æ˜¯å‰ä¸€å¤©çš„movementå¯¹ä¸‹ä¸€å¤©çš„å½±å“:
<ul class="org-ul">
<li><p>
å›¾1-2
</p>

<div id="org9789c8f" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/1-2.png" alt="1-2.png" />
</p>
<p><span class="figure-number">Figure 2: </span>isl/1-2.png</p>
</div></li>
<li>648å¤©ç¬¬äºŒå¤©ä¼šæ¶¨</li>
<li>602å¤©ç¬¬äºŒå¤©ä¼šè·Œ</li>
<li>å›¾1-2å·¦, è¿™ä¸¤ä¸ªplotçœ‹èµ·æ¥å®Œå…¨ä¸€æ ·,ä¹Ÿå°±æ„å‘³ç€ä½¿ç”¨æ˜¨å¤©çš„æ•°æ®æ¥é¢„æµ‹ä»Šå¤©çš„è¡Œæƒ…,ä¸å¤ªå¯èƒ½.</li>
<li>å›¾1-2ä¸­,å›¾1-2å³,æ˜¯ä¸¤å¤©å‰å’Œä¸‰å¤©å‰çš„æ•°æ®å’Œä»Šå¤©æ¶¨è·Œçš„å…³ç³»,ä¹Ÿçœ‹èµ·æ¥å¾ˆåƒ,æ— æ³•é¢„æµ‹ç¬¬äºŒå¤©çš„æ¶¨è·Œ</li>
<li>å›¾1-2çš„æ•°æ®lack of patternæ˜¯å¯ä»¥é¢„æœŸçš„: å¦‚æœè¿™äº›æ•°æ®å’Œæ¶¨è·Œè”ç³»ç´§å¯†,é‚£ä¹ˆä»…å‡­è¿™ä¸ªå°±å¯ä»¥èµšå¤§é’±</li>
</ul></li>
<li>æˆ‘ä»¬åé¢å°±é€šè¿‡quandratic discriminant analysis æ¨¡å‹,èƒ½å¤Ÿåœ¨60%çš„æƒ…å†µä¸‹,é¢„æµ‹
æ­£ç¡®æ¶¨è·Œ</li>
</ul>
</div>
</div>
<div id="outline-container-orgbe21d2b" class="outline-4">
<h4 id="orgbe21d2b"><span class="section-number-4">1.1.3.</span> Gene Expression Data</h4>
<div class="outline-text-4" id="text-1-1-3">
<ul class="org-ul">
<li>å‰é¢ä¸¤ç»„æ•°æ®éƒ½æ˜¯inputå’Œoutputå…¼æœ‰,å¦å¤–è¿˜æœ‰ä¸€ç§é‡è¦çš„æ•°æ®å°±åªæœ‰input,æ²¡æœ‰output</li>
<li>æ¯”å¦‚æˆ‘ä»¬æœ‰ä¸€ç»„å½“å‰ç”¨æˆ·çš„æ•°æ®,æˆ‘æƒ³çŸ¥é“å“ªäº›ç”¨æˆ·æ¯”è¾ƒç›¸ä¼¼,ç®—ä¸€ç±»(é€šè¿‡å¯ä»¥è§‚å¯Ÿåˆ°çš„ç‰¹ç‚¹)</li>
<li>å’Œå‰é¢ä¾‹å­ä¸åŒçš„æ˜¯,æˆ‘ä»¬è¿™é‡Œæ— æ³•é¢„æµ‹å‡ºä¸€ä¸ªoutput value</li>
<li>æˆ‘ä»¬ä¼šåœ¨ç¬¬10ç« ä¼šè®¨è®ºstatistical learning methodæ¥å¤„ç†è¿™ç§æ²¡æœ‰nutural output
variableçš„æƒ…å†µ</li>
<li>æˆ‘ä»¬ä½¿ç”¨äº†NCI60æ•°æ®,åŒ…å«6830 gene expression measurement(64ç§cancer cell line)</li>
<li>è¿™ç§æ•°æ®ä¸‹,æˆ‘ä»¬å·²ç»ä¸å†å…³æ³¨äºpredict ä¸€ä¸ªparticular output variable,è€Œæ˜¯è¦
åˆ¤æ–­æ˜¯å¦å­˜åœ¨ä¸€ä¸ªgroup, cluster</li>
<li><p>
å¦‚å›¾
</p>
<ul class="org-ul">
<li><p>
å›¾1-4
</p>

<div id="org57ee7d3" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/1-4.png" alt="1-4.png" />
</p>
<p><span class="figure-number">Figure 3: </span>isl/1-4.png</p>
</div></li>
<li>å›¾1-4å·¦è¾¹å°±æ˜¯æŠŠ64ä¸ªcell lineä»¥Z1å’ŒZ2ä¸¤ä¸ªæ•°å­—å±•ç¤ºå‡ºæ¥,è€Œä¸”åˆ†æˆäº†å››ç»„(å››ç§é¢œè‰²),ä¹Ÿå°±æ˜¯åŸºå› å¤§æ¦‚åˆ†æˆäº†å››ç§</li>
<li>å›¾1-4å³è¾¹æœ‰14ç§é¢œè‰²,è¿™äº›é¢œè‰²æ˜¯14ç§cancerçš„ç±»å‹,æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç›¸åŒç±»å‹çš„cancer</li>
</ul>
<p>
å…¶å®æ˜¯èšé›†çš„
</p></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org7d33c21" class="outline-3">
<h3 id="org7d33c21"><span class="section-number-3">1.2.</span> A Brief History of Statistical Learning</h3>
<div class="outline-text-3" id="text-1-2">
<ul class="org-ul">
<li>è™½ç„¶statistical learningæ˜¯ä¸€ä¸ªæ¯”è¾ƒæ–°çš„æ¦‚å¿µ,ä½†æ˜¯å¾ˆå¤šæ¦‚å¿µå·²ç»å­˜åœ¨äº†å¾ˆä¹…</li>
<li>åœ¨åä¹ä¸–çºªåˆ, Legendreå’ŒGausså‘è¡¨äº†è®ºæ–‡,å®è·µäº†linear regressionçš„æœ€åˆform</li>
<li>linear regressionæœ€åˆåœ¨å¤©æ–‡é—®é¢˜ä¸Šå¾—åˆ°äº†åº”ç”¨</li>
<li>æœ€åˆlinear regressionç”¨æ¥é¢„æµ‹quantitative value,æ¯”å¦‚æŸä¸ªäººçš„å·¥èµ„</li>
<li>åæ¥ä¸ºäº†é¢„æµ‹qualitative valueæ¯”å¦‚è‚¡ç¥¨æ˜¯æ¶¨è¿˜æ˜¯è·Œ,Fisheråœ¨1936å¹´ä¸ºè¿™ç±»é—®é¢˜èµ·å
linear discriminant analysis</li>
<li>åœ¨1940å¹´ä»£,å¤šä¸ªä½œè€…æŠŠlinear discriminant analysisæ”¹äº†ä¸€ä¸ªåå­—,æ–°åå­—å«åš
logistic regression(logistticå¯¹åº”qualitative)</li>
<li>1970å¹´ä»£,Nelderå’ŒWedderburnæŠŠlinear regressionå’Œlogistic regressionç»Ÿä¸€ä¸ºä¸€
ä¸ªåè¯:generalized linear model</li>
<li>æ•´ä¸ª70å¹´ä»£éƒ½æ˜¯å¯¹linear methodçš„ç ”ç©¶,å› ä¸ºå½“æ—¶æ— æ³•fit non-linear relation</li>
<li>80å¹´ä»£,è®¡ç®—æœºçš„å¼•å…¥ç»ˆäºèƒ½è®©non-linear relationçš„é€‚åº”æˆä¸ºå¯èƒ½. 1980å¹´ Breiman
å¼•å…¥äº†classification and regression tree,è¿™ä¸ªæŠ€æœ¯æœ‰å¦‚ä¸‹è·¨æ—¶ä»£çš„æ„ä¹‰:
<ul class="org-ul">
<li>éªŒè¯äº†detailed implementation of a methodçš„åŠ›é‡,æ¯”å¦‚cross-validation for
model selection</li>
</ul></li>
<li>1986å¹´, Hastieå‘æ˜äº†generalized additive model</li>
<li><p>
ä»é‚£ä»¥å,statistical learningå¼€å§‹åœ¨machine learningçš„å¸®åŠ©ä¸‹,èšç„¦åœ¨å¦‚ä¸‹é¢†åŸŸ
</p>
<pre class="example" id="org6e1dc2c">
supervised and unsupervised modeling and prediction
</pre></li>
</ul>
</div>
</div>
<div id="outline-container-org6c56c3a" class="outline-3">
<h3 id="org6c56c3a"><span class="section-number-3">1.3.</span> This Book</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li>ESLå¤§è€Œå…¨,æ¯”è¾ƒä¸“ä¸š</li>
<li>æœ¬ä¹¦(ISL)ä¸»è¦æ˜¯ä¸ºäº†æŠŠstatistical learningæ¨å‘ä¸»æµ</li>
<li>æœ¬ä¹¦(ISL)åŸºäºä»¥ä¸‹å‰æ:
<ol class="org-ol">
<li>å¾ˆå¤šstatistical learning methodåœ¨ç»Ÿè®¡å­¦ä»¥å¤–çš„é¢†åŸŸä¹Ÿå¾ˆæœ‰ä½œç”¨</li>
<li>statistical learningä¸åº”è¯¥ä½œä¸ºé»‘ç›’</li>
<li>æœ¬ä¹¦ä¸ä½¿ç”¨çŸ©é˜µå’Œå‘é‡,å°½å¯èƒ½ä½¿ç”¨è‹±è¯­æ¥æ•™è‚²ç”¨æˆ·</li>
<li>æˆ‘ä»¬å‡è®¾ç”¨æˆ·å–œæ¬¢ä½¿ç”¨statistical learningæ–¹æ³•æ¥è§£å†³å®é™…é—®é¢˜</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org66e0a75" class="outline-3">
<h3 id="org66e0a75"><span class="section-number-3">1.4.</span> Who Should Read This Book?</h3>
<div class="outline-text-3" id="text-1-4">
<ul class="org-ul">
<li>æ‰€æœ‰å¸Œæœ›ä½¿ç”¨statistical methodæ¥ä½¿ç”¨æ•°æ®,å®Œæˆæ¨¡å‹å’Œé¢„æµ‹çš„äºº</li>
</ul>
</div>
</div>
<div id="outline-container-org0bc0a8c" class="outline-3">
<h3 id="org0bc0a8c"><span class="section-number-3">1.5.</span> Notation and Simple Matrix Algebra</h3>
<div class="outline-text-3" id="text-1-5">
<ul class="org-ul">
<li>æ•™æé€‰æ‹©æ­£ç¡®çš„notationå¾ˆéš¾,æˆ‘ä»¬æœ¬ä¹¦å’ŒESLä½¿ç”¨åŒæ ·çš„notation</li>
<li>æˆ‘ä»¬ä¼šä½¿ç”¨næ¥ä»£è¡¨distinct data pointçš„æ•°ç›®</li>
<li>æˆ‘ä»¬ä¼šä½¿ç”¨pæ¥ä»£è¡¨èƒ½ç”¨æ¥åšpredictionçš„variableçš„æ•°ç›®</li>
<li>æ¯”å¦‚wage data setåŒ…å«12ä¸ªå˜é‡,3000ä¸ªäºº,æ‰€ä»¥æˆ‘ä»¬å°±æœ‰:
<ul class="org-ul">
<li>n = 3000</li>
<li>p = 12ä¸ªvariable(æ¯”å¦‚year, age, sexç­‰),æœ¬ä¹¦ä¸­variableéƒ½æ˜¯æœ‰é¢œè‰²çš„å­—ä½“</li>
</ul></li>
<li>æ€»ä½“ä¸Šæ¥è¯´,æˆ‘ä»¬è¦è®© \(x_{ij}\) æ¥ä»£è¡¨ç¬¬iæ¬¡è§‚å¯Ÿçš„æ—¶å€™,ç¬¬jæ¬¡çš„å˜é‡:
<ul class="org-ul">
<li>i = 1, 2,&#x2026;.n</li>
<li>j = 1, 2,&#x2026;p</li>
</ul></li>
<li><p>
è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°ä¸€ä¸ªçŸ©é˜µ
</p>
\begin{equation}
\boldsymbol{X} = \begin{pmatrix}
x_{11} & x_{12}  & \cdot\cdot\cdot & x_{1p} \\
x_{21} & x_{22}  & \cdot\cdot\cdot & x_{2p} \\
\cdot  & \cdot   & \cdot\cdot\cdot & \cdot  \\
x_{n1} & x_{n2}  & \cdot\cdot\cdot & x_{np}
\end{pmatrix}
\end{equation}</li>
<li><p>
æœ‰æ—¶å€™,æˆ‘ä»¬ä¼šå¯¹Xçš„row(è¡Œ)æ¯”è¾ƒæ„Ÿå…´è¶£,é‚£ä¹ˆå…¶ä¸­ä¸€ä¸ªrow(åå­—å«xi)å°±æ˜¯å¦‚ä¸‹,å®ƒæœ‰pä¸ªvariableçš„vector
</p>
\begin{equation}
x_i = \begin{pmatrix}
x_{i1} \\
x_{i2} \\
\cdot \\
\cdot \\
\cdot \\
x_{ip}
\end{pmatrix}
\end{equation}</li>
<li>æˆ‘ä»¬ä»¥wage dataä¸ºä¾‹,\(x_i\) å°±æ˜¯ä¸€ä¸ªé•¿åº¦ä¸º12çš„vector(12ç»´çš„vector),åŒ…æ‹¬year, age, sexç­‰ç­‰,ä¹Ÿå°±æ˜¯
ç¬¬iæ¬¡è§‚å¯Ÿå¾—åˆ°çš„,æŸä¸ªäººçš„ç”Ÿæ—¥,å¹´é¾„,æ€§åˆ«ç­‰åäºŒä¸ªå±æ€§æ•°æ®</li>
<li><p>
å¦å¤–ä¸€äº›æ—¶å€™,æˆ‘ä»¬å¯¹Xçš„column(åˆ—)æ¯”è¾ƒæ„Ÿå…´è¶£,é‚£ä¹ˆæˆ‘ä»¬å°±å¾—åˆ°äº† \(\boldsymbol{x_j}\),å¯ä»¥å†™æˆå¦‚ä¸‹æ ¼å¼
</p>
\begin{equation}
\boldsymbol{x_j} = \begin{pmatrix}
x_{1j} \\
x_{2j} \\
\cdot \\
\cdot \\
\cdot \\
x_{nj}
\end{pmatrix}
\end{equation}</li>
<li>å¯¹äºWage dataæ¥è¯´, \(\boldsymbol{x_j}\) åŒ…æ‹¬äº†3000æ¬¡è§‚å¯Ÿ,æ¯æ¬¡è§‚å¯Ÿçš„yearçš„æ•°æ®</li>
<li>æ€»ç»“å‰é¢çš„ä¸¤ç§å…¬å¼,æˆ‘ä»¬çš„ \(\boldsymbol{X}\) å…¶å®å¯ä»¥æœ‰ä¸¤ç§è¡¨ç°å½¢å¼:
<ul class="org-ul">
<li><p>
ä½¿ç”¨ \(\boldsymbol{x_j}\)
</p>
\begin{equation}
\boldsymbol{X} = (\boldsymbol{x_1} \quad \boldsymbol{x_2} \quad \cdot\cdot\cdot \quad \boldsymbol{x_p}),
\end{equation}</li>
<li><p>
ä½¿ç”¨ \(x_i\) çš„è½¬ç½®çŸ©é˜µ \(x_i^T\)
</p>
\begin{equation}
\boldsymbol{X} = \begin{pmatrix}
     x_1^T \\
     x_2^T \\
     \cdot \\
     \cdot \\
     \cdot \\
     x_n^T
     \end{pmatrix}
\end{equation}</li>
</ul></li>
<li>è¿™é‡Œçš„ \(^T\) ä»£è¡¨çš„å°±æ˜¯è½¬ç½®çŸ©é˜µæˆ–è€…vector</li>
<li><p>
ä¸Šé¢ä»‹ç»å®Œx(åé¢ä¼šè¯´åˆ°xæ˜¯predictor, predictorå¯èƒ½æœ‰å¤šä¸ª)äº†,ä¸‹é¢ä»‹ç»y(åé¢ä¼šä»‹ç»yæ˜¯response,æ²¡æœ‰
å¤šä¸ª,æ‰€ä»¥æ˜¯vector,ä¸æ˜¯matrix)
</p>
\begin{equation}
\boldsymbol{y} = \begin{pmatrix}
y_{1} \\
y_{2} \\
\cdot \\
\cdot \\
\cdot \\
y_{n}
\end{pmatrix}
\end{equation}</li>
<li>æ‰€ä»¥æˆ‘ä»¬çš„è§‚æµ‹ç»„åˆå°±æ˜¯{(x1,y1),(x2,y2)&#x2026;},æ¯ä¸ªxiå°±æ˜¯ä¸€ä¸ªé•¿åº¦ä¸ºpçš„vector</li>
<li>åœ¨æœ¬ä¹¦ä¸­:
<ul class="org-ul">
<li><p>
ä¸€ä¸ªé•¿åº¦ä¸ºnçš„vector,æˆ‘ä»¬éƒ½æ˜¯ä½¿ç”¨å°å†™çš„,ç²—ä½“è¡¨ç¤ºçš„,æ¯”å¦‚vector \(\boldsymbol{a}\)
</p>
\begin{equation}
\boldsymbol{a} = \begin{pmatrix}
a_{1} \\
a_{2} \\
\cdot \\
\cdot \\
\cdot \\
a_{n}
\end{pmatrix}
\end{equation}</li>
<li>ä¸€ä¸ªé•¿åº¦ä¸ä¸ºn(æ¯”å¦‚ä¸ºp)çš„vector,æˆ‘ä»¬å°±ä½¿ç”¨å°å†™,ä½†æ˜¯éç²—ä½“,æ¯”å¦‚a</li>
<li>scalar(ä¹Ÿå°±æ˜¯é•¿åº¦ä¸º1çš„vector),ä¹Ÿæ˜¯å°å†™,éç²—ä½“</li>
<li>matrixä¼šä½¿ç”¨ç²—ä½“,å¤§å†™æ¯”å¦‚ \(\boldsymbol{A}\)</li>
<li>random variableä¼šä½¿ç”¨å¤§å†™çš„éç²—ä½“</li>
</ul></li>
<li>åœ¨æœ¬ä¹¦ä¸­,æˆ‘ä»¬è¿˜å¯èƒ½ä¼šæŒ‡å‡ºparticular objecectçš„ç»´åº¦(dimension):
<ul class="org-ul">
<li>å¦‚æœæ˜¯ä¸€ç»´çš„(scalar),æˆ‘ä»¬ä½¿ç”¨ \(a \in \mathbb{R}\)</li>
<li>å¦‚æœæ˜¯kç»´çš„(vector of length k),æˆ‘ä»¬ä½¿ç”¨ \(a \in \mathbb{R}^k\), ç‰¹åˆ«çš„æ˜¯nç»´çš„(vector of length n)
è¯,æˆ‘ä»¬è¿˜ä½¿ç”¨ç²—ä½“çš„a \(\boldsymbol{a} \in \mathbb{R}^n\)</li>
<li>å¯¹äº \(r \times s\) çš„matrix,æˆ‘ä»¬ä½¿ç”¨ \(\boldsymbol{A} \in \mathbb{R}^{r \times s}\)</li>
</ul></li>
<li>æˆ‘ä»¬ä¼šå°½é‡é¿å…matrixçš„è®¡ç®—,ä½†æ˜¯æœ‰äº›æƒ…å†µä¸‹æ— æ³•é¿å…,è¿™æ—¶å€™,ç†è§£ä¸¤ä¸ªçŸ©é˜µçš„ä¹˜æ³•å°±éå¸¸é‡è¦:
<ul class="org-ul">
<li>å‡è®¾  \(\boldsymbol{A} \in \mathbb{R}^{r \times d}\) å¹¶ä¸” \(\boldsymbol{B} \in \mathbb{R}^{d \times s}\)</li>
<li>é‚£ä¹ˆ \(\boldsymbol{A}\) ä¹˜ä»¥ \(\boldsymbol{B}\) å°±å¯ä»¥å†™ä½œ \(\boldsymbol{AB}\)</li>
<li>è®¡ç®—æ–¹æ³•æ˜¯ \(\boldsymbol{(AB)}_{ij} = \sum_{k=1}^da_{ik}b_{kj}\)</li>
<li>æˆ‘ä»¬æ¥ä¸¾ä¸ªä¾‹å­:
<ul class="org-ul">
<li><p>
å‡è®¾æœ‰Aå¦‚ä¸‹
</p>
\begin{equation}
\boldsymbol{A} = \begin{pmatrix}
1 & 2 \\
3 & 4 \\
\end{pmatrix}
\end{equation}</li>
<li><p>
å‡è®¾æœ‰Bå¦‚ä¸‹
</p>
\begin{equation}
\boldsymbol{B} = \begin{pmatrix}
5 & 6 \\
7 & 8 \\
\end{pmatrix}
\end{equation}</li>
<li><p>
ABçš„è¯¦ç»†ç»“æœè®¡ç®—å¦‚ä¸‹
</p>
\begin{equation}
\boldsymbol{AB}
=
\begin{pmatrix}
1 & 2 \\
3 & 4 \\
\end{pmatrix}
\begin{pmatrix}
5 & 6 \\
7 & 8 \\
\end{pmatrix}
=
\begin{pmatrix}
1\times5+2\times7 & 1\times6+2\times8 \\
3\times5+4\times7 & 3\times6+4\times8 \\
\end{pmatrix}
=
\begin{pmatrix}
19 & 22 \\
43 & 50 \\
\end{pmatrix}
\end{equation}</li>
<li>éœ€è¦æ³¨æ„çš„æ˜¯èƒ½å¤Ÿäº§ç”Ÿ\(\boldsymbol{AB}\) çš„å¿…è¦æ¡ä»¶æ˜¯,å¦‚ä¸‹ä¸¤ä¸ªå€¼ç›¸ç­‰:
<ul class="org-ul">
<li>\(\boldsymbol{A}\) çš„åˆ—æ•°</li>
<li>\(\boldsymbol{B}\) çš„è¡Œæ•°</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgcccbc8c" class="outline-2">
<h2 id="orgcccbc8c"><span class="section-number-2">2.</span> Chapter 2: Statistical Learning</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-orge8d037c" class="outline-3">
<h3 id="orge8d037c"><span class="section-number-3">2.1.</span> What Is Statistical Learning?</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>ä¸ºäº†èƒ½å¤Ÿåˆºæ¿€æˆ‘ä»¬å¯¹äºstatistical learningçš„å­¦ä¹ ,æˆ‘ä»¬å…ˆä»ç®€å•çš„ä¾‹å­å¼€å§‹,å‡è®¾æˆ‘
ä»¬æ˜¯æ•°æ®åˆ†æå¸ˆ,è¢«é›‡ä½£æ¥å¯¹å¦‚ä½•æé«˜æŸä¸ªäº§å“é”€é‡æä¾›å»ºè®®</li>
<li>Advertising data setåŒ…å«:
<ul class="org-ul">
<li>ä¸€ä¸ªäº§å“åœ¨200ä¸ªä¸åŒå¸‚åœºçš„sales</li>
<li>200ä¸ªå¸‚åœºæ¯ä¸ªå¸‚åœºçš„é¢„ç®—æ€»å’Œ,ä»¥åŠåœ¨TV, radio, newspaperçš„åˆ†é…æ¯”ä¾‹</li>
<li><p>
å›¾-2.1
</p>

<div id="org7ab1314" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/2-1.png" alt="2-1.png" />
</p>
<p><span class="figure-number">Figure 4: </span>isl/2-1.png</p>
</div></li>
</ul></li>
<li>æˆ‘ä»¬æ•°æ®åˆ†æå¸ˆçš„å·¥ä½œæ˜¯åœ¨å®¢æˆ·ä¸å¢åŠ é¢„ç®—çš„æƒ…å†µä¸‹,æ‰¾åˆ°å¹¿å‘Šå’Œé”€å”®çš„association,
ç„¶åæ”¹å˜ä¸åŒé¢†åŸŸæŠ•å…¥çš„å¹¿å‘Šè´¹æ¯”ä¾‹,ä»è€Œæå‡æ•ˆæœ,æœ€ç»ˆæå‡é”€é‡</li>
<li>æ¢å¥è¯è¯´,æˆ‘ä»¬çš„ç›®æ ‡æ˜¯develop an accurate model, è®©è¿™ä¸ªmodelèƒ½å¤Ÿåœ¨æä¾›ä¸‰ç§ä¸
åŒbudgetä½œä¸ºè¾“å…¥çš„åŸºç¡€ä¸Š,é¢„æµ‹sales</li>
<li>ä»¥ä¸Šé¢çš„å›¾-2.1ä¾‹å­ä¸ºä¾‹:
<ul class="org-ul">
<li>å¹¿å‘Šé¢„ç®—å°±æ˜¯input variables</li>
<li>é”€å”®é¢å°±æ˜¯output variables</li>
<li>input variables, é€šå¸¸ä½¿ç”¨å¤§å†™çš„Xæ¥ä»£æ›¿,å…¶ä¸­æ¯ä¸ªinput variableå°±ç”¨ \(x_1,x_2\) ç­‰
ç­‰æ¥ä»£æ›¿,æ¯”å¦‚æˆ‘ä»¬å¯ä»¥ç”¨ \(x_1\) æ¥æŒ‡ä»£TV budget, \(x_2\) æŒ‡ä»£radio budget, \(x_3\) æŒ‡ä»£newspaper budget</li>
<li>inputsè¿˜æœ‰è®¸å¤šå…¶ä»–çš„åå­—,å…¶å®æ˜¯åŒä¸€å›äº‹:
<ol class="org-ol">
<li>predictors</li>
<li>independent variables</li>
<li>features</li>
<li>variables</li>
</ol></li>
<li>output vairable,é€šå¸¸ä½¿ç”¨å¤§å†™çš„Yæ¥è¡¨ç¤º,æ¯”å¦‚è¿™é‡Œçš„sales,å°±ä½¿ç”¨Yæ¥è¡¨ç¤º,outputsä¹Ÿæœ‰å¾ˆå¤šå…¶ä»–çš„åå­—,å…¶å®æ˜¯åŒä¸€å›äº‹:
<ol class="org-ol">
<li>response</li>
<li>dependent variable</li>
</ol></li>
</ul></li>
<li>ä¸€èˆ¬æ¥è¯´,å‡è®¾æˆ‘ä»¬è§‚æµ‹åˆ°äº†:
<ol class="org-ol">
<li>quantitative response Y</li>
<li>pä¸ªpredictor: \(X_1,X_2,\cdot\cdot\cdot,X_p\)</li>
</ol></li>
<li><p>
å¹¶ä¸”æˆ‘ä»¬assumeåœ¨Yå’ŒXä¹‹é—´æœ‰relationship,é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¦‚ä¸‹çš„å…¬å¼æ¥è¡¨ç¤º:
</p>
\begin{equation}
Y = f(X) + \varepsilon\tag{2.1}
\end{equation}</li>
<li>è¿™é‡Œçš„:
<ul class="org-ul">
<li>\(f\) æ˜¯fixedä½†æ˜¯å´æœªçŸ¥çš„ä½œç”¨äº \(X_1,\cdot\cdot\cdot,X_p\) çš„å‡½æ•°,å®ƒæ˜¯ä¸€ä¸ªsystematic information</li>
<li>\(varepsilon\) æ˜¯random error term,è¿™ä¸ªæ•°å€¼æ˜¯independentäºX,å¹¶ä¸”å¹³å‡å€¼ä¸ºzero(å°±æ˜¯æœ‰æ—¶å€™é«˜äº0,æœ‰æ—¶å€™ä½äº0,æœ€ç»ˆå¹³å‡å€¼ç­‰äº0)</li>
</ul></li>
<li>å¦‚å›¾
<ul class="org-ul">
<li><p>
å›¾2-2çš„
</p>

<div id="orga99ffad" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/2-2.png" alt="2-2.png" />
</p>
<p><span class="figure-number">Figure 5: </span>isl/2-2.png</p>
</div></li>
<li>æœ€å·¦è¾¹æ˜¯ä¸€ä¸ªå…³äºå¦‚ä¸‹ä¸¤ä¸ªé‡ä¹‹é—´çš„å…³ç³»:
<ol class="org-ol">
<li>income</li>
<li>years of education</li>
</ol></li>
<li><p>
è¿™ä¸ªå›¾æ˜¾ç¤ºç»™æˆ‘ä»¬çš„ä¿¡æ¯æ˜¯:æˆ‘ä»¬å¯ä»¥é€šè¿‡year of educationæ¥é¢„æµ‹income,ä½†æ˜¯é¢„æµ‹æ‰€éœ€è¦çš„function fé€šå¸¸æ˜¯æœªçŸ¥çš„
</p>
<pre class="example" id="org2ee6ef5">
The function f that connects the input variable to the output
variable is in general unknown
</pre></li>
<li>ä¸ºäº†è·å–f,æˆ‘ä»¬éœ€è¦é€šè¿‡æˆ‘ä»¬observed pointæ¥estimate f.</li>
<li>æ³¨æ„,è¿™é‡Œçš„incomeæ•°æ®æ˜¯æˆ‘ä»¬é€šè¿‡å‡½æ•°fæ¥ç¼–é€ çš„,ä¹Ÿå°±æ˜¯è¯´,è¿™é‡Œçš„fæ˜¯å·²çŸ¥çš„(å’Œæ•°æ®å·²çŸ¥,fæœªçŸ¥ç›¸å),ä¹Ÿå°±æ˜¯å›¾2-2ä¸­å³è¾¹æ‰€ç¤º</li>
<li>è¿™é‡Œçš„vertical lineä»£è¡¨error term \(\varepsilon\) ,æˆ‘ä»¬æ³¨æ„åˆ°æœ‰çš„ \(\varepsilon\) æ˜¯æ¯” \(f\) (è“è‰²çº¿)ä½ä¸€ç‚¹,æœ‰çš„æ¯”fé«˜ä¸€ç‚¹,æ€»ä½“æ¥è¯´å¹³å‡å€¼æ˜¯0</li>
</ul></li>
<li>å¦‚å›¾
<ul class="org-ul">
<li><p>
å›¾2-3
</p>

<div id="org722937c" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/2-3.png" alt="2-3.png" />
</p>
<p><span class="figure-number">Figure 6: </span>isl/2-3.png</p>
</div></li>
<li>é€šå¸¸æ¥è¯´,å‡½æ•°få¹¶ä¸ä»…ä»…åŒ…å«ä¸€ä¸ªinput variable,å¦‚å›¾2-3æ‰€ç¤º,æˆ‘ä»¬å¯ä»¥æŠŠincomeçœ‹æˆæ˜¯function of:
<ol class="org-ol">
<li>years of education</li>
<li>seniority</li>
</ol></li>
<li>è¿™é‡Œçš„få°±æ˜¯ä¸¤ä¸ªç»´åº¦çš„surface,å¹¶ä¸”å¿…é¡»ä½¿ç”¨è§‚å¯Ÿçš„æ•°æ®æ¥ä¼°è®¡</li>
</ul></li>
<li>æœ¬è´¨ä¸Šæ¥è¯´,statistical learningä»£è¡¨äº†ä¸€ç³»åˆ—estimating fçš„æ–¹æ³•.æœ¬ç« æˆ‘ä»¬ä¸»è¦åˆ—å‡º:
<ul class="org-ul">
<li>å…³é”®çš„æ¦‚å¿µ</li>
<li>ç”¨äºä¼°è®¡çš„å·¥å…·</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org68f8152" class="outline-4">
<h4 id="org68f8152"><span class="section-number-4">2.1.1.</span> Why Estimate f?</h4>
<div class="outline-text-4" id="text-2-1-1">
<ul class="org-ul">
<li>é‚£ä¹ˆæˆ‘ä»¬ä¸ºä»€ä¹ˆéœ€è¦æ¥estimate få‘¢?</li>
<li>ä¸¤ä¸ªåŸå› :
<ul class="org-ul">
<li>prediction</li>
<li>inference</li>
</ul></li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org18b918a"></a>Prediction<br />
<div class="outline-text-5" id="text-2-1-1-1">
<ul class="org-ul">
<li><p>
åœ¨å¾ˆå¤šæƒ…å†µä¸‹, inputs Xå·²ç»å­˜åœ¨äº†,ä½†æ˜¯output Yä¸å¤ªå®¹æ˜“è·å¾—,åœ¨è¿™ç§æƒ…å†µä¸‹,ç”±äº
error term è¯„ä»·æƒ…å†µä¸‹ä¸º0,é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¦‚ä¸‹çš„å…¬å¼æ¥é¢„æµ‹Y
</p>
\begin{equation}
\hat{Y} = \hat{f}(X)\tag{2.2}
\end{equation}</li>
<li>ç”±äºfæ˜¯ä¸å¯èƒ½å‡†ç¡®è·å–çš„,æˆ‘ä»¬è¿™é‡Œä½¿ç”¨ \(\hat{f}\) æ¥ä»£è¡¨æˆ‘ä»¬estimateçš„f</li>
<li>è¿™é‡Œçš„ \(\hat{Y}\) å°±æ˜¯æˆ‘ä»¬å¯¹Yçš„prediction</li>
<li>é€šå¸¸æ¥è¯´f^æ˜¯ä¸€ä¸ªblack box,å¦‚æœèƒ½å‡†ç¡®é¢„æµ‹çš„è¯,äººä»¬å¯¹ \(\hat{f}\) çš„çš„æ ·å¼å…¶å®ä¸æ˜¯å¾ˆå…³å¿ƒ</li>
<li>æˆ‘ä»¬æ¥ä¸¾ä¸ªä¾‹å­æ¥è¯´æ˜è¿™ä¸ªæƒ…å†µ:
<ul class="org-ul">
<li>X1&#x2026;.Xpæ˜¯ä¸€ä¸ªpatientçš„pä¸ªè¡€æ¶²ç‰¹å¾</li>
<li>Yæ˜¯ä»£è¡¨è¿™ä¸ªpatientå¯¹äºæŸä¸ªç‰¹å®šdrugçš„ä¸¥é‡ååº”æŒ‡æ•°</li>
</ul></li>
<li>å¯¹äºYçš„é¢„æµ‹å€¼ \(\hat{Y}\) çš„å‡†ç¡®æ€§ä¾èµ–äºä¸¤ä¸ªç±»å‹çš„ç‰¹å¾:
<ul class="org-ul">
<li>reducible error</li>
<li>irreducible error</li>
</ul></li>
<li>ä¸€èˆ¬æ¥è¯´, \(\hat{f}\) å’ŒçœŸæ­£çš„fä¹‹é—´æ˜¯æœ‰å·®è·çš„,è¿™ä¸ªå·®è·å°±æ˜¯reducible error,åå­—çš„æ¥æº
åœ¨äº,è¿™ä¸ªå·®è·æ˜¯å¯ä»¥reduceçš„,å› ä¸ºæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æœ€é«˜ç²¾å°–çš„statistical learning
ç®—æ³•æ¥è®© \(\hat{f}\) æ— çº¿æ¥è¿‘äºf</li>
<li>ç”±äºYè¿˜æ˜¯eçš„function,æ‰€ä»¥å’Œeç›¸å…³çš„,è¿˜æ˜¯ä¼šå½±å“predictionçš„æ•ˆæœ,è¿™å°±æ˜¯æ‰€è°“çš„
irreducible error,æ³¨æ„æ— è®ºæˆ‘ä»¬æ€ä¹ˆå®Œç¾çš„estimate f,æˆ‘ä»¬éƒ½æ— æ³•å‡å°eå¸¦æ¥çš„error</li>
<li>å¥½,æˆ‘ä»¬ä¸‹é¢æ¥è§£é‡Šä¸‹,ä¸ºä»€ä¹ˆæˆ‘ä»¬æ— æ³•å‡å°e:
<ul class="org-ul">
<li>eå¯èƒ½å«æœ‰unmeasurable variation,æ¯”å¦‚:
<ol class="org-ol">
<li>å¯¹è¯ç‰©çš„åæ˜ å¯èƒ½æ¯ä¸€å¤©éƒ½ä¸åŒ</li>
<li>drugçš„åˆ¶é€ æœ¬èº«ä¹Ÿæ˜¯ä¸åŒçš„</li>
<li>æ¯ä¸ªç—…äººçš„æ„Ÿå—å¯èƒ½è¡¨è¾¾å‡ºæ¥æ˜¯ä¸ä¸€æ ·çš„.</li>
</ol></li>
</ul></li>
<li>æœ¬ä¹¦ä»‹ç»å¦‚ä½•è®©reducible erroræœ€å°çš„estimating fçš„æ–¹æ³•,éœ€è¦ç‰¢è®°åœ¨å¿ƒçš„æ˜¯,irreducible error
ç»™äº†æˆ‘ä»¬çš„predictionä»¥ä¸Šé™,æ— æ³•è¾¾åˆ°,è€Œä¸”åœ¨å®è·µä¸­ä¹Ÿæ— æ³•çŸ¥é“è¿™ä¸ªbound</li>
</ul>
</div>
</li>
<li><a id="org6b7a8b0"></a>Inference<br />
<div class="outline-text-5" id="text-2-1-1-2">
<ul class="org-ul">
<li>inferenceæ¯”predictionè¿›äº†ä¸€æ­¥:
<ul class="org-ul">
<li>æˆ‘ä»¬ä¸ä»…ä»…å¸Œæœ›é¢„æµ‹å‡ºå‡†ç¡®çš„Y</li>
<li>æˆ‘ä»¬è¿˜å¸Œæœ›äº†è§£Xå’ŒYçš„relationship:å¸Œæœ›çŸ¥é“éšç€Xçš„å˜åŒ–,Yå¦‚ä½•å˜åŒ–</li>
</ul></li>
<li>åœ¨inferenceè¿™ç§æƒ…å†µä¸‹, \(\hat{f}\) ä¸èƒ½å†çœ‹æˆæ˜¯black box,æˆ‘ä»¬éœ€è¦çŸ¥é“å®ƒçš„å…·ä½“form</li>
<li>åœ¨inferenceè¿™ç§æƒ…å†µä¸‹,æˆ‘ä»¬éœ€è¦å…³ç³»å¦‚ä¸‹å‡ ä¸ªé—®é¢˜:
<ul class="org-ul">
<li>å“ªäº›predictorå’Œæœ€ç»ˆçš„responseæœ‰å…³?: å¤šæ•°æƒ…å†µä¸‹,åªæœ‰ä¸€å°éƒ¨åˆ†çš„predictorå’Œæœ€ç»ˆçš„
Yæœ‰å…³,åœ¨ç‰¹å®šçš„æƒ…å†µä¸‹,èƒ½å¤Ÿè¯†åˆ«å‡ºè¿™ä¸€å°éƒ¨åˆ†predictoræ˜¯éå¸¸é‡è¦çš„</li>
<li>responseå’Œæ¯ä¸ªpredictorä¹‹é—´æ˜¯æ­£å‘è¿˜æ˜¯è´Ÿå‘çš„å…³ç³»?:æœ‰äº›predictorå’ŒYæ˜¯æœ‰positive
relationshipçš„,æé«˜è¿™ç§predictorå°±ä¼šæé«˜response. æœ‰äº›predictorå’ŒYåˆ™ç›¸å</li>
<li>Yå’Œæ¯ä¸ªpredictorä¹‹é—´çš„å…³ç³»å¯ä»¥ç”¨linear equationæ¥è§£é‡Šä¹ˆ?è¿˜æ˜¯è¯´éœ€è¦æ›´åŠ å¤æ‚çš„å…¬å¼
æ¥è§£é‡Š:å†å²ä¸Šç»å¤§å¤šæ•°estimate fçš„éƒ½æ˜¯çº¿æ€§å…¬å¼,ä½†æ˜¯å®é™…ä¸Šå¯èƒ½æ˜¯æ›´åŠ å¤æ‚çš„relationship</li>
</ul></li>
<li>æœ¬ä¹¦æˆ‘ä»¬ä¸»è¦å­¦ä¹ å¦‚ä¸‹ä¸‰ç§ä¾‹å­:
<ul class="org-ul">
<li>prediction setting</li>
<li>inference setting</li>
<li>combination of prediction and inference setting</li>
</ul></li>
<li>æ¯”å¦‚,ä¸€ä¸ªå…¬å¸æƒ³ä¸¾åŠä¸€ä¸ªå¸‚åœºæ´»åŠ¨,è¿™ä¸ªæ´»åŠ¨:
<ul class="org-ul">
<li>éœ€è¦è¯†åˆ«å“ªäº›äººä¼šç§¯æçš„åé¦ˆmailing</li>
<li>inputsæ˜¯å¯¹æ¯ä¸ªç”¨æˆ·çš„äººå£ç»Ÿè®¡å­¦æ•°æ®</li>
<li>outputsæ˜¯ä¸ªäººå¯¹äºè°ƒæŸ¥çš„åæ˜ </li>
</ul></li>
<li>åœ¨è¿™ä¸ªä¾‹å­ä¸­,å…¬å¸å¯¹äºæ¯ä¸ªindividual predictorå’Œä»–çš„responseä¹‹é—´çš„deep understandingå¹¶ä¸æ„Ÿå…´è¶£,
å…¬å¸åªå¸Œæœ›æœ‰ä¸ªå‡†ç¡®çš„æ¨¡å‹,èƒ½å¤Ÿå‘Šè¯‰æˆ‘æŸä¸ªäººæ˜¯å¦ä¼šå¯¹mailingæ„Ÿå…´è¶£,æˆ‘å¥½å‘å¹¿å‘Šç»™ä»–.è¿™å°±æ˜¯ä¸€ä¸ªå…¸å‹çš„prediction
çš„ä¾‹å­</li>
<li>è€Œä¸€ä¸ªå…¸å‹çš„inferenceçš„ä¾‹å­,å°±æ˜¯æˆ‘ä»¬ä¸Šé¢è¯´çš„advertising dataçš„ä¾‹å­,æˆ‘ä»¬éœ€è¦èƒ½å¤Ÿæ¸…æ¥šçš„äº†è§£
inputså’Œoutputsä¹‹é—´çš„å…³ç³»,æ‰èƒ½åˆ†é…ä¸åŒçš„é¢„ç®—ç»™ä¸åŒåª’ä½“,ä»è€Œè¾¾åˆ°æ•ˆæœçš„æœ€å¤§åŒ–</li>
<li>è€Œæ‰€è°“çš„å…¼æœ‰predictionå’Œinferenceçš„ä¾‹å­æ˜¯æˆ¿åœ°äº§:
<ul class="org-ul">
<li>ä¸€ä¸ªäººè‚¯å®šéå¸¸æƒ³çŸ¥é“,å­¦æ ¡,ç¤¾åŒº,æ²³æ™¯æˆ¿ç­‰æ¯ä¸ªå› ç´ å¯¹äºæˆ¿ä»·çš„å½±å“,è¿™ç›¸å½“äºinference</li>
<li>å¦å¤–ä¸€ä¸ªäººåˆ™åªæƒ³çŸ¥é“,ä¸€ä¸ªæ ‡ä»·ä¸º600wçš„æˆ¿å­,æ˜¯é«˜ä¼°äº†è¿˜æ˜¯ä½ä¼°äº†.</li>
</ul></li>
<li>æˆ‘ä»¬çš„é¢„æµ‹é‡Œé¢æ˜¯å¦åŒ…å«inference(ä¹Ÿå°±æ˜¯æ˜¯å¦éœ€è¦çŸ¥é“inputså’Œoutputsçš„å…³ç³»)ä¼šå¯¼è‡´æˆ‘ä»¬é€‰å–ä¸åŒçš„
methodæ¥estimate f:
<ul class="org-ul">
<li>linear modelèƒ½å¤Ÿè·å¾—ç®€å•è€Œä¸”åˆå®¹æ˜“è§£é‡Šçš„inference,ä½†æ˜¯å¯èƒ½æ— æ³•äº§ç”Ÿè¶³å¤Ÿå‡†ç¡®çš„é¢„æµ‹ç»“æœ</li>
<li>å¾ˆå¤šnon-linear modelå¯ä»¥æä¾›éå¸¸ç²¾ç¡®çš„prediction,ä½†æ˜¯ä»£ä»·æ˜¯å…¶å¯è§£é‡Šæ€§ä¸ä½³</li>
</ul></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org90395e5" class="outline-4">
<h4 id="org90395e5"><span class="section-number-4">2.1.2.</span> How Do We Estimate f?</h4>
<div class="outline-text-4" id="text-2-1-2">
<ul class="org-ul">
<li>æœ¬ä¹¦ä¼šä»‹ç»å¾ˆå¤šlinearå’Œnon-linearåŠæ³•æ¥estimating f,æ— è®ºlinearä¸å¦,è¿™äº›methodéƒ½æœ‰å¾ˆå¤š
å…±æ€§:
<ul class="org-ul">
<li>ä½œä¸ºinputs,æˆ‘ä»¬è§‚å¯Ÿåˆ°nä¸ªdifferent data points</li>
<li>è¿™nä¸ªdifferent data pointså«åštraining data,å› ä¸ºæˆ‘ä»¬ç”¨è¿™äº›æ•°æ®æ¥train æˆ‘ä»¬çš„æ¨¡å‹</li>
<li>æˆ‘ä»¬ä½¿ç”¨ \(x_{ij}\) æ¥ä»£è¡¨ç¬¬jä¸ªpredictor(æ¯”å¦‚year of education),çš„ç¬¬iæ¬¡è§‚å¯Ÿåˆ°çš„å€¼</li>
<li>\(y_i\) æ¥ä»£è¡¨ç¬¬iæ¬¡è§‚å¯Ÿå¾—åˆ°çš„response</li>
<li>æ‰€ä»¥æˆ‘ä»¬çš„training dataåŒ…å«{(x1,y1),(x2,y2),&#x2026;.,(xn,yn)}</li>
</ul></li>
<li>æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä½¿ç”¨statistical learning methodæ¥è®­ç»ƒtraining dataæ¥estimate è¿™ä¸ªunknown function f</li>
<li>æ¢å¥è¯è¯´,æˆ‘ä»¬å¸Œæœ›æŸ¥æ‰¾ \(\hat{f}\) ,ä»è€Œå¾—åˆ° \(\hat{Y} = \hat{f}(X)\)</li>
<li>è¿™ç§æƒ…å†µä¸‹,å¤§å¤šæ•°çš„statistical learning methodå¯ä»¥è¢«åˆ†ç±»ä¸º:
<ul class="org-ul">
<li>parametric approach</li>
<li>non-parametric approach</li>
</ul></li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgf8f9d38"></a>Parametric Methods<br />
<div class="outline-text-5" id="text-2-1-2-1">
<ul class="org-ul">
<li>parametric methodåŒ…å«two-step model-based approach:
<ol class="org-ol">
<li><p>
é¦–å…ˆæˆ‘ä»¬æ¥assumeä¸€ä¸‹functional form,æ¯”å¦‚æˆ‘ä»¬å‡è®¾fæ˜¯linearçš„,é‚£ä¹ˆå°±æœ‰
</p>
\begin{equation}
f(X) = \beta_0 + \beta_1X_1 + \beta_2X_2 + \cdot\cdot\cdot + \beta_pX_p,\tag{2.4}
\end{equation}</li>
<li><p>
ä¸€æ—¦ç¡®å®šäº†model,æˆ‘ä»¬éœ€è¦ä¸€ä¸ªprocedureæ¥è®©æˆ‘ä»¬çš„training dataæ¥fitè¿™ä¸ªmodel.
æˆ‘ä»¬åªéœ€è¦ç¡®å®š \\(\beta_0, \beta_1, ...\beta_p\) ä½¿å¾—ç¬¦åˆä¸‹é¢çš„å…¬å¼,æœ€å¸¸è§çš„fitçš„æ–¹æ³•æ˜¯least squares(æœ€å°äºŒä¹˜æ³•)
</p>
\begin{equation}
Y \approx \beta_0 + \beta_1X_1 + \beta_2X_2 + \cdot\cdot\cdot + \beta_pX_p
\end{equation}</li>
</ol></li>
<li>è¿™ç§ä»¥modelä¸ºåŸºç¡€çš„approachä¹‹æ‰€ä»¥è¢«ç§°ä¹‹ä¸ºparametric,æ˜¯å› ä¸ºå…¶estimating fçš„è¿‡ç¨‹å°±æ˜¯
estimatingè¿™äº›parameter( \\(\beta_0, \beta_1, ...\beta_p\) )</li>
<li>parametric approachçš„ç¼ºç‚¹å°±æ˜¯æˆ‘ä»¬é€‰æ‹©çš„modelå¾ˆå¤šæƒ…å†µä¸‹å¯èƒ½å¹¶ä¸matché‚£ä¸ªunknown form of f</li>
<li>ä¸€æ—¦é€‰æ‹©çš„modelå’Œtrue fç›¸å·®å¤ªè¿œ,æˆ‘ä»¬çš„estimateç»“æœå°±ä¼šéå¸¸çš„å·®</li>
<li>ä¸€ä¸ªå¯èƒ½çš„ä¿®æ”¹,æ˜¯æˆ‘ä»¬ä½¿ç”¨flexible model,è¿™ç§modelå¯èƒ½å½¢æˆçš„functional formçš„å¯èƒ½æ€§æ›´å¤š,
æ›´æœ‰å¯èƒ½åŒ¹é…ä¸Šf</li>
<li>ä½†æ˜¯è¿™ç§æ›´åŠ flexible çš„modeléœ€è¦æ›´å¤šçš„å‚æ•°,ä¹Ÿæ›´æœ‰å¯èƒ½æ›´åŠ çš„è¿‡æ‹Ÿåˆ(overfitting)</li>
<li><p>
å‰é¢å›¾2-3çš„æƒ…å†µå¦‚æœæˆ‘ä»¬æœ€å¼€å§‹å‡è®¾çš„modelæ˜¯linearçš„è¯,æˆ‘ä»¬ä¼šå…ˆæœ‰ä¸€ä¸ªå…¬å¼
</p>

<div id="org07bf6cd" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/2-3.png" alt="2-3.png" />
</p>
<p><span class="figure-number">Figure 7: </span>isl/2-3.png</p>
</div></li>
<li><p>
ç„¶åæˆ‘ä»¬ä½¿ç”¨least squares linear regressionä¹‹å,å¾—åˆ°äº† \\(\beta_0, \beta_1, ...\beta_p\) çš„å€¼,
ä¹‹åæˆ‘ä»¬å¾—åˆ°äº†å›¾2-4
</p>

<div id="org8c10d52" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/2-4.png" alt="2-4.png" />
</p>
<p><span class="figure-number">Figure 8: </span>isl/2-4.png</p>
</div></li>
<li>å¯ä»¥çœ‹åˆ°å›¾2-4ä¸­çš„linear fitçš„ä¸å¦‚å›¾2-3ä¸­å¥½,ä½†æ˜¯:
<ul class="org-ul">
<li>linearä¾ç„¶æ­ç¤ºäº†years of educationå’Œincomeæ¯”è¾ƒpostiveçš„relationship</li>
<li>linearåŒæ—¶æ­ç¤ºäº†seniorityå’Œincome çš„less postiveçš„relationship</li>
<li>å¹¶ä¸”åœ¨observationæœ‰é™çš„æƒ…å†µä¸‹,linearæ˜¯æˆ‘ä»¬éå¸¸å¥½çš„é€‰æ‹©</li>
</ul></li>
</ul>
</div>
</li>
<li><a id="org0f0a3fa"></a>Non-parametric Methods<br />
<div class="outline-text-5" id="text-2-1-2-2">
<ul class="org-ul">
<li>non-parameter methodä¸ä¼šå»æ˜ç¡®çš„assume fçš„form</li>
<li><p>
ç”±äºå¼€å§‹æ²¡æœ‰å»assumeä¸€ä¸ªform,é‚£ä¹ˆnon-parameterå°±æœ‰ä¸€ä¸ªç›¸å¯¹çš„,éå¸¸å¤§çš„ä¼˜åŠ¿,é‚£å°±æ˜¯:
non-parameter methodæœ‰å¯èƒ½èƒ½å¤Ÿéå¸¸ç²¾ç¡®çš„fitä¸€ç³»åˆ—çš„å¯èƒ½æ€§form(of f)
</p>
<pre class="example" id="org285320e">
Non-parameter method have the potential to accurately fit a wider range of
possible shapes of f
</pre></li>
<li>non-parametric approachä¹Ÿæœ‰å¾ˆå¤šç¼ºç‚¹:å› ä¸ºä»–ä»¬ä¸æ˜¯ç®€å•çš„ä¼°è®¡å‡ ä¸ªå‚æ•°å°±å¯ä»¥çš„,æ‰€ä»¥ä¸ºäº†
å¾—åˆ°æ›´å‡†ç¡®çš„æ¨¡å‹,non-paramter approachéœ€è¦éå¸¸å¤§é‡çš„observation</li>
<li>å›¾2-5å°±æ˜¯ä¸€ä¸ªä½¿ç”¨non-parameteric approachæ¥fit Income dataçš„ä¾‹å­
<ul class="org-ul">
<li><p>
å›¾2-5
</p>

<div id="orgf368273" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/2-5.png" alt="2-5.png" />
</p>
<p><span class="figure-number">Figure 9: </span>isl/2-5.png</p>
</div></li>
<li>è¿™ä¸ªä¾‹å­ä¸­ä½¿ç”¨äº†thin-plate splineæ¥é¢„æµ‹f,å…¶åŸç†æ˜¯,å½¢æˆä¸€ä¸ªåˆ‡é¢(å›¾2-5ä¸­é»„è‰²
çš„éƒ¨åˆ†)è®©è§‚å¯Ÿåˆ°çš„è¿™äº›ç‚¹å°½å¯èƒ½çš„smooth</li>
<li>è¿™ä¸ªmethodè¿˜éœ€è¦è®¾ç½®smoothçš„level</li>
<li><p>
å›¾2-6
</p>

<div id="org8963056" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/2-6.png" alt="2-6.png" />
</p>
<p><span class="figure-number">Figure 10: </span>isl/2-6.png</p>
</div></li>
<li>é€šè¿‡è¿™ä¸ªmethodå’Œè®¾ç½®ä¸€ä¸ªlower level smoothå€¼,æˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ä¸ªå’Œobservationéå¸¸è´´åˆçš„æ¨¡å‹(å›¾2-6),
æ¢å¥è¯è¯´å›¾2-5çš„smoothå€¼æ›´å¤§,å›¾2-6çš„smoothå€¼æ›´å°</li>
<li>ä½†æ˜¯è¿™ç§methodä¼šæœ‰éå¸¸ä¸¥é‡çš„overfitting</li>
<li>æˆ‘ä»¬åé¢ä¼šé€‰æ‹©è®¾ç½®ä¸€ä¸ªcorrect ammountçš„smoothæ¥è§„é¿è¿‡æ‹Ÿåˆ</li>
</ul></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org9fed118" class="outline-4">
<h4 id="org9fed118"><span class="section-number-4">2.1.3.</span> The Trade-Off Between Prediction Accuracy and Model Interpretability</h4>
<div class="outline-text-4" id="text-2-1-3">
<ul class="org-ul">
<li>æˆ‘ä»¬è¿™æœ¬ä¹¦é‡Œé¢ä¼šé‡åˆ°çš„methodæ€»ä½“åˆ†ä¸ºä¸¤ç§:
<ul class="org-ul">
<li>less flexible(ä¹Ÿå°±æ˜¯more restrictive): è¿™ç§methodåªèƒ½å¤Ÿäº§ç”Ÿæ¯”è¾ƒå°‘çš„estimateçš„shape,
æ¯”å¦‚linear regresionå°±æ˜¯è¿™ç§method,å› ä¸ºä»–åªèƒ½äº§ç”Ÿæ–œç‡å’Œä½ç§»ä¸å¤ªä¸€æ ·çš„ç›´çº¿shape</li>
<li>more flexible: è¿™ç§method(æ¯”å¦‚thin plate splines)å¯ä»¥ä¸ºestimate fäº§ç”Ÿéå¸¸å¤šçš„shape</li>
</ul></li>
<li>ä¹ä¸€çœ‹,å¥½åƒé€‰æ‹©flexibleçš„methodæ˜¯å¿…ç„¶çš„é€‰æ‹©,å› ä¸ºå…¶èƒ½äº§ç”Ÿæ›´å¤šçš„å¯èƒ½æ€§(shape),ä½†æ˜¯è¿˜æ˜¯æœ‰
å¾ˆå¤šç†ç”±è®©æˆ‘ä»¬é€‰æ‹©less flexible(more restrictive)çš„modelçš„:
<ul class="org-ul">
<li>å¦‚æœæˆ‘ä»¬å¯¹inferenceæ›´æ„Ÿå…´è¶£,é‚£ä¹ˆrestrictive modelæ›´å…·æœ‰è§£é‡Šæ€§,æ¯”å¦‚å½“inference
æ›´é‡è¦çš„æ—¶å€™,linear modelå¯èƒ½æ˜¯æ›´å¥½çš„é€‰æ‹©,å› ä¸ºä»–èƒ½å¤Ÿè®©æˆ‘ä»¬æ›´å®¹æ˜“çš„ç†è§£Yå’Œ \(X_1,X_2,\cdot\cdot\cdot,X_p\)
ä¹‹é—´çš„å…³ç³».åä¹‹, æ¯”è¾ƒflexibleçš„approach,æ¯”å¦‚splines(æˆ–è€…boosting)ä¼šäº§ç”Ÿéå¸¸
å¤æ‚çš„estimate f, è¿™ä¸ªæ¨¡å‹é‡Œé¢æ¯ä¸ªpredictorå’Œresponseä¹‹é—´çš„å…³ç³»éå¸¸éš¾ä»¥ç†è§£</li>
</ul></li>
<li>å›¾2-7ä¸ºæˆ‘ä»¬å±•ç¤ºäº†ä¸åŒmethodä¹‹é—´flexiblilityå’Œinterpretabilityä¹‹é—´çš„æŠ‰æ‹©:
<ul class="org-ul">
<li><p>
å›¾2-7
</p>

<div id="orgdc62ee1" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/2-7.png" alt="2-7.png" />
</p>
<p><span class="figure-number">Figure 11: </span>isl/2-7.png</p>
</div></li>
<li>Least squares linear regression,æ˜¯ç›¸å¯¹æ¯”è¾ƒinflexibleçš„,ä½†æ˜¯éå¸¸çš„interpretable</li>
<li>lasso,åœ¨linear modelçš„åŸºç¡€ä¸Š,ä½¿ç”¨æ›´åŠ fittingçš„è¿‡ç¨‹æ¥è®¡ç®— \(\beta_0, \beta_1, ...\beta_p\),è¿™ä¸ªè¿‡ç¨‹ä¼š
éå¸¸çš„inflexible,å› ä¸ºå®ƒä¼šæŠŠä¸€éƒ¨åˆ†çš„å‚æ•° \(\beta_x\) ç›´æ¥è®¾ç½®ä¸º0,æ‰€ä»¥å®ƒæ¯”linear modelè¿˜è¦
less inflexible,ä½†æ˜¯å´æ˜¯æ¯”linear regressionæ›´åŠ çš„interpretable,å› ä¸ºæœ€åçš„model
åªæœ‰éƒ¨åˆ†ä¸æ˜¯0çš„ \(\beta_x\) èµ·åˆ°äº†ä½œç”¨(å¯èƒ½çš„shapeç§ç±»æ¯”linearè¿˜å°)</li>
<li>GAMs(Generalize additive models),æ‰©å±•äº†linear model,è®©è¿™ä¸ªmodelé‡Œé¢åŒ…å«äº†ä¸€äº›
non-linear relationship,æ‰€ä»¥GAMsä¼šæ¯”linear regressionæ›´åŠ çš„flexible,ä½†æ˜¯ä¹ŸåŒæ—¶
less interpretable.å› ä¸ºinputså’Œoutputsç°åœ¨ä½¿ç”¨æ›²çº¿è€Œä¸æ˜¯ç›´çº¿æ¥è¡¨ç¤º</li>
<li>å®Œå…¨çš„non-linear methodæ¯”å¦‚gagging, boosting, svmç­‰,éƒ½æ˜¯éå¸¸flexibleçš„ä½†æ˜¯ä¹Ÿæ˜¯
éå¸¸éš¾ä»¥interpretçš„</li>
</ul></li>
<li>å‰é¢æˆ‘ä»¬è®²äº†:
<ul class="org-ul">
<li>å¦‚æœæˆ‘ä»¬çš„ç›®æ ‡æ˜¯inference,é‚£ä¹ˆä¸ç”¨è¯´,æˆ‘ä»¬ä½¿ç”¨simpleå¹¶ä¸”ç›¸å¯¹inflexibleçš„statistical
learning method</li>
<li><p>
å¦‚æœæˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯predictionå‘¢(æ¯”å¦‚é¢„æµ‹è‚¡ç¥¨çš„ä»·æ ¼æ¶¨è·Œ)?é‚£ä¹ˆæ˜¯ä¸æ˜¯è¯´æˆ‘ä»¬ä½¿ç”¨æœ€
flexibleçš„modelå°±å¯ä»¥äº†å‘¢?ç­”æ¡ˆæ˜¯å¦å®šçš„,æˆ‘ä»¬å¾€å¾€ä½¿ç”¨less flexibleçš„modelä¼šå–å¾—
æ¯”è¾ƒaccurateçš„prediction,åŸå› åœ¨äº
</p>
<pre class="example" id="org032911a">
Hilly flexible çš„method,ä¹Ÿæœ‰æ›´å¤šå¯èƒ½ä¼šè¿‡æ‹Ÿåˆ(overfitting)
</pre></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgf6fc2b5" class="outline-4">
<h4 id="orgf6fc2b5"><span class="section-number-4">2.1.4.</span> Supervised Versus Unsupervised Learning</h4>
<div class="outline-text-4" id="text-2-1-4">
<ul class="org-ul">
<li>å¤§å¤šæ•°çš„statistical learningé—®é¢˜åˆ†ä¸ºä¸¤ä¸ªå¤§ç±»:
<ul class="org-ul">
<li>supervised(æœ¬ä¹¦ä¸»è¦æ¶‰çŒè¿™ä¸ªç±»åˆ«): å¯¹æ¯ä¸€ä¸ªpredictor,éƒ½ä¸¥æ ¼çš„æœ‰ä¸€ä¸ªresponse</li>
<li>unsupervised:predictorå­˜åœ¨,ä½†æ˜¯responseä¸å­˜åœ¨.è¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬è¦è¯•ç€å»ç†è§£ä¸åŒinputs
ä¹‹é—´çš„å…³ç³»</li>
</ul></li>
<li>å¯¹äºunsupervisedæ¥è¯´,æˆ‘ä»¬ä¸€ä¸ªå¯èƒ½çš„çš„statistical learningå·¥å…·æ˜¯cluster analysis,
è¿™ä¸ªå·¥å…·çš„åŠŸèƒ½å°±æ˜¯çœ‹çœ‹inputsæ˜¯ä¸æ˜¯èƒ½å¤Ÿåˆ†æˆå¤šä¸ªä¸åŒçš„group:
<ul class="org-ul">
<li>æ¯”å¦‚,æˆ‘ä»¬åœ¨å¸‚åœºåˆ†æçš„æ—¶å€™,æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°ä¸åŒçš„variable(zip code, family income, shopping habit)</li>
<li>è¿™äº›customerså¯èƒ½ä¼šè½åˆ°ä¸åŒçš„group,æ¯”å¦‚é«˜æ”¯å‡ºå’Œä½æ”¯å‡ºgroup</li>
</ul></li>
<li>åœ¨å®é™…å·¥ä½œå½“ä¸­,æˆ‘ä»¬ä¼šé‡åˆ°æºæ‚supervisedå’Œunsupervisedçš„æƒ…å†µ,æ¯”å¦‚:
<ul class="org-ul">
<li>æˆ‘ä»¬æœ‰nä¸ªinputs,å…¶ä¸­mä¸ªinputsæœ‰response,å¦å¤–çš„n-mä¸ªinputsæ²¡æœ‰respose</li>
<li>è¿™ç§æƒ…å†µé€šå¸¸æ˜¯inputæ¯”è¾ƒå®¹æ˜“è·å–,ä½†æ˜¯resposeçš„è·å–æ¯”è¾ƒæ˜‚è´µ,æ‰€ä»¥æˆ‘ä»¬è·å–äº†å…¶ä¸­mä¸ªresponse(mè¿œå°äºn)</li>
<li>è¿™ç§æƒ…å†µæˆ‘ä»¬ç§°ä¹‹ä¸ºsemi-supervised learning problem</li>
<li>è¿™ç§æƒ…å†µæœ¬ä¹¦ä¸è®¨è®º</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org8294b2d" class="outline-4">
<h4 id="org8294b2d"><span class="section-number-4">2.1.5.</span> Regression Versus Classification Problems</h4>
<div class="outline-text-4" id="text-2-1-5">
<ul class="org-ul">
<li>variableå¯ä»¥è¢«åˆ†ä¸ºä¸¤ç±»:
<ul class="org-ul">
<li>quantitative(æ•°é‡çš„): ä¸€èˆ¬æ˜¯numerical value,æ¯”å¦‚äººçš„å¹´é¾„,èº«é«˜,æ”¶å…¥</li>
<li>categorical(qualitativeè´¨é‡çš„): ä¸€èˆ¬æ˜¯å¯ä»¥åˆ†ç±»çš„,æ¯”å¦‚äººçš„æ€§åˆ«(ç”·æˆ–è€…å¥³),å•†å“å“ç‰Œ(nikeè¿˜æ˜¯adidas),
æ˜¯å¦é»˜è®¤é€‰æ‹©è´·æ¬¾(æ˜¯è¿˜æ˜¯å¦)</li>
</ul></li>
<li>æˆ‘ä»¬ä¼šæ ¹æ®variableçš„ä¸åŒ(ä¸»è¦æ˜¯response variable)æ¥åŒºåˆ†é—®é¢˜çš„åå­—:
<ul class="org-ul">
<li>æ‹¥æœ‰quantitative responseçš„å«åšregression problem(å›å½’é—®é¢˜)</li>
<li>æœ‰ç”¨categorical(qunlitative) responseçš„å«åšclassification problem(åˆ†ç±»é—®é¢˜)</li>
</ul></li>
<li>å½“ç„¶,è¿™ä¸ªåˆ†ç±»å¹¶ä¸æ˜¯ç‰¹åˆ«ä¸¥æ ¼,æ¯”å¦‚:
<ul class="org-ul">
<li>linear regressionä½¿ç”¨äº†quantitative response</li>
<li>logistic regressionå´ä½¿ç”¨äº†categorical response(æ¯”å¦‚two-class, binary)</li>
</ul></li>
<li>æœ‰å¾ˆå¤šstatistical methodå³å¯ä»¥ä½¿ç”¨quantitativeæˆ–è€…æ˜¯qualitative ä¸¤ç§response,æ¯”å¦‚:
<ul class="org-ul">
<li>K-nearest neighbors</li>
<li>boosting</li>
</ul></li>
<li>è¦æ³¨æ„,æˆ‘ä»¬æ˜¯æ ¹æ®responseæ˜¯å¦æ˜¯æ•°é‡çš„è¿˜æ˜¯è´¨é‡çš„æ¥é€‰æ‹©learning model(æ¯”å¦‚æ•°é‡çš„,æˆ‘ä»¬å°±
é€‰æ‹©linear regression,åˆ†ç±»çš„,æˆ‘ä»¬å°±é€‰æ‹©logistic regression)</li>
<li>ä½†æ˜¯,å¯¹äºpredictoræ˜¯æ•°é‡çš„è¿˜æ˜¯åˆ†ç±»çš„,æˆ‘ä»¬å¹¶ä¸æ€ä¹ˆåœ¨ä¹,å› ä¸ºå°±ç®—æ˜¯åˆ†ç±»çš„predictorä¹Ÿä¼šåœ¨
ä½¿ç”¨å‰è¢«coded</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orge780837" class="outline-3">
<h3 id="orge780837"><span class="section-number-3">2.2.</span> Assessing Model Accuracy</h3>
<div class="outline-text-3" id="text-2-2">
<ul class="org-ul">
<li>æœ¬ä¹¦çš„ä¸€å¤§ç›®çš„,å°±æ˜¯ä»‹ç»ä¸€ç³»åˆ—statistical learning method,è€Œä¸ä»…ä»…æ˜¯linear regression approach</li>
<li>é‚£ä¹ˆä¸ºä»€ä¹ˆè¦ä»‹ç»é‚£ä¹ˆå¤šæ¨¡å‹å‘¢?ä¸èƒ½é€‰ä¸€ä¸ªæœ€å¥½çš„æ¨¡å‹ä»‹ç»ä¹ˆ?
<ul class="org-ul">
<li><p>
ç­”æ¡ˆæ˜¯ä¸è¡Œ,ä¹Ÿæ²¡æœ‰æ‰€è°“"æœ€å¥½"çš„æ¨¡å‹:æ²¡æœ‰ä¸€ä¸ªmethodèƒ½å¤Ÿåœ¨æ‰€æœ‰çš„data setsä¸Šé¢å‡»è´¥æ‰€æœ‰å¯¹æ‰‹
</p>
<pre class="example" id="orgef3594e">
There is no free lunch in statistics
</pre></li>
<li>å¯¹æŸä¸ªç‰¹å®šçš„data set, ä¸€ä¸ªmethodå¯èƒ½å·¥ä½œçš„æœ€å¥½,ä½†æ˜¯data setç¨å¾®å˜ä¸€å˜,å¯èƒ½æœ€å¥½çš„method
å°±å˜æˆå¦å¤–çš„äº†.æ‰€ä»¥å¯¹äºç‰¹å®šçš„ä»»åŠ¡,é€‰å–åˆé€‚çš„methodå°±éå¸¸çš„é‡è¦</li>
</ul></li>
<li>æœ¬èŠ‚,æˆ‘ä»¬ä¼šè®¨è®ºä¸€äº›åœ¨é€‰å–statistical learning methodè¿‡ç¨‹ä¸­æœ€é‡è¦çš„ä¸€äº›æ¦‚å¿µ</li>
</ul>
</div>
<div id="outline-container-org61d67da" class="outline-4">
<h4 id="org61d67da"><span class="section-number-4">2.2.1.</span> Measuring the Quality of Fit</h4>
<div class="outline-text-4" id="text-2-2-1">
<ul class="org-ul">
<li>ä¸ºäº†éªŒè¯åœ¨ä¸€ä¸ªgiven data setä¸Šé¢æŸäº›statistical learning methodçš„performance,æˆ‘ä»¬éœ€è¦
measureè¿™ä¸ªmethodåšå‡ºçš„predictionå’Œobserved dataä¹‹é—´çš„å·®è·</li>
<li><p>
åœ¨regression settingä¸­,æœ€å¸¸è§çš„measureæ–¹æ³•å«åšMSE(mean squared error),å¦‚ä¸‹
</p>
\begin{equation}
MSE = \cfrac{1}{n}\displaystyle\sum_{i=1}^n{(y_i  - \hat{f}(x_i))^2},\tag{2.5}
\end{equation}</li>

<li>å…¶ä¸­çš„ \(\hat{f}(x_i)\) æŒ‡çš„æ˜¯ \(\hat{f}\) è¿™ä¸ªmodelç»™ä¸çš„prediction</li>
<li>å¦‚æœpredicted responseå’Œtrueresponseä¹‹é—´çš„å€¼éå¸¸çš„é è¿‘çš„è¯,MSEçš„ç»“æœä¼šéå¸¸ä½</li>
<li>MSEçš„è®¡ç®—,ä½¿ç”¨çš„æ˜¯training data,æ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç»™MSEä¸€ä¸ªæ›´åŠ ä¸¥è°¨çš„å‘½å: training MSE</li>
<li>ä½†æ˜¯,å®é™…ç”Ÿæ´»ä¸­,æˆ‘ä»¬ä¸æ˜¯ç‰¹åˆ«åœ¨æ„æ¨¡å‹åœ¨training dataä¸Šçš„è¡¨ç°,è€Œæ˜¯æ›´åœ¨æ„æ¨¡å‹åœ¨testæ•°æ®(ä¹Ÿå°±æ˜¯
ä¹‹å‰æ²¡è§åˆ°è¿‡çš„æ•°æ®)çš„è¡¨ç°</li>
<li><p>
æ‰€ä»¥å°±æœ‰å¦‚ä¸‹åˆ¤å®štest MSEæ˜¯å¦å¥½çš„å…¬å¼:å…¶ä¸­ \((x_0, y_0)\) æ˜¯æ²¡æœ‰åœ¨train dataä¸­ä½¿ç”¨çš„æ•°æ®,ä¹Ÿå°±æ˜¯testæ•°æ®
</p>
\begin{equation}
\hat{f}(x_0) \approx y_0
\end{equation}</li>
<li>æ³¨æ„è¿™é‡Œä¸è¦å’Œ \(\hat{f}(x_i) \approx y_i\) æƒ³æ··æ·†,å¸¦ \(x_i\) çš„è¡¨ç¤ºæ˜¯trainigæ•°æ®,è€Œ \(x_0\) è¡¨ç¤ºçš„æ˜¯testæ•°æ®</li>
<li><p>
å¦‚æœæˆ‘ä»¬æœ‰å¤§é‡çš„testæ•°æ®(æ³¨æ„è™½ç„¶æ˜¯å¤§é‡æ•°æ®,è¿˜æ˜¯ä½¿ç”¨ \((x_0, y_0)\) æ¥è¡¨ç¤º), é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¦‚ä¸‹
å…¬å¼æ¥è®¡ç®—æˆ‘ä»¬çš„å¹³å‡prediction error
</p>
\begin{equation}
  Avg(y_0 - \hat{f}(x_0))^2,\tag{2.6}
\end{equation}</li>
<li>é‚£ä¹ˆ,å¦‚ä½•æ¥é€‰å–ä¸€ä¸ªtest MSEæœ€å°çš„modelå‘¢?
<ul class="org-ul">
<li>åœ¨ä¸€èˆ¬æƒ…å†µä¸‹,ä½ æ˜¯èƒ½å¤Ÿæœ‰ä¸€ä¸ªtestæ•°æ®é›†çš„(è¿™äº›æ•°æ®æ²¡æœ‰ç”¨æ¥training model),å¹¶ä¸”inputå’Œresponse
éƒ½æœ‰,è¿™ç§æƒ…å†µä¸‹,æˆ‘ä»¬è®¡ç®—test MSE,ç„¶åé€‰æ‹©ä¸€ä¸ªtest MSEæœ€å°çš„modelå°±å¥½äº†</li>
<li>åœ¨æŸäº›æƒ…å†µä¸‹å¦‚æœæ²¡æœ‰testæ•°æ®é›†çš„æƒ…å†µä¸‹,å°±æ— æ³•è®¡ç®—test MSEäº†</li>
</ul></li>
<li><p>
æ²¡æœ‰testæ•°æ®é›†çš„æƒ…å†µä¸‹,å¾ˆå¤šäººè¯•å›¾ç¼©å°training MSEä»è€ŒæœŸæœ›test MSEä¹Ÿèƒ½ç›¸åº”çš„å‡å°.è¿™å…¶å®æ˜¯é”™è¯¯çš„
æƒ³æ³•
</p>
<pre class="example" id="org37fe949">
There is no guarantee that the method with the lowest training MSE
will also have the lowest test MSE.
</pre></li>
<li>å›¾2-9å·¦ä¾§ä»‹ç»äº†è¿™ä¸ªç°è±¡:
<ul class="org-ul">
<li><p>
å›¾2-9
</p>

<div id="org3dd701c" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/2-9.png" alt="2-9.png" />
</p>
<p><span class="figure-number">Figure 12: </span>isl/2-9.png</p>
</div></li>
<li>å·¦è¾¹çš„å›¾ä¸­,black curveæ˜¯true f</li>
<li>orangeæ˜¯linear regression fit, ä¸å¤ªinflexible</li>
<li>blueæ˜¯smoothing splines, less flexible</li>
<li>greenæ˜¯smoothing splines, more flexible</li>
<li>greenå’Œ data pointé…åˆçš„éå¸¸çš„ç´§å¯†,ä½†æ˜¯æˆ‘ä»¬çœ‹åˆ°å®ƒå’Œtrue få¹¶ä¸æ˜¯éå¸¸è´´åˆ</li>
<li>å›¾2-9å³ä¾§ä»‹ç»äº†éšç€flexibleçš„å¢åŠ , training MSEå’Œtest MSEçš„å˜åŒ–:</li>
<li>greyçš„æ›²çº¿è¡¨ç¤ºäº†éšç€å‡ ä¸ªä¸åŒçš„smoothing splines çš„flexiblity(degree of freedom)çš„å¢åŠ ,
training MSEçš„å˜åŒ–(å¯ä»¥çœ‹åˆ°è¿™æ˜¯ä¸ªå•è°ƒé€’å‡çš„å…³ç³»)</li>
<li>æˆ‘ä»¬æœ‰æ¡”çº¢è‰²,è“è‰²,ç»¿è‰²çš„ä¸‰ä¸ªå°æ–¹å—,åœ°è¡¨å›¾2-9ä¸­ä¸‰ç§ä¸åŒçš„modelçš„flexiblityå’Œ
training MSE(test MSE)çš„å¯¹åº”ç‚¹,æ¨ªè½´æ˜¯flibility,çºµè½´æ˜¯MSE</li>
<li>linear regressionæ˜¯æœ€restrictiveçš„,å®ƒçš„flexibleå€¼ä¸º2,MSEå€¼ä¸º1.7å·¦å³</li>
<li>training MSEå¾ˆæ˜æ˜¾çš„éšç€flexibilityçš„æå‡è€Œä¸‹é™</li>
<li>ç»¿è‰²çš„ç‚¹æ‹¥æœ‰æœ€å¤§çš„flexiblity(23),ä»è€Œå¾—åˆ°äº†æœ€ä½çš„training MSE(0.4)</li>
<li>ç”±äºè¿™ä¸ªä¾‹å­æˆ‘ä»¬çŸ¥é“true function f,æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è®¡ç®—test MSE(å½“ç„¶å®è·µä¸­,function fæ˜¯ä¸å­˜åœ¨çš„,
æˆ‘ä»¬è¿™é‡Œæ˜¯ä¸ºäº†è¯´æ˜é—®é¢˜,æ‰€ä»¥å…ˆåˆ›å»ºäº†function f),test MSEä½¿ç”¨çº¢è‰²çš„çº¿è¡¨ç¤º</li>
<li>å’Œtraining MSEç±»ä¼¼,test MSEå¼€å§‹çš„æ—¶å€™æ˜¯å…ˆéšç€flexibleçš„æå‡è€Œé™ä½çš„</li>
<li>ä½†æ˜¯åœ¨æŸä¸ªpoint, test MSEå¼€å‘éšç€flexibleçš„æå‡è€Œæå‡,æ€»ä½“æ¥çœ‹,å½¢æˆäº†ä¸€ä¸ªUå­—å‹</li>
<li>ç”±äºUå­—å‹çš„å­˜åœ¨,æ‰€ä»¥linear regressionçš„æ¡”è‰²å’Œéå¸¸flexibleçš„ç»¿è‰²,éƒ½æœ‰å¾ˆé«˜çš„test MSE</li>
<li>è€Œblueè·å¾—äº†æœ€å°åŒ–çš„test MSE,è¿™ä¸ä»¤äººæƒŠå¥‡,å› ä¸ºä»å›¾2-9ä¸­æˆ‘ä»¬å°±å¯ä»¥çœ‹åˆ°,blueå’Œtrue f
åŒ¹é…çš„æœ€å¥½</li>
<li>æœ€åMSEä¸º1.0çš„åœ°æ–¹æœ‰ä¸€æ¡è™šçº¿çš„æ¨ªçº¿,è¿™æ¡çº¿ä»£è¡¨çš„æ˜¯irreducible errorå¼•å…¥çš„Var(e),
ä¹Ÿå°±æ˜¯è¯´,æ— è®ºå¦‚ä½•éƒ½æ— æ³•å»é™¤çš„è¯¯å·®.æ‰€æœ‰çš„modelçš„MSEæœ€ä½ä¹Ÿä¸ä¼šä½è¿‡è¿™æ¡çº¿</li>
<li>é‚£ä¹ˆ,blueå¯¹åº”çš„ä½ç½®å·²ç»æ˜¯ç¦»è¿™æ¡çº¿æœ€è¿‘çš„ä½ç½®äº†,ä¹Ÿå¯ä»¥è¯´blueæ˜¯è¿™å‡ ä¸ªæ¨¡å‹é‡Œé¢æœ€æ¥è¿‘
ç†æƒ³çš„æ¨¡å‹äº†.</li>
</ul></li>
<li>åœ¨å›¾2-9é‡Œé¢:
<ul class="org-ul">
<li>éšç€flexibilityçš„æå‡,æˆ‘ä»¬çœ‹åˆ°training MSEæ˜¯å•è°ƒä¸‹é™çš„</li>
<li>éšç€flexibilityçš„æå‡,æˆ‘ä»¬çœ‹åˆ°test MSEæ˜¯å‘ˆç°ä¸€ä¸ªU-shapeçš„å½¢çŠ¶çš„</li>
</ul></li>
<li><p>
ä¸Šè¿°æ˜¯statistical learningçš„fundamental property,æ— è®ºä»€ä¹ˆæ ·çš„data set,ä¹Ÿæ— è®ºä»€ä¹ˆæ ·çš„method,
éƒ½æœ‰è¿™ä¸ªç°è±¡:
</p>
<pre class="example" id="org1dfa322">
As model flexibility increases, training MSE will decrease, but the test MSE may not.
</pre></li>
<li>å½“ä¸€ä¸ªmethodäº§ç”Ÿäº†small training MSE,ä½†æ˜¯è·å¾—äº†large test MSE,é‚£ä¹ˆæˆ‘ä»¬å°±è¯´,è¿™ä¸ªmodel
overfittingäº†å½“å‰çš„æ•°æ®</li>
<li>å‘ç”Ÿoverfittingçš„åŸå› æ˜¯æˆ‘ä»¬çš„ç»Ÿè®¡å­¦ä¹ è¿‡ç¨‹å¤ªæƒ³é…åˆæˆ‘ä»¬çš„training dataäº†,äºæ˜¯æ‰¾åˆ°äº†ä¸€ä¸ªè¿‡äº
å¤æ‚çš„pattern, è¿™ä¸ªpattern:
<ul class="org-ul">
<li>è¿‡äºé…åˆrandom change</li>
<li>æ²¡æœ‰é…åˆtrue properties of the unknownn function f</li>
</ul></li>
<li>ä¸€æ—¦å‘ç”Ÿäº†overfitting,test MSEå°±ä¼šæ¯”è¾ƒå¤§,å› ä¸ºtraining dataé‡Œé¢å‘ç°çš„patternå‹æ ¹å°±ä¸å­˜åœ¨</li>
<li>æ— è®ºæ˜¯å¦å‘ç”Ÿoverfitting,training MSEæ€»æ˜¯æ¯”test MSEå°,å› ä¸ºç»Ÿè®¡å­¦ä¹ methodæ€»æ˜¯è¯•å›¾å»å‡å°training MSE</li>
<li>æ€»ä½“æ¥è¯´less flexible modelä¼šäº§ç”Ÿæ›´å°çš„test MSE</li>
<li>æˆ‘ä»¬å†æ¥çœ‹å›¾2-10
<ul class="org-ul">
<li><p>
å›¾2-10
</p>

<div id="org7903e99" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/2-10.png" alt="2-10.png" />
</p>
<p><span class="figure-number">Figure 13: </span>isl/2-10.png</p>
</div></li>
<li>true fæ˜¯ä¸€ä¸ªlinear</li>
<li>training MSEéšç€flexibilityçš„æé«˜è€Œå•è°ƒé€’å‡</li>
<li>test MSEä¹Ÿæœ‰ä¸€ä¸ªU-shape</li>
<li>ç”±äºæˆ‘ä»¬çš„true fæ˜¯ä¸€ä¸ªlinear,æ‰€ä»¥test MSEçš„Uå·¦è¾¹å¾ˆå¹³ç¼“,å³è¾¹å¾ˆé™¡å³­. orangeä¹Ÿæ¯”greençš„æ›´ç¬¦åˆtrue f</li>
</ul></li>
<li>æˆ‘ä»¬å†æ¥çœ‹å›¾2-11:
<ul class="org-ul">
<li><p>
å›¾2-11
</p>

<div id="orga1b0b70" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/2-11.png" alt="2-11.png" />
</p>
<p><span class="figure-number">Figure 14: </span>isl/2-11.png</p>
</div></li>
<li>true fæ˜¯ä¸€ä¸ªhighly non-linear</li>
<li>training and test MSEçš„æ›²çº¿,è¿˜æ˜¯ç±»ä¼¼çš„æƒ…å†µ: training MSEå•è°ƒé€’å‡, test MSE U-shape</li>
<li>training and test MSEæ›²çº¿å¼€å§‹éƒ½æ˜¯rapidçš„decrease</li>
</ul></li>
<li>åœ¨å®è·µä¸­,è®¡ç®—training MSEæ˜¯æ¯”è¾ƒç®€å•çš„,ä½†æ˜¯è®¡ç®—test MSEæ˜¯æ¯”è¾ƒå›°éš¾çš„,å› ä¸ºtest dataæ²¡æœ‰responseæ•°æ®</li>
<li>å‰é¢çš„ä¾‹å­ä¸­, flexibility levelçš„æ”¹å˜è¿‡ç¨‹ä¸­ä¼šæœ‰ä¸€ä¸ªtest MSEæœ€ä½çš„ç‚¹(minium point),è¿™ä¸ªç‚¹ä¼šéšç€data set
ä¸åŒè€Œæ”¹å˜çš„.</li>
<li>æœ¬ä¹¦æˆ‘ä»¬ä¼šä½¿ç”¨å„ç§æ–¹æ³•æ¥è®¡ç®—è¿™ä¸ªminimum point:ä¸€ä¸ªé‡è¦çš„è®¡ç®—test MSEçš„methodå°±æ˜¯cross-validation</li>
</ul>
</div>
</div>
<div id="outline-container-orga2730fe" class="outline-4">
<h4 id="orga2730fe"><span class="section-number-4">2.2.2.</span> The Bias-Variance Trade-Off</h4>
<div class="outline-text-4" id="text-2-2-2">
<ul class="org-ul">
<li>ä¸Šé¢çš„å›¾2-9åˆ°å›¾2-11ä¸­çš„U-shapeå…¶å®æ˜¯ç»Ÿè®¡å­¦ä¹ æ–¹æ³•çš„ä¸¤ä¸ªcompeting property</li>
<li><p>
ä¸‹é¢çš„å…¬å¼2-7ä¸ºæˆ‘ä»¬ä»‹ç»äº†expected test MSEæ˜¯å¦‚ä½•è®¡ç®—çš„
</p>
\begin{equation}
E(y_0 - \hat{f}(x_0))^2 = Var(\hat{f}(x_0)) + [Bias(\hat{f}(x_0))]^2 + Var(\varepsilon)\tag{2.7}
\end{equation}</li>
<li>æˆ‘ä»¬ä¸‹é¢æ¥è¯¦ç»†è§£é‡Šä¸‹è¿™ä¸ªå…¬å¼:
<ul class="org-ul">
<li>è¿™é‡Œçš„ \(E(y_0 - \hat{f}(x_0))^2\) ä»£è¡¨äº†test MSEçš„æœŸæœ›,å…¶ä¸­çš„f^æ˜¯æˆ‘ä»¬é€šè¿‡å¤§é‡çš„training setè·å¾—çš„</li>
<li>å¦‚æœæˆ‘ä»¬æƒ³æ±‚å¹³å‡å€¼,é‚£ä¹ˆå¯¹äºæ¯ä¸ªå¯èƒ½çš„x0,æ±‚å‡ºexpected test MSE,ç„¶åæ±‚å¹³å‡å€¼å°±å¯ä»¥äº†.</li>
<li>å…¬å¼2-7å‘Šè¯‰æˆ‘ä»¬ä¸ºäº†å‡å°expected test error,æˆ‘ä»¬éœ€è¦é€‰æ‹©ä¸€ä¸ªç»Ÿè®¡å­¦ä¹ æ–¹æ³•èƒ½å¤ŸåŒæ—¶è®©å¦‚ä¸‹ä¸¤ä¸ªå€¼éƒ½å°:
<ol class="org-ol">
<li>low variance</li>
<li>low bias</li>
</ol></li>
<li>ç”±äºvariationå’Œbiaséƒ½æ˜¯éè´Ÿå€¼,æ‰€ä»¥æˆ‘ä»¬çš„expected test MSEå¿…ç„¶å¤§äºirreducible error: Var(e)</li>
<li>ä¸‹é¢æ¥è§£é‡Šä¸‹ä»€ä¹ˆæ˜¯variance: varianceä»£è¡¨å¦‚æœæˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„training data,æˆ‘ä»¬çš„f^ä¼šå¦‚ä½•change</li>
<li>varianceçš„å€¼è¶Šå°è¶Šå¥½:
<ol class="org-ol">
<li>å¦‚æœtrainig dataçš„æå°å˜åŠ¨å°±å¸¦æ¥äº†å·¨å¤§çš„f^å˜åŠ¨,æˆ‘ä»¬å°±è¯´è¿™ä¸ªmodelçš„varianceæ˜¯highçš„</li>
<li>å¦‚æœtrainig dataçš„å¤§å˜åŠ¨çˆ·ä¸ä¼šå¸¦æ¥äº†å·¨å¤§çš„f^å˜åŠ¨,æˆ‘ä»¬å°±è¯´è¿™ä¸ªmodelçš„varianceæ˜¯lowçš„</li>
</ol></li>
<li>ä¸€èˆ¬æ¥è¯´,è¶Šflexibleçš„modelæ‹¥æœ‰è¶Šhigherçš„variance,ä»¥å›¾2-9ä¸ºä¾‹:
<ol class="org-ol">
<li>flexible green curveå’Œinputsé…åˆçš„å¾ˆç´§å¯†,ä»–çš„varianceå°±å¾ˆé«˜,å› ä¸ºæ”¹å˜å…¶ä¸­ä»»ä½•ä¸€ä¸ªtraining
dataéƒ½ä¼šè®©f^å‰§çƒˆçš„æ”¹å˜,å› ä¸ºf^è¯•å›¾å’Œæ¯ä¸ªç‚¹éƒ½é…åˆçš„ç´§å¯†</li>
<li>inflexible orange lineçš„varianceå°±å¾ˆlow,å› ä¸ºæ”¹åŠ¨ä»»ä½•ä¸€ä¸ªinputéƒ½ä¸ä¼šè®©lineæ”¹åŠ¨å¾ˆå¤§,å› ä¸ºè¿™ä¸ª
æ¨¡å‹æœ¬æ¥ä¹Ÿæ²¡æŒ‡æœ›æ¯ä¸ªdata pointéƒ½é…åˆçš„å¥½(å®ƒæ˜¯ç›´çº¿,åªèƒ½é…åˆä¸ªå¤§æ¦‚)</li>
</ol></li>
<li>ä¸‹é¢å†æ¥è§£é‡Šä¸‹ä»€ä¹ˆæ˜¯bias: biasä»£è¡¨æˆ‘ä»¬æƒ³è¦é€¼è¿‘real-life problemçš„æ—¶å€™,ä¸å¾—ä¸å¼•å…¥çš„è¯¯å·®</li>
<li>æ¯”å¦‚linear regressionæ¨¡å‹ä¼šè®¤ä¸ºè‡ªå·±æ±‚è§£çš„é—®é¢˜æ˜¯ä¸€ä¸ªçº¿æ€§é—®é¢˜,æ‰€ä»¥è¿™ä¸ªæ¨¡å‹æ‰€æœ‰çš„data pointéƒ½åº”è¯¥
å†ä¸€æ¡çº¿ä¸Š,ä½†æ˜¯å®é™…ç”Ÿæ´»å½“ä¸­çš„é—®é¢˜ä¸å¯èƒ½æ˜¯è¿™ä¹ˆç®€å•çš„å…³ç³»,æ‰€ä»¥æˆ‘ä»¬çš„estimate fä¸Šé¢çš„ç‚¹ä¸å¯é¿å…
çš„å’ŒçœŸå®çš„pointåœ¨ä½ç½®ä¸Šæœ‰åŒºåˆ«,ä¹Ÿå°±æ˜¯è¯¯å·®:
<ol class="org-ol">
<li>å›¾2-11çš„ä¾‹å­,true fæ˜¯non-lineçš„,æ‰€ä»¥æ— è®ºæœ‰å¤šä¹ˆå¤šçš„inputæ•°æ®,ä½¿ç”¨linear regressionä¹Ÿä¸å¯èƒ½
å¾—åˆ°å¤šä¹ˆå‡†ç¡®çš„å€¼,æ¢å¥è¯è¯´åœ¨è¿™ä¸ªä¾‹å­é‡Œé¢,linear regressionå¸¦æ¥äº†high bias</li>
<li>å›¾2-10çš„ä¾‹å­,true fæœ¬æ¥å°±æ¥è¿‘äºlinear,æ‰€ä»¥è¶³å¤Ÿå¤šçš„inputs,æˆ‘ä»¬çš„linear regressionä¼šå¸¦æ¥æ¯”è¾ƒ
å‡†ç¡®çš„estimate</li>
</ol></li>
<li>æ€»ä½“ä¸Šæ¥è¯´,æ›´åŠ flexibleçš„methodä¼šå¯¼è‡´ä½çš„bias</li>
</ul></li>
<li>ä¸€èˆ¬æ¥è¯´,ä¸€æ—¦æˆ‘ä»¬é€‰æ‹©äº†more flexibleçš„method,é‚£ä¹ˆ:
<ul class="org-ul">
<li>varianceä¼šæå‡</li>
<li>biasä¼šé™ä½</li>
<li>å¦‚æœvarianceçš„æå‡æ©ç›–äº†biasçš„é™ä½,test MSEä¼šæå‡;åä¹‹,test MSEä¼šé™ä½</li>
</ul></li>
<li>ä¸€å¼€å§‹,flexçš„æå‡ä¼šå¯¼è‡´biasä¼šé™ä½çš„æ¯”è¾ƒå¿«(è¶…è¿‡varianceçš„æå‡),æ‰€ä»¥testMSEä¼šé™ä½</li>
<li>ä½†æ˜¯è¿‡äº†æŸä¸ªpointä¹‹å,flexçš„æå‡ä¸ä¼šè®©biasæœ‰æ˜æ˜¾çš„é™ä½,ä½†æ˜¯åŒæ—¶varianceå´æé«˜äº†,è¿™æ—¶å€™testMSE
ä¼šæé«˜äº†,æ¢å¥è¯è¯´,è¿‡äº†æŸä¸ªpointä¹‹å,å°±ä¸å®œå†æå‡flexäº†.</li>
<li>æˆ‘ä»¬å†æ¥çœ‹çœ‹å›¾2-12,ä¸€å…±æœ‰ä¸‰å¹…å›¾,ä¸‰ä¸ªcase:
<ul class="org-ul">
<li><p>
å›¾2-12
</p>

<div id="org89f3d95" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/2-12.png" alt="2-12.png" />
</p>
<p><span class="figure-number">Figure 15: </span>isl/2-12.png</p>
</div></li>
<li>æ¯ä¸ªcaseé‡Œ,blueéƒ½ä»£è¡¨squared bias</li>
<li>æ¯ä¸ªcaseé‡Œ,orangeä»£è¡¨variance</li>
<li>æ¯ä¸ªcaseé‡Œ,æ°´å¹³è™šçº¿ä»£è¡¨Var(e), irreducible error</li>
<li>æ¯ä¸ªcaseé‡Œ,redä»£è¡¨test set MSE,æ˜¯è¿™ä¸ªä¸‰ä¸ªå€¼çš„å’Œ</li>
<li>æ¯ä¸ªcaseé‡Œ,flexæå‡ä¼šä¼´éšvarianceçš„æå‡å’Œbiasçš„ä¸‹é™.ä½†æ˜¯varianceå’Œbiasçš„å˜åŒ–é€Ÿç‡æ˜¯ä¸ä¸€æ ·çš„</li>
<li>åœ¨å·¦è¾¹çš„caseé‡Œ,biaså¼€å§‹ä¸‹é™çš„éå¸¸è¿…é€Ÿ,å¯¼è‡´å¼€å§‹testMSEä¸‹é™çš„å¾ˆå‰å®³</li>
<li>åœ¨ä¸­é—´çš„caseé‡Œ,true fæ˜¯linearçš„,æ‰€ä»¥biaså¼€å§‹åªæœ‰æ¯”è¾ƒå°çš„é™å¹…(éšç€flexçš„æé«˜),è€ŒtestMSEå°±é™ä½
çš„å¾ˆå°äº†,åé¢è¿‡äº†æŸä¸ªpoint,éšç€varianceçš„æå‡,testMSEä¹Ÿå·¨å¹…æå‡</li>
<li>åœ¨å³è¾¹çš„caseé‡Œé¢,true fæ˜¯non-linearçš„, æ‰€ä»¥biaså¼€å§‹å°± å·¨å¹…é™ä½(éšç€flexçš„æé«˜),è€ŒåŒæ—¶variance
åªæœ‰å°å¹…æå‡,æ‰€ä»¥testMSEå¼€å§‹æ˜¯å·¨å¹…é™ä½.åé¢è¿‡äº†æŸä¸ªpointä¹‹å,ä¹Ÿæ˜¯å°å¹…æå‡</li>
<li>å›¾2-12é‡Œé¢ä»‹ç»çš„bias,variance,testMSEçš„å…³ç³»å«åšbias-variance trade-off</li>
</ul></li>
<li>æ—¢ç„¶å«trade-off,é‚£ä¹ˆå¿…ç„¶å¯ä»¥æœ‰ç®€å•çš„ä¸€è¾¹å€’çš„é€‰æ‹©:
<ul class="org-ul">
<li>éå¸¸ä½çš„bias,ä½†æ˜¯éå¸¸é«˜çš„variance: æ¯”å¦‚ç”»ä¸€æ¡çº¿,é€šè¿‡æ¯ä¸ªtraining dataçš„point</li>
<li>éå¸¸é«˜çš„bias,ä½†æ˜¯éå¸¸ä½çš„variance: æ¯”å¦‚ç”»ä¸€æ¡æ°´å¹³çº¿</li>
<li>æŒ‘æˆ˜åœ¨äºæ‰¾åˆ°ä¸€ä¸ªpoint,ç›¸å¯¹æ¥è¯´varianceå’Œbiaséƒ½ä½,è·å¾—æœ€ä½çš„testMSE</li>
</ul></li>
<li>æ—¥å¸¸ç”Ÿæ´»ä¸­,fæ˜¯æ— æ³•è§‚æµ‹åˆ°çš„, testMSE,bias,varianceä¹Ÿæ˜¯æ— æ³•è®¡ç®—çš„,ä½†æ˜¯,æˆ‘ä»¬è¦ä¸€ç›´åœ¨å¿ƒä¸­è°¨è®°
bias-variance trade-off:
<ul class="org-ul">
<li>æœ¬ä¹¦ä¼šä»‹ç»å¾ˆå¤šæè‡´flexibleçš„method,ä»–ä»¬çš„biaséå¸¸çš„ä½,ä½†æ˜¯è¿™ä¸ªmethoå´å¹¶ä¸ä¸€å®šèƒ½å¤Ÿæ‰“è´¥
ä¸€äº›æ¯”è¾ƒç®€å•çš„æ¨¡å‹,æ¯”å¦‚linear regression. ä¸¾ä¸ªç®€å•çš„ä¾‹å­: æˆ‘ä»¬çš„true få°±æ˜¯linearçš„,åœ¨
è¿™ç§æƒ…å†µä¸‹,æ¨¡å‹linear regressionå°±æ²¡æœ‰bias,é‚£ä¹ˆå…¶ä»–çš„æ›´åŠ flexibleçš„methodæ˜¯å¾ˆéš¾ç«äº‰çš„</li>
<li>å½“ç„¶äº†,å¦‚æœtrue fæ˜¯non-linearçš„è¯,å¹¶ä¸”inputsè¶³å¤Ÿçš„å¤š, highly flexible approachè‚¯å®šæ˜¯æ›´
ä¼˜çš„é€‰æ‹©</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org1630992" class="outline-4">
<h4 id="org1630992"><span class="section-number-4">2.2.3.</span> The Classification Setting</h4>
<div class="outline-text-4" id="text-2-2-3">
<ul class="org-ul">
<li>ç›®å‰ä¸ºæ­¢,æˆ‘ä»¬å¯¹æ¨¡å‹å‡†ç¡®ç‡çš„è®¨è®ºè¿˜æ˜¯é›†ä¸­åœ¨regression setting,ä½†æ˜¯å¾ˆå¤šæ¦‚å¿µ(å¦‚ä¸‹)éƒ½å¯ä»¥åº”ç”¨åˆ°
classification setting(å½“ç„¶,ç”±äºyiä¸å†æ˜¯numericalçš„äº†,æ‰€ä»¥è¿˜æ˜¯éœ€è¦åšä¸€äº›æ”¹åŠ¨):
<ul class="org-ul">
<li>bias-variance trade-off</li>
</ul></li>
<li><p>
æ¯”å¦‚å¯¹äºclassificationæ¥è¯´,{(x1,y1),&#x2026;,(xn,yn)}é‡Œé¢,y1&#x2026;ynéƒ½æ˜¯qualitativeçš„äº†,åœ¨classification
çš„æƒ…å½¢ä¸‹,è¯„åˆ¤æ¨¡å‹å‡†ç¡®ç‡(accuracy of our estimate f^)çš„æ–¹æ³•æ˜¯training error rate:
</p>
\begin{equation}
\cfrac{1}{n}\displaystyle\sum_{i=1}^n{I(y_i \ne \hat{y_i})},\tag{2.8}
\end{equation}</li>
<li>è§£é‡Šä¸‹ä¸Šé¢çš„å…¬å¼2-8:
<ul class="org-ul">
<li>\(\hat{y_i}\) æ˜¯å¯¹iä¸ªobservationåšå‡ºçš„predicted label</li>
<li>å¦‚æœ \(y_i = \hat{y_i}\) ,ä¹Ÿå°±æ˜¯é¢„æµ‹å‡†ç¡®äº†, \(I(y_i \ne \hat{y_i})\) å°±ä¸º0</li>
<li>å¦‚æœ \(y_i \ne \hat{y_i}\),ä¹Ÿå°±æ˜¯é¢„æµ‹é”™è¯¯äº†, \(I(y_i \ne \hat{y_i})\) å°±ä¸º1</li>
</ul></li>
<li><p>
å…¬å¼2-8ç”±äºæ˜¯ä½¿ç”¨training dataæ•°æ®è®¡ç®—çš„,æ‰€ä»¥åå­—å«training error rate,ä½†æ˜¯å’Œregressioné—®é¢˜ä¸€æ ·,
classificationé—®é¢˜ä¹Ÿæ¯”è¾ƒå…³æ³¨test error rate,è¿™ä¹Ÿå°±å¼•å…¥äº†å…¬å¼2-9:
</p>
\begin{equation}
Ave(I(y_0 \ne \hat{y_0})),\tag{2.9}
\end{equation}</li>
<li>è§£é‡Šä¸‹å…¬å¼2-9:
<ul class="org-ul">
<li>\(y_0\) æ˜¯ä¸ºtest observation predictor: \(x_0\) åšå‡ºçš„é¢„æµ‹,æ³¨æ„è¿™æ˜¯æµ‹è¯•æ•°æ®,ä¸æ˜¯trainingæ•°æ®</li>
<li>ä¸€ä¸ªå¥½çš„classifier(æ¨¡å‹)çš„ç‰¹ç‚¹,å°±æ˜¯æ‹¥æœ‰æ¯”è¾ƒå°çš„test error</li>
</ul></li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgfa4056a"></a>The Bayes Classifier<br />
<div class="outline-text-5" id="text-2-2-3-1">
<ul class="org-ul">
<li>è™½ç„¶å®šç†çš„è¯æ˜å·²ç»è¶…å‡ºäº†æœ¬ä¹¦çš„èŒƒç•´,ä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯å¯ä»¥ç›´æ¥æŠ›å‡ºç»“è®º:
<ul class="org-ul">
<li>å…¬å¼2-9åˆ—å‡ºçš„test error rate,æƒ³è¦è·å¾—å¹³å‡æƒ…å†µä¸‹çš„æœ€å°å€¼,åªéœ€è¦æ ¹æ®inputçš„valueçš„ä¸åŒ,
é€‰æ‹©ç»™æ¯ä¸ªobservationä¸€ä¸ªæœ€å¯èƒ½çš„class.</li>
<li><p>
æ¢å¥è¯è¯´å°±æ˜¯:å…¨å±€(å¹³å‡)çš„æœ€å°å€¼çš„è·å¾—,å¯ä»¥åˆ†è§£ä¸º,æ¯ä¸ªæˆå‘˜é€‰æ‹©å¯¹è‡ªå·±æ¥è¯´çš„æœ€ä¼˜é€‰æ‹©å°±å¯ä»¥.
</p>
<pre class="example" id="org1e64a21">
The test error rate given in (2.9) is minimized, on average, by a very simple classifier
that assigns each observation to the most likely class,given it predictor value
</pre></li>
<li><p>
å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªinput \(x_0\) , å¯¹äºè¿™ä¸ªinput \(x_0\) , yæ˜¯class jçš„æ¦‚ç‡æœ€å¤§,é‚£ä¹ˆæˆ‘ä»¬å°±èµ‹äºˆyä¸ºclass j,
å¦‚ä¸‹å…¬å¼2-10è¡¨ç¤º"å¯¹äºè¿™ä¸ªinput x0, yæ˜¯class jçš„æ¦‚ç‡"
</p>
\begin{equation}
Pr(Y = j | X= x_0)\tag{2.10}
\end{equation}</li>
<li>ä¸Šé¢çš„å…¬å¼2-10ç±»åˆ«å«åšconditional probability,ä¹Ÿå°±æ˜¯input ä¸º \(x_0\) æƒ…å†µä¸‹(ä¹Ÿå°±æ˜¯sample space
æ˜¯è¾“å…¥ä¸º \(x_0\) çš„æƒ…å†µä¸‹)çš„æ¦‚ç‡</li>
<li>ä¸Šé¢çš„è¿™ç§classifierå°±æ˜¯è´å¶æ–¯åˆ†ç±»å™¨</li>
</ul></li>
<li>å¯¹äºè´å¶æ–¯åˆ†ç±»å™¨,æˆ‘ä»¬ä»¥åªæœ‰ä¸¤ç§å¯èƒ½çš„responseå€¼,æ¯”å¦‚class1,å’Œclass2:
<ul class="org-ul">
<li>æˆ‘ä»¬å…ˆè®¡ç®—ä¸€ä¸ªæ¨¡å‹</li>
<li>æ¨¡å‹è®¡ç®—å¥½ä¹‹å,è¦ç”¨æ¥å¯¹æ–°çš„æ²¡è§è¿‡çš„ \(x_0\) è¿›è¡Œé¢„æµ‹,æ¨¡å‹é¢„æµ‹çš„ç»“æœ:
<ol class="org-ol">
<li>å¦‚æœ \(Pr(Y = j | X= x_0)\tag{2.10} > 0.5\) é‚£ä¹ˆå°±é€‰æ‹©class1</li>
<li>å¦‚æœ \(Pr(Y = j | X= x_0)\tag{2.10} <= 0.5\) é‚£ä¹ˆå°±é€‰æ‹©class2</li>
</ol></li>
</ul></li>
<li>ä¸‹é¢æ˜¯ä¸€ä¸ªè´å¶æ–¯åˆ†ç±»å™¨çš„ä¾‹å­:
<ul class="org-ul">
<li>å›¾2-13</li>
<li>æ©™è‰²çš„ç‚¹ä»£è¡¨ \(Pr(Y=orange|X) > 0.5\)</li>
<li>è“è‰²çš„ç‚¹ä»£è¡¨ \(Pr(Y=blue|X) > 0.5\)</li>
<li>ç´«è‰²çš„çº¿ä»£è¡¨æ¦‚ç‡å°±æ˜¯50%çš„çº¿,å«åšBayes decision boundary</li>
</ul></li>
</ul>
</div>
</li>
<li><a id="org5d63bed"></a>K-Nearest Neighbors<br />
<div class="outline-text-5" id="text-2-2-3-2">
<ul class="org-ul">
<li>ç†è®ºä¸Šæ¥è¯´,æˆ‘ä»¬åº”è¯¥ä¸€ç›´ä½¿ç”¨è´å¶æ–¯åˆ†ç±»å™¨,ä½†æ˜¯å®é™…æƒ…å†µæ˜¯,æˆ‘ä»¬ä¸çŸ¥é“æŸä¸ªobservation(X)å±äºå“ªä¸ªç±»
åˆ«(Y),è¿™ç§æƒ…å†µä¸‹,æ˜¯æ— æ³•ä½¿ç”¨è´å¶æ–¯åˆ†ç±»å™¨çš„</li>
<li><p>
æ¢å¥è¯è¯´,æˆ‘ä»¬çš„trainingæ•°æ®æ— æ³•çŸ¥é“å¦‚ä¸‹æ¦‚ç‡çš„å‡†ç¡®å€¼, ä¹Ÿå°±æ— æ³•æ¯”è¾ƒä¸åŒæ¦‚ç‡çš„å¤§å°,ä¹Ÿå°±æ— æ³•ä½¿ç”¨è´å¶æ–¯åˆ†ç±»
</p>
\begin{equation}
Pr(Y = j | X = x_i)
\end{equation}</li>
<li>å¾ˆå¤šåˆ†ç±»æ–¹æ³•çš„é‡ç‚¹,å°±æ˜¯ä½¿ç”¨å„ç§æ–¹æ³•æ¥å¾—å‡ºæ•°æ®åŒ–çš„ \(Pr(Y = j | X = x_i)\), ç„¶åé‚£ä¸ªç±»åˆ«çš„æ¦‚ç‡å¤§
å°±é€‰å“ªä¸ªæ¦‚ç‡. KNN(K-nearest neighbors)å°±æ˜¯è¿™ç§åˆ†ç±»æ–¹æ³•</li>
<li>KNNçš„è®¡ç®—æ–¹æ³•å¦‚ä¸‹:
<ul class="org-ul">
<li>ç»™å®šä¸€ä¸ªæ­£æ•´æ•°K,å’Œä¸€ä¸ªtest observation \(x_0\)</li>
<li>KNNåˆ†ç±»é¦–å…ˆæŸ¥æ‰¾ \(x_0\) é™„è¿‘çš„æœ€å¤šKä¸ª(ä½¿ç”¨ \(N_0\) )</li>
<li><p>
æœ€é‡è¦çš„ä¸€æ­¥æ¥äº†,KNNè®¡ç®—ç±»åˆ«j,åœ¨å…¨éƒ¨ \(N_0\) ä¸ªç‚¹ä¸­çš„ä¸ªæ•°. é™¤ä»¥Kå°±å¯ä»¥å¾—åˆ° \(x_0\) å±äºç±»åˆ«jçš„æ¦‚ç‡äº†
</p>
\begin{equation}
Pr(Y = j | X = x_0) = \frac{1}{K}\sum_{i \in N_0}I(y_i = j)\tag{2.12}
\end{equation}</li>
<li>æœ€åå–æ¦‚ç‡æœ€å¤§çš„ç±»å‹,å°±æ˜¯æˆ‘ä»¬ç”¨KNNå¾—åˆ°çš„åˆ†ç±»ç»“æœ</li>
</ul></li>
<li>è™½ç„¶KNNåªæ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„åˆ†ç±»å™¨,KNNå´ç»å¸¸èƒ½äº§ç”Ÿéå¸¸ä¼˜å¼‚çš„åˆ†ç±»ç»“æœ(é”™è¯¯ç‡é€¼è¿‘è´å¶æ–¯åˆ†ç±»):
<ul class="org-ul">
<li>å›¾2-15</li>
<li>K=10æƒ…å†µä¸‹, KNNçš„test erroræ˜¯0.1363</li>
<li>è´å¶æ–¯åˆ†ç±»çš„test erroræ˜¯0.1304</li>
</ul></li>
<li>KNNä¸­Kçš„å¤§å°çš„é€‰æ‹©ä¼šå¯¹ç»“æœæœ‰éå¸¸å¤§çš„æ”¹å˜:
<ul class="org-ul">
<li>å›¾2-16</li>
<li>ç´«è‰²çš„æ˜¯Bayes decision boundary</li>
<li>K = 1çš„æ—¶å€™, decision boundaryéå¸¸çš„flexible, è¿™å¯¹åº”é‚£ç§low bias, ä½†æ˜¯high varianceçš„åˆ†ç±»å™¨</li>
<li>éšç€Kçš„å¢åŠ , è¿™ä¸ªmethodä¼šè¶Šæ¥è¶Šinflexible,å¹¶ä¸”äº§ç”Ÿçš„decision boundaryè¶‹è¿‘äºç›´çº¿</li>
<li>K = 100çš„æ—¶å€™, decision boundaryéå¸¸çš„inflexible, è¿™å¯¹åº”é‚£ç§high bias, ä½†æ˜¯low varianceçš„åˆ†ç±»å™¨</li>
<li>K = 1çš„test errorä¸º0.1695,ä¸æ˜¯æœ€ä½³(æœ€ä½³ä¸ºK=10, test error 0.1363)</li>
<li>K = 100çš„test errorä¸º0.1925,ä¸æ˜¯æœ€ä½³(æœ€ä½³ä¸ºK=10, test error 0.1363)</li>
</ul></li>
<li>å’Œregressionä¸­ä¸€æ ·,å¦‚ä¸‹ä¸¤ä¸ªè®¾ç½®æ²¡æœ‰ä¸¥æ ¼çš„relationship:
<ul class="org-ul">
<li>training error rate</li>
<li>test error rate</li>
</ul></li>
<li>æ¯”å¦‚K=1çš„æƒ…å†µä¸‹,KNN traning error rateæ˜¯0, ä½†æ˜¯test error rateå¯èƒ½éå¸¸çš„é«˜</li>
<li>æ€»ä½“æ¥è¯´,éšç€flexibleçš„æå‡:
<ul class="org-ul">
<li>training error rateä¼šé™ä½</li>
<li>ä½†æ˜¯test error rate ä¸ä¸€å®š</li>
</ul></li>
<li>ä¸‹é¢æ˜¯1/K(æ³¨æ„,ä¸æ˜¯K)å’Œtraining error rate, test error rateä¹‹é—´çš„å…³ç³»:
<ul class="org-ul">
<li>å›¾2-17</li>
<li>éšç€1/Kçš„å¢åŠ , training error rateé€æ¸é™ä½(å½“K=1, 1/K=1çš„æ—¶å€™, training error rateå˜æˆäº†0)</li>
<li>éšç€1/Kçš„å¢åŠ , test error rateå…ˆé™ä½å†å‡é«˜,å‘ˆç°U-shape,åœ¨K=10dçš„æ—¶å€™,è¾¾åˆ°æœ€å°å€¼</li>
</ul></li>
<li>æ— è®ºæ˜¯regressionè¿˜æ˜¯classification,é€‰æ‹©æ­£ç¡®çš„level of flexibility(ä¹Ÿå°±æ˜¯bias-variance tradeoff)éå¸¸é‡è¦</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org0260ce2" class="outline-2">
<h2 id="org0260ce2"><span class="section-number-2">3.</span> Chapter 3: Linear Regression</h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li>çº¿æ€§æ¨¡å‹æ˜¯ä¸€ç§åœ¨ç›‘ç£å­¦ä¹ ä¸­éå¸¸ç®€å•çš„æ¨¡å‹,å¯¹äºé¢„æµ‹quantitative responseéå¸¸æœ‰ç”¨</li>
<li>è™½ç„¶çº¿æ€§æ¨¡å‹å’Œå…¶ä»–ç°ä»£çš„ç»Ÿè®¡å­¦ä¹ æ–¹æ³•å…ˆæ¯”,çœ‹èµ·æ¥æœ‰ç‚¹å‘†æ¿,çº¿æ€§æ¨¡å‹ä¾ç„¶éå¸¸æœ‰ç”¨å¹¶ä¸”å¹¿æ³›è¢«ä½¿ç”¨</li>
<li>å¾ˆå¤šfancyçš„ç»Ÿè®¡å­¦ä¹ æ–¹æ³•éƒ½å¯ä»¥çœ‹åšæ˜¯linear regressionçš„æ€»ç»“å’Œæ‰©å±•</li>
<li>æœ¬ç« æˆ‘ä»¬ä¼šè®²è§£:
<ul class="org-ul">
<li>linear regressionèƒŒåçš„key idea</li>
<li>ä¸ºäº†fit linear regression,æˆ‘ä»¬æ‰€ç”¨åˆ°çš„least squares approach</li>
</ul></li>
<li>å›æƒ³ä¸‹æˆ‘ä»¬åœ¨chapter2çš„å›¾2-1ä¸­ä»‹ç»çš„Advertising Data: salesä½œä¸ºYçš„æƒ…å†µä¸‹,å¦‚ä¸‹ä¸‰ä¸ªå‚æ•°åˆ†åˆ«ä½œä¸ºX:
<ul class="org-ul">
<li>advertising budget in TV</li>
<li>advertising budget in radio</li>
<li>advertising budget in newspaper</li>
</ul></li>
<li>å¦‚æœæˆ‘ä»¬ä½œä¸ºç»Ÿè®¡åˆ†æå¸ˆè¢«é—®åŠæ ¹æ®è¿™ä¸ªæ•°æ®æˆ‘ä»¬å¯¹ä¸‹ä¸€ä¸ªè´¢å¹´çš„marketing plan(ä¸ºäº†æé«˜sales)æœ‰ä»€ä¹ˆè®¡
åˆ’çš„æ—¶å€™,æˆ‘ä»¬è¯¥æ€ä¹ˆå›ç­”</li>
<li>ä¸ºäº†å›ç­”å¥½è¿™ä¸ªé—®é¢˜,æˆ‘ä»¬éœ€è¦å“ªäº›é‡è¦çš„ä¿¡æ¯?</li>
<li>ä¸ºäº†å›ç­”å¥½è¿™ä¸ªé—®é¢˜,ä½ å¯èƒ½éœ€è¦å›ç­”å¥½å¦‚ä¸‹è¿™äº›é—®é¢˜:
<ol class="org-ol">
<li>å¹¿å‘Šbudgetå’Œsalesä¹‹é—´,æ˜¯å¦å­˜åœ¨ç€relationship?
æˆ‘ä»¬ç¬¬ä¸€ä¸ªç›®çš„è‚¯å®šæ˜¯è¦æ¥åˆ¤æ–­,æ˜¯å¦åœ¨advertisingå’Œsalesä¹‹é—´,å­˜åœ¨ç€association.è€Œä¸”è¿™ä¸ª
associationå¿…é¡»è¦æœ‰,è€Œä¸”è¯æ˜associationå­˜åœ¨çš„è¯æ®è¦æ˜æ˜¾,å¦åˆ™å®¢æˆ·å¯èƒ½è§‰å¾—æˆ‘æ²¡å¿…è¦æŠ•å…¥å¹¿å‘Šäº†</li>
<li>è§£å†³äº†æ˜¯å¦æœ‰associationçš„é—®é¢˜ä¹‹å,ä¸‹ä¸€ä¸ªé—®é¢˜æ˜¯ad budgetå’Œsalesä¹‹é—´çš„relationshipæ˜¯å¦å¼º?
å¼ºçš„relationionshipæ„å‘³ç€"å¯é¢„æµ‹æ€§å¼º",æ¢å¥è¯è¯´,ä¸€æ—¦ç»™äº†ä¸€äº›advertising budget,æˆ‘å°±èƒ½é«˜ç²¾åº¦çš„é¢„æµ‹
å‡ºsales,è¿™å«relationshipå¼º.å¦‚æœé¢„æµ‹çš„salesç»“æœéå¸¸ä¸å‡†ç¡®,é‚£å°±æ˜¯å¯é¢„æµ‹æ€§å¼±</li>
<li>ä¸‹é¢è§£å†³å“ªä¸ªåª’ä½“å¯¹æœ€åçš„salesæœ‰è´¡çŒ®?
æ˜¯å¦æ‰€æœ‰çš„mediaéƒ½å¯¹salesæœ‰è´¡çŒ®,è¿˜æ˜¯åªæ˜¯å…¶ä¸­çš„ä¸€ä¸¤ä¸ªæœ‰è´¡çŒ®?ä¸ºäº†å›ç­”è¿™ä¸ªé—®é¢˜,æˆ‘ä»¬è¦æŠŠæ¯ä¸ªåª’ä½“çš„
å¯¹salesçš„å½±å“ç»™ç‹¬ç«‹å‡ºæ¥</li>
<li>æˆ‘ä»¬å¯¹æŸä¸ªåª’ä½“å•ç‹¬å¯¹salesçš„å½±å“çš„ä¼°ç®—,å‡†ç¡®åº¦æ˜¯å¤šå°‘?
åœ¨æ¯ç§åª’ä½“ä¸Šé¢èŠ±ä¸€ç¾å…ƒ,èƒ½å¾—åˆ°å¤šå°‘salesçš„æå‡?è¿™ä¸ªæå‡çš„ä¼°è®¡èƒ½ç²¾ç¡®åˆ°ä»€ä¹ˆé‡çº§</li>
<li>æˆ‘ä»¬èƒ½å¯¹æœªæ¥çš„é”€é‡åšå¤šå‡†ç¡®çš„é¢„æµ‹?
ä¸€æ—¦ç¡®å®šäº†ä¸‰ä¸ªåª’ä½“å¹¿å‘Šè´¹çš„æ¯”ä¾‹å’Œæ•°ç›®,æˆ‘ä»¬èƒ½å¤Ÿé¢„æµ‹æœ€åçš„salesä¹ˆ,æˆ‘ä»¬çš„é¢„æµ‹å‡†ç¡®åº¦æ˜¯å¤šå°‘</li>
<li>ä»–ä»¬çš„relationshipæ˜¯linearçš„ä¹ˆ?
å¦‚æœä¸åŒåª’ä½“çš„ad budgetå’Œsalesæ˜¯çº¿æ€§å…³ç³»çš„,é‚£ä¹ˆæˆ‘ä»¬å°±ä½¿ç”¨linear regressionä½œä¸ºå·¥å…·,å¦åˆ™,æˆ‘ä»¬
å¯èƒ½è¦å¯¹predictoræˆ–è€…responseåšäº›è½¬æ¢,æœ€ç»ˆè®©ä»–ä»¬å¯ä»¥ä½¿ç”¨linear regression</li>
<li>ä¸åŒçš„å¹¿å‘Šåª’ä½“ä¹‹é—´,æ˜¯å¦æœ‰ååŒä½œç”¨(synergy effect)?
æœ‰ä¸€ç§å«åšsynergy effect(åœ¨statisticsé‡Œé¢å«åšinteraction effect)çš„ç°è±¡,å°±æ˜¯ä¸¤ç§å¹¿å‘Šé…åˆèµ·æ¥æ•ˆ
æœæ›´å¥½,æ¯”å¦‚:
<ul class="org-ul">
<li>æ•ˆæœæ›´å¥½çš„é€‰æ‹©:èŠ±5ä¸‡ç¾å…ƒåœ¨tv,å¦å¤–èŠ±5ä¸‡ç¾å…ƒåœ¨radio</li>
<li>æ•ˆæœä¸å¦‚ä¸Šé¢å¥½çš„é€‰æ‹©:æŠŠ10ä¸‡ç¾å…ƒéƒ½èŠ±è´¹åœ¨tv</li>
</ul></li>
</ol></li>
<li>linear regressionå¯ä»¥ç”¨æ¥å›ç­”ä¸Šé¢çš„æ‰€æœ‰é—®é¢˜,æˆ‘ä»¬å…ˆå¤§ä½“ä¸Šå›å¤ä¸‹ä¸Šé¢çš„é—®é¢˜,ç„¶åä¼šåœ¨3.4éƒ¨åˆ†è¯¦ç»†è§£é‡Š</li>
</ul>
</div>
<div id="outline-container-org8a47d5c" class="outline-3">
<h3 id="org8a47d5c"><span class="section-number-3">3.1.</span> Simple Linear Regression</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li>Simple Linear Regressionæ˜¯éå¸¸ç®€å•çš„ä¸€ç§é¢„æµ‹å·¥å…·:
<ul class="org-ul">
<li>é¢„æµ‹ä¸€ä¸ªquantitative response Y</li>
<li>æ ¹æ®ä¸€ä¸ª(ä¸”ä»…æœ‰ä¸€ä¸ª)predictor variable X</li>
</ul></li>
<li><p>
æ¢å¥è¯è¯´,simple linear regressionè®¤ä¸ºYå’ŒXä¹‹é—´approximatelyæœ‰çº¿æ€§å…³ç³»,è¿™ä¸ªçº¿æ€§å…³ç³»ä½¿ç”¨æ•°å­¦çš„å†™æ³•å¦‚ä¸‹
</p>
\begin{equation}
Y \thickapprox \beta_0 + \beta_1X,\tag{3.1}
\end{equation}</li>
<li><p>
æˆ‘ä»¬ç§°ä¹‹ä¸ºåœ¨Xä¸Šå›å½’Y
</p>
<pre class="example" id="org19b3c08">
We are regressing Y on X
</pre></li>
<li>ä¸Šé¢çš„å…¬å¼ä¸­,\(\beta_0\) å’Œ \(\beta_1\) éƒ½æ˜¯æœªçŸ¥çš„å¸¸é‡,å…¶ä¸­:
<ul class="org-ul">
<li>\(\beta_0\) ä»£è¡¨æˆªè·</li>
<li>\(\beta_1\) æ–œç‡</li>
<li>\(\beta_0\) å’Œ \(\beta_1\) éƒ½å«åšæ¨¡å‹çš„ååŒå› ç´ (coefficient)æˆ–è€…æ˜¯parameter</li>
</ul></li>
<li>\(\beta_0\) å’Œ \(\beta_1\) éƒ½æ˜¯unknownçš„,æˆ‘ä»¬é€šè¿‡æˆ‘ä»¬çš„training dataè·å¾—çš„æ˜¯:
<ul class="org-ul">
<li>å¯¹äº \(\beta_0\) çš„estimate \(\hat{\beta_0}\)</li>
<li>å¯¹äº \(\beta_1\) çš„estimate \(\hat{\beta_1}\)</li>
<li><p>
æ‹¥æœ‰äº† \(\hat{\beta_0}\) å’Œ \(\hat{\beta_1}\) ä¹‹å,æˆ‘ä»¬é¢å¯¹æ–°çš„è¾“å…¥x,æ±‚å…¶estimate y(ä¹Ÿå°±æ˜¯ \(\hat{y}\) )
çš„æ—¶å€™,å¯ä»¥ä½¿ç”¨å¦‚ä¸‹çš„å…¬å¼
</p>
\begin{equation}
\hat{y} = \hat{\beta_0} + \hat{\beta_1}x,\tag{3.2}
\end{equation}</li>
</ul></li>
<li>è¿™é‡Œçš„æˆ‘ä»¬ä½¿ç”¨äº†hat symbol (^):
<ul class="org-ul">
<li>å¦‚æœæ˜¯coefficientä½¿ç”¨hat symbol,é‚£ä¹ˆå°±æ˜¯ä»£è¡¨estimated coeficient,æ¯”å¦‚\(\beta_0\) å’Œ\(\beta_1\)</li>
<li>å¦‚æœæ˜¯responseä½¿ç”¨æ¥hat symbol,é‚£ä¹ˆå°±æ˜¯ä»£è¡¨predicted value, æ¯”å¦‚ \(\hat{y}\)</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org849aad2" class="outline-4">
<h4 id="org849aad2"><span class="section-number-4">3.1.1.</span> Estimating the Coefficients</h4>
<div class="outline-text-4" id="text-3-1-1">
<ul class="org-ul">
<li>å®è·µå½“ä¸­,å¦‚æœæƒ³è¦è·å¾—coefficient( \(\beta_0, \beta_1\) )æ‰èƒ½åšå‡ºprediction</li>
<li><p>
è·å–coefficientçš„æ–¹æ³•æ˜¯é€šè¿‡å¦‚ä¸‹æ•°æ®ä¼°ç®—:æ¯ä¸ªæ•°æ®éƒ½æ˜¯å¯¹Xæˆ–è€…Yçš„ä¸€æ¬¡measurement,ä¹Ÿå°±æ˜¯ä¸€ä¸ªinput
å’Œoutputçš„pair
</p>
<pre class="example" id="org82bbf25">
(x1,y1),(x2,y2),...,(xn,yn)
</pre></li>
<li>åœ¨Advertising dataä¾‹å­ä¸­,è¿™ä¸ªxn,ynçš„æ•°æ®å°±æ˜¯200ä¸ªç‚¹(åœ¨äºŒç»´åæ ‡é‡Œé¢),æˆ‘ä»¬è¦æ±‚å‡ºæ¥ä¸€ä¸ª( \(\beta_0, \beta_1\) )çš„ç»„
åˆ,ä¹Ÿå°±å®šä¹‰äº†ä¸€æ¡çº¿.</li>
<li>è¿™æ¡çº¿ä¸æ˜¯éšä¾¿å®šä¹‰çš„,å®ƒè¦èƒ½å¤Ÿå°½å¯èƒ½çš„(æ€»ä½“æ¥è¯´)æ›´é è¿‘è¿™200ä¸ªç‚¹.æƒ³è¦åšåˆ°è¿™ä¸€ç‚¹,æˆ‘ä»¬è¦å°½å¯èƒ½çš„ç¼©
å°least squares criterion</li>
<li>æˆ‘ä»¬ä¸‹é¢æ¥ä»‹ç»ä¸‹least sequares criterion
<ul class="org-ul">
<li>å‡è®¾ \(\hat{y} = \hat{\beta_0} + \hat{\beta_1}x\)  ,é‚£ä¹ˆ \(\hat{y}\) å°±æ˜¯æˆ‘ä»¬å¯¹äºxiçš„ä¸€ä¸ªprediction</li>
<li>\(e_i=y_i - \hat{y_i}\) ä»£è¡¨ç¬¬iä¸ªresidual,ä¹Ÿå°±æ˜¯é¢„æµ‹å€¼å’Œè§‚å¯Ÿå€¼ä¹‹é—´çš„å·®è·</li>
<li><p>
æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªRSS(residual sum of squares)
</p>
\begin{equation}
RSS = e_1^2 + e_2^2 + \cdot\cdot\cdot + e_n^2
\end{equation}</li>
<li><p>
RSSç­‰åŒäºå¦‚ä¸‹ä»£ç 
</p>
\begin{equation}
RSS = (y_1 - \hat{\beta_0} - \hat{\beta_1}x_1)^2 + (y_2 - \hat{\beta_0} - \hat{\beta_2}x_2)^2
\cdot\cdot\cdot + (y_n - \hat{\beta_0} - \hat{\beta_n}x_n)^2\tag{3.3}
\end{equation}</li>
<li>least squares approachèƒ½å¤Ÿé€‰æ‹© (\(\beta_0, \beta_1\)),è®©RSSæœ€å°</li>
<li><p>
ä½¿ç”¨å¾®ç§¯åˆ†å,å¾—åˆ°å¦‚ä¸‹å…¬å¼
</p>
\begin{equation}
\begin{split}
\hat{\beta_1} = \cfrac{\sum_{i=1}^n{(x_i-\overline{x})(y_i-\overline{y})}}{\sum_{i=1}^n{(x_i - \overline{x})^2}}, \\
\hat{\beta_0} = \overline{y} - \hat{\beta_1}\overline{x}\tag{3.4} \\
\end{split}
\end{equation}</li>
<li>å…¶ä¸­:
<ol class="org-ol">
<li>\(\overline{y}\) ä¸ºyçš„sample mean</li>
<li>\(\overline{x}\) ä¸ºxçš„sample mean</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org97dd9f3" class="outline-4">
<h4 id="org97dd9f3"><span class="section-number-4">3.1.2.</span> Assessing the Accuracy of the Coefficient Estimates</h4>
<div class="outline-text-4" id="text-3-1-2">
<ul class="org-ul">
<li>ç¬¬äºŒç« æˆ‘ä»¬å­¦è¿‡,Xå’ŒYä¹‹é—´çš„true relationshipå¯ä»¥ä½¿ç”¨  \(Y = f(x) + \varepsilon\) æ¥è¡¨ç¤º,å…¶ä¸­çš„:
<ul class="org-ul">
<li>f(x)æ˜¯æœªçŸ¥çš„</li>
<li>\(\varepsilon\) æ˜¯mean-zero random error term</li>
</ul></li>
<li>åœ¨real applicationä¸­,æˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ç³»åˆ—çš„observations,ä»è¿™äº›observationä¸­:
<ul class="org-ul">
<li>æˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºleast squares line</li>
<li>ä½†æ˜¯çœŸæ­£çš„population regression lineæ˜¯æ— æ³•å¾—åˆ°çš„</li>
</ul></li>
<li>ä¸‹å›¾çš„å³è¾¹,æˆ‘ä»¬ä»åä¸ªä¸åŒçš„data seté‡Œé¢å°±å¯ä»¥è®¡ç®—å‡ºåä¸ªä¸åŒçš„least squares line,ä½†æ˜¯population regression lineå§‹ç»ˆä¸å˜
<ul class="org-ul">
<li><p>
å›¾3-3
</p>

<div id="orgcb47a00" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/3-3.png" alt="3-3.png" />
</p>
<p><span class="figure-number">Figure 16: </span>isl/3-3.png</p>
</div></li>
</ul></li>
<li>å¦‚ä¸‹çš„ä¸¤ä¸ªæ¦‚å¿µéå¸¸è®©äººå›°æƒ‘:
<ul class="org-ul">
<li>population regression line</li>
<li>least squares line</li>
</ul></li>
<li><p>
è¿™ä¸¤ä¸ªæ¦‚å¿µæ¥æºäºstandard statistical approaché‡Œé¢çš„ä¸€ä¸ªç”¨æ³•
</p>
<pre class="example" id="org218b2b6">
ä½¿ç”¨sampleä¿¡æ¯æ¥estimate large populationç‰¹å¾
</pre></li>
<li>æ¯”å¦‚,æˆ‘ä»¬æƒ³äº†è§£populationçš„æŸä¸ªvariable Yçš„å¹³å‡å€¼ \(\mu\):
<ul class="org-ul">
<li>\(\mu\) æ˜¯unknownçš„</li>
<li>ä½†æ˜¯æˆ‘ä»¬å¯ä»¥è§£é™¤åˆ°Yçš„nä¸ªobservation,æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™nä¸ªobservationæ¥estimate \(\mu\)</li>
<li>æ¯”å¦‚æˆ‘ä»¬è®¡ç®—è¿™nä¸ªobservationçš„å¹³å‡å€¼, ä¸€ä¸ªå¯è¡Œçš„æ–¹æ³•æ±‚sample mean \(\hat{\mu}\)(æ¥estimate \(\mu\)):
<ul class="org-ul">
<li>\(\hat{\mu} = \overline{y}\)</li>
<li>å…¶ä¸­,\(\overline{y} = \frac{1}{n}\sum_{i=1}^n\)</li>
</ul></li>
<li><p>
sample meanå’Œpopulation meanè‚¯å®šæ˜¯ä¸ä¸€æ ·çš„,ä½†æ˜¯æ€»ä½“ä¸Šæ¥è¯´,sample meanä¹Ÿèƒ½æä¾›ä¸€ä¸ªå¥½çš„estimate
</p>
<pre class="example" id="orgf438864">
In general the sample mean will provide a good estimate of the population mean
</pre></li>
</ul></li>
<li>æ­£æ˜¯åŸºäºå’Œä¸Šé¢åŒæ ·çš„è€ƒé‡,åœ¨linear regressionä¸­:
<ul class="org-ul">
<li>æœªçŸ¥çš„coefficients \(\beta_0\) å’Œ \(\beta_1\) å®šä¹‰äº†population regression line</li>
<li>æˆ‘ä»¬è¯•å›¾å»å¯»æ‰¾ \(\hat{\beta_0}\) å’Œ \(\hat{\beta_1}\) ,è¿™ä¸¤ä¸ªå‚æ•°å®šä¹‰äº†least squares line</li>
</ul></li>
<li>æˆ‘ä»¬çš„analogyæ˜¯ä¸€ä¸ªæ°å½“çš„ç±»æ¯”,ç†è®ºåŸºç¡€æ¥æºäºbias,æˆ‘ä»¬ç±»æ¯”çš„ä¸¤ä¸ªå¯¹è±¡æ˜¯:
<ul class="org-ul">
<li>linear regression</li>
<li>estimation of the mean of a random variable</li>
</ul></li>
<li>æˆ‘ä»¬ä¹‹æ‰€ä»¥å¯ä»¥ä½¿ç”¨sample mean \(\hat{\mu}\) æ¥estimate \(\mu\),å¹¶ä¸”è¿™ä¸ªestimateè¿˜æ˜¯unbiasd(å…¬å¹³)çš„,
æ˜¯å› ä¸ºä»æœŸæœ›ä¸Šæ¥è¯´,å¹³å‡ä¸‹æ¥æˆ‘ä»¬æœŸæœ› \(\hat{\mu}\) ç­‰äº \(\mu\)</li>
<li>æˆ‘ä»¬æ¥è§£é‡Šä¸‹ä¸Šé¢çš„è¿™å¥è¯,ç±»æ¯”è€…2(estimation of the mean of a random variable):
<ul class="org-ul">
<li>åœ¨æŸä¸ªç‰¹å®šçš„observations(\(y_1,y_2,...y_n\))ä¸Šé¢è®¡ç®—å‡ºæ¥çš„ \(\hat{\mu}\) å¯èƒ½é«˜äº \(\mu\)</li>
<li>åœ¨å¦å¤–ä¸€ä¸ªobservationsä¸Šé¢è®¡ç®—å‡ºæ¥çš„ \(\hat{\mu}\) å¯èƒ½ä½äº \(\mu\)</li>
<li><p>
å¦‚æœæˆ‘ä»¬çš„æœ‰éå¸¸å¤šä¸ªobservation, æ¯æ¬¡æˆ‘ä»¬éƒ½è®¡ç®—æ¥ä¸€ä¸ª \(\hat{\mu_i}\) , è¿™éå¸¸å¤šä¸ª \(\hat{\mu_i}\)
çš„å¹³å‡å€¼,æˆ‘ä»¬å¯ä»¥è®¤ä¸ºç­‰äº \(\mu\)
</p>
<pre class="example" id="orgb5003b2">
If we could average a huge number of estimates of Î¼
obtained from a huge number of sets of observations,
then this average would exactly equal Î¼
</pre></li>
</ul></li>
<li>ä¸€æ—¦æˆ‘ä»¬çš„ç±»æ¯”è€…2æˆç«‹,é‚£ä¹ˆæˆ‘ä»¬çš„ç±»æ¯”è€…1(linear regression)ä¹Ÿèƒ½æˆç«‹:
<ul class="org-ul">
<li>ä»å¤šä¸ªdata seté‡Œé¢è®¡ç®—å¤šä¸ª \(\hat{\beta_0}\) å’Œ \(\hat{\beta_1}\)</li>
<li><p>
æ±‚è¿™å¤šä¸ª \(\hat{\beta_0}\) å’Œ \(\hat{\beta_1}\) çš„å¹³å‡å€¼,é‚£ä¹ˆå¹³å‡å€¼å°±å¯ä»¥è®¤ä¸ºç­‰äº \(\beta_0\) å’Œ \(\beta_1\)
</p>
<pre class="example" id="org540fe66">
If we estimate B0 and B1 on the basis of a particular data set, then
our estimates won't be exactly equalt to B0 and B1.
But if we could average the estimates obtained over a huge number of
data sets, then the average of these estimates would be spot on!
</pre></li>
<li>æˆ‘ä»¬å¯ä»¥æ¥çœ‹çœ‹å›¾3-3çš„å³è¾¹,æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä»ä¸åŒdata setè·å¾—äº†å¾ˆå¤šçš„least squares line,è¿™äº›
lineçš„å¹³å‡å€¼ä¼šå’Œæœ€ç»ˆçš„true population regression lineéå¸¸çš„æ¥è¿‘</li>
</ul></li>
<li>æˆ‘ä»¬å‰é¢è®²åˆ°è¿‡,å¦‚ä¸‹ä¸¤ä¸ªå€¼æ˜¯å¯ä»¥è®¤ä¸ºåŸºæœ¬ç›¸ç­‰çš„:
<ul class="org-ul">
<li>average of \(\hat{\mu}\) over many data sets</li>
<li>true \(\mu\)</li>
</ul></li>
<li>é‚£ä¹ˆå¾ˆè‡ªç„¶çš„,å¦‚æœæˆ‘ä»¬åªæœ‰ä¸€ä¸ªdata sets,é‚£ä¹ˆå¾—åˆ°çš„æŸä¸€ä¸ª \(\hat{\mu}\) è‚¯å®šä¸ç­‰äºtrue \(\mu\) ,è€Œæ˜¯
ä¼šå¤§äºæˆ–è€…å°äºtrue \(\mu\).æ¢å¥è¯è¯´,æˆ‘ä»¬ä¸‹é¢å¼€å§‹è®¨è®ºæŸä¸€ä¸ªsampleè·å¾—çš„ \(\mu\) æœ‰å¤šå‡†ç¡®</li>
<li>ä¸‹é¢çš„é—®é¢˜å°±æ¥åˆ°,æˆ‘ä»¬çš„æŸä¸€ä¸ª \(\hat{\mu}\) çš„è·ç¦»æœ‰å¤šå°‘?
<ul class="org-ul">
<li><p>
æˆ‘ä»¬è®¡ç®—standard error of \(\mu\) (å†™ä½œ \(SE\left(\mu\right)\) æ¥è¯´æ˜è¿™ä¸ªè·ç¦»
</p>
\begin{equation}
Var\left(\hat{\mu}\right) = SE\left(\hat{\mu}\right)^2 = \frac{\sigma^2}{n},\tag{3.7}
\end{equation}</li>
<li><p>
è¿™é‡Œçš„ \(\sigma\) å°±æ˜¯Yä¸­æ¯ä¸ªpopulationçš„æ ‡å‡†æ–¹å·®,ä¹Ÿå°±æ˜¯æˆ‘ä»¬çš„é¢„æµ‹å’Œtrue fçš„å¹³å‡å·®è·,ç”±äºtrue féƒ½æ˜¯çŸ¥é“çš„
æ‰€ä»¥æˆ‘ä»¬çš„ \(\sigma\) ä¹Ÿunknownçš„
</p>
<pre class="example" id="org0b866f6">
æ ‡å‡†æ–¹å·®æ˜¯ä¸€ç»„æ•°å€¼è‡ªå¹³å‡å€¼åˆ†æ•£å¼€æ¥çš„ç¨‹åº¦çš„ä¸€ç§æµ‹é‡è§‚å¿µã€‚ä¸€ä¸ªè¾ƒå¤§çš„æ ‡å‡†å·®ï¼Œ
ä»£è¡¨å¤§éƒ¨åˆ†çš„æ•°å€¼å’Œå…¶å¹³å‡å€¼ä¹‹é—´å·®å¼‚è¾ƒå¤§ï¼›ä¸€ä¸ªè¾ƒå°çš„æ ‡å‡†å·®ï¼Œä»£è¡¨è¿™äº›æ•°å€¼è¾ƒæ¥è¿‘å¹³å‡å€¼ã€‚
</pre></li>
<li>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°standard erroræœ‰ä¸¤ä¸ªå½±å“çš„å› å­:
<ol class="org-ol">
<li>é¦–å…ˆæ˜¯ \(\hat{\mu}\) å’Œ \(\mu\) çš„å¹³å‡å·®è·</li>
<li>æ‹¥æœ‰è¶Šå¤šçš„observation,æˆ‘ä»¬å°±æœ‰è¶Šå°çš„standard error</li>
</ol></li>
</ul></li>
<li>æˆ‘ä»¬ä»¥æŸä¸ªdata set(sample)çš„ \(\mu\) æ¥äº†è§£äº†standard errorçš„æ¦‚å¿µ,ä¸»è¦æ˜¯ä¸ºäº†åº”ç”¨åˆ°æˆ‘ä»¬çš„least square approach
çš„coefficientä¸Šé¢</li>
<li><p>
å’Œå¹³å‡å€¼ \(\mu\) ä¸€æ ·, \(\beta_0\) \(\beta_1\) éƒ½æœ‰standard error,ç»è¿‡ä¸€äº›æ•°å­¦è½¬æ¢,æˆ‘ä»¬å¾—åˆ° \(\beta_0\) \(\beta_1\) çš„è®¡ç®—å…¬å¼
</p>
\begin{equation}
SE\left(\hat{\beta_0}\right)^2 = \sigma^2\left[\frac{1}{n} + \frac{\overline{x}^2}{\sum_{i=1}^n(x_i-\overline{x})^2}\right], \quad \quad\\
SE\left(\hat{\beta_1}\right)^2 = \frac{\sigma^2}{\sum_{i=1}^n(x_i-\overline{x})^2},\\
\tag={3.8}
\end{equation}</li>
<li>æ³¨æ„,è¿™é‡Œçš„ \(\sigma^2\) å°±æ˜¯æˆ‘ä»¬çš„æ¨¡å‹å’Œtrue fä¹‹é—´çš„æœªçŸ¥çš„æ–¹å·®(æ‰€ä»¥ \(\sigma\) ä¹Ÿæ˜¯æœªçŸ¥çš„),ä¹Ÿå¯ä»¥è®°åš \(Var(\varepsilon)\)</li>
<li>ä¸Šé¢ä¸¤ä¸ªå…¬å¼æ­ç¤ºäº†å¦‚ä¸‹ä¸¤ä»¶äº‹:
<ul class="org-ul">
<li>å¯¹äº \(\hat{\beta_0}\) æ¥è¯´,å¦‚æœ \(\overline{x}\) ç­‰äº0çš„è¯, \(SE( \hat{\beta_0})\) å°±ç­‰äº \(SE(\hat{\mu})\)</li>
<li>å¯¹äº \(SE(\hat{\beta_1})\) æ¥è¯´, å¦‚æœ \(x_i\) æ›´åˆ†æ•£çš„è¯,é‚£ä¹ˆæˆ‘ä»¬çš„å€¼è¶Šå°,æ¨¡å‹ä¹Ÿå°±è¶Šå‡†ç¡®, è¿™å¾ˆå¥½ç†è§£,å¦‚æœéƒ½åœ¨ä¸€ä¸ªå¹³å‡å€¼é™„è¿‘,é‚£ä¹ˆå¯èƒ½æ˜¯ä¸€æ¡å¹³çº¿</li>
</ul></li>
<li><p>
å†æ¥è®¨è®ºä¸‹ \(\sigma\) çš„é—®é¢˜,å‰é¢è¯´äº†,è¿™ä¸ª \(\sigma\) ç”±äºæ˜¯æ¨¡å‹å’Œunknown true fä¹‹é—´çš„å·®è·,æ‰€ä»¥å®ƒæœ¬èº«ä¹Ÿæ˜¯unknownçš„.ä½†æ˜¯ä¸ºäº†è®¡ç®—å‡º
\(SE(\hat{\beta_0})\) å’Œ \(SE(\hat{\beta_1})\), ä½ å¿…é¡»è¦èƒ½ç®—å‡º \(\sigma\) æ¥,äºæ˜¯æœ‰äº†ä¸‹é¢çš„estimate \(\sigma\) å…¬å¼ (RSEä»£è¡¨å¯¹ \(\sigma\) çš„estimate,å«åš
residual standard error
</p>
\begin{equation}
RSE = \sqrt{RSS/(n-2)},\tag={3.8}
\end{equation}</li>
<li>ç”±äºæˆ‘ä»¬çš„ \(\sigma\) ä¹Ÿæ˜¯estimateçš„,é‚£ä¹ˆæˆ‘ä»¬è®¡ç®—çš„æ‰€è°“ \(SE(\hat{\beta_1})\) å…¶å®åº”è¯¥å†™ä½œ  \(\hat{SE}(\hat{\beta_1})\), ä½†æ˜¯å®é™…æƒ…å†µä¸‹å°±ä¸ä¼š
å†™é‚£ä¹ˆç»†è‡´äº†,è¿˜æ˜¯å†™ä½œ \(SE(\hat{\beta_1})\)</li>
<li>è´¹äº†é‚£ä¹ˆå¤§åŠ²,æˆ‘ä»¬äº†è§£äº†å¦‚ä½•è®¡ç®— Standard Error(ç‰¹åˆ«æ˜¯åˆ†åˆ«è®¡ç®—äº† \(\beta_0\) å’Œ \(\beta_1\) çš„SE),ä¸»è¦æ˜¯å› ä¸ºStandard Error
æœ‰å…¶ç‰¹æ®Šçš„ä½œç”¨,ç¬¬ä¸€ä¸ªä½œç”¨,å°±æ˜¯è®¡ç®—Confidence interval(ç½®ä¿¡åŒºé—´)</li>
<li><p>
ç»Ÿè®¡å­¦ä¸Šå¸¸ç”¨95%ç½®ä¿¡åº¦åŒºé—´,æ‰€è°“95%ç½®ä¿¡åº¦åŒºé—´,æ˜¯æŒ‡:æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªåŒºé—´çš„æ•°æ®,åœ¨95%çš„æ¦‚ç‡ä¸‹,è¿™ä¸ªåŒºé—´ä¼šåŒ…å«çœŸæ­£çš„,æœªçŸ¥çš„,å‚æ•°çš„å€¼
</p>
<pre class="example" id="org89c8220">
A 95% confidence interval is defined as a range of values such that with
95% probability, the range will contain the true unknown value of the parameter
</pre></li>
<li><p>
åœ¨çº¿æ€§å›å½’ä¸­, \(\beta_1\) çš„95%çš„ç½®ä¿¡åŒºé—´,å®šä¹‰å¦‚ä¸‹:
</p>
\begin{equation}
\left[\hat{\beta_1} - 2\cdot SE(\hat{\beta_1}),\quad \hat{\beta_1} + 2\cdot SE(\hat{\beta_1}) \right],\tag{3.10}
\end{equation}</li>
<li><p>
ç»è¿‡è®¡ç®— \(\beta_1\) çš„95%ç½®ä¿¡åŒºé—´å¦‚ä¸‹:
</p>
<pre class="example" id="org8d6a4cc">
[0.042,0.053]
</pre></li>
<li><p>
ç±»ä¼¼çš„, \(\beta_0\) çš„95%çš„ç½®ä¿¡åŒºé—´,å®šä¹‰å¦‚ä¸‹:
</p>
\begin{equation}
\left[\hat{\beta_0} - 2\cdot SE(\hat{\beta_0}),\quad \hat{\beta_0} + 2\cdot SE(\hat{\beta_0}) \right],\tag{3.11}
\end{equation}</li>
<li><p>
ç»è¿‡è®¡ç®— \(\beta_0\) çš„95%ç½®ä¿¡åŒºé—´å¦‚ä¸‹:
</p>
<pre class="example" id="org301512d">
[6.130,7.935]
</pre></li>
<li><p>
æœ‰äº†è¿™ä¸¤ä¸ªå…¬å¼,æˆ‘ä»¬å°±çŸ¥é“äº†,åœ¨æ²¡æœ‰ä»»ä½•çš„å¹¿å‘ŠæŠ•å…¥çš„æƒ…å†µä¸‹(xä¸º0),å•†å“çš„é”€å”®é‡åœ¨å¦‚ä¸‹åŒºé—´
</p>
<pre class="example" id="org105aeaa">
[6130,7940]
</pre></li>
<li><p>
æ¯å½“æˆ‘ä»¬æŠ•å…¥1000ç¾é‡‘å¹¿å‘Š,é‚£ä¹ˆ,æˆ‘ä»¬çš„é”€é‡æå‡ç©ºé—´ä¸º
</p>
<pre class="example" id="orga8f6da8">
[42, 53]
</pre></li>
<li>é™¤äº†ç½®ä¿¡åŒºé—´ä»¥å¤–,standard errorè¿˜å¯ä»¥ç”¨æ¥å¯¹coefficientåšhypothesis test(å‡è®¾æ£€éªŒ)</li>
<li>å¸¸è§çš„å‡è®¾æ£€éªŒæœ‰:
<ul class="org-ul">
<li><p>
null hypothesis:
</p>
<pre class="example" id="orgc5d791c">
H0: There is not relationship between X and Y
</pre></li>
<li><p>
alternative hypothesis:
</p>
<pre class="example" id="org5c2a433">
Ha: There is some relationship between X and Y
</pre></li>
</ul></li>
<li>åœ¨æ•°å­¦ä¸ŠH0å’ŒH1çš„å®šä¹‰åˆ†åˆ«æ˜¯:
<ul class="org-ul">
<li><p>
null hypothesis: å¦‚æœä¸€æ—¦ \(\beta_1\) ç­‰äº0, é‚£ä¹ˆæˆ‘ä»¬çš„æ¨¡å‹å°±ç®€åŒ–ä¸º \(Y , = \beta_0 + \varepsilon\),
é‚£ä¹ˆæ˜¾ç„¶Xå°±å’ŒYä¸ç›¸å…³äº†
</p>
\begin{equation}
H_0 : \beta_1 = 0,
\end{equation}</li>
<li><p>
alternative hypothesis
</p>
\begin{equation}
H_1 : \beta_1 \not = 0,
\end{equation}</li>
</ul></li>
<li>ä¸ºäº†åˆ¤æ–­åˆ°åº•æ˜¯null hypothesisè¿˜æ˜¯alternative hypothesis,æˆ‘ä»¬éœ€è¦æˆ‘ä»¬çš„ \(\beta_1\) æ˜¯å¦è¶³å¤Ÿè¿œç¦»0,ä¸€æ—¦
è¶³å¤Ÿè¿œç¦»0,æˆ‘ä»¬å°±å¯ä»¥è®¤ä¸º \(\beta_1\) æ˜¯non-zeroçš„</li>
<li>é‚£ä¹ˆ,è¿™ä¸ªè¶³å¤Ÿè¿œæ˜¯å¤šè¿œå‘¢:
<ul class="org-ul">
<li>å¦‚æœ \(SE(\hat{\beta_1})\) è¶³å¤Ÿå°,é‚£ä¹ˆå°±ç®— \(\hat{\beta_1}\) å°ä¸€ç‚¹,ä¹Ÿæ²¡å…³ç³»</li>
<li>å¦‚æœ \(SE(\hat{\beta_1})\) å¤ªå¤§,é‚£ä¹ˆ \(\hat{\beta_1}\) ä¹Ÿå¿…é¡»å¾ˆå¤§,å¦åˆ™\(\hat{\beta_1} - SE(\hat{\beta_1})\)
å°±æœ‰å¯èƒ½æ˜¯0</li>
</ul></li>
<li><p>
æˆ‘ä»¬ä½¿ç”¨t-statisticæ¥è®¡ç®—è¿™ä¸ªè·ç¦»
</p>
\begin{equation}
t = \frac{\hat{\beta_1} - 0}{SE(\hat{\beta_1})},\tag={3.14}
\end{equation}</li>
<li>æˆ‘ä»¬è¿˜ä½¿ç”¨p-valueæ¥è®¡ç®—null hypothesisçš„æ¦‚ç‡:
<ul class="org-ul">
<li>å¦‚æœp-valueè¶³å¤Ÿå°,é‚£ä¹ˆæˆ‘ä»¬å°±è®¤å®špredictorå’Œresponseä¹‹é—´æœ‰å…³ç³»</li>
<li>å¦‚æœp-valueå¤§,é‚£ä¹ˆæˆ‘ä»¬å°±è®¤å®špredictorå’Œresponseä¹‹é—´æ²¡æœ‰å…³ç³»</li>
</ul></li>
<li>p-valueè¶³å¤Ÿå°çš„è¶³å¤Ÿæ˜¯å¤šè¶³å¤Ÿ:
<ul class="org-ul">
<li>5% (å¯¹åº”n=30æƒ…å†µä¸‹çš„t-statistics 2)</li>
<li>1% (å¯¹åº”n=30æƒ…å†µä¸‹çš„t-statistics 2.75)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orge4fd700" class="outline-4">
<h4 id="orge4fd700"><span class="section-number-4">3.1.3.</span> Assessing the Accuracy of the Model</h4>
<div class="outline-text-4" id="text-3-1-3">
<ul class="org-ul">
<li><p>
ä¸€æ—¦æˆ‘ä»¬rejectäº†null hypothesis(é€‰æ‹©äº†alternative hypothesis),é‚£ä¹ˆæˆ‘ä»¬ä¸‹ä¸€æ­¥å°±è¦é‡åŒ–æˆ‘ä»¬çš„model
æœ‰å¤šfitæˆ‘ä»¬çš„data
</p>
<pre class="example" id="orga600e3f">
quantify the extent to which the model fits the data
</pre></li>
<li>å¯¹äºlinear regressionæ¥è¯´,æˆ‘ä»¬é‡åŒ–æ¨¡å‹å¥½è¿˜æ˜¯å·®çš„æ–¹æ³•æœ‰ä¸¤ç§:
<ul class="org-ul">
<li>RSE (residual standard error)</li>
<li>\(R^2\)</li>
</ul></li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org4760ccd"></a>Residual Standard Error<br />
<div class="outline-text-5" id="text-3-1-3-1">
<ul class="org-ul">
<li>æˆ‘ä»¬ä»å…¬å¼3.5( \(Y = \beta_0 + \beta_1X + \varepsilon\))å¯ä»¥çœ‹åˆ°,æ¯ä¸ªobservationéƒ½è¦æœ‰ä¸€ä¸ªerror term \(\varepsilon\)</li>
<li>ç”±äºè¿™ä¸ªerror term \(\varepsilon\) çš„å­˜åœ¨,å³ä¾¿æˆ‘ä»¬çŸ¥é“äº† true \(\beta_0\) å’Œ true \(\beta_1\), æˆ‘ä»¬ä¾ç„¶
æ— æ³•é¢„æµ‹å‡ºå‡†ç¡®çš„Y(å› ä¸º \(\varepsilon\) unknown)</li>
<li><p>
æˆ‘ä»¬è¿™é‡Œçš„RSEå…¶å®å°±æ˜¯æ±‚ \(\varepsilon\) çš„æ ‡å‡†å·®,å‡†ç¡®å®šä¹‰å°±æ˜¯
</p>
<pre class="example" id="orge4715c4">
RSE is the average amount that the response will deviate from the true regression line
</pre></li>
<li><p>
RSEçš„è®¡ç®—å…¬å¼å¦‚ä¸‹
</p>
\begin{equation}
RSE = \sqrt{\frac{1}{n-2}RSS}=\sqrt{\frac{1}{n-2}\displaystyle\sum_{i=1}^n (y_i - \hat{y_i})^2},\tag{3.15}
\end{equation}</li>
<li>åœ¨æˆ‘ä»¬çš„Advertisingä¾‹å­ä¸­,æˆ‘ä»¬çš„RSEæ˜¯3.26,ä¹Ÿå°±æ˜¯è¯´,å³ä¾¿æˆ‘ä»¬çš„modelèƒ½å¤Ÿå¾—åˆ°true \(\beta_0\) å’Œ true \(\beta_1\),
æˆ‘ä»¬çš„é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹Ÿè¦æœ‰å¹³å‡3260çš„å·®è·</li>
<li>å½“ç„¶äº†3260è¿™ä¸ªå·®è·æ˜¯å¦æ˜¯å¯ä»¥æ¥å—çš„,è¦çœ‹å…·ä½“çš„problem context</li>
<li>RSEè¿˜ä¼šè¢«è®¤ä¸ºæ˜¯modelå’Œdataçš„fitç¨‹åº¦çš„è¡¨è¾¾:
<ul class="org-ul">
<li>å¦‚æœä»modelå¾—åˆ°çš„predictionéå¸¸çš„å‡†ç¡®,é‚£ä¹ˆRSEå°±ä¼šå¾ˆå°,æˆ‘ä»¬è®¤ä¸ºmodel fits the data well</li>
<li>å¦‚æœä»modelå¾—åˆ°çš„ \(\hat{y}\) å’Œyå·®è·éå·®å¤§,é‚£ä¹ˆRSEå°±ä¼šéå¸¸å¤§,ä¹Ÿå°±æ„å‘³ç€modelå’Œdata fitçš„ä¸å¤ªå¥½</li>
</ul></li>
</ul>
</div>
</li>
<li><a id="org41774f1"></a>\(R^2\) Statistic<br />
<div class="outline-text-5" id="text-3-1-3-2">
<ul class="org-ul">
<li>RSE æä¾›äº†å’Œmodelçš„å·®è·çš„ç»å¯¹å€¼,ä½†æ˜¯ä»–çš„ç¼ºç‚¹æ˜¯ä»–æ˜¯ä»¥Yä¸ºåº¦é‡å•ä½çš„,å°±ä¸å…éš¾ä»¥ç•Œå®šè¿™ä¸ªRSEæ˜¯å¥½è¿˜æ˜¯å</li>
<li>\(R^2\) statisticå°±ä¸ä¸€æ ·å•¦,å®ƒä½¿ç”¨äº†proportion(èƒ½å¤Ÿè§£é‡Šè‡ªå·±çš„varianceç™¾åˆ†æ¯”),ä¹Ÿå°±æ˜¯è¯´, \(R^2\) statisticæ˜¯ä¸€ä¸ªä»‹äº0å’Œ1ä¹‹é—´çš„æµ®ç‚¹æ•°
å…¶å€¼æ˜¯independent of the scale of Y</li>
<li><p>
ä¸‹é¢æˆ‘ä»¬æ¥çœ‹çœ‹ \(R^2\) çš„è®¡ç®—å…¬å¼
</p>
\begin{equation}
R^2 = \frac{TSS-RSS}{TSS} = 1 - \frac{RSS}{TSS},\tag{3.17}
\end{equation}</li>
<li>è¿™ä¸ªå…¬å¼ä¸­çš„:
<ul class="org-ul">
<li><p>
TSS æ˜¯total sum of squares
</p>
\begin{equation}
TSS = \sum(y_i - \overline{y})^2
\end{equation}</li>
<li><p>
RSS æ˜¯residual sum of squares
</p>
\begin{equation}
RSS = \sum_{i=1}^n(y_i - \hat{y_i})^2
\end{equation}</li>
</ul></li>
<li>TSS åº¦é‡çš„,æ˜¯responseè‡ªå·±çš„å˜åŠ¨(æ–¹å·®), åœ¨regressionå¼•å…¥ä¹‹å‰å°±æœ‰äº†</li>
<li>è€ŒRSSåˆ™æ˜¯åœ¨regressionå¼•å…¥ä¹‹åå¸¦æ¥çš„,æ— æ³•è§£é‡Šçš„(unexplained)çš„variability</li>
<li>æ‰€ä»¥TSS-RSSå°±æ˜¯èƒ½å¤Ÿè§£é‡Šçš„variability</li>
<li>å¯¹äº \(R^2\) çš„å€¼:
<ul class="org-ul">
<li>å¦‚æœæ¥è¿‘1,é‚£ä¹ˆè¯´æ˜å¤§éƒ¨åˆ†çš„responseä¸­çš„variabilityéƒ½è¢«è§£é‡Šäº†</li>
<li>å¦‚æœæ¥è¿‘0,é‚£ä¹ˆè¯´æ˜å¤§éƒ¨åˆ†çš„responseä¸­çš„variabilityéƒ½æ²¡æœ‰è¢«è§£é‡Š,è¿™å¯èƒ½å‡ºç°åœ¨linear modelé”™è¯¯çš„æƒ…å†µä¸‹(æˆ–è€…è‡ªå¸¦çš„ error \(\sigma^2\) å¤ªé«˜</li>
</ul></li>
<li>æˆ‘ä»¬çš„Advertising ä¾‹å­ä¸­çš„ \(R^2\) å€¼ä¸º0.61,ä¹Ÿå°±æ˜¯è¯´ä¸‰åˆ†ä¹‹äºŒçš„variabilityéƒ½å·²ç»è¢«è§£é‡Šäº†</li>
<li>\(R^2\) statistic å¯¹æ¯”RSE,æ‹¥æœ‰å®¹æ˜“è§£é‡Šè¿™ä¸ªä¼˜åŠ¿,å› ä¸ºä¸åƒRSE, \(R^2\) ä¸€ç›´èƒ½å¤Ÿåœ¨0å’Œ1ä¹‹é—´</li>
<li>è™½ç„¶ \(R^2\) statistic æ€»æ˜¯åœ¨[0,1]ä¹‹é—´,ä½†æ˜¯åˆ¤æ–­ä»€ä¹ˆæ˜¯å¥½çš„ \(R^2\) valueæ˜¯éå¸¸ä¸å®¹æ˜“çš„:
<ul class="org-ul">
<li>åœ¨ç‰©ç†å­¦é‡Œé¢, æ•°æ®éƒ½æ˜¯ç›´æ¥æ¥è‡ªäºlinear modelçš„(residual errorå¾ˆå°),è¿™ç§æƒ…å†µä¸‹,åªæœ‰ \(R^2\) éå¸¸æ¥è¿‘1æ‰æ˜¯å¥½çš„å€¼</li>
<li>åœ¨å…¶ä»–æƒ…å†µä¸‹, linear modelåªä¸è¿‡æ˜¯å¯¹äºdataçš„ä¸€ä¸ªç²—ç•¥ä¼°è®¡, residual erroré€šå¸¸éƒ½éå¸¸çš„é«˜,è¿™ç§
æƒ…å†µä¸‹ \(R^2\) å¤§æ¦‚æ˜¯0.1ä»¥ä¸‹,æ˜¯æ¯”è¾ƒç°å®çš„</li>
</ul></li>
<li>\(R^2\) statistic æ˜¯ç”¨æ¥åº¦é‡ linearä¸­Xå’ŒYçš„å…³ç³»,correlationä¹Ÿæ˜¯ç”¨æ¥åº¦é‡linearä¸­Xå’ŒYçš„å…³ç³»</li>
<li>åœ¨simple linear regressionä¸­ \(R^2\) statistic å’Œ correlationæ˜¯ç­‰ä»·çš„</li>
<li>ä½†æ˜¯correlationæ— æ³•é€‚åº”multiple linear regression,è€Œ \(R^2\) åˆ™è‡ªåŠ¨é€‚åº”è¿™ç§æƒ…å†µ</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-org0f973b6" class="outline-3">
<h3 id="org0f973b6"><span class="section-number-3">3.2.</span> Multiple Linear Regression</h3>
<div class="outline-text-3" id="text-3-2">
<ul class="org-ul">
<li>Simple Linear regression å¯¹äºå•ä¸€input (predictor variable)æ˜¯éå¸¸å¥½çš„,ä½†æ˜¯åœ¨å®è·µä¸­,æˆ‘ä»¬å¾€å¾€ä¸æ­¢
ä¸€ä¸ªpredictor</li>
<li>ä»¥Advertisingä¸ºä¾‹,æˆ‘ä»¬ä½¿ç”¨simple linear modeæ¥éªŒè¯äº†å¦‚ä¸‹ä¸¤ä¸ªæ•°æ®çš„å…³ç³»:
<ul class="org-ul">
<li>sales</li>
<li>TV advertisingèŠ±è´¹</li>
</ul></li>
<li>ä½†æ˜¯å®é™…ä¸Š,æˆ‘ä»¬è¿˜æœ‰ä¸¤ä¸ªæ²¡æœ‰ç”¨åˆ°çš„æ•°æ®:
<ul class="org-ul">
<li>radio advertisingèŠ±è´¹</li>
<li>newspaper advertisingèŠ±è´¹</li>
</ul></li>
<li>æƒ³çŸ¥é“è¿™ä¸¤ä¸ªæ•°æ®å’Œsaleæœ‰æ²¡æœ‰å…³ç³»,æˆ‘ä»¬å°±è¦å¼•ç”¨åˆ°è¿™ä¸¤ä¸ªæ•°æ®,é‚£æˆ‘ä»¬å¦‚ä½•æ‰©å±•æˆ‘ä»¬çš„åˆ†ææ¥å¼•å…¥è¿™ä¸¤ä¸ªæ•°æ®å‘¢?
<ul class="org-ul">
<li>ä¸€ä¸ªå¯è¡Œçš„æ–¹æ¡ˆ,æ˜¯å…è®¸ä¸‰ä¸ªåˆ†å¼€çš„simple linear regression,åˆ†åˆ«ä½¿ç”¨TV, radio, newspaperä½œä¸ºpredictor</li>
<li>æˆ‘ä»¬æ‰§è¡Œä¹‹åå¾—åˆ°ä¸‰å¼ è¡¨:
<ol class="org-ol">
<li><p>
TV
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Coefficient</th>
<th scope="col" class="org-right">Std.error</th>
<th scope="col" class="org-right">t-statistic</th>
<th scope="col" class="org-left">p-value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Intercept</td>
<td class="org-right">7.0325</td>
<td class="org-right">0.4578</td>
<td class="org-right">15.36</td>
<td class="org-left">&lt; 0.0001</td>
</tr>

<tr>
<td class="org-left">TV</td>
<td class="org-right">0.0475</td>
<td class="org-right">0.0027</td>
<td class="org-right">17.67</td>
<td class="org-left">&lt; 0.0001</td>
</tr>
</tbody>
</table></li>
<li><p>
Radio
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Coefficient</th>
<th scope="col" class="org-right">Std.error</th>
<th scope="col" class="org-right">t-statistic</th>
<th scope="col" class="org-left">p-value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Intercept</td>
<td class="org-right">9.312</td>
<td class="org-right">0.563</td>
<td class="org-right">16.54</td>
<td class="org-left">&lt; 0.0001</td>
</tr>

<tr>
<td class="org-left">radio</td>
<td class="org-right">0.203</td>
<td class="org-right">0.020</td>
<td class="org-right">9.92</td>
<td class="org-left">&lt; 0.0001</td>
</tr>
</tbody>
</table></li>

<li><p>
Newspaper
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Coefficient</th>
<th scope="col" class="org-right">Std.error</th>
<th scope="col" class="org-right">t-statistic</th>
<th scope="col" class="org-left">p-value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Intercept</td>
<td class="org-right">12.31</td>
<td class="org-right">0.621</td>
<td class="org-right">19.88</td>
<td class="org-left">&lt; 0.0001</td>
</tr>

<tr>
<td class="org-left">newspaper</td>
<td class="org-right">0.055</td>
<td class="org-right">0.017</td>
<td class="org-right">3.30</td>
<td class="org-left">0.00115</td>
</tr>
</tbody>
</table></li>
</ol></li>
<li>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¯æŠ•å…¥1000ç¾é‡‘,TVå¢é•¿47.5, radioå¢é•¿203, newspaperå¢é•¿55</li>
</ul></li>
<li>ä¸‰ä¸ªç‹¬ç«‹çš„linear regressionæœ‰å¦‚ä¸‹çš„é—®é¢˜:
<ul class="org-ul">
<li>ç»™å®šäº†ä¸‰ä¸ªåª’ä½“çš„é¢„ç®—ä¹‹å,æ— æ³•é¢„æµ‹é”€é‡,å› ä¸ºæ¯ä¸ªé¢„ç®—éƒ½æœ‰è‡ªå·±çš„linear regression,è¾“å…¥è¿›å»ä¼šå¾—åˆ°ä¸‰ä¸ª
ä¸åŒçš„salesæ•°æ®</li>
<li>æ¯ä¸ªé¢„ç®—çš„linear regressionå…¶å®éƒ½å¿½ç•¥äº†å¦å¤–çš„ä¸¤ä¸ªé¢„ç®—çš„å½±å“,è¿™å¯¹æ¨¡å‹å‡†ç¡®åº¦è‚¯å®šæœ‰å½±å“</li>
</ul></li>
<li>å¯¹simple linear regressionçš„ä¸€ä¸ªé‡å¤§æ”¹è¿›,å°±æ˜¯æŠŠå®ƒæ‰©å±•åˆ°èƒ½å¤Ÿå…³è”å¤šä¸ªpredictor.è¿™å°±æ˜¯multiple linear
regression model</li>
<li><p>
å‡è®¾æˆ‘ä»¬æœ‰pä¸ªä¸åŒçš„predictor,æˆ‘ä»¬çš„multiple linear regression modelçš„å…¬å¼å¦‚ä¸‹
</p>
\begin{equation}
Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \cdot\cdot\cdot + \beta_pX_p + \varepsilon,\tag{3.19}
\end{equation}
<ul class="org-ul">
<li>è¿™é‡Œçš„ \(X_j\) ä»£è¡¨ç¬¬ jthä¸ªpredictor</li>
<li>\(\beta_j\) ä»£è¡¨jthä¸ªpreditorå’Œresponseä¹‹é—´çš„å…³ç³»</li>
<li><p>
æˆ‘ä»¬ä½¿ç”¨ \(\beta_j\) çš„æ—¶å€™,è¦assumeå…¶ä»–predictoréƒ½æ˜¯fixedçš„
</p>
<pre class="example" id="org96cbc95">
We interpret Bj as the average effect on Y of a one unit increase in Xj,
holding all other predictors fixed.
</pre></li>
</ul></li>
</ul>
</div>
<div id="outline-container-orgc7964f6" class="outline-4">
<h4 id="orgc7964f6"><span class="section-number-4">3.2.1.</span> Estimating the Regression Coefficients</h4>
<div class="outline-text-4" id="text-3-2-1">
<ul class="org-ul">
<li>å°±åƒsimple regressioné‡Œé¢çš„è®¾ç½®ä¸€æ ·, \(\beta_0,\beta_1,...,\beta_p\) éƒ½æ˜¯unknownçš„,æˆ‘ä»¬å¿…é¡»estimate
ä»–ä»¬,estimateçš„å€¼æ˜¯åŠ hatçš„: \(\hat{\beta_0},\hat{\beta_1},...,\hat{\beta_p}\)</li>
<li><p>
æˆ‘ä»¬çš„é¢„æµ‹è®¡ç®—ä½¿ç”¨çš„å…¬å¼å¦‚ä¸‹:
</p>
\begin{equation}
\hat{y}=\hat{\beta_0} + \hat{\beta_1}x_1 + \hat{\beta_2}x_2 + \cdot\cdot\cdot + \hat{\beta_p}x_p,\tag{3.21}
\end{equation}</li>
<li><p>
æˆ‘ä»¬é€‰å– \(\hat{\beta_0},\hat{\beta_1},...,\hat{\beta_p}\) çš„æ ‡å‡†ä¾ç„¶æ˜¯ä½¿å¾—RSSæœ€å°,ç”±äºè¡¨è¾¾æ–¹å¼æœ€
å¥½ä½¿ç”¨çŸ©é˜µ,è¿™é‡Œä¸åˆ—å‡º.å„ç§ç»Ÿè®¡å­¦libraryå¯ä»¥è‡ªè¡Œè®¡ç®—.ä¸‹é¢å°±æ˜¯æˆ‘ä»¬ä½¿ç”¨ç»Ÿè®¡å­¦libraryè®¡ç®—å‡ºæ¥çš„ç»“æœ
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Coefficient</th>
<th scope="col" class="org-right">Std. error</th>
<th scope="col" class="org-right">t-statistic</th>
<th scope="col" class="org-left">p-value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Intercept</td>
<td class="org-right">2.939</td>
<td class="org-right">0.3119</td>
<td class="org-right">9.42</td>
<td class="org-left">&lt;0.0001</td>
</tr>

<tr>
<td class="org-left">TV</td>
<td class="org-right">0.046</td>
<td class="org-right">0.0014</td>
<td class="org-right">32.81</td>
<td class="org-left">&lt;0.0001</td>
</tr>

<tr>
<td class="org-left">radio</td>
<td class="org-right">0.189</td>
<td class="org-right">0.0086</td>
<td class="org-right">21.89</td>
<td class="org-left">&lt;0.0001</td>
</tr>

<tr>
<td class="org-left">newspaper</td>
<td class="org-right">-0.001</td>
<td class="org-right">0.0059</td>
<td class="org-right">-0.18</td>
<td class="org-left">0.8599</td>
</tr>
</tbody>
</table></li>
<li><p>
æˆ‘ä»¬è¦è¿™æ ·è§£è¯»multiple linear regression
</p>
<pre class="example" id="org6b091a9">
åœ¨TVå’Œnewspaperçš„é¢„ç®—å›ºå®šçš„æƒ…å†µä¸‹,æ¯é¢å¤–æé«˜1000ç¾å…ƒé¢„ç®—åœ¨radioä¸Šé¢,å¯ä»¥å¾—åˆ°189å•ä½
</pre></li>
<li>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°, åœ¨ä¸¤ç§linear regressionæƒ…å†µä¸‹, TVå’Œradioçš„coefficientç›¸å·®ä¸å¤š:
<ul class="org-ul">
<li>åœ¨simple linear regressionçš„æƒ…å†µä¸‹, TVå’Œradioæ¯å¢åŠ 1000ç¾å…ƒçš„æé«˜å€¼ä¸º47.5, 203</li>
<li>åœ¨multiple linear regressionçš„æƒ…å†µä¸‹, TVå’Œradioæ¯å¢åŠ 1000ç¾å…ƒçš„æé«˜å€¼ä¸º46, 189</li>
</ul></li>
<li>ä½†æ˜¯,newspaperåœ¨single linear regressioné‡Œé¢æ˜¯é0çš„,è€Œåœ¨multiple linear regressioné‡Œé¢ç«Ÿç„¶æ¥è¿‘0
äº†,è€Œä¸”ä»–çš„p-valueä¸å†significant(å°äº0.0001å°±æ˜¯significant),å˜æˆäº†0.8599,ä¸€ä¸ªéå¸¸å¤§çš„å€¼.
<ul class="org-ul">
<li>è¿™è¯´æ˜äº†linearå’Œmultiple linear regressionä¸­çš„coefficientä¼šæœ‰éå¸¸å¤§çš„ä¸åŒ</li>
</ul></li>
<li><p>
é‚£ä¹ˆæˆ‘ä»¬ä¸‹é¢çš„æƒ…å†µæ˜¯åˆç†çš„ä¹ˆ?:
</p>
<pre class="example" id="org15f2ca0">
åœ¨multiple linear regressioné‡Œé¢, saleså’Œnewspaperæ˜¯æ²¡æœ‰å…³ç³»çš„,ä½†æ˜¯åœ¨single linear regression
é‡Œé¢saleså’Œnewspaperæ˜¯æœ‰å…³ç³»çš„
</pre></li>
<li>ç­”æ¡ˆæ˜¯åˆç†çš„.</li>
<li><p>
æˆ‘ä»¬å…ˆå¼•å…¥ä¸€ä¸ªcorrelation matrix for TV, radio, newspaper
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">TV</th>
<th scope="col" class="org-right">radio</th>
<th scope="col" class="org-right">newspaper</th>
<th scope="col" class="org-right">sales</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">TV</td>
<td class="org-right">1.0000</td>
<td class="org-right">0.0548</td>
<td class="org-right">0.0567</td>
<td class="org-right">0.7822</td>
</tr>

<tr>
<td class="org-left">radio</td>
<td class="org-right">&#xa0;</td>
<td class="org-right">1.0000</td>
<td class="org-right">0.3541</td>
<td class="org-right">0.5762</td>
</tr>

<tr>
<td class="org-left">newspaper</td>
<td class="org-right">&#xa0;</td>
<td class="org-right">&#xa0;</td>
<td class="org-right">1.0000</td>
<td class="org-right">0.2283</td>
</tr>

<tr>
<td class="org-left">sales</td>
<td class="org-right">&#xa0;</td>
<td class="org-right">&#xa0;</td>
<td class="org-right">&#xa0;</td>
<td class="org-right">1.0000</td>
</tr>
</tbody>
</table></li>
<li>æˆ‘ä»¬ä»ä¸Šé¢çš„è¡¨æ ¼æˆ‘ä»¬å¯ä»¥çœ‹åˆ°radioå’Œnewspaperçš„correlationæ˜¯0.35,è¿™æ ·å°±æ„å‘³ç€radioé¢„ç®—å¤šçš„åœ°æ–¹,
newspaperé¢„ç®—ä¹Ÿå¤š</li>
<li>å‡è®¾multiple regressionæ˜¯æ­£ç¡®çš„,newspaperå¯¹salesæ²¡æœ‰ç›´æ¥ä½œç”¨,ä½†æ˜¯radioå¯¹salesæœ‰ç›´æ¥ä½œç”¨:
<ul class="org-ul">
<li>é‚£ä¹ˆåœ¨æŸä¸ªmarketä¸Š,æˆ‘ä»¬radioçš„é¢„ç®—é«˜,é‚£ä¹ˆæˆ‘ä»¬çš„saleså°±é«˜</li>
<li>é€šè¿‡correlation matrixæˆ‘ä»¬å‘ç°,åœ¨è¿™ä¸ªmarketä¸Š,æˆ‘ä»¬newspaperçš„é¢„ç®—ä¹Ÿé«˜</li>
<li>å¦‚æœæ²¡æœ‰multiple linear regression,åªæœ‰simple linear regressionçš„æƒ…å†µä¸‹(åªè€ƒè™‘saleså’Œnewspaper),
æˆ‘ä»¬çœ‹åˆ°çš„ç»“æœå°±æ˜¯:newspaperé¢„ç®—é«˜,saleså°±é«˜(è™½ç„¶å…¶å®newspaperå¯¹é”€é‡æ²¡ä½œç”¨,ä½†æ˜¯radioæœ‰ä½œç”¨,
newspaperæ²¾äº†radioçš„å…‰)</li>
</ul></li>
<li>æˆ‘ä»¬å¯ä»¥åœ¨è®²ä¸€ä¸ªç±»ä¼¼çš„æƒ…æ™¯:
<ul class="org-ul">
<li>å¦‚æœè·‘ä¸€ä¸ªsimple regressionä¼šå‘ç°å¦‚ä¸‹ä¸¤ä¸ªäº‹ä»¶æœ‰positive relationship:
<ol class="org-ol">
<li>é²¨é±¼æ”»å‡» (sales)</li>
<li>å†°æ·‡æ·‹é”€é‡ (newspaper budget)</li>
</ol></li>
<li>æˆ‘ä»¬å†è·‘ä¸€ä¸ªmultiple regression,åŠ ä¸Štemperature,å°±ä¼šå‘ç°,å…¶å®é²¨é±¼æ”»å‡»å…¶å®æ˜¯å’Œå¤©æ°”çƒ­å¼ºç›¸å…³(å¤©
æ°”çƒ­å»æ²™æ»©çš„äººå¤š,è‡ªç„¶é²¨é±¼æ”»å‡»å¤š):
<ol class="org-ol">
<li>é²¨é±¼æ”»å‡» (sales)</li>
<li>å†°æ·‡æ·‹é”€é‡ (newspaper budget)</li>
<li>æ¸©åº¦ (radio)</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org6833422" class="outline-4">
<h4 id="org6833422"><span class="section-number-4">3.2.2.</span> Some Important Questions</h4>
<div class="outline-text-4" id="text-3-2-2">
<ul class="org-ul">
<li>å½“ä½ è¿è¡Œmultiple linear regressionçš„æ—¶å€™,ä½ è¦é—®ä¸€ä¸‹å¦‚ä¸‹å‡ ä¸ªé—®é¢˜:
<ul class="org-ul">
<li>æˆ‘ä»¬çš„pä¸ªå‚æ•° \(X_1,X_2,\cdot\cdot\cdot,X_p\) ä¸­,æ˜¯å¦è‡³å°‘æœ‰ä¸€ä¸ªpredictoræ˜¯æœ‰ä½œç”¨çš„</li>
<li>æ‰€æœ‰çš„predictoréƒ½å¯ä»¥ç”¨æ¥è§£é‡ŠYä¹ˆ,è¿˜æ˜¯åªæœ‰ä¸€å°éƒ¨åˆ†çš„predictoræœ‰ä½œç”¨?</li>
<li>æˆ‘ä»¬çš„modelå’Œdata fitçš„æ€ä¹ˆæ ·?</li>
<li>ç»™predictorçš„ä¸€ä¸ªå­é›†,æˆ‘ä»¬èƒ½é¢„æµ‹å‡ºä»€ä¹ˆresponse,æˆ‘ä»¬çš„é¢„æµ‹å‡†ç¡®åº¦æœ‰å¤šå°‘?</li>
</ul></li>
<li>æˆ‘ä»¬ä¸‹é¢æ¥å›ç­”è¿™å‡ ä¸ªé—®é¢˜</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org9303a69"></a>Is There a Relationship Between the Response and Predictors?<br />
<div class="outline-text-5" id="text-3-2-2-1">
<ul class="org-ul">
<li>åœ¨multiple regressioné‡Œé¢:
<ul class="org-ul">
<li><p>
null hypothesiséœ€è¦
</p>
\begin{equation}
H_0 : \beta_1 = \beta_2 = \cdot\cdot\cdot = \beta_p = 0
\end{equation}</li>
<li><p>
alternative hypothesiséœ€è¦:
</p>
\begin{equation}
H_a : at \quad least \quad one \quad \beta_j \quad is \quad non-zero
\end{equation}</li>
</ul></li>
<li><p>
hypothesis test è½¬è€Œè½¬åŒ–ä¸ºè®¡ç®—F-statistic
</p>
\begin{equation}
F = \frac{(TSS-RSS)/p}{RSS/(n-p-1)},\tag{3.23}
\end{equation}</li>
<li>æˆ‘ä»¬è®¤çœŸè§‚å¯Ÿf-statisticå°±ä¼šå‘ç°,å¯¹äºsimple linear regressionæ¥è¯´:
<ul class="org-ul">
<li><p>
å¦‚æœlinear modelçš„å‡è®¾æ­£ç¡®çš„è¯,åˆ†å­çš„æœŸæœ›ä¸º \(\sigma^2\)
</p>
\begin{equation}
E\left\{RSS/(n-p-1)\right\} = \sigma^2
\end{equation}</li>
<li><p>
å¦‚æœ \(H_0\) ä¸ºçœŸçš„è¯,,åˆ†æ¯çš„æœŸæœ›ä¹Ÿä¸º \(\sigma^2\)
</p>
\begin{equation}
E\left\{(TSS-RSS)/p\right\} = \sigma^2
\end{equation}</li>
<li>æ¢å¥è¯è¯´,å¦‚æœpredictorå’Œresponseæ²¡æœ‰å…³ç³»çš„è¯,f-statisticå°±ä¼šæ˜¯1</li>
<li>å¦‚æœpredictorå’Œresponseæœ‰å…³ç³»(ä¹Ÿå°±æ˜¯ \(H_a\) ä¸ºtrue),é‚£ä¹ˆ \(E\left\{(TSS-RSS)/p\right\} > \sigma^2\),
æ‰€ä»¥æˆ‘ä»¬çš„F-statisticä¹Ÿå°±å¤§</li>
</ul></li>
<li>F-statisticåˆ°åº•å’Œ1æœ‰å¤šè¿œçš„è·ç¦»,æ‰èƒ½è®©æˆ‘ä»¬ç¡®è®¤againt \(H_0\) å‘¢? è¿™ä¸ªå’Œnè¿˜æœ‰pçš„å¤§å°æœ‰å…³:
<ul class="org-ul">
<li>å¦‚æœæˆ‘ä»¬çš„nç‰¹åˆ«çš„å¤§,é‚£ä¹ˆå³ä¾¿æ˜¯F-statisticç¨å¾®å¤§äº1,é‚£ä¹ˆä¹Ÿæ˜¯å¯ä»¥æ¥å—çš„</li>
<li>å¦‚æœæˆ‘ä»¬çš„næ¯”è¾ƒå°,é‚£ä¹ˆå°±éœ€è¦æ¯”è¾ƒå¤§çš„F-statisticæ‰èƒ½reject \(H_0\)</li>
</ul></li>
<li>å¦å¤–ä¸€ä¸ªç»´åº¦,å¦‚æœæˆ‘ä»¬ç¡®è®¤æˆ‘ä»¬çš„ \(H_0\) ä¸ºtrue,è€Œä¸” errors \(\varepsilon_i\) éµä»æ­£æ€åˆ†å¸ƒçš„è¯,F-statistic
ä¹Ÿéµä»æ­£æ€åˆ†å¸ƒ</li>
<li>å¯¹äºä»»æ„çš„nå’Œpäº§ç”Ÿçš„F-statistic,æˆ‘ä»¬å¯ä»¥è®¡ç®—å…¶p-value(è¶Šæ¥è¿‘0,è¡¨ç¤ºè¶Šstrongçš„relation):
<ul class="org-ul">
<li>å¯¹äºp-valueæ¥è¯´,è¶Šæ¥è¿‘0,è¯´æ˜è¶Šæœ‰relation</li>
</ul></li>
<li><p>
æœ‰äº›æ—¶å€™æˆ‘ä»¬æƒ³æµ‹è¯•coefficientçš„ä¸€ä¸ªsubset(å¤§å°ä¸ºq)æ˜¯å¦å’ŒYæœ‰relation,è¿™ç§null hypothesiså¯ä»¥åˆ—
ä¸º
</p>
\begin{equation}
H_0: \beta_{p-q+1}=\beta_{p-q+2}=\cdot\cdot\cdot=\beta_p=0,
\end{equation}</li>
<li><p>
å¦‚æœè¿™ä¸ªnull hypothesisæˆç«‹çš„è¯,é‚£ä¹Ÿå°±æ˜¯æ„å‘³ç€æˆ‘ä»¬ä½¿ç”¨p-qä¸ªå‚æ•°åˆ›å»ºäº†ä¸€ä¸ªmodel,å‡è®¾è¿™ä¸ªmodelçš„
residual sum of squareså«åš \(RSS_0\),é‚£ä¹ˆè¿™ä¸ªæ¨¡å‹çš„F-statisticå°±æ˜¯å¦‚ä¸‹è®¡ç®—
</p>
\begin{equation}
F = \frac{(RSS_0 - RSS)/q}{RSS/(n-p-1)},\tag{3.24}
\end{equation}</li>
<li>å…¬å¼3.24å’Œå…¬å¼3.23è™½ç„¶éƒ½æ˜¯æ±‚f-statistic,ä½†æ˜¯åˆ†å­å´å®Œå…¨ä¸ä¸€æ ·,éœ€è¦å¯¹f-statisticæœ‰æ¯”è¾ƒæ¸…æ™°çš„äº†è§£
æ‰èƒ½å¼„æ¸…æ¥šè¿™ä¸ªå…¬å¼çš„æ¥å†:
<ul class="org-ul">
<li>åˆ†å­æ˜¯æ±‚å¹³å‡åç§»çš„,å…¬å¼3.23é™¤ä»¥çš„æ˜¯p,ä¹Ÿå°±æ˜¯æ‰€æœ‰çš„variable</li>
<li>å…¬å¼3.24é™¤ä»¥çš„æ˜¯q,ä¹Ÿå°±æ˜¯ä¸èµ·ä½œç”¨çš„è¿™äº›ä¸ªvariable. æ˜¯ç”¨ \(RSS_0\)(ä¹Ÿå°±æ˜¯è¿™p-qä¸ªvariableçš„RSS)
å‡å»RSS(ä¹Ÿå°±æ˜¯pä¸ªvariableçš„RSS)</li>
</ul></li>
<li><p>
è¿™é‡Œæˆ‘ä»¬å†å›å¤´çœ‹ä¸€ä¸‹,åœ¨è¡¨æ ¼3.4(å¦‚ä¸‹)é‡Œé¢,æˆ‘ä»¬åˆ—å‡ºäº†æ¯ä¸ªpredictorçš„t-statisticå’Œp-value,è¿™è¡¨æ˜
äº†è¿™ä¸ªpredictoræ˜¯å¦å’Œresponseæœ‰å…³
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Coefficient</th>
<th scope="col" class="org-right">Std. error</th>
<th scope="col" class="org-right">t-statistic</th>
<th scope="col" class="org-left">p-value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Intercept</td>
<td class="org-right">2.939</td>
<td class="org-right">0.3119</td>
<td class="org-right">9.42</td>
<td class="org-left">&lt;0.0001</td>
</tr>

<tr>
<td class="org-left">TV</td>
<td class="org-right">0.046</td>
<td class="org-right">0.0014</td>
<td class="org-right">32.81</td>
<td class="org-left">&lt;0.0001</td>
</tr>

<tr>
<td class="org-left">radio</td>
<td class="org-right">0.189</td>
<td class="org-right">0.0086</td>
<td class="org-right">21.89</td>
<td class="org-left">&lt;0.0001</td>
</tr>

<tr>
<td class="org-left">newspaper</td>
<td class="org-right">-0.001</td>
<td class="org-right">0.0059</td>
<td class="org-right">-0.18</td>
<td class="org-left">0.8599</td>
</tr>
</tbody>
</table></li>
<li><p>
æ¯ä¸ªpredictorçš„t-statisticå’Œp-value,å«åšåŠ å…¥è¿™ä¸ªvariableåˆ°modelåçš„éƒ¨åˆ†ä½œç”¨,ç”¨è‹±æ–‡æè¿°å°±æ˜¯
</p>
<pre class="example" id="orgd88457f">
Partial effect of adding that variable to the model
</pre></li>
<li>æ—¢ç„¶æˆ‘ä»¬å·²ç»æœ‰æ¯ä¸ªpredictoræ˜¯å¦å¯¹responseæœ‰å½±å“çš„æ•°æ®äº†,é‚£ä¹ˆæˆ‘ä»¬çœ‹ä¸€çœ¼è¿™äº›æ•°æ®,å¦‚æœå…¶ä¸­æœ‰ä¸€ä¸ªpredictor
å¯¹responseæœ‰å½±å“,é‚£ä¹ˆå²‚ä¸æ˜¯å°±ä¸ç”¨ç®—å…¨å±€F-statisticäº†,å› ä¸ºå…¨å±€F-statisticè‚¯å®šæ˜¯"è‡³å°‘æœ‰ä¸€ä¸ªvariable
å¯¹responseæœ‰å½±å“"</li>
<li><p>
è¿™é‡Œå°±å‡ºç°äº†ä¸€ä¸ªlogic:
</p>
<pre class="example" id="org1cde936">
If any one of the p-value for the individual variables is very small, then
at least one of the predictors is related to the response.
</pre></li>
<li>éå¸¸ä¸å¹¸çš„æ˜¯,è¿™ä¸ªçœ‹ä¼¼æ­£ç¡®çš„logic,ç¡®æ˜¯é”™è¯¯çš„.å› ä¸ºç­”æ¡ˆæ˜¯:ä¸ä¸€å®š,pè¶Šå¤§è¶Šä¸ä¸€å®š
<ul class="org-ul">
<li>æ¯”å¦‚,å‡è®¾p=100, å¹¶ä¸” \(H_0 : \beta_1=\beta_2= \cdot\cdot\cdot = \beta_p = 0\) (ä¹Ÿå°±æ˜¯è¯´,æ²¡æœ‰variableå’Œresponseæœ‰å…³ç³»)</li>
<li>åœ¨è¿™ç§æƒ…å†µä¸‹,è¿˜æ˜¯æœ‰çº¦5%çš„variableçš„p-valueä¼šæ„å¤–åœ°(by chance)çš„ä½äº0.05</li>
<li>å®é™…æƒ…å†µå°±æ˜¯,æˆ‘ä»¬å‡ ä¹è‚¯å®šä¼šåœ¨100ä¸ªvariableé‡Œé¢æ‰¾åˆ°å…¶ä¸­ä¸€ä¸ªçš„variableçš„p-valueå°äº0.05</li>
<li>é‚£ä¹ˆæˆ‘ä»¬å¦‚æœæ ¹æ®è¿™ä¸€ä¸ªvariableçš„ä½p-valueæ¥æ–­å®š"è‚¯å®šæœ‰variableå’Œresponseæœ‰å…³ç³»",é‚£ä¹ˆ,æˆ‘ä»¬å°±å¤§é”™ç‰¹é”™äº†</li>
<li><p>
ä½†æ˜¯F-statisticå°±æ²¡æœ‰è¿™ä¸ªé—®é¢˜äº†,å› ä¸ºF-statisticå·²ç»æ ¡å‡†(adjust)è¿‡predictorå‚æ•°æ•°é‡äº†,ä¹Ÿå°±æ˜¯è¯´
</p>
<pre class="example" id="orgabf65a8">
å¦‚æœ H0 = true , æ— è®ºpredictoræœ‰å¤šå°‘(æˆ–è€…observationæœ‰å¤šå°‘),æˆ‘ä»¬çš„F-statisticåªä¼šæœ‰5%çš„å¯èƒ½å¾—åˆ°ä¸€ä¸ª
ä½äº0.05çš„p-value.æˆ‘ä»¬å‡ºé”™çš„æ¦‚ç‡åªæœ‰5%,è€Œä¸Šé¢é”™è¯¯çš„logic,é”™è¯¯çš„æ¦‚ç‡åœ¨p=100çš„æƒ…å†µä¸‹,å‡ ä¹æ˜¯100%
</pre></li>
</ul></li>
<li>ä½¿ç”¨F-statisticæ¥æµ‹è¯•predictorå’Œresponseä¹‹é—´å…³ç³»è¿™ç§approach,åœ¨pæ¯”è¾ƒå°çš„æ—¶å€™æ¯”è¾ƒåˆé€‚,æ‰€è°“pæ¯”è¾ƒ
å°,æŒ‡çš„æ˜¯pç›¸å¯¹äºnæ¥è¯´,æ¯”è¾ƒå°</li>
<li>ä½†æ˜¯,æœ‰äº›æƒ…å†µä¸‹,æˆ‘ä»¬çš„pç‰¹åˆ«çš„å¤§,æ¯”nè¿˜å¤§(p&gt;n),æ¢å¥è¯è¯´,æˆ‘ä»¬"è¦é¢„æµ‹çš„coefficient \(\beta_j\) "æ¯”
"æä¾›é¢„æµ‹æ•°æ®çš„observation"è¿˜å¤š.è¿™ç§æƒ…å†µä¸‹,æˆ‘ä»¬è¿least squareéƒ½æ²¡æ³•ä½¿ç”¨,æ›´ä¸å¿…è¯´f-statisticäº†</li>
<li>å¯¹äºè¿™ç§pç‰¹åˆ«å¤§çš„æƒ…å†µ,æˆ‘ä»¬å¯èƒ½éœ€è¦æ–°çš„approach,æ¯”å¦‚åé¢è¦è®²åˆ°çš„forward selection</li>
</ul>
</div>
</li>
<li><a id="orgf0b1ccd"></a>Two: Deciding on Important Variables<br />
<div class="outline-text-5" id="text-3-2-2-2">
<ul class="org-ul">
<li>æ­£å¦‚å‰é¢è®¨è®ºçš„,multiple regressionåˆ†æçš„ç¬¬ä¸€æ­¥æ˜¯è®¡ç®—æ‰€æœ‰variableçš„F-statistic</li>
<li>å¦‚æœæˆ‘ä»¬çš„f-statisticèƒ½å¤Ÿè¯æ˜è‡³å°‘æœ‰ä¸€ä¸ªvariableæ˜¯å’Œresponseç›¸å…³çš„,é‚£ä¹ˆ,æˆ‘ä»¬çš„é—®é¢˜å°±è½¬æ¢ä¸ºæ‰¾åˆ°
è¿™äº›èµ·ä½œç”¨çš„variable(è™½ç„¶æœ‰å¯èƒ½æ‰€æœ‰çš„variableéƒ½æœ‰ä½œç”¨,ä½†æ˜¯æ›´å¸¸è§çš„æƒ…å†µæ˜¯ä¸€éƒ¨åˆ†variableæœ‰ä½œç”¨)</li>
<li>æŒ‘é€‰è¿™äº›variable,å¹¶ä¸”ç»„æˆä¸€ä¸ªæ–°çš„,åªæœ‰è¿™äº›variableç»„æˆçš„modelçš„è¿‡ç¨‹,å«åšvariable selection,
æˆ‘ä»¬å°†ä¼šåœ¨ç¬¬å…­ç« è¯¦ç»†ä»‹ç»,è¿™é‡Œåªä»‹ç»äº›æ¦‚å¿µ</li>
<li>æœ€ä½³æƒ…å†µä¸‹,æ˜¯æˆ‘ä»¬æŠŠæ‰€æœ‰çš„variableç»„åˆéƒ½ç»™ç»™æ‰¾å‡ºæ¥.å‡è®¾æˆ‘ä»¬çš„p=2,é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥æ’åˆ—ç»„åˆå‡ºå¦‚ä¸‹çš„ä¸åŒmodel:
<ul class="org-ul">
<li>æ²¡æœ‰variableçš„model</li>
<li>åªåŒ…å« \(X_1\) çš„model</li>
<li>åªåŒ…å« \(X_2\) çš„model</li>
<li>åŒ…å« \(X_1\) å’Œ \(X_2\) çš„model</li>
</ul></li>
<li>ç„¶åæˆ‘ä»¬ä½¿ç”¨å¦‚ä¸‹çš„modelåˆ¤åˆ«å·¥å…·,æ¥é€‰æ‹©æœ€å¥½çš„model:
<ul class="org-ul">
<li>Mallow</li>
<li>Akaike information criterion (AIC)</li>
<li>Bayesian information criterion (BIC)</li>
<li>adjusted \(R^2\)</li>
</ul></li>
<li>è¿™ç§æ–¹æ³•è¦æµ‹è¯• \(2^p\) ç§ç»„åˆ,åœ¨på¾ˆå¤§çš„æƒ…å†µä¸‹,ä¸æ˜¯éå¸¸å¯è¡Œ.æ‰€ä»¥ä¸Šè¿°æ–¹æ³•åªé€‚ç”¨äºpä¸å¤§çš„æƒ…å†µ,åœ¨p
å¾ˆå¤§çš„æƒ…å†µä¸‹,æˆ‘ä»¬éœ€è¦å¦‚ä¸‹çš„ä¸‰ç§ç»å…¸æ–¹æ³•:
<ul class="org-ul">
<li>Forward selection:
<ul class="org-ul">
<li>æˆ‘ä»¬ä»null modelå¼€å§‹</li>
<li>ä»pä¸ªvariableé‡Œé¢æŒ‘é€‰ä¸€ä¸ªåŠ åˆ°æ¨¡å‹é‡Œ,é€‰æ‹©æ ‡å‡†æ˜¯åŠ å…¥å,è®©æ¨¡å‹è¾¾åˆ°lowest RSS</li>
<li>é‡å¤ä¸Šé¢çš„è¿‡ç¨‹,ç›´åˆ°æŸäº›æ¡ä»¶è¾¾åˆ°</li>
</ul></li>
<li>Backward selection:
<ul class="org-ul">
<li>æˆ‘ä»¬ä»all variable modelå¼€å§‹</li>
<li>ä»pä¸ªvariableé‡Œé¢æŒ‘é€‰ä¸€ä¸ªä»æ¨¡å‹é‡Œåˆ é™¤,é€‰æ‹©çš„æ ‡å‡†æ˜¯p-valueæœ€å¤§çš„</li>
<li>é‡å¤ä¸Šé¢çš„è¿‡ç¨‹,ç›´åˆ°æŸäº›æ¡ä»¶è¾¾åˆ°(æ¯”å¦‚æ‰€æœ‰çš„variableéƒ½åªæœ‰ä¸€ä¸ªå¾ˆå°çš„p-value)</li>
</ul></li>
<li>Mixed selection:
<ul class="org-ul">
<li>æˆ‘ä»¬ä»null modelå¼€å§‹</li>
<li>ä»pä¸ªvariableé‡Œé¢æŒ‘é€‰ä¸€ä¸ªåŠ åˆ°æ¨¡å‹é‡Œ,é€‰æ‹©æ ‡å‡†æ˜¯åŠ å…¥å,è®©æ¨¡å‹è¾¾åˆ°lowest RSS</li>
<li>éšç€variableçš„å¢åŠ ,ä¸€æ—¦å‘ç°å·²ç»åŠ å…¥çš„æŸä¸ªvariable,åœ¨æ–°çš„variableåŠ å…¥å,å…¶p-valueè¶…è¿‡äº†æŸ
ä¸ªé˜ˆå€¼,æˆ‘ä»¬å°±åˆ é™¤è¿™ä¸ªvariable</li>
<li>æœ€ç»ˆçš„æ•ˆæœå°±æ˜¯åœ¨modelé‡Œé¢çš„æ‰€æœ‰çš„variable,éƒ½æœ‰æ¯”è¾ƒä½çš„p-value.æ‰€æœ‰æ²¡æœ‰åŠ å…¥çš„variableæ˜¯å› ä¸º
ä»–ä»¬ä¸€æ—¦åŠ å…¥,å°±ä¼šæœ‰æ¯”è¾ƒå¤§çš„p-value,æ‰€ä»¥åªå¥½å¾…åœ¨modelä»¥å¤–</li>
</ul></li>
</ul></li>
<li>ä¸‰ç§ç»å…¸æ–¹æ³•ä½¿ç”¨ä¹Ÿæœ‰å…¶è¦æ±‚:
<ul class="org-ul">
<li>backward selectionä¸èƒ½åœ¨p&gt;nçš„æƒ…å†µä¸‹ä½¿ç”¨, forward selectionå¯ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹ä½¿ç”¨</li>
<li>forward selectionæ˜¯è´ªå¿ƒç®—æ³•,æœ€åå¯èƒ½ä¼šåŒ…å«æ—©æœŸåŠ å…¥çš„,å…¶å®ä¸éœ€è¦çš„variable, mixd selectionå¯
ä»¥è¡¥æ•‘è¿™ä¸ªé—®é¢˜</li>
</ul></li>
</ul>
</div>
</li>
<li><a id="orgb078311"></a>Three: Model Fit<br />
<div class="outline-text-5" id="text-3-2-2-3">
<ul class="org-ul">
<li>æœ€å¸¸è§çš„æ•°å­—åŒ–measureå°±æ˜¯ä¸¤ä¸ª,è®¡ç®—æ–¹æ³•multipleå’Œsimple linear regressionä¸€è‡´:
<ul class="org-ul">
<li>\(R^2\)</li>
<li>RSE</li>
</ul></li>
<li>æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹ \(R^2\),æˆ‘ä»¬ä¹‹å‰çŸ¥é“, \(R^2\) çº¦æ¥è¿‘1,è¯´æ˜æ¨¡å‹ä¸­è¢«è§£é‡Šçš„variableè¶Šå¤š:
<ul class="org-ul">
<li>åœ¨simple linear regressioné‡Œé¢,è¿™å°±æ„å‘³ç€æ¨¡å‹çš„å”¯ä¸€variableè¢«å¾ˆå¥½çš„è§£é‡Šäº†</li>
<li>åœ¨multiple linear regressioné‡Œé¢,åˆ™å¯ä»¥ç”¨æ¥åˆ¤æ–­æŸä¸ªvariableæ˜¯å¦å’Œresponseæœ‰å…³:
<ul class="org-ul">
<li>åœ¨Advertising dataé‡Œé¢,ä¸‰ä¸ªvariableéƒ½ä½¿ç”¨çš„model,å…¶ \(R^2\) å€¼ä¸º0.8972</li>
<li>åœ¨Advertising dataé‡Œé¢,åªä½¿ç”¨TVå’Œradioçš„model,å…¶ \(R^2\) å€¼ä¸º0.89719</li>
<li>æ¢å¥è¯è¯´,å¼•å…¥newspaperåˆ°å·²ç»æœ‰TVå’Œradioçš„model,å¯¹ \(R^2\) çš„æå‡æä¸ºæœ‰é™(æ³¨æ„,å¤šå¼•å…¥ä¸€ä¸ªvariable
\(R^2\) æ€»ä¼šæå‡,æ— è®ºè¿™ä¸ªvariableæ˜¯å¦èµ·ä½œç”¨,å› ä¸ºæˆ‘ä»¬è¦æ›´fit trainigæ•°æ®)</li>
<li>åŠ å…¥newspaperå \(R^2\) å¾—åˆ°äº†éå¸¸tinyçš„æå‡,æ›´è¯´æ˜äº†newspaperæ²¡æœ‰ä½œç”¨</li>
<li>ä¸ä¹‹ç›¸å¯¹çš„,åªæœ‰TVçš„modelçš„ \(R^2\) å€¼ä¸º0.61, åŠ å…¥radioå,å…¶ \(R^2\) å€¼çš„æå‡éå¸¸å·¨å¤§,è¿™è¯´æ˜,ä½¿ç”¨
TVå’Œradioçš„modelæ¯”å•çº¯ä½¿ç”¨TVçš„modelè¦å¥½</li>
</ul></li>
</ul></li>
<li>æˆ‘ä»¬å†æ¥çœ‹çœ‹RSE,æˆ‘ä»¬ä¹‹å‰çŸ¥é“, RSEè¶Šå°è¶Šå¥½
<ul class="org-ul">
<li>åªæœ‰TVçš„modelçš„RSEä¸º3.26</li>
<li>TV+radio modelçš„RSEä¸º1.681</li>
<li>TV+radio+newspaper modelçš„RSEä¸º1.686</li>
<li>æˆ‘ä»¬çœ‹åˆ°,å†å¢åŠ äº†ä¸€ä¸ªvariable newspaperä¹‹å,RSEåè€Œæå‡äº†,è¿™è¯æ˜newspaperç¡®å®æ˜¯ä¸éœ€è¦çš„variable</li>
</ul></li>
<li><p>
é™¤äº†ä¸Šé¢è®¨è®ºçš„RSEå’Œ \(R^2\), æˆ‘ä»¬è¿˜å¯ä»¥æŠŠdataç»™æ‰“å°(plot)å‡ºæ¥,å› ä¸ºå›¾åƒä¼šç»™æˆ‘ä»¬æ›´å¥½çš„æ­ç¤ºé—®é¢˜
</p>
<pre class="example" id="orga8d389f">
Graphical summaries can reveal problems with a model that are not
visible from numerical statistics.
</pre></li>
<li>ä¸‹å›¾å°±æ˜¯ä¸€ä¸ªä¸‰ç»´çš„plot,åŒ…å«äº†TV+radioå’Œsalesä¹‹é—´çš„å…³ç³»
<ul class="org-ul">
<li><p>
å›¾3-5
</p>

<div id="org503619b" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/3-5.png" alt="3-5.png" />
</p>
<p><span class="figure-number">Figure 17: </span>isl/3-5.png</p>
</div></li>
</ul></li>
<li>æˆ‘ä»¬ä»ä¸Šå›¾ä¸­å¯çŸ¥:
<ul class="org-ul">
<li>å¦‚æœå•ç‹¬åªç”¨TV budget,æˆ–è€…å•ç‹¬åªç”¨radio budget,é‚£ä¹ˆä¼šoverestimate sale</li>
<li>å¦‚æœæ··åˆä½¿ç”¨TVå’Œradio,é‚£ä¹ˆä¼šunderestimate sale</li>
<li>è¿™è¯´æ˜non-linear pattern æ— æ³•ç²¾ç¡®çš„ä½¿ç”¨linear regressionæ¥å»ºæ¨¡</li>
<li>è¿™è¯´æ˜äº†ååŒä½œç”¨(synergy or interaction)çš„å­˜åœ¨,ä¹Ÿå°±æ˜¯mediaç»“åˆèµ·æ¥çš„æå‡,æ¯”å•ä¸€çš„mediaå¸¦æ¥
çš„æå‡è¦å¤§</li>
</ul></li>
</ul>
</div>
</li>
<li><a id="orga2ff104"></a>Four: Predictions<br />
<div class="outline-text-5" id="text-3-2-2-4">
<ul class="org-ul">
<li>ä¸€æ—¦æˆ‘ä»¬ç¡®å®šäº†ä½¿ç”¨multiple regression modeläº†,é‚£ä¹ˆä¸‹ä¸€æ­¥å°±æ˜¯åœ¨ä¸€å †predictor \(X_1,X_2,\cdot\cdot\cdot,X_p\)
çš„åŸºç¡€ä¸Šè¿›è¡Œé¢„æµ‹äº†,ä¸‰åè¿™ä¸ªpredictionåŒ…å«äº†å¾ˆå¤šçš„uncertainty:
<ol class="org-ol">
<li>é¦–å…ˆ,æˆ‘ä»¬çš„coefficient estimates \(\hat{\beta_0},\hat{\beta_1},\cdot\cdot\cdot,\hat{\beta_p}\)
åªä¸è¿‡æ˜¯å¯¹çœŸå®å€¼ \(\beta_0,\beta_1,\cdot\cdot\cdot,\beta_p\) çš„é¢„ä¼°å€¼:
<ul class="org-ul">
<li><p>
least squares planeå…¬å¼æ˜¯å¯¹true populationregression planeçš„estimate, least squares planeå…¬å¼å¦‚ä¸‹:
</p>
\begin{equation}
\hat{Y} = \hat{\beta_0} + \hat{\beta_1}X_1 + \cdot\cdot\cdot + \hat{\beta_p}X_p
\end{equation}</li>
<li><p>
true populationregression planeçš„å…¬å¼å¦‚ä¸‹:
</p>
\begin{equation}
f(X) = \beta_0 + \beta_1X_1+\cdot\cdot\cdot+\beta_pX_p
\end{equation}</li>
<li>coefficient estimatesæ—¢ç„¶æ˜¯estimates,é‚£ä¹ˆå°±ä¸å¯èƒ½å®Œå…¨å’ŒçœŸå®å€¼ä¸€è‡´,ä»–ä»¬çš„inaccuracy
å’Œreducible errorç›¸å…³.</li>
<li>æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¡ç®—confidence intervalæ¥åˆ¤æ–­ \hat{Y} å’Œf(X)æœ‰å¤šclose</li>
</ul></li>
<li>åœ¨å®è·µä¸­,æˆ‘ä»¬assume f(X)å°±æ˜¯linear model,å…¶å®æ˜¯ä¸€ç§çŒœæµ‹.å¦‚æœtrue f(X)ä¸æ˜¯linear model
çš„è¯,æˆ‘ä»¬å®é™…ä¸Šå°±å¼•å…¥äº†model bias.
<ul class="org-ul">
<li>æˆ‘ä»¬ä¸€æ—¦ä½¿ç”¨äº†linear model,é‚£ä¹ˆæˆ‘ä»¬estimateçš„,å…¶å®æ˜¯èƒ½å¤Ÿæœ€å¤§åŠªåŠ›fit true f(X) surfaceçš„
linear</li>
<li>ä½†æ˜¯,æˆ‘ä»¬ä¸€èˆ¬å¿½ç•¥è¿™ä¸ªçŸ›ç›¾(discrepancy),ä½¿ç”¨äº†linear model,å°±å‡è®¾linear modelæ˜¯æ­£ç¡®çš„model</li>
</ul></li>
<li>å³ä¾¿æˆ‘ä»¬çŸ¥é“çœŸå®çš„true f(X),ä¹Ÿå°±æ˜¯æˆ‘ä»¬çŸ¥é“äº† \(\beta_0,beta_1,\cdot\cdot\cdot,\beta_p\),æˆ‘ä»¬
ä¹Ÿä¸å¯èƒ½å¾—åˆ°å®Œç¾çš„prediction,å› ä¸ºrandom error \(\varepsilon\) çš„å­˜åœ¨
<ul class="org-ul">
<li>åœ¨ç¬¬2ç« ,æˆ‘ä»¬æŠŠrandom errorå«åširreducible error</li>
<li>Yå’Œ \(\hat{Y}\) åœ¨è·ç¦»,æˆ‘ä»¬ä½¿ç”¨prediction intervalæ¥æ ‡è¯†</li>
<li>prediction intervalæ°¸è¿œæ¯”confidence intervalå®½,å› ä¸ºprediction intervalåŒ…å«äº†å¦‚ä¸‹ä¸¤ä¸ªéƒ¨åˆ†:
<ul class="org-ul">
<li>reducible error: error in estimate for f(x)</li>
<li>irreducible error: uncertainty as to how much an individual point will differ from
the population regression plane</li>
</ul></li>
<li>æˆ‘ä»¬ä½¿ç”¨confidence intervalæ¥é‡åŒ–uncertainty surrounding the average(æ³¨æ„è¿™ä¸ªå¹³å‡)
sale,æ¯”å¦‚èŠ±è´¹100000åœ¨TVå¹¿å‘Š,å¦å¤–èŠ±è´¹20000åœ¨radioå¹¿å‘Šä¸Š,æˆ‘ä»¬çš„confidence intervalä¸º
[10985,11528],ä¹Ÿå°±æ˜¯æ„å‘³ç€,95%çš„æƒ…å½¢ä¸‹,è¿™ä¸ªåŒºé—´åŒ…å«çœŸæ­£çš„f(X)</li>
<li>æˆ‘ä»¬ä½¿ç”¨prediction intervalæ¥é‡åŒ–uncertainty surrounding sales for a particular(æ³¨æ„è¿™ä¸ª
æŒ‡å®š)city.èŠ±è´¹100000åœ¨TV,èŠ±è´¹20000åœ¨radio,å¾—åˆ°95%çš„prediction interval,ä¹Ÿå°±æ˜¯æ„å‘³ç€95%çš„
æƒ…å†µä¸‹,è¿™ä¸ªåŒºé—´åŒ…å«çœŸæ­£çš„Y for this city</li>
<li>prediction intervalç”±äºæ˜¯é¢„æµ‹çš„æŒ‡å®šçš„city,æ‰€ä»¥èŒƒå›´è¦å¤§äºconfidence interval(ä¸åŒlocationçš„
å¹³å‡sales)</li>
</ul></li>
</ol></li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-org7212140" class="outline-3">
<h3 id="org7212140"><span class="section-number-3">3.3.</span> Other Considerations in the Regression Model</h3>
<div class="outline-text-3" id="text-3-3">
</div>
<div id="outline-container-orgb81cadd" class="outline-4">
<h4 id="orgb81cadd"><span class="section-number-4">3.3.1.</span> Qualitative Predictors</h4>
<div class="outline-text-4" id="text-3-3-1">
<ul class="org-ul">
<li>æˆªæ­¢ç›®å‰çš„è®¨è®º,æˆ‘ä»¬assume linear regression modelé‡Œé¢æ‰€æœ‰çš„variableéƒ½æ˜¯quantitative(å®šé‡çš„)</li>
<li>ä½†æ˜¯åœ¨å®è·µä¸­,å¹¶ä¸å…¨æ˜¯è¿™ç§æƒ…å†µ,æ¯”å¦‚æœ‰äº›æ—¶å€™æœ‰äº›predictoræ˜¯qualitative(å®šæ€§çš„)</li>
<li>å›¾3-6å°±æ˜¯è¿™æ ·ä¸€ä¸ªä¾‹å­
<ul class="org-ul">
<li><p>
å›¾3-6
</p>

<div id="org969aec0" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/3-6.png" alt="3-6.png" />
</p>
<p><span class="figure-number">Figure 18: </span>isl/3-6.png</p>
</div></li>
<li>ä¸Šå›¾åŒ…å«çš„æ˜¯Credit data set balance,åŒ…å«ä¸€æ‰¹äººçš„ä¿¡ç”¨å¡çš„å¹³å‡debt,åŒæ—¶åŒ…æ‹¬å¾ˆå¤šå®šé‡çš„æ•°æ®:
<ol class="org-ol">
<li>age</li>
<li>cards</li>
<li>education</li>
<li>income</li>
<li>limit</li>
<li>rating</li>
</ol></li>
<li>æ¯ä¸ªå›¾çš„æ¨ªåæ ‡å’Œçºµåæ ‡éƒ½åˆ—åœ¨å›¾çš„å·¦è¾¹å’Œä¸‹è¾¹</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgc9f69d3" class="outline-4">
<h4 id="orgc9f69d3"><span class="section-number-4">3.3.2.</span> Predictors with Only Two Levels</h4>
<div class="outline-text-4" id="text-3-3-2">
<ul class="org-ul">
<li>å‡è®¾æˆ‘ä»¬å¸Œæœ›è°ƒæŸ¥å¦‚ä¸‹ä¸¤è€…çš„å…³ç³»(å¿½ç•¥å…¶ä»–çš„variable):
<ul class="org-ul">
<li>creadit card balance</li>
<li>æ€§åˆ«</li>
</ul></li>
<li><p>
å¦‚æœqualitative predictor(åˆåfactor)åªæœ‰ä¸¤ä¸ªlevel,é‚£ä¹ˆæƒ³æŠŠè¿™ç§variableæ•´åˆè¿›regression model
å°±éå¸¸ç®€å•:åˆ›å»ºä¸€ä¸ªdummy variableåªæœ‰ä¸¤ä¸ªnumerical value,æ¯”å¦‚,å¯¹äºgender variable,æˆ‘ä»¬å¯ä»¥åˆ›å»º
ä¸€ä¸ªæ–°çš„variable,å…¶æ ·å¼å¦‚ä¸‹
</p>
\begin{equation}
x_i =
   \begin{cases}
   1 &\text{if ith person is female} \\
   0 &\text{if ith person is male} \tag{3.26}
   \end{cases}
\end{equation}</li>
<li><p>
ä½¿ç”¨ä¸Šé¢çš„variableä½œä¸ºpredictoråœ¨regressionå…¬å¼å½“ä¸­,ä¼šå¾—åˆ°å¦‚ä¸‹çš„model
</p>
\begin{equation}
y_i = \beta_0 + \beta_1x_i + \varepsilon_i =
   \begin{cases}
   \beta_0 + \beta_1 + \varepsilon_i &\text{if ith person is female} \\
   \beta_0 + \varepsilon_i &\text{if ith person is male} \tag{3.27}
   \end{cases}
\end{equation}</li>
<li>é’ˆå¯¹è¿™ä¸ªmodel,æˆ‘ä»¬å¯ä»¥å¾—åˆ°:
<ul class="org-ul">
<li>\(\beta_0\) å°±å¯ä»¥è§£é‡Šä¸ºmaleä¸­çš„å¹³å‡credit card balance</li>
<li>\(\beta_1\) å°±å¯ä»¥è§£é‡Šä¸ºmaleå’Œfemaleçš„credit card balanceå·®å€¼</li>
</ul></li>
<li><p>
å…¬å¼3.27å®šä¹‰çš„æ¨¡å‹çš„coefficientå€¼å¦‚ä¸‹
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Coefficient</th>
<th scope="col" class="org-right">Std.error</th>
<th scope="col" class="org-right">t-statistic</th>
<th scope="col" class="org-left">p-value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Intercept</td>
<td class="org-right">509.80</td>
<td class="org-right">33.13</td>
<td class="org-right">15.389</td>
<td class="org-left">&lt;0.0001</td>
</tr>

<tr>
<td class="org-left">gender[Femaile]</td>
<td class="org-right">19.73</td>
<td class="org-right">46.05</td>
<td class="org-right">0.429</td>
<td class="org-left">0.6690</td>
</tr>
</tbody>
</table></li>
<li>maleçš„å¹³å‡è´¦å•æ˜¯509.80,femaleåœ¨æ­¤åŸºç¡€ä¸Šå¢åŠ 19.73</li>
<li>ä½†æ˜¯æˆ‘ä»¬å‘ç°dummy variableçš„p-valueéå¸¸çš„é«˜,è¿™è¯´æ˜æ€§åˆ«é—´çš„ä¿¡ç”¨å¡è´¦å•,æ²¡æœ‰ç»Ÿè®¡å­¦ä¸Šçš„ä¸åŒ</li>
<li>æœ‰äº›åŒå­¦å¯èƒ½è§‰å¾—æ˜¯ä¸æ˜¯æŠŠfemaleä»1å˜æˆ0, maleä»0å˜æˆ1,èƒ½å¤Ÿæœ‰æ‰€æ”¹å˜,å…¶å®è¿™æ˜¯ä¸å¯¹çš„.æ— è®ºæ€ä¹ˆé€‰,éƒ½
ä¼šå¾—åˆ°ç›¸åŒçš„ç»“æœ(æ€§åˆ«å’Œè´¦å•æ²¡æœ‰ç»Ÿè®¡å­¦æ„ä¹‰)</li>
<li><p>
åŒæ ·çš„æˆ‘ä»¬å³ä¾¿ä½¿ç”¨ä¸åŒçš„coding schema,ä¹‹å‰æˆ‘ä»¬ä½¿ç”¨æ˜¯0/1 coding schema,æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨-1/1 coding schema
</p>
\begin{equation}
x_i =
   \begin{cases}
   1 &\text{if ith person is female} \\
   -1 &\text{if ith person is male}
   \end{cases}
\end{equation}</li>
<li><p>
ä½¿ç”¨è¿™ä¸ªvariable,æˆ‘ä»¬å¾—åˆ°çš„regression equation,å¦‚ä¸‹
</p>
\begin{equation}
y_i = \beta_0 + \beta_1x_i + \varepsilon_i =
   \begin{cases}
   \beta_0 + \beta_1 + \varepsilon_i &\text{if ith person is female} \\
   \beta_0 - \beta_1 + \varepsilon_i &\text{if ith person is male}
   \end{cases}
\end{equation}</li>
<li>æ¢æˆä¸Šé¢çš„æ¨¡å‹å,æˆ‘ä»¬å¯¹ \(\beta_0\) å’Œ \(\beta_1\) çš„è§£é‡Šå¦‚ä¸‹:
<ul class="org-ul">
<li>\(\beta_0\) å¯ä»¥è¢«è§£é‡Šä¸ºoverall average credit card balance(å¿½ç•¥æ€§åˆ«)</li>
<li>\(\beta_1\) æ˜¯femaleæ¯”maleé«˜çš„amount</li>
</ul></li>
<li><p>
å†æ¬¡å¼ºè°ƒ,æ— è®ºdummy variableæ›´æ”¹æˆä»€ä¹ˆå½¢å¼, preditionçš„ç»“æœéƒ½æ˜¯ä¸å˜çš„!
</p>
<pre class="example" id="org63c8829">
The final predictions for the credit balances of males and females
will be identical regardless of the coding scheme used. The only
difference is in the way that the coefficients are interpreted
</pre></li>
</ul>
</div>
</div>
<div id="outline-container-org47f0cc4" class="outline-4">
<h4 id="org47f0cc4"><span class="section-number-4">3.3.3.</span> Qualitative Predictors with More than Two Levels</h4>
<div class="outline-text-4" id="text-3-3-3">
<ul class="org-ul">
<li>å½“æˆ‘ä»¬çš„qualitative predictoræ‹¥æœ‰è¶…è¿‡ä¸¤ä¸ªlevel(å¤šä¸ªå¯èƒ½çš„å€¼)çš„æ—¶å€™,æˆ‘ä»¬å°±ä¸èƒ½ç”¨ä¸€ä¸ªdummy variable
æ¥ä»£è¡¨æ‰€æœ‰çš„possible valueäº†.</li>
<li>æˆ‘ä»¬éœ€è¦åˆ›å»ºadditional dummy variableäº†.æ¯”å¦‚ç§æ—ä¸æ˜¯ä¸€ä¸¤ä¸ª,è€Œæ˜¯å¾ˆå¤šä¸ª(ä¹Ÿå°±æ˜¯ä¸‰ä¸ª,é»„ç§äºº,ç™½ç§äºº,
é»‘ç§äºº),é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸¤ä¸ªdummy variable:
<ul class="org-ul">
<li><p>
variable \(x_{i1}\)
</p>
\begin{equation}
x_{i1} =
   \begin{cases}
   1 &\text{if ith person is Asian} \\
   0 &\text{if ith person is not Asian}
   \end{cases}
\end{equation}</li>
<li><p>
variable \(x_{i2}\)
</p>
\begin{equation}
x_{i2} =
   \begin{cases}
   1 &\text{if ith person is Caucasian} \\
   0 &\text{if ith person is not Caucasian}
   \end{cases}
\end{equation}</li>
<li><p>
æŠŠè¿™ä¸¤ä¸ªvariableéƒ½å¸¦å…¥åˆ°æˆ‘ä»¬çš„å…¬å¼,å¾—åˆ°æ–°çš„regression equation
</p>
\begin{equation}
y_i = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + \varepsilon_i =
   \begin{cases}
   \beta_0 + \beta_1 + \varepsilon_i &\text{if ith person is Asian} \\
   \beta_0 + \beta_2 + \varepsilon_i &\text{if ith person is Caucasian} \\
   \beta_0 + \varepsilon_i &\text{if ith person is African American}
   \end{cases}
\end{equation}</li>
<li>ç°åœ¨æˆ‘ä»¬å†æ¥åœ¨å½“å‰çš„è¯­å¢ƒä¸‹,ç†è§£ä¸‹ä¸Šé¢çš„å‡ ä¸ªcoefficient:
<ol class="org-ol">
<li>\(\beta_0\) å¯ä»¥è§£é‡Šä¸ºé»‘äººçš„å¹³å‡ä¿¡ç”¨å¡è´¦å•æ•°ç›®</li>
<li>\(\beta_1\) å¯ä»¥è§£é‡Šä¸ºé»„ç§äººä¿¡ç”¨å¡è´¦å•æ•°ç›®å’Œé»‘äººä¿¡ç”¨å¡è´¦å•æ•°ç›®çš„å·®å€¼</li>
<li>\(\beta_1\) å¯ä»¥è§£é‡Šä¸ºç™½ç§äººä¿¡ç”¨å¡è´¦å•æ•°ç›®å’Œé»‘äººä¿¡ç”¨å¡è´¦å•æ•°ç›®çš„å·®å€¼</li>
</ol></li>
</ul></li>
<li>é€šè¿‡ä¸Šé¢çš„ä¾‹å­,æˆ‘ä»¬å¯ä»¥çœ‹åˆ°. dummy variable(2ä¸ª)æ€»æ¯”level(3ä¸ªäººç§)å°‘ä¸€ä¸ª,è€Œæ²¡æœ‰variableçš„é‚£ä¸ª
level(è¿™é‡Œå°±æ˜¯é»‘äºº)å«åšbaseline</li>
<li>åŒæ ·éœ€è¦æ³¨æ„çš„æ˜¯,baselineé€‰æ‹©å“ªä¸ªéƒ½ä¸€æ ·,éƒ½ä¸ä¼šå½±å“æœ€åçš„ç»“æœ</li>
<li><p>
ä¸Šé¢æ¨¡å‹çš„coefficientå¦‚ä¸‹
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Coefficient</th>
<th scope="col" class="org-right">Std. error</th>
<th scope="col" class="org-right">t-statistic</th>
<th scope="col" class="org-right">p-value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Intercept</td>
<td class="org-right">531.00</td>
<td class="org-right">46.32</td>
<td class="org-right">11.464</td>
<td class="org-right">&lt; 0.0001</td>
</tr>

<tr>
<td class="org-left">Asian</td>
<td class="org-right">-18.69</td>
<td class="org-right">65.02</td>
<td class="org-right">-0.287</td>
<td class="org-right">0.7740</td>
</tr>

<tr>
<td class="org-left">Caucasian</td>
<td class="org-right">-12.50</td>
<td class="org-right">56.68</td>
<td class="org-right">-0.221</td>
<td class="org-right">0.8260</td>
</tr>
</tbody>
</table></li>
<li>æ ¹æ®ä¸Šé¢çš„è¡¨æ ¼æˆ‘ä»¬å¯ä»¥çŸ¥é“:
<ul class="org-ul">
<li>é»‘äººçš„å¹³å‡ä¿¡ç”¨å¡è´¦å•æ˜¯531ç¾å…ƒ</li>
<li>é»„ç§äººå¹³å‡è´¦å•æ¯”é»‘äººå°‘18.69ç¾å…ƒ</li>
<li>ç™½äººå¹³å‡è´¦å•æ¯”é»‘äººå°‘12.50ç¾å…ƒ</li>
</ul></li>
<li>ä½†æ˜¯ä¸¤ä¸ªdummy variableçš„p-valueç‰¹åˆ«çš„é«˜,ä¹Ÿå°±æ˜¯è¯´è¿™ä¸ªå‡è®¾åœ¨ç»Ÿè®¡å­¦ä¸Šä¸æˆç«‹</li>
<li>å‰é¢è¯´è¿‡,é€‰æ‹©å“ªä¸ªbaseline,ä¸ä¼šå½±å“predictionçš„ç»“æœ,ä½†æ˜¯: coefficientå’Œp-valueç¡®å®ä¼šè¢«dummy
variable coding</li>
<li><p>
å¦‚æœä¸æƒ³ä¾èµ–å•ä¸ªcoefficient,æˆ‘ä»¬å¯ä»¥ä½¿ç”¨F-testæ¥æµ‹è¯•å¦‚ä¸‹å…¬å¼(è¿™ä¸ªä¸ä¾èµ–äºcoding):
</p>
\begin{equation}
H_0 : \beta_1 = \beta_2 = 0
\end{equation}</li>
<li>F-testçš„ç»“æœæ˜¯0.96,ä¹Ÿå°±æ„å‘³ç€æˆ‘ä»¬ä¸èƒ½reject null hypothesis(balanceå’Œç§æ—æœ‰å…³ç³»)</li>
<li>ä½¿ç”¨è¿™ç§dummy variableçš„åŠæ³•,åœ¨é¢å¯¹å®šé‡å’Œå®šæ€§çš„predictoræ—¶,éƒ½æ²¡æœ‰é—®é¢˜</li>
<li>é™¤äº†dummy variable, è¿˜æœ‰å¾ˆå¤šcoding qualitative variableçš„åŠæ³•,è¿™äº›ä¸åŒçš„åŠæ³•éƒ½ä¼šå¾—åˆ°model fit,
ä½†æ˜¯coefficientçš„è§£é‡Šæ˜¯ä¸ä¸€æ ·çš„</li>
</ul>
</div>
</div>
<div id="outline-container-orgf39078e" class="outline-4">
<h4 id="orgf39078e"><span class="section-number-4">3.3.4.</span> Extensions of the Linear Model</h4>
<div class="outline-text-4" id="text-3-3-4">
<ul class="org-ul">
<li>æ ‡å‡†çš„linear regression(å…¬å¼3-19),æä¾›äº†å¯è§£é‡Šçš„result,å¹¶ä¸”åœ¨å¾ˆå¤šreal-worldé—®é¢˜ä¸Šé¢å·¥ä½œçš„å¾ˆå¥½,
ä½†æ˜¯,è¿™æ˜¯å»ºç«‹åœ¨å¾ˆå¤šæç«¯å‡è®¾(highly restrictive assumptions)çš„åŸºç¡€ä¸Šçš„, è€Œä¸”è¿™äº›å‡è®¾åœ¨å®è·µå½“ä¸­
è¿˜å¾ˆå®¹æ˜“è¢«violated</li>
<li>æœ€é‡è¦çš„ä¸¤ä¸ªå‡è®¾(assumption)æ˜¯, predictorå’Œresponseä¹‹é—´çš„å…³ç³»æ˜¯:
<ul class="org-ul">
<li>æ—¢additive: è¿™ä¸ªassumptionæ„å‘³ç€,ä¸åŒpredictorä¹‹é—´çš„æ˜¯ç›¸äº’ç‹¬ç«‹çš„(independent)</li>
<li>åˆlinear: è¿™ä¸ªassumptionæ„å‘³ç€,ä¸€ä¸ªunitçš„ \(X_j\) çš„å¢é•¿,ä¼šå¸¦æ¥constçš„Yçš„å¢é•¿</li>
</ul></li>
<li>æœ¬ä¹¦æˆ‘ä»¬ä¼šå¸¦å¤§å®¶è®¤è¯†ä¸€äº›sophisticatedçš„method,è¿™äº›method,ä¼šrelaxè¿™ä¸¤ä¸ªassumption</li>
<li>è¿™é‡Œæˆ‘ä»¬å…ˆçœ‹ä¸€äº›method,è¿™äº›method:
<ul class="org-ul">
<li>æ˜¯å¯¹linear modelçš„æ‰©å±•</li>
<li>åŒæ—¶è¿˜relaxäº†è¿™ä¸¤ä¸ªassumption</li>
</ul></li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orge86586a"></a>Removing the Additive Assumption<br />
<div class="outline-text-5" id="text-3-3-4-1">
<ul class="org-ul">
<li>åœ¨å‰é¢çš„Advertising dataçš„åˆ†æå½“ä¸­,æˆ‘ä»¬æ€»ç»“åˆ°TVå’Œradioéƒ½å’Œsalesæœ‰å…³ç³»</li>
<li>è¿™ä¸ªconclusion,åŸºäºå¦‚ä¸‹çš„ä¸¤ä¸ª:
<ul class="org-ul">
<li>æ¯ä¸ªå¹¿å‘Šåª’ä½“(æ¯”å¦‚TV, radio)å¯¹äºsalesçš„ä½œç”¨éƒ½æ˜¯ç›¸äº’ç‹¬ç«‹çš„.ä½†æ˜¯è¿™ä¸ªå‡è®¾å¾ˆå¯èƒ½æ˜¯ä¸æˆç«‹çš„:
<ol class="org-ol">
<li>åŒæ ·æœ‰10ä¸‡ç¾å…ƒ,æˆ‘ä»¬å¯ä»¥å…¨éƒ¨æŠ•åœ¨TVä¸Š,æˆ–è€…å…¨éƒ¨æŠ•åœ¨radioä¸Š,æˆ–è€…ä¸€åŠTV,ä¸€åŠradioä¸Š</li>
<li>å®è·µè¯æ˜ä¸€åŠTV,ä¸€åŠradioå¾—åˆ°çš„salesæœ€é«˜</li>
<li>åœ¨å¸‚åœºè¥é”€é¢†åŸŸè¿™ä¸ªç°è±¡å«åšsynergy effect,åœ¨ç»Ÿè®¡å­¦é¢†åŸŸ,è¿™ä¸ªç°è±¡å«åšinteraction effect</li>
<li>æˆ‘ä»¬ä»å›¾3-5ä¹Ÿèƒ½çœ‹åˆ°:
<ul class="org-ul">
<li>å½“æ€»é’±æ•°ä¸€å®šçš„æƒ…å†µä¸‹,å¦‚æœTV,radioçš„æŸä¸€ä¸ªæ¯”ä¾‹ä½çš„è¯(æ¯”å¦‚10%å’Œ90%), salesä¼šæ¯”predictionä½</li>
<li>å½“æ€»é’±æ•°ä¸€å®šçš„æƒ…å†µä¸‹,å¦‚æœTV,radioåˆ†çš„æ¯”è¾ƒå‡åŒ€çš„è¯(æ¯”å¦‚50%å’Œ50%), salesä¼šæ¯”predictioné«˜</li>
</ul></li>
</ol></li>
<li>æ¯ä¸€ä¸ªunitçš„å¹¿å‘Šåª’ä½“(æ¯”å¦‚TV, radio)è´¹ç”¨çš„å¢åŠ ,salesä¼šè·å–constçš„å¢åŠ .æˆ‘ä»¬å¯ä»¥ä»å¦‚ä¸‹å…¬å¼ä¸­çœ‹åˆ°
<ul class="org-ul">
<li><p>
å…¬å¼
</p>
\begin{equation}
Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \varepsilon
\end{equation}</li>
<li>é€šè¿‡ä¸Šé¢å…¬å¼æˆ‘ä»¬å¯ä»¥çœ‹åˆ°,å¦‚æœ \(X_1\) å¢åŠ ä¸€ä¸ªunit,é‚£ä¹ˆYå°±å¢åŠ  \(\beta_1\) unit, \(X_2\) å®Œå…¨æ²¡
æœ‰å‚ä¸è¿›æ¥</li>
<li><p>
å¦‚æœæˆ‘ä»¬æƒ³è®© \(X_2\) å‚ä¸è¿›æ¥(å…è®¸interaction effect),é‚£ä¹ˆæˆ‘ä»¬å°±è¦å¼•å…¥ç¬¬ä¸‰ä¸ªpredictor,å«åš
interaction term,å¦‚ä¸‹
</p>
\begin{equation}
Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_1X_2 + \varepsilon
\end{equation}</li>
</ul></li>
</ul></li>
<li><p>
æˆ‘ä»¬æŠŠå¼•å…¥ç¬¬ä¸‰ä¸ªpredictorçš„ä¾‹å­å¥—ç”¨åˆ°Advertisingçš„ä¾‹å­ä¸Šé¢,å¾—åˆ°å¦‚ä¸‹
</p>
\begin{equation}
\tag{3.33}
\begin{split}
sales = \beta_0 + \beta_1 \times TV + \beta_2 \times radio + \beta_3 \times ( radio \times TV) + \varepsilon\\
      = \beta_0 + (\beta_1 + \beta_3 \times  radio) \times TV + \beta_2 \times radio  + \varepsilon.
\end{split}
\end{equation}</li>
<li>è¿™é‡Œ,æˆ‘ä»¬å°±å¯ä»¥æŠŠ \(\beta_3\) è§£é‡Šä¸ºä¸€ä¸ªunitçš„radioçš„æå‡å¸¦æ¥çš„é˜ŸTVçš„æå‡</li>
<li><p>
ä¸‹é¢æ˜¯å…¬å¼3.33çš„çš„coefficient
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Coefficient</th>
<th scope="col" class="org-right">Std.error</th>
<th scope="col" class="org-right">t-statistic</th>
<th scope="col" class="org-left">p-value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Intercept</td>
<td class="org-right">6.7502</td>
<td class="org-right">0.248</td>
<td class="org-right">27.23</td>
<td class="org-left">&lt; 0.0001</td>
</tr>

<tr>
<td class="org-left">TV</td>
<td class="org-right">0.0191</td>
<td class="org-right">0.002</td>
<td class="org-right">12.70</td>
<td class="org-left">&lt; 0.0001</td>
</tr>

<tr>
<td class="org-left">radio</td>
<td class="org-right">0.0289</td>
<td class="org-right">0.009</td>
<td class="org-right">3.24</td>
<td class="org-left">0.0014</td>
</tr>

<tr>
<td class="org-left">TV * radio</td>
<td class="org-right">0.0011</td>
<td class="org-right">0.000</td>
<td class="org-right">20.73</td>
<td class="org-left">&lt; 0.0001</td>
</tr>
</tbody>
</table></li>
<li>ä»ä¸Šè¡¨ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°:
<ul class="org-ul">
<li>åŒ…å«interaction termçš„modelè¦å¼ºäº</li>
<li>åªåŒ…å«main effectçš„model</li>
</ul></li>
<li><p>
interaction term (TV * radio)æœ‰éå¸¸å°çš„p-value,ä¹Ÿå°±è¯´æˆ‘ä»¬æœ‰strong evidenceä¸‹é¢çš„å…¬å¼æˆç«‹
</p>
\begin{equation}
H_a : \beta_3 \neq 0
\end{equation}</li>
<li>æ¢å¥è¯è¯´,å¾ˆæ˜æ˜¾çš„true relationä¸å¯èƒ½æ˜¯additiveçš„</li>
<li>æ¨¡å‹(å…¬å¼3.33)çš„ \(R^2\) ä¸º96.8%, è€Œæ²¡æœ‰åŠ å…¥interaction termçš„æ¨¡å‹çš„ \(R^2\) å€¼ä¸º89.7%,è¿™è¯´æ˜
å¾ˆå¤šåœ¨additive modelä¸­ä¸èƒ½è§£é‡Šçš„éƒ¨åˆ†,è¢«interaction termç»™è§£é‡Šäº†</li>
<li>ä¸Šé¢çš„è¡¨æ ¼æˆ‘ä»¬çœ‹åˆ°äº†,å¦‚ä¸‹ä¸¤ç§variableçš„p-valueéƒ½å¾ˆä½:
<ul class="org-ul">
<li>main effect (TV, radio)</li>
<li>interaction term</li>
</ul></li>
<li><p>
ä½†æ˜¯åœ¨å¾ˆå¤šæƒ…å†µä¸‹,interaction termçš„p-valueå¾ˆä½,ä½†æ˜¯main effectå´ä¸ä½.å³ä¾¿æ˜¯è¿™ç§æƒ…å†µä¸‹,æˆ‘ä»¬çš„
æ¨¡å‹è¿˜æ˜¯è¦åŒ…æ‹¬main effect.è¿™æ˜¯ç”±hierarchical principleå†³å®šçš„
</p>
<pre class="example" id="orgd94fdb1">
Hierarchical principle states that if we include an interaction in a model,
we should also include the main effects, even if the p-values associated
with their coefficients are not significant.
</pre></li>
<li>interaction ä¸ä»…ä»…èƒ½å¤Ÿä½œç”¨äºå®šé‡çš„variableä¹‹é—´,è¿˜å¯ä»¥ä½œç”¨äºå®šé‡çš„variableå’Œå®šæ€§çš„variableä¹‹é—´</li>
</ul>
</div>
</li>
<li><a id="org72190e3"></a>Non-linear Relationships<br />
<div class="outline-text-5" id="text-3-3-4-2">
<ul class="org-ul">
<li>å‰é¢çš„å‡è®¾ä¹‹ä¸€æ˜¯additive,å‡è®¾ä¹‹äºŒå°±æ˜¯linear,ä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬è®¤å®šæˆ‘ä»¬çš„predictorå’Œresponseä¹‹é—´æ˜¯çº¿
æ€§çš„å…³ç³». ä½†æ˜¯å¾ˆå¤šæƒ…å†µä¸‹,çœŸå®çš„relationshipå…¶å®çœŸçš„ä¸ä¸€å®šæ˜¯linearçš„</li>
<li>æˆ‘ä»¬è¿™é‡Œå…ˆä½¿ç”¨ä¸€ä¸ªæœ€ç®€å•æŠŠlinear modelæ‰©å±•åˆ°non-linear relationshipçš„æ–¹æ³•,å«åšpolynomial regression</li>
<li>æˆ‘ä»¬çœ‹ä¸‹å›¾3-8
<ul class="org-ul">
<li><p>
å›¾3-8
</p>

<div id="org36895c7" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/3-8.png" alt="3-8.png" />
</p>
<p><span class="figure-number">Figure 19: </span>isl/3-8.png</p>
</div></li>
<li>è¿™æ˜¯ä¸€ä¸ªAutoçš„dataset,è¡¨ç¤ºçš„æ˜¯å¦‚ä¸‹ä¸¤ä¸ªvariableçš„å…³ç³»:
<ol class="org-ol">
<li>mpg:æ¯åŠ ä»‘è·‘çš„mileæ•°ç›®</li>
<li>horsepower:é©¬åŠ›</li>
</ol></li>
<li>å›¾ä¸­çš„æ¡”é»„è‰²çº¿è¡¨ç¤ºçš„æ˜¯linear regression fit</li>
<li>ä»å›¾ä¸­æˆ‘ä»¬å¾ˆæ˜æ˜¾çš„çœ‹åˆ°mpgå’Œhorsepoweræ˜æ˜¾æ˜¯æœ‰å…³ç³»çš„,ä½†æ˜¯ä»ç‚¹çš„åˆ†å¸ƒæ¥çœ‹,æ›´åƒæ˜¯æ›²çº¿,è€Œéç›´çº¿</li>
<li>æœ€ç®€å•çš„åœ¨linear modelåŸºç¡€ä¸Šå¼•å…¥non-linear modelçš„æ–¹æ³•,æ˜¯ä½¿ç”¨transformed version of predictor</li>
<li><p>
æ¯”å¦‚å›¾3-8,çœ‹èµ·æ¥åƒæ˜¯ä¸€ä¸ªäºŒæ¬¡æ–¹çš„shape,é‚£ä¹ˆæˆ‘ä»¬æŠŠhorsepowerçš„å¹³æ–¹å¼•å…¥åˆ°modelé‡Œé¢,å¾—åˆ°
</p>
\begin{equation}
mpg = \beta_0 + \beta_1 \times horsepower + \beta_2 \times horsepower^2 + \varepsilon \tag{3.36}
\end{equation}</li>
<li>æˆ‘ä»¬è¿™é‡Œä½¿ç”¨äº†non-linearçš„function,ä½†æ˜¯æˆ‘ä»¬çš„modelç¡®å®è¿˜æ˜¯èƒ½å¤Ÿçœ‹åšæ˜¯linear model,å› ä¸ºæˆ‘ä»¬å¯
ä»¥è¿™æ ·ç†è§£æˆ‘ä»¬çš„æ¨¡å‹:
<ol class="org-ol">
<li>\(X_1=horsepower\)</li>
<li>\(X_2=horsepower^2\)</li>
</ol></li>
<li>è¿™ä¸ªæ¨¡å‹æ—¢ç„¶è¿˜æ˜¯linear model,é‚£ä¹ˆæˆ‘ä»¬è¿˜æ˜¯å¯ä»¥ä½¿ç”¨standard linear regression softwareæ¥é¢„æµ‹coefficient:
\(\beta_0, \beta_1, \beta_2\). è¿™ä¸ªæ¨¡å‹å°±æ˜¯æ‰€è°“çš„linear model with non-linear fit</li>
<li>å›¾3-8ä¸­çš„blueçº¿å°±è¡¨ç¤ºäº†äºŒæ¬¡æ–¹çš„fit</li>
<li>è“è‰²çš„äºŒæ¬¡æ–¹fitä»å›¾ä¸­çœ‹å‡ºæ¥çš„åŒ¹é…æ•ˆæœå°±å¥½äºæ¡”é»„è‰²çš„linear model fit:
<ol class="org-ol">
<li>è“è‰²äºŒæ¬¡æ–¹fitçš„ \(R^2\) å€¼(0.688)ä¹Ÿæ˜¯è¦é«˜äºlinear fitçš„(0.606)</li>
<li>æ–°æ¨¡å‹çš„p-valueä¹Ÿéå¸¸çš„ä½</li>
</ol></li>
<li>å¼•å…¥ \(horsepower^2\) å°±å¸¦æ¥äº†å¯¹modelçš„improvement,é‚£ä¹ˆå¾ˆè‡ªç„¶çš„è¯,æˆ‘ä»¬ä¼šæƒ³æƒ³åˆ°å¼•å…¥ \(horsepower^3, horsepower^4, horsepower^5\)
å›¾3-8ä¸­çš„greençº¿å°±æ˜¯å¼•å…¥äº†\(horsepower^3, horsepower^4, horsepower^5\) ä¹‹åçš„ç»“æœ.ä½†æ˜¯æˆ‘ä»¬çœ‹åˆ°è¿™ä¸ªæ•ˆæœå¹¶ä¸å¥½(æ¨¡å‹è¿‡äºå˜åŒ–è«æµ‹),
ä¹Ÿå°±æ˜¯è¯´å¹¶ä¸æ˜¯å¼•å…¥æ›´é«˜levelå°±èƒ½å¾—åˆ°æ›´å¥½çš„model</li>
</ul></li>
<li>ä¸Šé¢è¿™ç§æ‰©å±•linear modelæ¥é€‚åº”non-linear relationshipçš„approachå«åšpolynomial regression(å› ä¸ºå¼•å…¥äº†polynomial function)</li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org973c2ae" class="outline-4">
<h4 id="org973c2ae"><span class="section-number-4">3.3.5.</span> Potential Problems</h4>
<div class="outline-text-4" id="text-3-3-5">
<ul class="org-ul">
<li>å½“ä½¿ç”¨linear regression modelæ¥fitä¸€ä¸ªç‰¹å®šçš„data set çš„æ—¶å€™,å¾ˆå¤šé—®é¢˜éƒ½ä¼šå‘ç”Ÿ,æœ€å¸¸è§çš„é—®é¢˜æœ‰:
<ul class="org-ul">
<li>Non-linearity of the response-predictor relationships</li>
<li>Correlation of error term</li>
<li>Non-constant variance of error terms.</li>
<li>outliers</li>
<li>High-leverage points</li>
<li>Collinearity</li>
</ul></li>
<li>å®è·µå½“ä¸­,åˆ†è¾¨å¹¶ä¸”å¤„ç†è¿™äº›é—®é¢˜æ—¢æ˜¯ç§‘å­¦,åˆæ˜¯è‰ºæœ¯.ä¸‹é¢æˆ‘ä»¬ç®€è¦åˆ†æä¸‹è¿™å‡ ä¸ªå†…å®¹</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orga061177"></a>Non-linearity of the Data<br />
<div class="outline-text-5" id="text-3-3-5-1">
<ul class="org-ul">
<li>linear regression modelçš„æˆåŠŸ,æœ‰ä¸€ä¸ªå‡è®¾:åœ¨predictorå’Œresponseä¹‹é—´,å­˜åœ¨çš„æ˜¯straight-line
relationship</li>
<li>å¦‚æœtrue relationshipä¸æ˜¯linear,è€Œä¸”å’Œlinearç›¸è·ç”šè¿œçš„è¯,é‚£ä¹ˆæˆ‘ä»¬ä»è¿™çº¿æ€§æ¨¡å‹è·å¾—çš„conclusion
éƒ½æ˜¯ç«™ä¸ä½è„šçš„.ä»è¿™ä¸ªmodelè·å¾—çš„predictionnçš„å‡†ç¡®ç‡ä¹Ÿä¼šå¤§æ‰“æŠ˜æ‰£</li>
<li>æ®‹å·®å›¾(Residual plots) æ˜¯éå¸¸æœ‰æ•ˆçš„åˆ¤æ–­non-linearityçš„æœ‰æ•ˆgraphical toolæ‰‹æ®µ.æ‰€è°“æ®‹å·®å›¾,è¿™ä¹ˆä¸€ç§å›¾:
<ul class="org-ul">
<li>åœ¨çºµè½´æ˜¾ç¤ºresidual(\(y_i - \hat{y_i}\))</li>
<li>æ¨ªè½´æ˜¾ç¤ºindependent variable(æ³¨æ„,ä¸ä¸€å®šæ˜¯predictor, åœ¨predictoræ˜¯å¤šä¸ªçš„æƒ…å†µä¸‹,å¯ä»¥ä½¿ç”¨prediction,
ä¹Ÿå°±æ˜¯ \(\hat{y_i}\) )</li>
</ul></li>
<li>å¯¹æ®‹å€¼å›¾çš„åˆ¤æ–­å¾ˆæœ‰æ„æ€:
<ul class="org-ul">
<li>å¦‚æœæ®‹å€¼å›¾çš„pointæ˜¯éšæœºçš„åˆ†é…å†æ¨ªåæ ‡ä¸Šé¢çš„,é‚£ä¹ˆè¿™ä¸ªæ•°æ®å°±æ˜¯ä¸€ä¸ªregression data,å¦‚ä¸‹</li>
<li>å¦‚æœæ®‹å€¼å›¾çš„pointæ˜¯æˆnon-randomçš„åˆ†é…(æ¯”å¦‚Uå½¢,æˆ–è€…å€’Uå‹çš„åˆ†é…),é‚£ä¹ˆè¯´æ˜è¿™æ˜¯ä¸€ä¸ªnonlinear model</li>
</ul></li>
<li>çœ‹æˆ‘ä»¬çš„ä¾‹å­:
<ul class="org-ul">
<li><p>
å›¾3-9
</p>

<div id="orgb44e164" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/3-9.png" alt="3-9.png" />
</p>
<p><span class="figure-number">Figure 20: </span>isl/3-9.png</p>
</div></li>
<li>å·¦è¾¹çš„æ®‹å€¼å›¾(linear regression for Auto data set)ä¸ºæ˜æ˜¾çš„Uå‹(çº¢è‰²æ˜¯smooth fit,ç”¨æ¥åˆ¤æ–­trend),è¯´æ˜æ•°æ®æ˜¯éçº¿æ€§çš„</li>
<li>å³è¾¹çš„æ®‹å€¼å›¾(model contains quadratic term),åˆ™æ˜¯æ˜¯æ²¡æœ‰ä»€ä¹ˆpattern(æ¯”è¾ƒrandom),è¯´æ˜quadratic termå¢è¿›äº†data fit</li>
</ul></li>
<li>ä¸€æ—¦ä½¿ç”¨äº†æ®‹å·®å›¾å‘ç°dataä¸æ˜¯linear association,é‚£ä¹ˆæœ€ç®€å•çš„æ–¹æ³•å°±æ˜¯å¯¹predictorä½¿ç”¨non-linear
transformation,æ¯”å¦‚ \(logX, \sqrt{X}, X^2\)</li>
</ul>
</div>
</li>
<li><a id="orgbb7570a"></a>Correlation of Error Terms<br />
<div class="outline-text-5" id="text-3-3-5-2">
<ul class="org-ul">
<li>å¯¹çº¿æ€§æ¨¡å‹æ¥è¯´,ä¸€ä¸ªé‡è¦çš„assumptionæ˜¯error term( \(\varepsilon_1, \varepsilon_2,...\varepsilon_n\)) ä¹‹é—´æ˜¯uncorrelatedçš„.è¿™å°±æ„å‘³ç€:
<ul class="org-ul">
<li><p>
å¦‚æœerror term( \(\varepsilon_1, \varepsilon_2,...\varepsilon_n\)) ä¹‹é—´æ˜¯uncorrelatedçš„,é‚£ä¹ˆ
\(\varepslionj_i\) æ˜¯positive,å°±ä¸èƒ½ä¸º \(\varepslionj_i+1\) æ˜¯æ­£è¿˜æ˜¯è´Ÿæä¾›ä»»ä½•çš„å¸®åŠ©
</p>
<pre class="example" id="orgcc16001">
If the errors are uncorrelated, then the fact that e_i is positive provides little or
no information about the sign of e_i+1
</pre></li>
</ul></li>
<li>æˆ‘ä»¬å‰é¢çš„ä¸ºestimated regression coefficientè®¡ç®—çš„standard erroréƒ½æ˜¯åŸºäºerror termä¹‹é—´æ˜¯uncorrelatedçš„</li>
<li>å¦‚æœerror termä¹‹é—´æœ‰correlationçš„è¯,é‚£ä¹ˆestimated standard errorä¼šunderestimate çœŸæ­£çš„standard error.é‚£ä¹ˆ:
<ul class="org-ul">
<li>æˆ‘ä»¬ç®—å‡ºæ¥çš„confidence intervalè¦æ¯”çœŸå®çš„ confidence intervalè¦"å®½æ³›"</li>
<li>p-valueä¹Ÿç®—å‡ºæ¥æ¯”çœŸå®çš„p-valueè¦lower, è¿™å°±ä¼šè®©æˆ‘ä»¬åšå‡ºä¸æ­£ç¡®çš„åˆ¤æ–­:æˆ‘ä»¬ä¼šè¯¯ä»¥ä¸ºè¿™ä¸ªparameter æ˜¯statistically significantçš„</li>
<li>æ€»ä½“æ¥è¯´,å¦‚æœerror termæ˜¯correlated,é‚£ä¹ˆæˆ‘ä»¬å°±ä¼šå¯¹modelæœ‰ä¸æ­£ç¡®çš„è‡ªä¿¡</li>
</ul></li>
<li>ä¸ºä»€ä¹ˆerror termä¹‹é—´ä¼šå‘ç”Ÿcorrelationå‘¢?ç­”æ¡ˆæ˜¯:
<ul class="org-ul">
<li>è¿™ç±»correlationç»å¸¸å‡ºç°(ä¸æ˜¯å¿…ç„¶å‡ºç°åœ¨contex of time series data</li>
<li>æ‰€è°“time series data,å°±æ˜¯åœ¨ä¸€æ®µæ—¶é—´å†…,æ¯éš”å›ºå®šçš„æ—¶é—´å»åº¦é‡å¾—æ¥çš„æ•°æ®,æ¯”å¦‚,1995-2010,æ¯å¹´çš„
å›½æ°‘ç”Ÿäº§æ€»å€¼,å°±æ˜¯ä¸€ä¸ªå…¸å‹çš„time series data</li>
</ul></li>
<li>æˆ‘ä»¬ä»¥ä¸‹å›¾æ¥çœ‹ä¸€ä¸‹ä¸‰ä¸ªtime series data,çœ‹çœ‹å“ªäº›å‡ºç°äº†correlation:
<ul class="org-ul">
<li><p>
å›¾3-10
</p>

<div id="org7402a38" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/3-10.png" alt="3-10.png" />
</p>
<p><span class="figure-number">Figure 21: </span>isl/3-10.png</p>
</div></li>
<li>æœ€ä¸Šé¢æˆ‘ä»¬çœ‹åˆ°çš„æ˜¯ä¸€ä¸ªuncorrelated errorçš„residual,æ¯ä¸ªresidualå’Œç›¸é‚»çš„residualçš„æ•°å€¼æ²¡å…³ç³»,ä¹Ÿå°±æ˜¯æ²¡æœ‰trend</li>
<li>ç›¸å,æœ€ä¸‹é¢çš„å›¾,æ˜¯ä¸€ä¸ªcorrelationä¸º0.9çš„residual,ç°åœ¨å°±æœ‰trendäº†:ç›¸é‚»çš„residualæ•°å€¼ç›¸ä¼¼</li>
<li>ä¸­é—´çš„å›¾ä¸­æ˜¯correlationä¸º0.5çš„residual,æœ‰trend,ä½†æ˜¯ä¸æ˜æ˜¾</li>
</ul></li>
<li>error termä¹‹é—´çš„correlationä¹Ÿä¼šå‘ç”Ÿåœ¨étime series dataèº«ä¸Š,æ¯”å¦‚æˆ‘ä»¬æœ‰ä¸ª"èº«é«˜å’Œä½“é‡å…³ç³»"çš„ç ”ç©¶,
å¦‚æœè¿›å…¥ç ”ç©¶çš„éƒ½æ˜¯ä¸€å®¶äºº,æˆ–è€…åƒåŒæ ·é£Ÿç‰©,æœ‰ä¸€æ ·çš„ç”Ÿæ´»ç¯å¢ƒ,é‚£ä¹ˆassumption of uncorrelated error
å°±å·²ç»è¢«è¿åäº†</li>
<li>æ€»çš„æ¥è¯´,å¯¹äºlinear regressionä»¥åŠå…¶ä»–çš„statistical methodæ¥è¯´,assumption of uncorrelated error
éƒ½æ˜¯éå¸¸é‡è¦çš„,ä¸€ä¸ªå¥½çš„å®éªŒè®¾è®¡è¦å‡è½»correlationçš„å±å®³</li>
</ul>
</div>
</li>
<li><a id="org9ba94f9"></a>Non-constant Variance of Error Terms<br />
<div class="outline-text-5" id="text-3-3-5-3">
<ul class="org-ul">
<li>linear regression modelçš„å¦å¤–ä¸€ä¸ªé‡è¦çš„assumptionæ˜¯error termçš„æ–¹å·®ä¸ºå¸¸æ•°(constant variance)
\(Var(\varepsilon_i) = \sigma^2\)</li>
<li>å¦‚ä¸‹æ¦‚å¿µéƒ½ä¾èµ–è¿™ä¸ªassumption:
<ul class="org-ul">
<li>standard error</li>
<li>confidence interval</li>
<li>hypothesis test</li>
</ul></li>
<li>ä½†æ˜¯,é—æ†¾çš„æ˜¯,error termçš„æ–¹å·®å¾€å¾€éƒ½ä¸æ˜¯constçš„,è¿™ä¸ªå€¼å¾€å¾€ä¼šéšç€responseçš„æ‰©å¤§è€Œæ‰©å¤§</li>
<li>å¦‚æœä¸€ä¸ªerrorçš„æ–¹å·®ä¸æ˜¯constçš„,æˆ‘ä»¬ä¼šå«ä»–heteroscedasticity,ä¼šå‘ˆç°å‡ºä¸€ä¸ªæ¼æ–—çš„å½¢çŠ¶:
<ul class="org-ul">
<li><p>
å›¾3-11
</p>

<div id="org9a73ba4" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/3-11.png" alt="3-11.png" />
</p>
<p><span class="figure-number">Figure 22: </span>isl/3-11.png</p>
</div></li>
<li>å›¾å·¦è¾¹çš„éƒ¨åˆ†residualå°±å‘ˆç°ä¸€ä¸ªæ¼æ–—å½¢çŠ¶</li>
<li>ä¸ºäº†è§£å†³å·¦è¾¹çš„é—®é¢˜,æˆ‘ä»¬å¯ä»¥æŠŠresponseè½¬æ¢æˆlogYæˆ–è€…æ˜¯ \(\sqrt{Y}\) çš„å½¢å¼,å›¾å³å°±æ˜¯æŠŠresponse
æŒ‰ç…§logYè½¬æ¢åçš„æ ·å­,residualå°±çœ‹èµ·æ¥æ¯”è¾ƒconstäº†</li>
</ul></li>
<li>weighted least squares</li>
</ul>
</div>
</li>
<li><a id="org8bac1c0"></a>Outliers<br />
<div class="outline-text-5" id="text-3-3-5-4">
<ul class="org-ul">
<li>æ‰€è°“outlier,å°±æ˜¯ \(y_i\) å’Œpredicted valueä¹‹é—´çš„è·ç¦»</li>
<li>outlierä¸Šå‡çš„åŸå› å¾ˆå¤š,æ¯”å¦‚åœ¨data collectioné˜¶æ®µ,ä¸æ­£ç¡®çš„record observation</li>
<li>æˆ‘ä»¬çœ‹å›¾æ¥è§£é‡Šä¸‹:
<ul class="org-ul">
<li><p>
å›¾3-12
</p>

<div id="org60db108" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/3-12.png" alt="3-12.png" />
</p>
<p><span class="figure-number">Figure 23: </span>isl/3-12.png</p>
</div></li>
<li>å·¦è¾¹å›¾ä¸Šçš„çº¢è‰²çš„ç‚¹(observation 20)å°±æ˜¯ä¸€ä¸ªå…¸å‹çš„outliter</li>
<li>çº¢è‰²çš„å®çº¿æ˜¯,åŒ…å«outlierçš„æœ€å°äºŒä¹˜å›å½’æ‹Ÿåˆ(Least Squres regression fit)</li>
<li>è“è‰²çš„è™šçº¿æ˜¯,å»æ‰outlierçš„æœ€å°äºŒä¹˜å›å½’æ‹Ÿåˆ(Least Squres regression fit)</li>
<li><p>
è¿™ç§æƒ…å†µä¸‹,å»é™¤outlier,å¹¶æ²¡æœ‰æ”¹å˜least square lineå¤ªå¤š.è¿™ç§æƒ…å†µæ˜¯æ­£å¸¸çš„
</p>
<pre class="example" id="org8f58946">
It is typical for an outlier that does not have an unusual predictor value to
have little effect on the least squares fit.
</pre></li>
<li>ä½†æ˜¯outlierå´ä¼šå¼•èµ·å…¶ä»–çš„é—®é¢˜:
<ul class="org-ul">
<li>åœ¨åŒ…æ‹¬outlierçš„regressioné‡Œé¢,RSEä¸º1.09, \(R^2\) ä¸º0.892</li>
<li>ä¸åŒ…æ‹¬outlierçš„regressioné‡Œé¢,RSEä¸º0.77, \(R^2\) ä¸º0.805</li>
<li>ç”±äºRSEè¢«ç”¨æ¥è®¡ç®—confidence intervalå’Œp-value,RSEçš„æ”¹åŠ¨ä¼šå½±å“è¿™ä¸¤ä¸ªå€¼</li>
</ul></li>
<li>å›¾3-12ä¸­é—´çš„æ˜¯Residual plot,æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“å‘ç°å“ªä¸ªæ˜¯outlier</li>
<li>å®è·µå½“ä¸­,ä½¿ç”¨residual plotä¸å¤ªæ–¹ä¾¿,å› ä¸ºä¸çŸ¥é“è¶…è¿‡residualå¤šå°‘ç®—outlier(è¶…è¿‡10,20,è¿˜æ˜¯30?),
æ²¡æœ‰ä¸€ä¸ªç»Ÿä¸€çš„æ•°å€¼,æ‰€ä»¥æˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨å›¾3-12å³ä¾§çš„studentized residual,å› ä¸ºå®ƒèƒ½å¤Ÿç¡®å®šæ˜ç¡®çš„èŒƒå›´:
studentized residualå€¼å¤§äº6çš„é€šå¸¸è¢«è®¤ä¸ºæ˜¯outlier</li>
<li><p>
studentized residual valueä¹‹æ‰€ä»¥èƒ½å¤Ÿæœ‰æ˜ç¡®çš„èŒƒå›´,å› ä¸ºä»–æ˜¯ä½¿ç”¨residualé™¤ä»¥standard error,è¿™æ ·
ä¸€æ¥ä½¿ç”¨standard errorä½œä¸ºäº†åŸºæ•°,ç¿»è¯‘èµ·æ¥å°±æ˜¯
</p>
<pre class="example" id="orgc7f17d8">
è¶…è¿‡standard errorå…­å€çš„residualéƒ½è¢«è®¤ä¸ºæ˜¯outlier
</pre></li>
</ul></li>
<li>å¦‚æœæˆ‘ä»¬å‘ç°äº†outlier,å½“ç„¶ç¬¬ä¸€ååº”å°±æ˜¯åˆ é™¤è¿™ä¸ªobservation,ä½†æ˜¯å®é™…ä¸Š,åˆ é™¤ä¹‹å‰,æˆ‘ä»¬è¦ç¡®è®¤ä¸‹,æ˜¯
ä¸æ˜¯æˆ‘ä»¬modelçš„é—®é¢˜</li>
</ul>
</div>
</li>
<li><a id="org3a544d9"></a>High Leverage Points<br />
<div class="outline-text-5" id="text-3-3-5-5">
<ul class="org-ul">
<li>å‰é¢è®²è¿‡,å¯¹äºæŸä¸ªresponse \(y_i\) çš„observertionæ¯”è¾ƒåå¸¸çš„çš„æƒ…å†µå«åšoutlier</li>
<li>è¿™èŠ‚è¦è®²çš„æ˜¯,å¯¹äºæŸä¸ªpredictor \(x_i\) çš„observertionæ¯”è¾ƒåå¸¸çš„çš„æƒ…å†µå«åšhigh leverage</li>
<li>æˆ‘ä»¬ä»å›¾ä¸­è§£é‡Šä¸€ä¸‹:
<ul class="org-ul">
<li><p>
å›¾3-13
</p>

<div id="org7fce393" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/3-13.png" alt="3-13.png" />
</p>
<p><span class="figure-number">Figure 24: </span>isl/3-13.png</p>
</div></li>
<li>å·¦ä¾§å›¾ä¸­çš„41 observationå°±æ˜¯high leverage,è¿™ä¸ªobservationçš„predictor valueç›¸å¯¹äºå…¶ä»–predictor
æ¥è¯´æ¯”è¾ƒå¤§</li>
<li>çº¢è‰²å®çº¿æ˜¯åŒ…æ‹¬41 observationçš„æœ€å°äºŒä¹˜å›å½’æ‹Ÿåˆ</li>
<li>è“è‰²è™šçº¿æ˜¯å»é™¤41 observationçš„æœ€å°äºŒä¹˜å›å½’æ‹Ÿåˆ</li>
<li>ç›¸æ¯”äºå»é™¤outlier,å»é™¤high leverageä¼šæå¤§çš„å½±å“least squares line.</li>
<li>æ­£æ˜¯ç”±äºå‡ ä¸ªhigh leverage observationå°±ä¼šä¸¥é‡å½±å“æœ€å°äºŒä¹˜å›å½’çš„line,æ‰€ä»¥æˆ‘ä»¬ä¸€å®šè¦æŠŠè¿™äº›high
leverageçš„obervationç»™æ‰¾å‡ºæ¥</li>
<li>åœ¨simple linear regressioné‡Œé¢,éå¸¸å®¹æ˜“æ‰¾åˆ°high leverage,å› ä¸ºåªéœ€è¦çœ‹çœ‹predictorçš„å€¼æ˜æ˜¾å’Œå…¶
ä»–predictorä¸åœ¨ä¸€å—çš„æƒ…å†µå°±å¯ä»¥äº†.</li>
<li>ä½†æ˜¯åœ¨multiple linear regressioné‡Œé¢,å´å¯èƒ½å‡ºç°è¿™ç§æƒ…å†µ: æœ‰ä¸ªpredictor,å®ƒåœ¨æ¯ä¸ªç»´åº¦ä¸Šé¢çš„å€¼
éƒ½æ˜¯"åˆç¾¤"çš„,ä½†æ˜¯è¿™äº›å€¼ç»„åˆèµ·æ¥å°±ä¸"åˆç¾¤"äº†.æ¯”å¦‚ä¸Šé¢ä¸­é—´çš„å›¾:
<ol class="org-ol">
<li>æ‰€æœ‰çš„"åˆç¾¤"çš„å€¼,åº”è¯¥æ˜¯åœ¨è“è‰²è™šçº¿æ¡†å®šçš„ä¸€ä¸ªæ¤­åœ†å½¢é‡Œé¢</li>
<li>çº¢è‰²çš„ç‚¹åœ¨äºŒç»´ç©ºé—´é‡Œé¢è‚¯å®šæ˜¯ä¸åˆç¾¤çš„</li>
<li>çº¢è‰²çš„ç‚¹çš„ä¸¤ä¸ªå€¼X1,X2åœ¨å„è‡ªçš„ä¸€ç»´ç©ºé—´é‡Œé¢,å´æ˜¯"åˆç¾¤"çš„.</li>
</ol></li>
<li>äºŒç»´ç©ºé—´æˆ‘ä»¬è¿˜èƒ½ç”»å‡ºæ¥,ä½†æ˜¯ä¸€æ—¦åˆ°äº†Nç»´ç©ºé—´æˆ‘ä»¬æ˜¯ç”»ä¸å‡ºæ¥çš„,æ‰€ä»¥,æˆ‘ä»¬å¿…é¡»è¦æœ‰ä¸ªæ•°å€¼æ¥åˆ¤å®šæ˜¯
å¦æ˜¯high leverage,å°±æ˜¯leverage statistic:
<ul class="org-ul">
<li><p>
simple linear regressionçš„è®¡ç®—leverage statisticçš„å…¬å¼å¦‚ä¸‹
</p>
\begin{equation}
h_i = \frac{1}{n} + \frac{(x_i - \overline{x})^2}{\sum_{i'=1}^n(x_{i'}-\overline{x})^2}\tag{3.37}
\end{equation}</li>
<li>statisticçš„å€¼è¶Šå¤§,è¯´æ˜è¶Šå¯èƒ½æ˜¯high leverage</li>
<li>\(h_i\) çš„å€¼æ€»æ˜¯åœ¨1/nå’Œ1ä¹‹é—´</li>
<li>æ‰€æœ‰çš„observationçš„å¹³å‡leverageç­‰äº(p+1)/n,å¦‚æœæŸä¸ªobservationçš„leverage statisticè¿œè¿œ
å¤§äº(p+1)/n,æˆ‘ä»¬å°±ä¼šè®¤ä¸ºä»–æ˜¯æ‹¥æœ‰high leverageçš„</li>
</ul></li>
</ul></li>
<li>å›¾3-13çš„å³ä¾§æ˜¯æŠŠstudentized residualå’Œ \(h_i\) éƒ½åˆ—åœ¨ä¸€èµ·:
<ul class="org-ul">
<li>obvervation 41ä¸ä»…ä»…æ˜¯high leverage åŒæ—¶ä¹Ÿæ˜¯high studentized redidual</li>
<li>observation 20ä»…ä»…æ˜¯high studentized redidual, å®ƒçš„leverageå¹¶ä¸high,æ‰€ä»¥å…¶å¯¹least square fit
å½±å“å¹¶ä¸å¤§</li>
</ul></li>
</ul>
</div>
</li>
<li><a id="org4adc25d"></a>Collinearity<br />
<div class="outline-text-5" id="text-3-3-5-6">
<ul class="org-ul">
<li>Collinearityæ˜¯è¯´ä¸¤ä¸ªæˆ–è€…ä¸¤ä¸ªä»¥ä¸Šçš„predictor variableæ˜¯ç›¸äº’è”ç³»çš„</li>
<li>æˆ‘ä»¬è¿˜æ˜¯é€šè¿‡å›¾æ¥è§£é‡Š
<ul class="org-ul">
<li><p>
å›¾3-14
</p>

<div id="org11c12cf" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/3-14.png" alt="3-14.png" />
</p>
<p><span class="figure-number">Figure 25: </span>isl/3-14.png</p>
</div></li>
<li>å·¦è¾¹çš„å›¾ä¸­çš„limitå’Œageæ²¡æœ‰æ˜æ˜¾çš„å…³ç³»</li>
<li>ç›¸å,å³è¾¹å›¾ä¸­çš„limitå’Œratingå´æœ‰æ˜æ˜¾çš„å…³ç³»,è¿™ç§æƒ…å†µå°±æ˜¯collinear</li>
<li>colinearçš„é—®é¢˜åœ¨äº,limitå’Œratingå…±åŒå¢åŠ æˆ–å‡å°‘,æ‰€ä»¥å¾ˆéš¾å‘ç°å•ç‹¬çš„ä¸€ä¸ªpredictorå’Œresponseçš„å…³ç³»</li>
</ul></li>
<li>æˆ‘ä»¬å†æ¥çœ‹ä¸€ä¸ªå›¾è¡¨ç°äº†æˆ‘ä»¬çš„å›°éš¾
<ul class="org-ul">
<li>å›¾3-15</li>
<li>ä¸Šå›¾æ˜¯ä¸åŒæ¨¡å‹RSSçš„contour plot:
<ol class="org-ol">
<li>å·¦ä¾§æ˜¯predictorä¸ºlimit,age,responseä¸ºbalanceçš„æ¨¡å‹,å¯ä»¥çœ‹åˆ°æ˜¯ä¸€ä¸ªæ¯”è¾ƒæ­£å¸¸çš„ç­‰å€¼çº¿</li>
<li>å³ä¾§æ˜¯predictorä¸ºlimit,rating,responseä¸ºbalanceçš„æ¨¡å‹,å¯ä»¥çœ‹åˆ°ç”±äº \(\(beta_Limit, \beta_Rating)\)
å¤ªå¤šç›¸è¿‘å€¼,å¯¼è‡´æœ€åçš„ç­‰å€¼çº¿éå¸¸çš„ä¸æ­£å¸¸</li>
</ol></li>
</ul></li>
<li>ç”±äºcollinearityå‡å°‘äº†coefficientçš„ç²¾åº¦,è¿™ä¼šå¯¼è‡´standard error \(\hat{\beta_j}\) çš„æå‡,è¿˜ä¼šå¯¼è‡´
t-statisticçš„é™ä½</li>
<li><p>
ç”±äºt-statisticçš„é™ä½,æˆ‘ä»¬çš„ \(H_0 : \beta_j = 0\) å¯èƒ½ä¼šæˆç«‹.æ¢å¥è¯è¯´,non-zero coefficientçš„å¯
èƒ½æ€§è¢«collinearityé™ä½äº†
</p>
<pre class="example" id="orgdd079b2">
The probability of correctly detecting a non-zero coefficient is reduced by collinearity
</pre></li>
<li>ä¸‹é¢çš„å›¾å±•ç¤ºäº†ä¸¤ç§ä¸åŒçš„multiple regression modelçš„coefficient
<ul class="org-ul">
<li><p>
è¡¨3-11
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Coefficient</th>
<th scope="col" class="org-right">Std.error</th>
<th scope="col" class="org-right">t-statistic</th>
<th scope="col" class="org-left">p-value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Model1 Intercept</td>
<td class="org-right">-173.411</td>
<td class="org-right">43.828</td>
<td class="org-right">-3.957</td>
<td class="org-left">&lt; 0.0001</td>
</tr>

<tr>
<td class="org-left">age</td>
<td class="org-right">-2.292</td>
<td class="org-right">0.672</td>
<td class="org-right">-3.407</td>
<td class="org-left">0.0007</td>
</tr>

<tr>
<td class="org-left">limit</td>
<td class="org-right">0.173</td>
<td class="org-right">0.005</td>
<td class="org-right">34.496</td>
<td class="org-left">&lt; 0.0001</td>
</tr>

<tr>
<td class="org-left">Model2 Intercept</td>
<td class="org-right">-377.537</td>
<td class="org-right">45.254</td>
<td class="org-right">-8.343</td>
<td class="org-left">&lt;0.0001</td>
</tr>

<tr>
<td class="org-left">rating</td>
<td class="org-right">2.202</td>
<td class="org-right">0.952</td>
<td class="org-right">2.312</td>
<td class="org-left">0.0213</td>
</tr>

<tr>
<td class="org-left">limit</td>
<td class="org-right">0.025</td>
<td class="org-right">0.064</td>
<td class="org-right">0.384</td>
<td class="org-left">0.7012</td>
</tr>
</tbody>
</table></li>
<li>ç¬¬ä¸€ä¸ªregressionçš„predictoræ˜¯ageå’Œlimit</li>
<li>ç¬¬äºŒä¸ªregressionçš„predictoræ˜¯ratingå’Œlimit</li>
<li>å¯ä»¥çœ‹åˆ°ç¬¬ä¸€ä¸ªregression, ageå’Œlimitéƒ½å…·æœ‰highly significant</li>
<li>å¯ä»¥çœ‹åˆ°ç¬¬äºŒä¸ªregression, ageå’Œlimitçš„p-valueå¢åŠ åˆ°äº†0.701</li>
</ul></li>
<li>æ¯å½“é‡åˆ°collinearityé—®é¢˜çš„æ—¶å€™,æœ‰ä¸¤ç§è§£å†³åŠæ³•:
<ul class="org-ul">
<li>ç›´æ¥å»æ‰collinearityä¸­çš„ä¸€ä¸ªvariable</li>
<li>æŠŠcollinearityçš„ä¸¤ä¸ªvariableåˆå¹¶æˆä¸€ä¸ª</li>
</ul></li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-orgc6e4926" class="outline-3">
<h3 id="orgc6e4926"><span class="section-number-3">3.4.</span> The Marketing Plan</h3>
<div class="outline-text-3" id="text-3-4">
<ul class="org-ul">
<li>æˆ‘ä»¬ç°åœ¨å›åˆ°å¼€å¤´çš„å…³äºAdvertising dataçš„ä¸ƒä¸ªé—®é¢˜</li>
</ul>
</div>
<div id="outline-container-org3b75b30" class="outline-4">
<h4 id="org3b75b30"><span class="section-number-4">3.4.1.</span> Is there a relationship between advertising sales and budget?</h4>
<div class="outline-text-4" id="text-3-4-1">
<ul class="org-ul">
<li>æƒ³è¦å›ç­”è¿™ä¸ªé—®é¢˜,æˆ‘ä»¬å°±éœ€è¦åˆ›å»ºä¸€ä¸ªmultiple regression model:
<ul class="org-ul">
<li>predictorä¸ºTV, radio, newspaper</li>
<li>responseä¸ºsales</li>
</ul></li>
<li><p>
é’ˆå¯¹è¿™ä¸ªæ–°çš„model,æˆ‘ä»¬æ¥åšæµ‹è¯•ä¸€ä¸‹å¦‚ä¸‹çš„hypothesis
</p>
\begin{equation}
H_0 : \beta_{tv} = \beta_{radio} = \beta_{newspaper} = 0
\end{equation}</li>
<li>æˆ‘ä»¬ä½¿ç”¨f-statisticæ¥åˆ¤æ–­,æˆ‘ä»¬æ˜¯å¦åº”è¯¥reject è¿™ä¸ªnull hypothesis</li>
<li>åœ¨è¿™ä¸ªä¾‹å­ä¸­,f-statisticå¯¹åº”çš„p-valueéå¸¸çš„ä½,è¯´æ˜advertisigå’Œsalesä¹‹é—´,å¼ºçƒˆçš„å…³ç³»</li>
</ul>
</div>
</div>
<div id="outline-container-orgb646876" class="outline-4">
<h4 id="orgb646876"><span class="section-number-4">3.4.2.</span> How strongis the relationship?</h4>
<div class="outline-text-4" id="text-3-4-2">
<ul class="org-ul">
<li>æˆ‘ä»¬æœ¬ç« å­¦ä¹ äº†ä¸¤ç§æ–¹æ³•æ¥è®¡ç®—æ¨¡å‹çš„accuracy:
<ul class="org-ul">
<li>RSE: RSEä½¿ç”¨population regression lineæ¥ä¼°è®¡responseçš„standard deviation,Advertising dataé‡Œé¢æ±‚å¾—
çš„RSEæ˜¯1681,è€Œresponseçš„å¹³å‡å€¼ä¸º14022,è¯´æ˜é”™è¯¯ç‡å¤§æ¦‚æ˜¯12%</li>
<li>\(R^2\): \(R^2\) è®°å½•responseä¸­æœ‰å¤šå°‘çš„ç™¾åˆ†æ¯”è¢«predictoræ‰€è§£é‡Š</li>
<li>åœ¨Advertisingä¾‹å­ä¸­, \(R^2\) å€¼ä¸º90%,è¯´æ˜90%çš„sales varianceè¢«predictoræ‰€è§£é‡Šäº†</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgf4608f9" class="outline-4">
<h4 id="orgf4608f9"><span class="section-number-4">3.4.3.</span> Which media contribute to sales?</h4>
<div class="outline-text-4" id="text-3-4-3">
<ul class="org-ul">
<li>è§£é‡Šè¿™ä¸ªé—®é¢˜çš„æ³•å®æ˜¯predictor t-statisticçš„p-value</li>
<li>åœ¨Advertisingè¿™ä¸ªä¾‹å­ä¸­:
<ul class="org-ul">
<li>TV, radioçš„p-valueå¾ˆä½,è¯´æ˜ä»–ä»¬å’Œsalesæœ‰ç›´æ¥ä½œç”¨</li>
<li>newspaperçš„p-valueå¾ˆé«˜,è¯´æ˜newspaperå¯¹salesæ²¡æœ‰ç›´æ¥ä½œç”¨</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org4bf462b" class="outline-4">
<h4 id="org4bf462b"><span class="section-number-4">3.4.4.</span> How large is the effect of each medium on seles?</h4>
<div class="outline-text-4" id="text-3-4-4">
<ul class="org-ul">
<li>æˆ‘ä»¬å¯ä»¥ä½¿ç”¨standard error of \(\hat{\beta_j}\) æ¥ç»„å»º \(\beta_j\) çš„confidence interval</li>
<li>å¯¹äºAdvertisingæ•°æ®æ¥è¯´, 95%çš„confidence intervalçš„å€¼:
<ul class="org-ul">
<li>TVæ˜¯(0.043, 0.049)</li>
<li>radioæ˜¯(0.172, 0.206)</li>
<li>newspaperæ˜¯(-0.013, 0.001): è¿™ä¸ªåŒºé—´ç«Ÿç„¶åŒ…æ‹¬0,è¯´æ˜variableä¸æ˜¯statistically significantçš„</li>
</ul></li>
<li>æˆ‘ä»¬åé¢å­¦åˆ°äº†collinearity,ä¸‹é¢é€šè¿‡VIFå€¼æ¥åˆ¤æ–­newspaperçš„confidence intervalæ•°æ®å¹¿,æ˜¯ä¸æ˜¯å› ä¸ºcollinearity:
<ul class="org-ul">
<li>TVçš„VIF scoreæ˜¯1.005</li>
<li>radioçš„VIF scoreæ˜¯1.145</li>
<li>newspaperçš„VIF scoreæ˜¯1.145</li>
<li>æ²¡æœ‰colinearityçš„è¿¹è±¡</li>
</ul></li>
<li>æ’é™¤å¦å¤–ä¸¤ä¸ªpredictor,å•ç‹¬åˆ›å»ºsimple linear regressionçš„æ•ˆæœ:
<ul class="org-ul">
<li>TVå’Œsalesçš„association æ˜¯strong</li>
<li>radioå’Œsalesçš„association æ˜¯strong</li>
<li>newspaperå’Œsalesçš„association æ˜¯mild</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org3a41324" class="outline-4">
<h4 id="org3a41324"><span class="section-number-4">3.4.5.</span> How accurately can we predict future sales?</h4>
<div class="outline-text-4" id="text-3-4-5">
<ul class="org-ul">
<li><p>
æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¦‚ä¸‹çš„å…¬å¼è®¡ç®—predictå€¼
</p>
\begin{equation}
\hat{y}=\hat{\beta_0} + \hat{\beta_1}x_1 + \hat{\beta_2}x_2 + \cdot\cdot\cdot + \hat{\beta_p}x_p,\tag{3.21}
\end{equation}</li>
<li>å¦‚æœè¦è®¡ç®—è¿™ä¸ªæ¨¡å‹çš„accuracy,é‚£ä¹ˆå°±è¦åˆ†æƒ…å†µè®¨è®º:
<ul class="org-ul">
<li>å¦‚æœè¦è®¡ç®—individual response(ä¹Ÿå°±æ˜¯ \(Y = f(x) + \varepsilon\) ), æˆ‘ä»¬å°±ä½¿ç”¨prediction interval</li>
<li>å¦‚æœè¦è®¡ç®—average response(ä¹Ÿå°±æ˜¯ \(Y = f(x)\) ), æˆ‘ä»¬å°±ä½¿ç”¨confidence interval</li>
<li>ç”±äºprediction interval åŒ…æ‹¬äº†irreducible error ( \(\varepsilon\) ),æ‰€ä»¥ç›¸å¯¹äºconfidence intervalè¦å¤§ä¸€äº›</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org8b95c7a" class="outline-4">
<h4 id="org8b95c7a"><span class="section-number-4">3.4.6.</span> Is the relationship linear?</h4>
<div class="outline-text-4" id="text-3-4-6">
<ul class="org-ul">
<li>æˆ‘ä»¬å­¦åˆ°äº†ä½¿ç”¨residual plotæ¥åˆ¤æ–­non-linearity:
<ul class="org-ul">
<li>å¦‚æœrelationshipæ˜¯linearçš„,é‚£ä¹ˆresidual plot åº”è¯¥æ˜¾ç¤ºå‡ºno pattern(æ¯”è¾ƒéšæœº)</li>
<li>å¦‚æœrelationshipæ˜¯non-linearçš„,é‚£ä¹ˆresidual plot åº”è¯¥æ˜¾ç¤ºå‡ºpattern (U,æˆ–è€…å€’-U)</li>
</ul></li>
<li>å¯¹äºAdvertising dataæˆ‘ä»¬é€šè¿‡å›¾3-5å‘ç°äº†å®ƒçš„non-linear effect(å½“ç„¶é€šè¿‡residual plotä¹Ÿå¯ä»¥å‘ç°),
ç„¶åæˆ‘ä»¬ä»‹ç»äº†transformation of the predictoræ¥ç¼“è§£non-linear relationship</li>
</ul>
</div>
</div>
<div id="outline-container-org9f6c31c" class="outline-4">
<h4 id="org9f6c31c"><span class="section-number-4">3.4.7.</span> Is there synergy among the advertising media?</h4>
<div class="outline-text-4" id="text-3-4-7">
<ul class="org-ul">
<li><p>
standard linear regression modelæœ‰ä¸€ä¸ªå‡è®¾å°±æ˜¯: additive relationship between predictor and response:
</p>
<pre class="example" id="orgdcfceb3">
Additive modelæ˜¯éå¸¸å®¹æ˜“è§£é‡Šçš„,å…¶å«ä¹‰å°±æ˜¯æ¯ä¸ªpredictorå¯¹äºresponseçš„è´¡çŒ®å€¼æ˜¯å’Œå…¶ä»–predictoræ²¡æœ‰å…³ç³»çš„
</pre></li>
<li>å¯¹äºç‰¹å®šçš„æ•°æ®é›†, additive assumptionå¯èƒ½éå¸¸çš„ä¸ç°å®,æˆ‘ä»¬ä»‹ç»äº†å¦‚ä½•å¼•å…¥ä¸€ä¸ªinteraction termæ¥é™ä½non-additive relationship</li>
<li>interaction termçš„ä½p-valueä¼šæ­ç¤ºadditive relationshipçš„å­˜åœ¨</li>
<li>åœ¨ Advertisingçš„ä¾‹å­ä¸­å¼•å…¥äº†interaction termä¹‹å,æ¨¡å‹çš„ \(R^2\) å€¼ä»90%æå‡åˆ°äº†97%</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org1d8f340" class="outline-3">
<h3 id="org1d8f340"><span class="section-number-3">3.5.</span> Comparison of Linear Regression</h3>
<div class="outline-text-3" id="text-3-5">
<ul class="org-ul">
<li>æ­£å¦‚ç¬¬äºŒç« è®²çš„,linear regressionæ˜¯ä¸€ç§parametric approach,å› ä¸ºå®ƒæˆç«‹æœ‰ä¸€ä¸ªå‡è®¾,å°±æ˜¯å‡è®¾ä½ æœä»ä¸€
ä¸ªlinear functional form: f(x)</li>
<li>parametric methodæœ‰å¾ˆå¤šçš„ä¼˜åŠ¿:
<ul class="org-ul">
<li>å®¹æ˜“fit</li>
<li>coefficientæ‹¥æœ‰simple interpretation</li>
<li>test of statistical significanceå®¹æ˜“</li>
</ul></li>
<li>parametric methodä¹Ÿæœ‰å¾ˆå¤šçš„ç¼ºç‚¹:
<ul class="org-ul">
<li>ä¸ºäº†æ„å»ºmodel,å®ƒå¿…é¡»è®¾ç½®ä¸€ä¸ªå¼ºçƒˆçš„assumption,å°±æ˜¯æ•°æ®ç¬¦åˆä¸€ä¸ªf(X)</li>
<li>å¦‚æœçœŸå®çš„function formä¸æ˜¯æˆ‘ä»¬å‡è®¾çš„æ ·å¼,é‚£ä¹ˆæ¨¡å‹çš„å‡†ç¡®ç‡å°±éå¸¸çš„å·®</li>
</ul></li>
<li>ç›¸æ¯”ä¹‹ä¸‹, non-parametric methodå°±ä¸éœ€è¦æ˜ç¡®çš„assumeä¸€ä¸ªparametric form f(X),å®ƒèƒ½å¤Ÿæä¾›ä¸€ä¸ªæ›´åŠ 
flexibleçš„åŠæ³•æ¥performing regression</li>
<li>æœ¬ä¹¦ä»‹ç»å¾ˆå¤šç§non-parametirc method,è¿™é‡Œæˆ‘ä»¬å…ˆä»‹ç»ä¸€ç§æœ€ç®€å•çš„,ä¹Ÿæ˜¯æœ€å¹¿ä¸ºäººçŸ¥çš„non-parametric
method: KNN regression(K-nearest neighbors regression)</li>
<li>KNN regression methodçš„ä½¿ç”¨æ–¹æ³•å¦‚ä¸‹:
<ul class="org-ul">
<li>ç»™å®šä¸€ä¸ªKçš„value,å’Œä¸€ä¸ªprediction point \(x_0\)</li>
<li>KNN regressionä¼šé¦–å…ˆç¡®å®šKä¸ªç¦» \(x_0\) æœ€è¿‘çš„observation,ä»¥ \(N_0\) ä»£è¡¨</li>
<li>æœ€åæ±‚è¿™Kä¸ªå€¼çš„å¹³å‡å€¼</li>
<li><p>
æ•´ä¸ªè¿‡ç¨‹çš„å…¬å¼å¦‚ä¸‹
</p>
\begin{equation}
\hat{f}(x_0) = \frac{1}{K} \sum_{x_i \in N_0} {y_i}
\end{equation}</li>
</ul></li>
<li>æˆ‘ä»¬ä½¿ç”¨ä¸‹å›¾æ¥ä»‹ç»ä¸‹æ‹¥æœ‰ä¸¤ä¸ªpredictorçš„KNN
<ul class="org-ul">
<li>å›¾3-16</li>
<li>å·¦è¾¹çš„å›¾æ˜¯ä¸€ä¸ªK=1çš„æƒ…å†µ,KNNçš„fit,æ¯”è¾ƒæ˜æ˜¾çš„åˆ†æˆäº†å‡ ä¸ªé˜¶æ®µ</li>
<li>å³è¾¹çš„å›¾æ˜¯ä¸€ä¸ªK=9çš„æƒ…å†µ,KNNçš„fitå°±ä¼šå˜å¾—æ¯”è¾ƒå¹³æ»‘</li>
<li>æ€»å¾—æ¥è¯´Kçš„æœ€ä½³å€¼ä¼šä¾èµ–äºbias-variance tradeoff:
<ol class="org-ol">
<li>ä¸€ä¸ªæ¯”è¾ƒå°çš„Kå€¼ä¼šæä¾›æœ€flexible fit(å’Œresponseæ‹Ÿåˆçš„æ¯”è¾ƒå¥½,æ›²çº¿æ¯”è¾ƒå¤æ‚): æ‹¥æœ‰low bias,ä½†æ˜¯high variance</li>
<li>ä¸€ä¸ªæ¯”è¾ƒå¤§çš„kå€¼ä¼šæä¾›smootherçš„fit</li>
<li>ç¬¬äº”ç« æˆ‘ä»¬ä¼šä»‹ç»å¤šä¸ªestimating test error rateçš„æ–¹æ³•,è¿™äº›æ–¹æ³•å¯ä»¥ç”¨æ¥åˆ¤æ–­Kçš„æœ€ä½³å€¼</li>
</ol></li>
</ul></li>
<li><p>
åœ¨ä»€ä¹ˆæƒ…å†µä¸‹, least squares linear regressionè¿™ç§parametric approachä¼šè¶…è¿‡non-parametric
approach(æ¯”å¦‚KNN),ç­”æ¡ˆå¾ˆç®€å•:é‚£å°±æ˜¯å¦‚æœæˆ‘ä»¬çš„parameteric formå’Œtrue formæ›´æ¥è¿‘
</p>
<pre class="example" id="orgec87093">
The answer is simple: the parametric approach will outperform the non-parametric approach
if the parametric form that has been selected is cloe to the true form of f
</pre></li>
<li>ä¸‹å›¾å°±æ˜¯ä¸€ä¸ªä½¿ç”¨one-dimensional linear regression modelç”Ÿæˆçš„data
<ul class="org-ul">
<li>å›¾3-17</li>
<li>é»‘è‰²çš„å®çº¿ä»£è¡¨f(X)</li>
<li>å·¦ä¾§è“è‰²çš„æ›²çº¿ä»£è¡¨K=1æ—¶å€™çš„KNN:æ‹Ÿåˆçš„ä¸å¥½</li>
<li>å³ä¾§è“è‰²çš„æ›²çº¿ä»£è¡¨K=9æ—¶å€™çš„KNN:æ‹Ÿåˆçš„æ¯”è¾ƒå¥½</li>
</ul></li>
<li>å®é™…æƒ…å†µæ˜¯,å³ä¾¿æ˜¯true relationshipæ˜¯highly non-linearçš„,KNNæ•ˆæœä¾ç„¶æ¯”linear regressionå·®</li>
</ul>
</div>
</div>
<div id="outline-container-orgf70aba0" class="outline-3">
<h3 id="orgf70aba0"><span class="section-number-3">3.6.</span> Lab: Linear Regression</h3>
<div class="outline-text-3" id="text-3-6">
</div>
</div>
</div>
<div id="outline-container-org52e8bc8" class="outline-2">
<h2 id="org52e8bc8"><span class="section-number-2">4.</span> Chapter 4: Classification</h2>
<div class="outline-text-2" id="text-4">
<ul class="org-ul">
<li>ç¬¬ä¸‰ç« ä»‹ç»çš„response variableéƒ½æ˜¯quantitativeçš„,ä½†æ˜¯å¾ˆå¤šæ—¶å€™,æˆ‘ä»¬çš„responseæ˜¯qualitativeçš„,æ¯”å¦‚
çœ¼ç›çš„é¢œè‰²,åªå¯èƒ½æ˜¯:
<ul class="org-ul">
<li>blue</li>
<li>brown</li>
<li>green</li>
</ul></li>
<li>qualitative variableé€šå¸¸è¢«ç§°ä¹‹ä¸ºcategorical, æˆ‘ä»¬ä¼šé—´æˆ–ç€ä½¿ç”¨å¦‚ä¸‹ä¸¤ä¸ªå•è¯è¡¨è¾¾åŒæ ·çš„æ„æ€:
<ul class="org-ul">
<li>qualitative</li>
<li>categorical</li>
</ul></li>
<li>æœ¬ç« ,æˆ‘ä»¬å­¦ä¹ é¢„æµ‹qualitative responseçš„æ–¹æ³•,è¿™äº›æ–¹æ³•ä¹Ÿå«åšclassification(åˆ†ç±»)</li>
<li>ç”±äºclassificationçš„åŸºæœ¬æ–¹æ³•,æ˜¯é¦–å…ˆé¢„æµ‹f(x)å¯èƒ½æ˜¯æŸç§åˆ†ç±»ç»“æœçš„æ¦‚ç‡(æ•°å€¼å‹),æ‰€ä»¥åˆ†ç±»(classification)
é—®é¢˜å’Œå›å½’(regression)é—®é¢˜æœ‰ç±»ä¼¼çš„åœ°æ–¹</li>
<li>classification techniqueä¹Ÿå«åšclassifier</li>
<li>æˆ‘ä»¬æœ¬ç« ä¼šå­¦ä¹ å¾ˆå¤šä¸åŒçš„classifier,ä¸»è¦æ˜¯ä¸‰ç§:
<ul class="org-ul">
<li>logistic regression</li>
<li>linear discriminant analysis</li>
<li>K-nearest neighbors</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orgfe8ab59" class="outline-3">
<h3 id="orgfe8ab59"><span class="section-number-3">4.1.</span> An Overview of Classification</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li>åˆ†ç±»é—®é¢˜,æ¯”çº¿æ€§å›å½’é—®é¢˜å‘ç”Ÿçš„æ›´æ™®é,ä¸‹é¢æ˜¯å‡ ä¸ªä¾‹å­:
<ol class="org-ol">
<li>ä¸€ä¸ªç—…äººè¢«é€åˆ°æ€¥æ•‘å®¤,ä»–æœ‰å¾ˆä½œç—‡çŠ¶,è¿™äº›ç—‡çŠ¶å¯èƒ½æ˜¯ä¸‰ç§medical conditionçš„ä¸€ç§,é‚£ä¹ˆè¿™ä¸ªç—…äººç©¶ç«Ÿ
æ˜¯å“ªä¸€ç§medical condiitonå‘¢?</li>
<li>çº¿ä¸Šçš„é“¶è¡ŒæœåŠ¡è¦æ¥åˆ¤æ–­æŸä¸€ç¬”äº¤æ˜“åˆ°åº•æ˜¯ä¸æ˜¯æ¬ºè¯ˆäº¤æ˜“,æ ¹æ®è¿™ä¸ªäº¤æ˜“çš„å¾ˆå¤šä¿¡æ¯,æ¯”å¦‚IP,ç”¨æˆ·è¿‡å»çš„äº¤æ˜“è®°å½•ç­‰ç­‰</li>
<li>æ ¹æ®æŸäº›DNAä¼šå¾—ç—…,å¦å¤–ä¸€äº›DNAä¸ä¼šå¾—ç—…,ç”Ÿæ´»å­¦å®¶æ¥åˆ¤æ–­å“ªäº›DNAæ˜¯æœ‰å®³çš„.</li>
</ol></li>
<li>å’Œregression settingä¸€æ ·,åœ¨classificationé‡Œé¢,æˆ‘ä»¬ä¹Ÿæœ‰ä¸€ç³»åˆ—çš„training observation: \((x_1, y_1), \cdot\cdot\cdot,(x_n, y_n)\)
æˆ‘ä»¬åœ¨classificationé‡Œé¢,ä½¿ç”¨è¿™äº›training observationæ¥åšclassifier</li>
<li>åŒæ ·çš„,æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„classifierä¸ä»…ä»…å¯¹training dataåˆ†ç±»åˆ†çš„å‡†,å¯¹æ²¡è§è¿‡çš„æ•°æ®ä¹Ÿèƒ½åˆ†ç±»åˆ†çš„å‡†</li>
<li>æœ¬ç« æˆ‘ä»¬ä½¿ç”¨Default data set(è¿çº¦æ•°æ®é›†),åœ¨è¿™ä¸ªæ•°æ®é›†ä¸Š,æˆ‘ä»¬:
<ul class="org-ul">
<li>input: ç”¨æˆ·çš„å¹´æ”¶å…¥å’Œä¿¡ç”¨å¡ä½™é¢</li>
<li>output: é¢„æµ‹æŸä¸ªäººæ˜¯å¦ä¼šè´¦å•é¢„æœŸ(default on his or her credit card payment)</li>
</ul></li>
<li>è¿çº¦æ•°æ®é›†å¦‚å›¾
<ul class="org-ul">
<li>å›¾4-1</li>
<li>æ•´ä¸ªå›¾å±•ç¤ºäº†10000ä¸ªç”¨æˆ·çš„å¹´æ”¶å…¥å’Œæœˆåº¦ä¿¡ç”¨å¡ä½™é¢</li>
<li>åœ¨å›¾å·¦è¾¹å±•ç¤ºäº†æŸä¸ªæœˆä»½çš„ç”¨æˆ·:
<ol class="org-ol">
<li>æ©™è‰²æ˜¯è¿çº¦çš„(å æ€»ä½“çš„3%)</li>
<li>è“è‰²æ˜¯æ²¡æœ‰è¿çº¦çš„(å æ€»ä½“çš„97%,è¿™é‡Œåªåˆ—å‡ºä¸€éƒ¨åˆ†)</li>
</ol></li>
<li>æˆ‘ä»¬ä»å·¦å›¾ä¼¼ä¹å‘ç°é€¾æœŸçš„äººçš„ä¿¡ç”¨å¡ä½™é¢æ¯”ä¸é€¾æœŸçš„äººé«˜</li>
<li>ä¸­é—´çš„å›¾æ˜¯ä¸€ä¸ªbolplot:
<ol class="org-ol">
<li>inputæ˜¯balance</li>
<li>outputæ˜¯default variable(æ˜¯å¦è¿çº¦)</li>
<li>å¯è§balanceè¶Šé«˜è¶Šå®¹æ˜“è¿çº¦</li>
</ol></li>
<li>å³é—´çš„å›¾æ˜¯å¦å¤–ä¸€ä¸ªbolplot:
<ol class="org-ol">
<li>inputæ˜¯income</li>
<li>outputæ˜¯default variable(æ˜¯å¦è¿çº¦)</li>
<li>incomeå’Œdefaultæ²¡æœ‰æ˜æ˜¾å…³ç³»</li>
</ol></li>
<li>æœ¬ç« æˆ‘ä»¬å…¶å®å°±æ˜¯å­¦ä¹ å¦‚ä½•å»ºç«‹ä¸€ä¸ªmodelæ¥æ ¹æ®balance( \(X_1\) ), income( \(X_2\) )é¢„æµ‹default( \(Y\) ),
å½“ç„¶äº†,è¿™é‡Œçš„ \(Y\) æ˜¯quantitativeçš„,æ‰€ä»¥simple linear regression modelå°±ä¸å†åˆé€‚äº†</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org8af2708" class="outline-3">
<h3 id="org8af2708"><span class="section-number-3">4.2.</span> Why Not Linear Regression?</h3>
<div class="outline-text-3" id="text-4-2">
<ul class="org-ul">
<li>é¦–å…ˆæ¥è§£é‡Šä¸‹ä¸ºä»€ä¹ˆlinear regressionå¯¹äºqualitative responseä¸åˆé€‚</li>
<li><p>
å‡è®¾æˆ‘ä»¬å¸Œæœ›æ ¹æ®ç—…äººçš„ç—‡çŠ¶æ¥é¢„æµ‹è¯¥ç—…äººç¬¦åˆå“ªç§medical condition,é‚£ä¹ˆæˆ‘ä»¬è€ƒè™‘æŠŠquantitative response
è¿›è¡Œencoding
</p>
\begin{equation}
Y = \begin{cases}
1 & \text{if } stroke; \\
2 & \text{if } drug overdose; \\
3 & \text{if } epileptic seizure;
\end{cases}
\end{equation}</li>
<li>ä½¿ç”¨äº†è¿™ç§codingæ–¹æ³•,æˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ä¸Šä¸€ç« å­¦ä¹ çš„linear regression modelæ¥é¢„æµ‹Yäº†,ä½†æ˜¯å¾ˆä¸å¹¸,è¿™ç§åšæ³•æ˜¯é”™è¯¯çš„!åŸå› å¦‚ä¸‹:
<ul class="org-ul">
<li>è¿™ç§åšæ³•æš—ç¤ºäº†orderingçš„å­˜åœ¨,æŠŠdrug overdoseå®‰æ’åœ¨strokeå’Œepileptic seizureä¸­é—´,æš—ç¤ºäº†ä¸‰è€…çš„order</li>
<li>è¿™ç§åšæ³•åŒæ—¶æš—ç¤ºäº†å¦‚ä¸‹ä¸¤ä¸ªçš„differenceéƒ½æ˜¯ä¸€æ ·çš„(1å’Œ2å·®1, 2å’Œ3å·®1):
<ol class="org-ol">
<li>stroke å’Œ drug overdose</li>
<li>drug overdose  å’Œepileptic seizure</li>
</ol></li>
<li><p>
å…¶ä»–äººç”šè‡³å¯ä»¥æ›´æ”¹codingçš„é¡ºåº(å¦‚ä¸‹),ç„¶åè¿™ä¸‰ä¸ªconditionçš„ç›¸äº’ä¹‹é—´çš„relationshipå°±å®Œå…¨ä¸ä¸€æ ·äº†
</p>
\begin{equation}
Y = \begin{cases}
1 & \text{if } epileptic seizure;\\
2 & \text{if } stroke; \\
3 & \text{if } drug overdose;
\end{cases}
\end{equation}</li>
<li>ä½¿ç”¨ä¸Šé¢ä¸¤ç§ä¸åŒçš„codingä¼šäº§ç”Ÿå®Œå…¨ä¸ä¸€æ ·çš„linear model,ä¹Ÿå°±ä¼šäº§ç”Ÿå®Œå…¨ä¸ä¸€æ ·çš„prediction</li>
</ul></li>
<li>å¦‚æœresponse variableçœŸçš„å­˜åœ¨natural ordering(mild, moderate, severe),å¹¶ä¸”æˆ‘ä»¬è®¤ä¸ºgap(mildå’Œmoderate)
å’Œ gap(moderateå’Œsevere)ä¸€æ ·,é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ä¾æ¬¡ç»™ä»–ä»¬èµ‹å€¼1,2,3</li>
<li>ä½†æ˜¯ä¸Šè¿°æƒ…å†µéå¸¸å°‘,ç»å¤§éƒ¨åˆ†æƒ…å†µä¸‹:
<ul class="org-ul">
<li>å¦‚æœqualitative responseè¶…è¿‡ä¸¤ç§,é‚£ä¹ˆè½¬æ¢æˆquantitative responseå°±éå¸¸å›°éš¾</li>
<li><p>
å¦‚æœqualitative responseåªæœ‰ä¸¤ç§,é‚£ä¹ˆæƒ…å†µè¿˜å¯ä»¥,æ¯”å¦‚åªæœ‰ä¸¤ç§æƒ…å†µ: stroke, drug overdose,æˆ‘ä»¬å¯
ä»¥ä½¿ç”¨ç¬¬ä¸‰ç« è®²è§£çš„dummy variable è¿›è¡Œå¦‚ä¸‹coding
</p>
\begin{equation}
Y = \begin{cases}
0 & \text{if  stroke};\\
1 & \text{if  drug overdose};
\end{cases}
\end{equation}</li>
<li>è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¯¹è¿™ä¸ªbinary responseåº”ç”¨linear regression:
<ol class="org-ol">
<li>å¦‚æœ \(\hat{Y} > 0.5\) é‚£ä¹ˆå°±æ˜¯drug overdose</li>
<li>å¦‚æœ \(\hat{Y} <= 0.5\) é‚£ä¹ˆå°±æ˜¯stroke</li>
</ol></li>
<li>bianry responseä¹‹æ‰€ä»¥è¿˜å¥½,å°±æ˜¯å› ä¸ºå³ä¾¿æˆ‘ä»¬switchä¸€ä¸‹coding,é‚£ä¹ˆæˆ‘ä»¬çš„predictionä¹Ÿswitchä¸€ä¸‹å°±å¯ä»¥äº†.</li>
<li>è¿™ç§responseåªæœ‰ä¸¤ç§ç»“æœ,ç„¶åcodingæˆ0,1(dummy variable)çš„æ–¹æ³•ç»ˆç©¶æ˜¯æœ‰é—®é¢˜çš„(æ‰€ä»¥æˆ‘ä»¬è¦ä½¿ç”¨å
é¢ä»‹ç»çš„classification method):
<ol class="org-ol">
<li>line regressionçš„ç»“æœå¯èƒ½ä¸å†[0,1]åŒºé—´å†…,æ¯”å¦‚å›¾4-2,å¾—åˆ°äº†è´Ÿå€¼</li>
<li>dummy variableçš„æ–¹æ³•è¿˜ä¸å®¹æ˜“æ‰©å±•åˆ°è¶…è¿‡ä¸¤ä¸ªlevel responseçš„æƒ…å†µ</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org92abfbc" class="outline-3">
<h3 id="org92abfbc"><span class="section-number-3">4.3.</span> Logistic Regression</h3>
<div class="outline-text-3" id="text-4-3">
<ul class="org-ul">
<li>æˆ‘ä»¬å†æ¥çœ‹çœ‹Default data set,å…¶responseå€¼default(è¿çº¦)åˆ†æˆäº†ä¸¤ä¸ªcategory:
<ul class="org-ul">
<li>Yes</li>
<li>No</li>
</ul></li>
<li><p>
å¦‚æœæ˜¯linear regression,é‚£ä¹ˆå°±ä¼šç›´æ¥modelè¿™ä¸ªresponseäº†,è€Œlogistic regression modelçš„æ–¹å‘æ˜¯:
</p>
<pre class="example" id="org3dc1d0e">
Y å±äºæŸä¸ªcategoryçš„æ¦‚ç‡
</pre></li>
<li><p>
å¯¹äºDefault dataæ¥è¯´,logistic regression modelçš„å°±æ˜¯defaultçš„æ¦‚ç‡,æ¯”å¦‚ç»™ä¸€ä¸ªæ–°çš„ç‰¹å®šå€¼çš„balance(æ²¡è§è¿‡),
è¿™ä¸ªbalanceçš„å€¼çš„ç”¨æˆ·è¿çº¦çš„æ¦‚ç‡å¯ä»¥å†™ä½œ
</p>
\begin{equation}
Pr(\text{default = Yes} | \text{balance})
\end{equation}</li>
<li>ä¸Šé¢çš„å…¬å¼å¯ä»¥ç®€å†™æˆ \(p(\text{balance})\), å€¼çš„èŒƒå›´æ˜¯0åˆ°1</li>
<li>æœ‰äº†æ¦‚ç‡ä¹‹å,æˆ‘ä»¬åˆ¤æ–­æ˜¯å¦è¿çº¦å°±å¯ä»¥æ›´åŠ çš„çµæ´»äº†:
<ul class="org-ul">
<li>ä¸€èˆ¬æƒ…å†µä¸‹,å¦‚æœ \(p(balance) > 0.5\),é‚£ä¹ˆæˆ‘ä»¬å°±é¢„æµ‹è¿™ä¸ªç”¨æˆ·ä¼šè¿çº¦</li>
<li>å¦‚æœç”¨æˆ·æ¯”è¾ƒä¿å®ˆ,é‚£ä¹ˆæˆ‘ä»¬å¯ä»¥æ›´æ”¹æ ‡å‡†,æˆ‘ä»¬å¯ä»¥çº¦å®šä¸€æ—¦\(p(balance) > 0.1\),å°±é¢„æµ‹ç”¨æˆ·ä¼šè¿çº¦</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orgae2aae1" class="outline-4">
<h4 id="orgae2aae1"><span class="section-number-4">4.3.1.</span> The Logistic Model</h4>
<div class="outline-text-4" id="text-4-3-1">
<ul class="org-ul">
<li>ç¡®å®šäº†æœ€ç»ˆå½¢æ€ä¹‹å,æˆ‘ä»¬å°±è¦æƒ³å¦‚ä½•modelå¦‚ä¸‹ä¸¤ä¸ªéƒ¨åˆ†äº†:
<ul class="org-ul">
<li>input: X</li>
<li>output: \(p(X) = Pr(Y = 1 | X)\)</li>
</ul></li>
<li><p>
å¾ˆæ˜¾ç„¶æˆ‘ä»¬ä¸èƒ½å†ç”¨å¦‚ä¸‹çš„å½¢å¼äº†,å› ä¸ºè¿™ä¸ªå½¢å¼ä¼šç®—å‡ºæ¥å°äº0,å¤§äº1çš„æ¦‚ç‡
</p>
\begin{equation}
p(X) = \beta_0 + \beta_1X
\end{equation}</li>
<li><p>
ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜,æˆ‘ä»¬è¦è®©æˆ‘ä»¬çš„modelä½¿ç”¨ä¸€ä¸ªfunction,å…¶f(x)çš„ç»“æœåœ¨0å’Œ1ä¹‹é—´,å¾ˆå¤šfunctionéƒ½å…·æœ‰
è¿™ä¹ˆä¸€ä¸ªç‰¹ç‚¹,åœ¨logistic regressioné‡Œé¢,æˆ‘ä»¬ä½¿ç”¨logistic function
</p>
\begin{equation}
p(X) = \cfrac{e^{\beta_0 + \beta_1X}}{1+e^{\beta_0 + \beta_1X}},\tag{4.2}
\end{equation}</li>
<li>ä¸ºäº†èƒ½å¤Ÿfitè¿™ä¸ªmodel,æˆ‘ä»¬éœ€è¦ä½¿ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡(maximum likelihood),åé¢ä¼šè®²åˆ°è¿™ä¸ª</li>
<li>å†æ¥çœ‹å›¾4-2
<ul class="org-ul">
<li>å›¾4-2</li>
<li>ä¸Šå›¾çš„å³ä¾§æè¿°äº†logistic regression modelçš„fit</li>
<li>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°,å¯¹äºlow balance,æˆ‘ä»¬å¯ä»¥å¾—åˆ°å¾ˆä½çš„æ¦‚ç‡å€¼,ä½†æ˜¯ä¹Ÿä¸ä¼šä½äº0</li>
<li>å¯¹äºhigh balance,æˆ‘ä»¬å¯ä»¥å¾—åˆ°å¾ˆé«˜çš„æ¦‚ç‡å€¼,ä½†æ˜¯ä¹Ÿä¸ä¼šé«˜äº1</li>
</ul></li>
<li><p>
å¯¹4-2è¿›è¡Œä¸‹æ”¹åŠ¨,å¯ä»¥å¾—åˆ°4-3,å¦‚ä¸‹
</p>
\begin{equation}
\cfrac{p(X)}{1-p(X)} = e^{\beta_0 + \beta_1X},\tag{4.3}
\end{equation}</li>
<li>å…¬å¼å·¦è¾¹çš„ \(\cfrac{p(X)}{1-p(X)}\) å«åšèµ”ç‡,èµ”ç‡å¯ä»¥æ˜¯0åˆ° \(\infty\):
<ul class="org-ul">
<li>æ•°å€¼è¶Šå°è¯´æ˜è¿çº¦å¯èƒ½è¶Šå°</li>
<li>æ•°å€¼è¶Šå¤§è¯´æ˜è¿çº¦å¯èƒ½è¶Šå¤§</li>
</ul></li>
<li>æ¯”å¦‚ \(p(X) = 0.9\), é‚£ä¹ˆèµ”ç‡å°±æ˜¯9 ( \(\cfrac{0.9}{1-0.9} = 9\) )</li>
<li><p>
ä¸ºäº†æŠŠeæ¶ˆæ‰,æˆ‘ä»¬å¯ä»¥ä¸¤è¾¹å–å¯¹æ•°
</p>
\begin{equation}
log\bigg(\cfrac{p(X)}{1-p(X)}\bigg) = \beta_0 + \beta_1X,\tag{4.4}
\end{equation}</li>
<li>å…¬å¼4-4å·¦è¾¹å°±æ˜¯å«åšlog-odds,æˆ–è€…logit.</li>
<li>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°logistic regression modelçš„logitæ˜¯linearçš„(å¯¹äºXæ¥è¯´)</li>
</ul>
</div>
</div>
<div id="outline-container-org91dcdec" class="outline-4">
<h4 id="org91dcdec"><span class="section-number-4">4.3.2.</span> Estimating the Regression Coefficients</h4>
<div class="outline-text-4" id="text-4-3-2">
<ul class="org-ul">
<li>linear regressionéœ€è¦ä½¿ç”¨æœ€å°äºŒä¹˜æ³•(least square approach)æ¥è®¡ç®—coefficient</li>
<li>å¯¹äºlogistical regressionæˆ‘ä»¬è¦ä½¿ç”¨æ›´åŠ é«˜é˜¶çš„åŠæ³•:æœ€å¤§ä¼¼ç„¶(maximum likelihood), æœ€å¤§ä¼¼ç„¶æ‹¥æœ‰æ›´
å¥½çš„ç»Ÿè®¡å­¦ç‰¹æ€§</li>
<li>ä½¿ç”¨æœ€å¤§ä¼¼ç„¶æ¥fité€»è¾‘å›å½’çš„æœ€åŸºæœ¬ç›´è§‰æ˜¯:æˆ‘ä»¬é€‰å– \(\beta_0, beta_1\), èƒ½è®© \(\hat{p}(x)\) çš„å€¼å’Œobserved
çš„å€¼æœ€æ¥è¿‘.æ¢å¥è¯è¯´å°±æ˜¯
<ul class="org-ul">
<li>å¯¹äºè§‚æµ‹åˆ°defaultçš„æƒ…å†µä¸‹,æˆ‘ä»¬çš„ \(\hat{\beta_0},\hat{\beta_1}\) è®©p(X)æ›´æ¥è¿‘äº1</li>
<li>å¯¹äºè§‚æµ‹åˆ°édefaultçš„æƒ…å†µä¸‹,æˆ‘ä»¬çš„ \(\hat{\beta_0},\hat{\beta_1}\) è®©p(X)æ›´æ¥è¿‘äº0</li>
</ul></li>
<li><p>
æˆ‘ä»¬çš„ç›´è§‰å¯ä»¥ä½¿ç”¨å¦‚ä¸‹çš„æ•°å­¦è¡¨è¾¾å¼å†™å‡ºæ¥,å«åšlikelihood function
</p>
\begin{equation}
l(\beta_0, \beta_1) = \prod_{i:y_i=1} p(x_i) \prod_{i':y_{i'}=0} (1 - p(x_{i'}))
\end{equation}</li>
<li>æˆ‘ä»¬é€‰æ‹©çš„ \(\hat{\beta_0} \hat{\beta_1}\) å°±æ˜¯ç”¨æ¥æœ€å¤§åŒ–è¿™ä¸ªlikelihood functionçš„</li>
<li><p>
è®¡ç®—å¾—åˆ°çš„ç»“æœå¦‚ä¸‹
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Coefficient</th>
<th scope="col" class="org-right">Std. error</th>
<th scope="col" class="org-right">Z-statistic</th>
<th scope="col" class="org-left">P-value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Intercept</td>
<td class="org-right">-10.6513</td>
<td class="org-right">0.3612</td>
<td class="org-right">-29.5</td>
<td class="org-left">&lt; 0.0001</td>
</tr>

<tr>
<td class="org-left">balance</td>
<td class="org-right">0.0055</td>
<td class="org-right">0.0002</td>
<td class="org-right">24.9</td>
<td class="org-left">&lt; 0.0001</td>
</tr>
</tbody>
</table></li>
<li>æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¡ç®—standard erroræ¥è®¡ç®—è¿™ä¸ªmodelçš„å‡†ç¡®ç‡. è¿™é‡Œçš„z-statisticå’Œå‰é¢çº¿æ€§æ¨¡å‹ä¸­çš„t-statistic
èµ·åˆ°åŒæ ·çš„ä½œç”¨</li>
</ul>
</div>
</div>
<div id="outline-container-org695d05f" class="outline-4">
<h4 id="org695d05f"><span class="section-number-4">4.3.3.</span> Making Predictions</h4>
<div class="outline-text-4" id="text-4-3-3">
<ul class="org-ul">
<li>ä¸€æ—¦æœ‰äº†coefficientä¹‹å,æˆ‘ä»¬å†æŠŠbalanceå¸¦å…¥å,å¯ä»¥å¾—åˆ°ä¸åŒbalanceçš„é¢„æµ‹å€¼:
<ul class="org-ul">
<li>balanceä¸º1000çš„æƒ…å†µä¸‹é¢„æµ‹å€¼ä¸º0.00576</li>
<li>balanceä¸º2000çš„æƒ…å†µä¸‹é¢„æµ‹å€¼ä¸º0.586</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org59c16cd" class="outline-4">
<h4 id="org59c16cd"><span class="section-number-4">4.3.4.</span> Multiple Logistic Regression</h4>
<div class="outline-text-4" id="text-4-3-4">
<ul class="org-ul">
<li><p>
æˆ‘ä»¬è¿˜å¯ä»¥æŠŠlogistic Regressionæ‰©å±•åˆ°å¤šä¸ªpredictor,æ¯”å¦‚
</p>
\begin{equation}
log\bigg(\cfrac{p(X)}{1-p(X)}\bigg) = \beta_0 + \beta_1X_1 + \cdot\cdot\cdot + \beta_pX_p,\tag{4.6}
\end{equation}</li>
<li><p>
ä¸Šé¢çš„å…¬å¼å¯ä»¥é‡æ–°å†™ä¸º:
</p>
\begin{equation}
p(X) = \cfrac{e^{\beta_0 + \beta_1X_1+\cdot\cdot\cdot + \beta_pX_p}}{1+e^{\beta_0 + \beta_1X_1+\cdot\cdot\cdot + \beta_pX_p}}\tag{4.7}
\end{equation}</li>
</ul>
</div>
</div>
<div id="outline-container-orge8ea61f" class="outline-4">
<h4 id="orge8ea61f"><span class="section-number-4">4.3.5.</span> Logistic Regression for &gt; 2 Response Classes</h4>
<div class="outline-text-4" id="text-4-3-5">
<ul class="org-ul">
<li>æˆ‘ä»¬ä¸€èˆ¬ä¸ä½¿ç”¨æœ€å¤§ä¼¼ç„¶æ³•æ¥å¤„ç†è¶…è¿‡ä¸¤ç§responseçš„æƒ…å†µ</li>
<li>discriminant analysisæ˜¯å¤„ç†multiple-class classificationçš„æµè¡Œæ–¹æ¡ˆ</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgf067726" class="outline-3">
<h3 id="orgf067726"><span class="section-number-3">4.4.</span> Linear Discriminant Analysis</h3>
<div class="outline-text-3" id="text-4-4">
<ul class="org-ul">
<li>å‰é¢è®²äº†Logistic regressionå¦‚ä½•è¿›è¡Œåˆ†ç±»ï¼ˆä¸»è¦æ˜¯two response classåˆ†ç±»ï¼‰:
<ul class="org-ul">
<li><p>
ä½¿ç”¨çš„ logistic function å¦‚ä¸‹
</p>
\begin{equation}
p(X) = \cfrac{e^{\beta_0 + \beta_1X_1+\cdot\cdot\cdot + \beta_pX_p}}{1+e^{\beta_0 + \beta_1X_1+\cdot\cdot\cdot + \beta_pX_p}}\tag{4.7}
\end{equation}</li>
<li>logistic function çš„ç»“æœç”¨æ¥åˆ¤æ–­å¦‚ä¸‹çš„æ¦‚ç‡ \(Pr(Y=k|X=x)\) :
<ol class="org-ol">
<li>å¦‚æœæ¦‚ç‡å¤§äº 0.5,åˆ™æ˜¯å±äºç±»å‹k</li>
<li>å¦‚æœæ¦‚ç‡å°äº 0.5,åˆ™å±äºå¦å¤–çš„çš„ç±»å‹</li>
</ol></li>
</ul></li>
<li>è¿™ä¸€èŠ‚æˆ‘ä»¬è¦ä»‹ç»ä¸€ä¸ªæ–°çš„æ›¿ä»£logistic regressionçš„approachæ¥ä¼°è®¡è¿™äº›æ¦‚ç‡.è¿™ä¸ªæ–°æ–¹æ³•å«åšLinear Discriminant Analysis</li>
<li>è¿™ä¸ªæ–°çš„æ–¹æ³•ä¸æ˜¯é‚£ä¹ˆçš„ç›´æ¥:
<ul class="org-ul">
<li>æˆ‘ä»¬é¦–å…ˆæŸ¥æ‰¾åœ¨given Yå­˜åœ¨çš„æƒ…å†µä¸‹,Xçš„æ¦‚ç‡,ä¹Ÿå°±æ˜¯ \(Pr(Y=x|X=k)\) çš„æ¦‚ç‡</li>
<li>ç„¶åç”± \(Pr(Y=x|X=k)\) æ ¹æ®è´å¶æ–¯å®šå¾‹è®¡ç®—è·å¾— \(Pr(Y=k|X=x)\)</li>
</ul></li>
<li>åœ¨å·²ç»æœ‰logistic regressionçš„æƒ…å†µä¸‹,ä¸ºä»€ä¹ˆè¿˜è¦å¦å¤–çš„method,åŸå› å¦‚ä¸‹:
<ul class="org-ul">
<li>å½“æˆ‘ä»¬çš„responseçš„åˆ†ç±»,åˆ†æ•£çš„æ¯”è¾ƒå¼€çš„æ—¶å€™, logistic regressionçš„ç»“æœæ˜¯æ¯”è¾ƒä¸ç¨³å®šçš„,è€Œæ–°çš„LDAæ€æ²¡æœ‰è¿™ä¸ªé—®é¢˜</li>
<li>å½“æˆ‘ä»¬çš„predictor Xçš„næ¯”è¾ƒå°,å¹¶ä¸”predictoråœ¨åˆ†ç±»ä¸­ç¬¦åˆæ­£æ€åˆ†å¸ƒçš„æƒ…å†µä¸‹,LDAæ¯”linear regressionæ›´ç¨³å®š</li>
<li>å¦å¤–,å½“æˆ‘ä»¬çš„responseæœ‰è¶…è¿‡ä¸¤ä¸ªçš„åˆ†ç±»çš„æƒ…å†µä¸‹,LDAæ›´æµè¡Œ</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orgb0aabbe" class="outline-4">
<h4 id="orgb0aabbe"><span class="section-number-4">4.4.1.</span> Using Bayes' Theorem for Classification</h4>
<div class="outline-text-4" id="text-4-4-1">
<ul class="org-ul">
<li>å‡è®¾æˆ‘ä»¬æƒ³æŠŠä¸€ä¸ªobservationåˆ†åˆ°Kä¸ªç±»é‡Œé¢(å…¶ä¸­K&gt;=2)</li>
<li>æ¢å¥è¯è¯´,å°±æ˜¯æˆ‘ä»¬çš„qualitative responseèƒ½å¤Ÿæœ‰Kç§ä¸åŒçš„distinct, unordered value</li>
<li><p>
é‚£ä¹ˆ,æˆ‘ä»¬å°±è®© \(\pi_k\) æ¥ä»£è¡¨
</p>
<pre class="example" id="org64f6d75">
éšä¾¿æ‰¾ä¸€ä¸ªobservation,è¿™ä¸ªobservationåˆšå¥½åœ¨ç¬¬kä¸ªç±»åˆ«,è¿™ç§æƒ…å†µçš„å…ˆéªŒæ¦‚ç‡(prior probability)
</pre></li>
<li>å…ˆéªŒæ¦‚ç‡å¾ˆå®¹æ˜“ç®—,æˆ‘ä»¬ç»Ÿè®¡æ‰€æœ‰çš„obervationçš„æ•°ç›®,ç„¶åå‡è®¾æ˜¯N,å…¶ä¸­å±äºclass kçš„obervationçš„æ•°ç›®æ˜¯x,é‚£ä¹ˆ \(\pi_k = \cfrac{x}{N}\)</li>
<li><p>
ç„¶å,æˆ‘ä»¬å†å¼•å…¥ä¸€ä¸ªæ¦‚å¿µdensity function,æœ¬ä¾‹ä¸­çš„density functionå¦‚ä¸‹
</p>
\begin{equation}
f_k(x) = Pr(X = x | Y= k)
\end{equation}</li>
<li>å¯¹density functionå¯ä»¥ç®€å•å¦‚ä¸‹ç†è§£:
<ul class="org-ul">
<li>\(f_k(x)\) å¦‚æœå¤§,é‚£ä¹ˆå°±æ„å‘³ç€å¦‚ä¸‹æƒ…å†µæœ‰é«˜æ¦‚ç‡:ç¬¬Kä¸ªç±»åˆ«çš„observationçš„Xçº¦ç­‰äºx</li>
<li>\(f_k(x)\) å¦‚æœå°,é‚£ä¹ˆå°±æ„å‘³ç€å¦‚ä¸‹æƒ…å†µåªæœ‰ä½æ¦‚ç‡:ç¬¬Kä¸ªç±»åˆ«çš„observationçš„Xçº¦ç­‰äºx</li>
</ul></li>
<li><p>
æœ‰äº†density functionä¹‹å,æˆ‘ä»¬åˆæ ¹æ®è´å¶æ–¯å®šå¾‹,å¯ä»¥å¾—åˆ°å¦‚ä¸‹å…¬å¼
</p>
\begin{equation}
Pr(Y=k|X=x) = \cfrac{\pi_kf_k(x)}{\sum_{l=1}^K\pi_lf_l(x)},\tag{4.10}
\end{equation}</li>
<li>ä¸Šè¿°å…¬å¼å¯ä»¥å‘Šè¯‰æˆ‘ä»¬:
<ul class="org-ul">
<li>æˆ‘ä»¬å¯ä»¥ä¸ç”¨ç›´æ¥è®¡ç®— \(Pr(Y=k|X=x)\)</li>
<li>è€Œæ˜¯é€šè¿‡è®¡ç®— \(f_k(x)\) å’Œ \(\pi_k\) æ¥åæ¨\(Pr(Y=k|X=x)\)</li>
<li>\(\pi_k\) æ˜¯æ¯”è¾ƒå®¹æ˜“ç®—å‡ºçš„(ç»Ÿè®¡æ‰€æœ‰çš„obervationçš„æ•°ç›®,ç„¶åå‡è®¾æ˜¯N,å…¶ä¸­å±äºclass kçš„obervation
çš„æ•°ç›®æ˜¯x,é‚£ä¹ˆ \(\pi_k = \cfrac{x}{N}\)),æ‰€ä»¥é—®é¢˜çš„å…³é”®åœ¨äºæ±‚ \(f_k(x)\)</li>
</ul></li>
<li>ä¸ºäº†æ–¹ä¾¿,æˆ‘ä»¬æŠŠ \(Pr(Y=k|X=x)\) ç®€ç§°ä¸º \(p_k(X)\) , æˆ‘ä»¬æŠŠ \(p_k(X)\) ç§°ä¹‹ä¸ºåéªŒæ¦‚ç‡,ä¹Ÿå°±æ˜¯
åœ¨ obervation çš„predictorå€¼å·²çŸ¥çš„æƒ…å†µä¸‹, obervation X å±äºclass k çš„æ¦‚ç‡</li>
<li>æœ¬ç« çš„é‡ç‚¹å°±åœ¨äºå¯»æ‰¾ä¸€ä¸ªæ–¹æ³•æ¥ä¼°è®¡ \(f_k(x)\)</li>
</ul>
</div>
</div>
<div id="outline-container-org9d21c72" class="outline-4">
<h4 id="org9d21c72"><span class="section-number-4">4.4.2.</span> Linear Discriminant Analysis for p = 1</h4>
<div class="outline-text-4" id="text-4-4-2">
<ul class="org-ul">
<li>æˆ‘ä»¬å‡è®¾ p=1,ä¹Ÿå°±æ˜¯åªæœ‰ä¸€ä¸ª predictor çš„æƒ…å†µä¸‹,æˆ‘ä»¬å¦‚ä½•é€šè¿‡ estimate \(f_k(x)\) æ¥é¢„ä¼° \(p_k(x)\)</li>
<li>ä¸ºäº†é¢„æµ‹ estimate \(f_k(x)\) ,æˆ‘ä»¬é¦–å…ˆè¦å¯¹observation çš„ form åšä¸€å®šçš„ assumption</li>
<li><p>
å‡è®¾,æˆ‘ä»¬è®¤ä¸º \(f_k(x)\) ç¬¦åˆé«˜æ–¯åˆ†å¸ƒ(æ­£æ€åˆ†å¸ƒ),åœ¨åªæœ‰ä¸€ä¸ª dimension çš„æƒ…å†µä¸‹,normal density çš„ form å¦‚ä¸‹
</p>
\begin{equation}
f_k(x) = \cfrac{1}{\sqrt{2\pi}\sigma_k}exp(-\cfrac{1}{2\sigma_k^2}(x-\mu_k)^2),\tag{4.11}
\end{equation}</li>
<li>å…¶ä¸­ \(\mu_k\) æ˜¯ç¬¬ k ä¸ªclassçš„å¹³å‡æ•°(mean)</li>
<li>å…¶ä¸­ \(\sigma_k^2\) æ˜¯ç¬¬ k ä¸ªclassçš„æ–¹å·®(variance)</li>
<li>æˆ‘ä»¬æ›´è¿›ä¸€æ­¥å‡è®¾æ¯ä¸ªclassçš„æ–¹å·®éƒ½ç›¸ç­‰,ä¹Ÿå°±æ˜¯ \(\sigma_1^2 = \cdot\cdot\cdot = \sigma_1^2\),æˆ‘ä»¬
å°±å¯ä»¥ç®€å•çš„ä½¿ç”¨ \(\sigma^2\) æ¥æ ‡è¯†äº†.</li>
<li><p>
æˆ‘ä»¬æŠŠ4.10å’Œ4.11ç»“åˆèµ·æ¥,å¾—åˆ°äº†ä¸‹é¢çš„å…¬å¼
</p>
\begin{equation}
p_k(x) = \cfrac{\pi_k\cfrac{1}{\sqrt{2\pi}\sigma}exp(-\cfrac{1}{2\sigma^2}(x- \mu_k)^2)}{\sum_{l=1}^K\pi_l\cfrac{1}{\sqrt{2\pi}\sigma}exp(-\cfrac{1}{2\sigma^2}(x- \mu_l)^2)}\tag{4.12}
\end{equation}</li>
<li>æ ¹æ®è´å¶æ–¯å®šå¾‹,ä¸Šé¢çš„ \(p_k(x)\) ä¸­X=xä¸­å“ªä¸ªkå¯¹åº”çš„æ¦‚ç‡æœ€å¤§,é‚£ä¹ˆæˆ‘ä»¬çš„xå°±å±äºç¬¬kä¸ªclass</li>
<li><p>
å¯¹4.12è¿™ä¸ªå…¬å¼è¿›è¡Œä¸¤è¾¹å–log,åœ¨æ•´ç†ä¸€ä¸‹,ä¼šå¾—åˆ°å¦‚ä¸‹çš„å…¬å¼
</p>
\begin{equation}
\delta(x) = x\cdot\cfrac{\mu_k}{\sigma^2} - \cfrac{\mu_k^2}{2\sigma^2} + log(\pi_k),\tag{4.13}
\end{equation}</li>
<li>ä¸Šé¢çš„å…¬å¼ä¹Ÿæ˜¯æ±‚X=xå¯¹åº”çš„kä¸ªæ¦‚ç‡,å“ªä¸ªå¤§xå°±å±äºå“ªä¸ªç±»</li>
<li>æˆ‘ä»¬å†å¯¹ä¸Šé¢çš„å…¬å¼è¿›è¡Œä¸€äº›ç®€åŒ–:
<ul class="org-ul">
<li>å‡è®¾K=2</li>
<li>å‡è®¾ \(\pi_1 = \pi_2\)</li>
</ul></li>
<li>é‚£ä¹ˆ,æˆ‘ä»¬å¯ä»¥å¿½ç•¥4.13ä¸­çš„ \(\sigma\) å’Œ \(\pi_k\) ,å¾—åˆ°:
<ul class="org-ul">
<li><p>
å±äºclass 1çš„æ¦‚ç‡å¤§äºå±äºclass 2 çš„æ¦‚ç‡,å°±æœ‰
</p>
\begin{equation}
x\mu_1 - \cfrac{\mu_2^2}{2} > x\mu_2 - \mu_2^2
\end{equation}</li>
<li><p>
å±äºclass 1çš„æ¦‚ç‡å°äºå±äºclass 2 çš„æ¦‚ç‡,å°±æœ‰
</p>
\begin{equation}
x\mu_1 - \cfrac{\mu_2^2}{2} <= x\mu_2 - \mu_2^2
\end{equation}</li>
<li>ç»¼åˆèµ·æ¥åˆ¤æ–­å°±æ˜¯:
<ol class="org-ol">
<li>å¦‚æœ \(2x(\mu1 - \mu2) > \mu1^2 - \mu2^2\) é‚£ä¹ˆå°±æŠŠobservationèµ‹ç»™class1</li>
<li>å¦‚æœ \(2x(\mu1 - \mu2) <= \mu1^2 - \mu2^2\) é‚£ä¹ˆå°±æŠŠobservationèµ‹ç»™class2</li>
</ol></li>
<li><p>
é’ˆå¯¹K=2çš„æƒ…å†µ,æˆ‘ä»¬è¿˜å¯ä»¥ç”»å‡ºä¸€æ¡bayes decision boundary,è¿™ä¸ªboundaryçš„ä¸¤è¾¹å°±æ˜¯ä¸åŒçš„åˆ†ç±»
</p>
\begin{equation}
x = \cfrac{\mu_1^2 - \mu_2^2}{2(\mu_1 - \mu_2)} = \cfrac{\mu_1 + \mu_2}{2},\tag{4.14}
\end{equation}</li>
</ul></li>
<li>æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå›¾æ¥è¡¨ç¤ºä¸Šé¢çš„æƒ…å†µ
<ul class="org-ul">
<li><p>
å›¾4-4
</p>

<div id="org385193e" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/4-4.png" alt="4-4.png" />
</p>
<p><span class="figure-number">Figure 26: </span>isl/4-4.png</p>
</div></li>
<li>ä¸¤ä¸ªdensity functionåˆ†åˆ«æ˜¯ \(f_1(x)\) å’Œ \(f_2(x)\),åˆ†åˆ«ä»£è¡¨ä¸¤ä¸ªclass</li>
<li>density function \(f_1(x)\) çš„å¹³å‡æ•° \(\mu_1 = -1.25\), æ–¹å·® \(\sigma^2=1\)</li>
<li>density function \(f_2(x)\) çš„å¹³å‡æ•° \(\mu_2 = 1.25\), æ–¹å·® \(\sigma^2=1\)</li>
<li><p>
è¿™ä¸¤ä¸ªdensity functionæœ‰é‡åˆéƒ¨åˆ†,æ‰€ä»¥å¯¹äºæŸä¸ªX=x,æ˜¯ä¸ç¡®å®šobservationåˆ°åº•å±äºå“ªä¸ªclassçš„,è¿™ä¸ª
æ—¶å€™æˆ‘ä»¬å°±è¦åšä¸€ä¸ªå‡è®¾: obervationä»æ¯ä¸ªç±»é‡Œé¢å‡ºæ¥çš„æ¦‚ç‡æ˜¯ç›¸åŒçš„(å…ˆéªŒæ¦‚ç‡ç›¸åŒ)
</p>
\begin{equation}
\pi_1 = \pi_2 = 0.5
\end{equation}</li>
<li>æˆ‘ä»¬ä¼šçœ‹åˆ°æ ¹æ®è´å¶æ–¯classifer:
<ol class="org-ol">
<li>å¦‚æœx &lt; 0,é‚£ä¹ˆobservationå±äºclass1</li>
<li>å¦‚æœx &gt; 0,é‚£ä¹ˆobservationå±äºclass2</li>
</ol></li>
<li>æ³¨æ„,æœ¬ä¾‹å¯ä»¥è®¡ç®—Bayes classifier,æ˜¯æœ‰å¦‚ä¸‹ä¸¤ä¸ªå‰æçš„:
<ol class="org-ol">
<li>æ¯ä¸ªclassä¸­çš„Xæ˜¯ä»é«˜æ–¯åˆ†å¸ƒè·å¾—çš„</li>
<li>æˆ‘ä»¬çŸ¥é“æ¶‰åŠçš„æ‰€æœ‰çš„parameter</li>
</ol></li>
<li>åœ¨ç°å®åœºæ™¯ä¸‹,æˆ‘ä»¬æ— æ³•è®¡ç®—Bayes classifier</li>
</ul></li>
<li>åœ¨å®è·µå½“ä¸­,å³ä¾¿æˆ‘ä»¬éå¸¸ç¡®ä¿¡æ¯ä¸ªclassé‡Œé¢çš„Xæ˜¯ç¬¦åˆé«˜æ–¯åˆ†å¸ƒçš„,æˆ‘ä»¬è¿˜æ˜¯è¦estimateå¦‚ä¸‹çš„å‚æ•°:
<ul class="org-ul">
<li>\(\mu_1,\cdot\cdot\cdot,\mu_K\)</li>
<li>\(\pi_1,\cdot\cdot\cdot,\pi_K\)</li>
<li>\(\sigma^2\)</li>
</ul></li>
<li>LDA(linear discriminant analysis)å…¶å®å°±æ˜¯åœ¨å®è·µå½“ä¸­,ä½¿ç”¨observationæ¥estimateä¸Šè¯‰å‚æ•°çš„ä¸€ç§approach
æˆ‘ä»¬ä¼šä»¥å¦‚ä¸‹æ–¹æ³•æ¥é¢„æµ‹å‚æ•°:
<ul class="org-ul">
<li><p>
é¢„æµ‹å¹³å‡å€¼
</p>
\begin{equation}
\hat{\mu}_k = \cfrac{1}{n_k}\sum_{\matchclap{i:y_i=k}}x_i
\end{equation}</li>
<li><p>
é¢„æµ‹æ–¹å·®
</p>
\begin{equation}
\hat{\sigma}^2 = \cfrac{1}{n-K}\sum_{\matchclap{k=1}}^K\sum_{\matchclap{i:y_i=k}}(x_i - \hat{u}_k)^2
\end{equation}</li>
<li><p>
é¢„æµ‹å…ˆéªŒæ¦‚ç‡
</p>
\begin{equation}
\hat{\pi}_k = n_k / n
\end{equation}</li>
</ul></li>
<li>ä¸Šé¢çš„ä¸¤ä¸ªé¢„æµ‹å…¬å¼ä¸­:
<ul class="org-ul">
<li>næ˜¯æ‰€æœ‰çš„è®­ç»ƒobservationçš„ä¸ªæ•°</li>
<li>\(n_k\) æ˜¯ç¬¬kä¸ªclassçš„training observation</li>
<li>å¯¹äº \(\mu_k\) çš„estimate(ä¹Ÿå°±æ˜¯ä¸Šé¢çš„\(\hat{\mu}_k\))çš„è®¡ç®—ficoç®€å•,å°±æ˜¯æ‰€æœ‰å±äºkth classçš„observationçš„å¹³å‡å€¼</li>
<li>\(\hat{\sigma}^2\)  å¯ä»¥çœ‹åšæ˜¯Kä¸ªclassçš„sampleæ–¹å·®çš„åŠ æƒå¹³å‡å€¼</li>
<li>å¦‚æœ \(\pi_1\cdot\cdot\cdot\pi_K\) å·²ç»çŸ¥é“çš„æƒ…å†µä¸‹,å¯ä»¥ä¸ç”¨estimate \(\pi_k\)</li>
</ul></li>
<li><p>
æŠŠè¿™ä¸‰ä¸ªestimateçš„æ–¹æ³•å¸¦å…¥4-13,é‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°å¦‚ä¸‹è®¡ç®—xå±äºé‚£ä¸ªkçš„æ¦‚ç‡,xè®¡ç®—å¾—åˆ°çš„å±äºå“ªä¸ªk
çš„æ¦‚ç‡é«˜,xå°±å±äºå“ªä¸ªk
</p>
\begin{equation}
\hat{\delta}_k(x) = x \cdot\cfrac{\hat{\mu}_k}{\hat{\sigma}^2} - \cfrac{\hat{\mu}_k^2}{2\hat{\sigma}^2} + log(\hat{\pi}_k),\tag{4.17}
\end{equation}</li>
<li>LDA(Linear Discriminant Analysis)ä¸­çš„Linear,æŒ‡çš„æ˜¯:
<ul class="org-ul">
<li>\(\hat{\delta}_k(x)\) æ˜¯xçš„linear function(å…¶ä»–éƒ½å¯ä»¥çœ‹åšå¸¸æ•°)</li>
</ul></li>
<li>å¦‚å›¾
<ul class="org-ul">
<li><p>
å›¾4-4
</p>

<div id="org5955d2f" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/4-4.png" alt="4-4.png" />
</p>
<p><span class="figure-number">Figure 27: </span>isl/4-4.png</p>
</div></li>
<li>ä¸Šå›¾çš„æœ‰åŠéƒ¨åˆ†è¡¨ç¤ºäº†20ä¸ªrandom sample observationçš„histogram</li>
<li>ä¸ºäº†ä½¿ç”¨LDA,æˆ‘ä»¬ä½¿ç”¨ä¸Šé¢çš„estimateçš„æ–¹æ³•æ¥estimate( \(\pi_k, \mu_k, \sigma^2\),ç„¶åè®¡ç®—å‡ºdecison
boundaryåœ¨ä¸Šå›¾æ˜¯é»‘è‰²å®çº¿è¡¨ç¤º(è¿™ä¸ªå®çº¿æ¥è‡ªèƒ½ä½¿4.17æœ€å¤§çš„å–å€¼)</li>
<li>åœ¨è¿™æ¡çº¿çš„å·¦è¾¹å°±æ˜¯green class,åœ¨è¿™æ¡çº¿çš„å³è¾¹å°±æ˜¯purple class</li>
<li>åœ¨è¿™ä¸ªä¾‹å­ä¸­,ç”±äº \(n_1 = n_2 = 20\),æ‰€ä»¥æˆ‘ä»¬æœ‰ \(\pi_1 = \pi_2\), æ‰€ä»¥é»‘è‰²çš„çº¿è·¯å…¶å®å°±æ˜¯å‚ç›´äºè¿™
ä¸ªç‚¹ \((\hat{\mu}_1 + \hat{\mu}_2)/2\) çš„çº¿</li>
<li>è™šçº¿å°±æ˜¯Bayes decision boundary(é”™è¯¯ç‡æ˜¯10.6%),æˆ‘ä»¬çš„LDA decision boundaryåœ¨å®ƒå·¦è¾¹ä¸€ç‚¹ç‚¹(é”™
è¯¯ç‡11.1%),LDAé”™è¯¯ç‡åªæ¯”è´å¶æ–¯åˆ†ç±»(ç†æƒ³æƒ…å†µ)å·®ä¸€ç‚¹ç‚¹.å¯è§å¯¹äºè¿™ä¸ªdata set,LDAåšçš„éå¸¸çš„å¥½</li>
</ul></li>
<li>éœ€è¦æ³¨æ„çš„æ˜¯,æˆ‘ä»¬çš„LDAåˆ†ç±»è¾¾åˆ°ä¸Šè¿°æ•ˆæœ,åŸºäºäº†å¤šç§å‡è®¾:
<ul class="org-ul">
<li>æ¯ä¸ªclasså†…éƒ¨çš„observationéƒ½æœä»æ­£æ€åˆ†å¸ƒ</li>
<li>æ‰€æœ‰çš„æ–¹å·®éƒ½æ˜¯ä¸€æ ·çš„</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgc5cdef8" class="outline-4">
<h4 id="orgc5cdef8"><span class="section-number-4">4.4.3.</span> Linear Discriminant Analysis for p &gt; 1</h4>
<div class="outline-text-4" id="text-4-4-3">
<ul class="org-ul">
<li>æœ¬èŠ‚æˆ‘ä»¬ä¼šæŠŠLDA classifieræ¨å¹¿åˆ°å¤šä¸ªpredictor</li>
<li>TODO</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-orgbb6f844" class="outline-2">
<h2 id="orgbb6f844"><span class="section-number-2">5.</span> Chapter 5: Resampling Method</h2>
<div class="outline-text-2" id="text-5">
<ul class="org-ul">
<li>é‡é‡‡æ ·(Resampling Method)æ˜¯ç°ä»£ç»Ÿè®¡å­¦ä¸å¯æˆ–ç¼ºçš„å·¥å…·</li>
<li>é‡é‡‡æ ·åŒ…æ‹¬ä»training seté‡Œé¢ä¸æ–­çš„æå–sample,å¹¶ä¸”æ ¹æ®è¿™ä¸ªsampleä¸åœçš„è®­ç»ƒä¸åŒçš„model,å› ä¸ºè¿™æ ·å¯ä»¥
è·å–é¢å¤–çš„ä¿¡æ¯</li>
<li>é‡é‡‡æ ·å¯èƒ½ä¼šè®¡ç®—èµ·æ¥éå¸¸çš„ç¹é‡,å› ä¸ºä»–ä»¬ä¼šä½¿ç”¨training dataçš„ä¸€ä¸ªéƒ¨åˆ†,ç„¶ååå¤fitåŒä¸€ä¸ªstatistical method</li>
<li>ä½†æ˜¯,ç”±äºè¿‘äº›å¹´æ¥è®¡ç®—æœºç®—åŠ›çš„æé«˜,è®¡ç®—åŠ›å·²ç»ä¸ç®—å¤ªå¤§çš„é—®é¢˜</li>
<li>æœ¬ç« æˆ‘ä»¬ä¼šè®¨è®ºä¸¤ç§æœ€å¸¸è§çš„é‡é‡‡æ ·çš„æ–¹æ³•:
<ul class="org-ul">
<li>cross-validation</li>
<li>bootstrap</li>
</ul></li>
<li>è¿™ä¸¤ç§æ–¹æ³•åœ¨å®è·µå½“ä¸­,éƒ½æ˜¯éå¸¸é‡è¦çš„å·¥å…·,æ¯”å¦‚:
<ul class="org-ul">
<li>cross-validationå¯ä»¥ç”¨æ¥ä¼°è®¡ä¸€ä¸ªstatistical learning methodçš„test error,ç”¨æ¥è¯„ä¼°æ€§èƒ½,æˆ–è€…é€‰æ‹©flexibilityçš„çº§åˆ«</li>
</ul></li>
<li>evaluatingä¸€ä¸ªmodelçš„performanceçš„è¿‡ç¨‹å«åšmodel assessment(æ¨¡å‹è¯„ä¼°)</li>
<li>selectingä¸€ä¸ªmodelçš„level of flexibilityçš„è¿‡ç¨‹å«åšmodel selection(æ¨¡å‹é€‰æ‹©)</li>
<li>bootstrapå¯ä»¥ç”¨åˆ°å¤šä¸ªcontext:
<ul class="org-ul">
<li>ä¸ºæŸä¸ªç‰¹å®šçš„parameter estimateæä¾›measure of accuracy</li>
<li>ä¸ºæŸä¸ªç‰¹å®šçš„statistical learning methodæä¾›measure of accuracy</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orgc4694ed" class="outline-3">
<h3 id="orgc4694ed"><span class="section-number-3">5.1.</span> Cross-Validation</h3>
<div class="outline-text-3" id="text-5-1">
<ul class="org-ul">
<li>ç¬¬äºŒç« æˆ‘ä»¬è®¨è®ºäº†test eror rateå’Œtraining error rateä¹‹é—´çš„åŒºåˆ«:
<ul class="org-ul">
<li>test erroræ˜¯ä½¿ç”¨statistical learning methodæ¥predictæ–°çš„obervationäº§ç”Ÿçš„å¹³å‡error(æ³¨æ„è¿™äº›æ–°çš„
observationåœ¨training setæ˜¯ä¸å­˜åœ¨çš„)</li>
</ul></li>
<li>å¯¹äºä¸€ä¸ªç»™å®šçš„date set,æŸä¸ªä¸€ä¸ªstatistical learning methodè¢«æ‰¹å‡†ä½¿ç”¨çš„å‰æ,æ˜¯è¿™ä¸ªmethodçš„test errorè¶³å¤Ÿä½</li>
<li>åœ¨æ•°é‡æ¯”è¾ƒå¤§çš„test setå·²ç»å®šçš„æƒ…å†µä¸‹, test erroå¯ä»¥å¾ˆè½»æ˜“çš„ç®—å‡ºæ¥.ä½†æ˜¯ç¡®å®štest setå¹¶ä¸å®¹æ˜“</li>
<li><p>
training errorçš„è®¡ç®—æ–¹æ³•,æ˜¯æŠŠstatistical learning methodåº”ç”¨åˆ°trainingä½¿ç”¨çš„è¿™äº›observation.æ­£
å¦‚ç¬¬äºŒç« æ‰€è¯´
</p>
<pre class="example" id="orgb47e255">
training error rateé€šå¸¸å’Œtest error rateçš„å€¼ä¸ä¸€è‡´: ç»å¸¸æ¥è¯´training error rateä¼šä½äºtest error rate
</pre></li>
<li>åœ¨æ²¡æœ‰æ•°æ®é‡åºå¤§çš„test setçš„æƒ…å†µä¸‹,å¯ä»¥ä½¿ç”¨å¾ˆå¤šå…¶ä»–çš„æ–¹æ³•æ¥estimateè¿™ä¸ªæ•°å€¼(å€Ÿç”¨training data)</li>
</ul>
</div>
<div id="outline-container-org4d1102d" class="outline-4">
<h4 id="org4d1102d"><span class="section-number-4">5.1.1.</span> The Validation Set Approach</h4>
<div class="outline-text-4" id="text-5-1-1">
<ul class="org-ul">
<li>å‡è®¾æˆ‘ä»¬çš„å·¥ä½œå¦‚ä¸‹:
<ol class="org-ol">
<li>fittingä¸€ä¸ªstatistical learning methodåˆ°ä¸€ç³»åˆ—çš„observationä¸Šå»</li>
<li>ä¼°ç®—è¿™ä¸ªstatistical learning methodçš„test error</li>
</ol></li>
<li>é‚£ä¹ˆæˆ‘ä»¬çš„å·¥ä½œå¾ˆé€‚åˆä½¿ç”¨validation set approach:
<ul class="org-ul">
<li><p>
å›¾5-1
</p>

<div id="orgb607e92" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/5-1.png" alt="5-1.png" />
</p>
<p><span class="figure-number">Figure 28: </span>isl/5-1.png</p>
</div></li>
<li>validation set approachçš„ç¬¬ä¸€æ­¥æ˜¯éšæœºçš„å§oversvationåˆ†æˆä¸¤ä¸ªéƒ¨åˆ†:
<ol class="org-ol">
<li>training st: å›¾ä¸­è“è‰²éƒ¨åˆ†</li>
<li>validation set(æˆ–è€…å«åšhold-out set): å›¾ä¸­ç±³é»„è‰²éƒ¨åˆ†</li>
</ol></li>
<li>æˆ‘ä»¬çš„modelåœ¨fittingçš„æ—¶å€™,æ˜¯ä½¿ç”¨validation set</li>
<li>å·²ç»fitted modelåœ¨è®¡ç®—test error rate(ä¸»è¦æ˜¯ä½¿ç”¨MSE),æ˜¯ä½¿ç”¨validation set</li>
</ul></li>
<li>æˆ‘ä»¬ä½¿ç”¨Auto data setæ¥ä»‹ç»ä¸‹validation set approach:
<ul class="org-ul">
<li>å‰é¢è®²äº†åœ¨ Auto data setä¸­,mpgå’Œhorsepowerå¥½åƒä¸æ˜¯çº¿æ€§å…³ç³»</li>
<li>æ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨mpgå’Œ \(horsepower^2\) æ¥æä¾›æ›´å¥½çš„model</li>
<li>äºŒé¡¹å¼æä¾›äº†æ›´å¥½çš„model,é‚£ä¹ˆå¾ˆè‡ªç„¶çš„,æˆ‘ä»¬ä¼šæƒ³,ä¸‰é¡¹å¼,ä¹ƒè‡³æ›´å¤šé¡¹å¼ä¼šä¸ä¼šæä¾›æ›´å¥½çš„model</li>
<li>æˆ‘ä»¬ä¹‹å‰æ˜¯ä½¿ç”¨p-valueæ¥æ¯”è¾ƒäºŒé¡¹å¼,ä¸‰é¡¹å¼,Né¡¹å¼çš„fitç»“æœ</li>
<li>ä½†æ˜¯æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨validation set approachæ¥åšè¿™ä»¶äº‹</li>
</ul></li>
<li>å¦‚å›¾
<ul class="org-ul">
<li><p>
å›¾5-2
</p>

<div id="orge08b1f2" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/5-2.png" alt="5-2.png" />
</p>
<p><span class="figure-number">Figure 29: </span>isl/5-2.png</p>
</div></li>
<li>ä¸Šå›¾å·¦è¾¹æˆ‘ä»¬å¯ä»¥çœ‹åˆ°:
<ol class="org-ol">
<li>äºŒé¡¹å¼test error(MSE)ä¼šæ¯”çº¿æ€§çš„ test error(MSE)å°å¾ˆå¤š</li>
<li>ä½†æ˜¯ä¸‰é¡¹å¼çš„test errorå°±åˆæ¯”äºŒé¡¹å¼çš„test erroré«˜äº†.æ‰€ä»¥,å¼•å…¥ä¸‰é¡¹å¼å¹¶ä¸èƒ½æé«˜prediction</li>
</ol></li>
</ul></li>
<li>æ•´ä¸ªè¿‡ç¨‹ä¸­,è·å–training setå’Œvalidation setçš„è¿‡ç¨‹éƒ½æ˜¯è‡ªåŠ¨çš„:
<ul class="org-ul">
<li>æ¯æ¬¡æŒ‰æ¯”ä¾‹"éšæœº"çš„åˆ’åˆ†ä¸€éƒ¨åˆ†æ•°æ®åˆ°training set,å¦å¤–ä¸€éƒ¨åˆ†æ•°æ®åˆ°test set</li>
</ul></li>
<li>å¦‚æœæˆ‘ä»¬é‡å¤ä¸Šé¢çš„è¿‡ç¨‹Næ¬¡,é‚£ä¹ˆNæ¬¡è·å¾—çš„training setæ•°ç›®ä¸€è‡´,ä½†æ˜¯å†…å®¹ä¸ä¸€è‡´.</li>
<li>åŒæ ·validation setæ•°ç›®ä¸€è‡´,å†…å®¹ä¸ä¸€è‡´.</li>
<li>ä¸¤ç»„å†…å®¹ä¸ä¸€è‡´çš„training setå’Œvalidation set,æˆ‘ä»¬è¿˜æ˜¯ä¼šå¾—åˆ°Nä¸ªä¸åŒmodel,å’ŒNä¸ªä¸åŒçš„testMSE</li>
<li>ä»¥Auto data setä¸ºä¾‹:
<ul class="org-ul">
<li><p>
å›¾5-2
</p>

<div id="org39e6d78" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/5-2.png" alt="5-2.png" />
</p>
<p><span class="figure-number">Figure 30: </span>isl/5-2.png</p>
</div></li>
<li>å³å›¾æ˜¯N=10çš„æƒ…å†µä¸‹,å¾—åˆ°çš„åæ¬¡test MSEæ›²çº¿(æ¯ä¸ªç‚¹ä»£è¡¨horsepowerå–äº†xæ¬¡é¡¹)</li>
<li>åæ¬¡çš„æ›²çº¿éƒ½è¯æ˜,äºŒæ¬¡horsepoweræ¨¡å‹å¥½äºä¸€æ¬¡horsepoweræ¨¡å‹</li>
</ul></li>
<li>validation set approachä»æ¦‚å¿µä¸Šæ¥è¯´æ¯”è¾ƒç®€å•,è€Œä¸”å®¹æ˜“å®ç°,ä½†æ˜¯å®ƒæœ‰å¦‚ä¸‹ä¸¤ä¸ªæ½œåœ¨çš„ç¼ºç‚¹:
<ul class="org-ul">
<li>å¦‚å›¾5-2å³è¾¹æ‰€ç¤º,ç”±äºé€‰å–training set, validation setçš„ä¸åŒ,ç®—å‡ºæ¥çš„test error rateä¼šæœ‰åŒºåˆ«</li>
<li>åªæœ‰ä¸€éƒ¨åˆ†çš„observationä½œç”¨äºmodel(å°±æ˜¯é‚£äº›è¿›äº†training setçš„observation).è€Œå¯¹äºstatistical
methodæ¥è¯´,æ•°æ®è¶Šå¤šè¶Šå¥½,éƒ¨åˆ†çš„æ•°æ®è®­ç»ƒæ¨¡å‹ç›¸æ¯”äºå…¨é‡æ•°æ®è®­ç»ƒçš„æ¨¡å‹æ•ˆæœè¦å·®</li>
</ul></li>
<li>ä¸‹é¢è®²çš„cross-validtion,ä¼šè§£å†³ä¸Šé¢ä¸¤ä¸ªé—®é¢˜</li>
</ul>
</div>
</div>
<div id="outline-container-orgd0243c8" class="outline-4">
<h4 id="orgd0243c8"><span class="section-number-4">5.1.2.</span> Leave-One-Out Cross-Validation</h4>
<div class="outline-text-4" id="text-5-1-2">
<ul class="org-ul">
<li>Leave-one-out cross-validation(LOOCV)å’Œä¸Šä¸€èŠ‚çš„ validation set approachç±»ä¼¼,ä½†æ˜¯æ˜¯ä¸ºäº†è§£å†³ä¸Šé¢
ä¸€èŠ‚ validation set approachçš„ç¼ºç‚¹çš„</li>
<li>å’Œvalidation set approachç±»ä¼¼, LOOCVä¹Ÿè¦æŠŠobservationåˆ†æˆä¸¤ä¸ªéƒ¨åˆ†,ä½†æ˜¯å’Œvalidation set approach
ä¸åŒçš„æ˜¯:
<ul class="org-ul">
<li>LOOCVå¹¶ä¸æ˜¯æŠŠobservationå¹³åˆ†æˆä¸¤ä¸ªç›¸ç­‰çš„set(training setå’Œvalidation set)</li>
<li>LOOCVçš„validation setå°±ä¸€ä¸ªobervation \((x_1, y_1)\) ,å‰©ä¸‹çš„éƒ¨åˆ† \({(x_2, y_2),\cdot\cdot\cdot,(x_n, y_n)\) åštraining set</li>
</ul></li>
<li>å¦‚å›¾
<ul class="org-ul">
<li><p>
å›¾5-3
</p>

<div id="orgcb0c480" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/5-3.png" alt="5-3.png" />
</p>
<p><span class="figure-number">Figure 31: </span>isl/5-3.png</p>
</div></li>
<li>å¦‚ä¸Šå›¾,LOOCVæ¯æ¬¡éƒ½æ˜¯é€‰å–ä¸€ä¸ªä½œä¸ºvalidation set,ä¸€å…±è¦é€‰å–næ¬¡</li>
</ul></li>
<li>æˆ‘ä»¬çš„statistical learning method,åœ¨è®­ç»ƒçš„æ—¶å€™,æ˜¯ä½¿ç”¨n-1æ¬¡çš„observation</li>
<li>é¢„æµ‹çš„æ—¶å€™,å°±ä½¿ç”¨validation seté‡Œé¢å”¯ä¸€çš„å€¼ç±»è®¡ç®—prediction \(\hat{y}\),æ¯”å¦‚æŠŠ \((x_1, y_1)\) ä½œä¸º
validation setçš„æ—¶å€™,è®¡ç®—è·å¾—çš„predictionå°±æ˜¯ \(\hat{y}_1\) ,é‚£ä¹ˆ \(MSE_1 = (y_1 - \hat{y}_1)\)</li>
<li>\(MSE_1\) è™½ç„¶æ˜¯unbiasedçš„(å› ä¸ºå®ƒçš„training setå æ®ç»å¤§éƒ¨åˆ†observation),ä½†æ˜¯ç”±äºvalidationå¤ªå°‘(åª
æœ‰ä¸€ä¸ª),æ‰€ä»¥ \(MSE_1\) æ˜¯high variableçš„</li>
<li>ä¸ºäº†è§£å†³ \(MSE_1\) high variableçš„é—®é¢˜,æˆ‘ä»¬è¦é‡å¤ä¸Šé¢çš„è¿‡ç¨‹:
<ul class="org-ul">
<li>é€‰æ‹© \((x_2, y_2)\) ä½œä¸ºvalidation set,ç„¶åé€‰æ‹© \((x_3, y_3)\) &#x2026;ç›´åˆ° \((x_n, y_n)\)</li>
<li>ç„¶åä¾æ¬¡å¾—åˆ° \(MSE_1, MSE_2, MSE_3, \cdot\cdot\cdot, MSE_n\)</li>
<li><p>
LOOCVæœ€ç»ˆè®¡ç®—MSEçš„æ–¹æ³•æ˜¯æŠŠæ‰€æœ‰å¾—åˆ°çš„MSEæ±‚å¹³å‡å€¼
</p>
\begin{equation}
CV_{(n)} = \cfrac{1}{n}\sum_{i=1}^nMSE_i
\end{equation}</li>
</ul></li>
<li>LOOCVç›¸æ¯”äºvalidation set approachæœ‰å¾ˆå¤šä¼˜ç‚¹:
<ul class="org-ul">
<li>LOOCVçš„biasæ›´ä½,å› ä¸ºæˆ‘ä»¬å‡ ä¹ä½¿ç”¨äº†æ•´ä¸ªobservationæ¥è¿›è¡Œè®­ç»ƒ,ç›¸æ¯”è¾ƒè€Œè¨€validation set approach
åªä½¿ç”¨äº†ä¸€åŠçš„observation. ç”±äºbiasæ›´ä½, LOOCVçš„test error rateåœ¨çœŸçš„predictionçš„æ—¶å€™,ä¹Ÿä¸æ˜¯
overestimateçš„å¾ˆå‰å®³</li>
<li>validation set approachæ¯æ¬¡æ˜¯éšæœºè¯„åˆ†training setå’Œvalidation set,æ‰€ä»¥ä¼šå¯¼è‡´ç®—å‡ºæ¥çš„æ¨¡å‹ä¹Ÿå¥½
test error rateä¹Ÿå¥½,æ¯æ¬¡éƒ½ä¸ä¸€æ ·. è€ŒLOOCVæ¯æ¬¡ç®—å‡ºæ¥çš„å€¼æ˜¯ä¸€æ ·çš„,æ²¡æœ‰éšæœºæ€§</li>
</ul></li>
<li>æˆ‘ä»¬ä½¿ç”¨LOOCVæ¥é¢„æµ‹ä¸€ä¸‹Auto data set
<ul class="org-ul">
<li><p>
å›¾5-4
</p>

<div id="org7e660e2" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/5-4.png" alt="5-4.png" />
</p>
<p><span class="figure-number">Figure 32: </span>isl/5-4.png</p>
</div></li>
</ul></li>
<li>LOOCVæœ‰å¯èƒ½ä¼šéå¸¸çš„expensive,å› ä¸ºmodeléœ€è¦fit næ¬¡,å¦‚æœnéå¸¸å¤§,å¹¶ä¸”model fitå¾ˆæ…¢çš„æƒ…å†µä¸‹,æ•´ä¸ªæµ
ç¨‹ä¸‹æ¥,éå¸¸è´¹æ—¶é—´.</li>
<li><p>
å¯¹äºleast squareslinear æˆ–è€…polynomial regression, LOOCVæœ‰ä¸ªå¿«æ·è®¡ç®—æ–¹å¼(æ³¨æ„è¿™ä¸ªå…¬å¼é‡Œé¢çš„ \(\hat{y}\)
æ˜¯ä¹‹å‰çš„least square fitçš„å¾—åˆ°çš„å€¼
</p>
\begin{equation}
CV_{(n)} = \cfrac{1}{n}\sum_{i=1}^n(\cfrac{y_i - \hat{y}_i}{1 - h_i})
\end{equation}</li>
</ul>
</div>
</div>
<div id="outline-container-orga5282f7" class="outline-4">
<h4 id="orga5282f7"><span class="section-number-4">5.1.3.</span> K-Fold Cross-Validation</h4>
<div class="outline-text-4" id="text-5-1-3">
<ul class="org-ul">
<li>å¯¹LOCVçš„ä¸€ä¸ªæ›¿ä»£è€…æ˜¯k-fold CV. k-fold CV approachåŒ…æ‹¬:
<ul class="org-ul">
<li>éšæœºçš„æŠŠobservationåˆ†åˆ°kä¸ªgroup(ä¹Ÿå«fold),ç„¶åæ¯ä¸ªfoldçš„å¤§å°åŸºæœ¬ç›¸åŒ</li>
<li>ç¬¬ä¸€ä¸ªfoldä½œä¸ºvalidation set</li>
<li>statistical methodä¼šåœ¨å‰©ä¸‹çš„k-1ä¸ªfoldä¸Šé¢è¿›è¡Œè®­ç»ƒ</li>
<li>\(MSE_1\) ä¼šåœ¨ç¬¬ä¸€ä¸ªfoldä¸Šé¢è®¡ç®—</li>
</ul></li>
<li><p>
ä¸Šé¢çš„æµç¨‹é‡å¤kæ¬¡ä¼šå¾—åˆ°kä¸ªMSE,k-fold CVå°±æ˜¯è®¡ç®—è¿™äº›MSEçš„å¹³å‡å€¼
</p>
\begin{equation}
CV_{(k)} = \cfrac{1}{k}\sum_{i=1}^kMSE_i\tag{5.3}
\end{equation}</li>
<li>æˆ‘ä»¬ä¸éš¾å‘ç°LOOCVæ˜¯ä¸€ç§ç‰¹æ®Šæƒ…å†µ(k=n)ä¸‹çš„k-fold CV</li>
<li>kä¸€èˆ¬é€‰æ‹©5æˆ–è€…10.è¿è¡Œ10æ¬¡fittingæ˜¾ç„¶æ¯”næ¬¡(næ¯”è¾ƒå¤§çš„æƒ…å†µä¸‹),çœ‹èµ·æ¥å¯è¡Œ</li>
<li>å¦‚å›¾
<ul class="org-ul">
<li><p>
å›¾5-4
</p>

<div id="org3a90b5b" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/5-4.png" alt="5-4.png" />
</p>
<p><span class="figure-number">Figure 33: </span>isl/5-4.png</p>
</div></li>
<li>ä¸Šå›¾çš„å³ä¾§æ˜¯ä½¿ç”¨Auto data set, è¿›è¡Œäº†9æ¬¡10-fold CVåç”»å‡ºæ¥çš„æ•ˆæœå›¾</li>
<li>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°k-foldè¿˜æ˜¯æœ‰ä¸€äº›variability,ä½†æ˜¯è¿œæ¯”validation set approachç¨³å®š</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgb27462f" class="outline-4">
<h4 id="orgb27462f"><span class="section-number-4">5.1.4.</span> Bias-Variance Trade-Off for k-Fold Cross-Validation</h4>
<div class="outline-text-4" id="text-5-1-4">
<ul class="org-ul">
<li>ä¸Šä¸€èŠ‚æˆ‘ä»¬è®²äº†, k-fold CV(kå°äºn)ç›¸æ¯”äºLOOCVæœ‰è®¡ç®—ä¸Šé¢çš„ä¼˜åŠ¿</li>
<li>å…¶å®,é™¤äº†è®¡ç®—ä¼˜åŠ¿,å¦å¤–ä¸€ä¸ªæ›´é‡è¦(ä½†ä¸æ˜¾è‘—)çš„ä¼˜åŠ¿æ˜¯,k-fold CVèƒ½ç»™å‡ºå¯¹test error rateæ¥è¯´,æ›´åŠ accurate
çš„estimate.åŸå› åœ¨äºbias-variance trade-off:
<ul class="org-ul">
<li>ä»bias reductionçš„è§’åº¦è€ƒè™‘,LOOCVè‚¯å®šæ¯”k-fold CVè¦å¥½</li>
<li>ä»varianceçš„è§’åº¦ä¸Šæ¥è¯´, LOOCVåˆæ¯”k-foldè¦å·®</li>
</ul></li>
<li>LOOCVçš„biaså¤ªå¥½,vairanceå¤ªå·®,è€Œä¸”ä¸èƒ½å˜é€š,ä½†æ˜¯k-foldé€šè¿‡kçš„æ”¹åŠ¨,èƒ½å¤Ÿå®ç°bias-varianceçš„trade-off:
<ul class="org-ul">
<li>æƒ³è¦biaså°‘,å°±å¢å¤§k,æƒ³è¦varianceå°‘,å°±å‡å°‘k.æœ€ç»ˆè¾¾åˆ°ä¸€ä¸ªå¹³è¡¡</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgd309ba1" class="outline-4">
<h4 id="orgd309ba1"><span class="section-number-4">5.1.5.</span> Cross-Validation on Classification Problems</h4>
<div class="outline-text-4" id="text-5-1-5">
<ul class="org-ul">
<li>cross-validationé™¤äº†èƒ½å¤Ÿç”¨å­å•Š regressioné—®é¢˜é‡Œé¢,è¿˜èƒ½ç”¨åœ¨åˆ†ç±»é—®é¢˜é‡Œé¢</li>
<li><p>
åœ¨åˆ†ç±»é—®é¢˜é‡Œé¢,ä¸èƒ½å†ç”¨MSEæ¥ç¡®å®štest erroräº†,è€Œæ˜¯è¦ä½¿ç”¨misclassified observation.æ¯”å¦‚,åœ¨åˆ†ç±»é—®
é¢˜é‡Œé¢,LOOCV error rateä½¿ç”¨å¦‚ä¸‹å…¬å¼
</p>
\begin{equation}
CV_{(n)} = \cfrac{1}{n}\sum_{i=1}^nErr_i,\tag{5.4}
\end{equation}</li>
<li>å…¶ä¸­ \(Err_i = I(y_i \neq \hat{y}_i\))</li>
<li>å¦‚å›¾
<ul class="org-ul">
<li><p>
å›¾5-7
</p>

<div id="orgb8dfe01" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/5-7.png" alt="5-7.png" />
</p>
<p><span class="figure-number">Figure 34: </span>isl/5-7.png</p>
</div></li>
<li>é»‘è‰²å®çº¿ä»£è¡¨standard logistic regression modelä¼°è®¡å‡ºæ¥çš„decision boundary</li>
<li>ç´«è‰²å®çº¿ä»£è¡¨Bayesä¼°è®¡å‡ºæ¥çš„decision boundary</li>
<li>è¿™ä¸ªæ•°æ®é›†æ˜¯simulatedçš„,æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºDegree=1æ—¶:
<ol class="org-ol">
<li>standard logistic regressionçš„test error rateæ˜¯0.201</li>
<li>Bayesçš„test error rateæ˜¯0.133</li>
</ol></li>
<li>å¾ˆæ˜¾ç„¶,çº¿æ€§çš„logistic regressionæ²¡æœ‰è¶³å¤Ÿçš„flexibilityæ¥model bayes decision boundary,æ‰€ä»¥æˆ‘ä»¬
è¦æ‰©å±•logistic regressionåˆ°polynomial function</li>
<li>æˆ‘ä»¬çœ‹Degree=2(äºŒé¡¹å¼å‡½æ•°)çš„å›¾,è¿™æ—¶å€™çš„test error rateåªæé«˜äº†ä¸€ç‚¹ç‚¹,åˆ°äº†0.197</li>
<li>Degree=3(ä¸‰é¡¹å¼å‡½æ•°)çš„å›¾,test error rateç›¸æ¯”äºDegree=2,æé«˜äº†å¾ˆå¤š,è¾¾åˆ°äº†0.160</li>
<li>Degree=4(å››é¡¹å¼å‡½æ•°)çš„å›¾,test error rateç›¸æ¯”äºDegree=3,æé«˜äº†å¾ˆå°‘</li>
</ul></li>
<li>åœ¨å®è·µä¸­,å¯¹äºçœŸå®çš„æ•°æ®,å¯¹äºä¸€ä¸ªæ¨¡å‹,å¦‚ä¸‹ä¸¤ä¸ªå€¼æ˜¯ä¸å¯èƒ½çŸ¥é“çš„:
<ul class="org-ul">
<li>Bayes decision boundary</li>
<li>test error rate</li>
</ul></li>
<li>æ‰€ä»¥åœ¨å®è·µå½“ä¸­,æˆ‘ä»¬å°±æ˜¯å»ç®—cross-validation,å–ä¸€ä¸ªtest error rateæœ€ä½çš„æ¨¡å‹</li>
<li>å¦‚å›¾
<ul class="org-ul">
<li><p>
å›¾5-8
</p>

<div id="org56bbf9f" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/5-8.png" alt="5-8.png" />
</p>
<p><span class="figure-number">Figure 35: </span>isl/5-8.png</p>
</div></li>
<li>å·¦è¾¹çš„å›¾ä½¿ç”¨modelæ˜¯logisitic regression(ä½¿ç”¨ä¸åŒé¡¹å¼çš„function):
<ol class="org-ol">
<li>true test error ä½¿ç”¨é»„è‰²æ ‡è¯†</li>
<li>training errorä½¿ç”¨è“è‰²æ ‡è¯†</li>
<li>10-fold CV errorä½¿ç”¨é»‘è‰²æ ‡è¯†</li>
</ol></li>
<li>å·¦è¾¹å›¾ä¸­å¯ä»¥çœ‹å‡º,å¯¹äºtrainig erroræ¥è¯´,éšç€flexibilityçš„æé«˜,training erroræ˜¯ä¸æ–­é™ä½çš„</li>
<li>å·¦å›¾å¯ä»¥çœ‹å‡º,å’Œtrainig errorä¸åŒ, true, test erroråˆ™æ˜¯å‘ˆç°å‡ºä¸€ä¸ªU-shape(å…ˆä½åé«˜), è€Œ10-fold
CV error rateéå¸¸æ¼‚äº®çš„æ¨¡æ‹Ÿäº†è¿™ä¸ªU-shape(è™½ç„¶å€¼æœ‰å·®å¼‚)</li>
<li>å·¦å›¾å¯ä»¥çœ‹å‡º:
<ol class="org-ol">
<li>å½“ä½¿ç”¨ä¸‰æ¬¡æ–¹å‡½æ•°çš„æ—¶å€™,true test error rateè¾¾åˆ°äº†æœ€ä½å€¼</li>
<li>å½“ä½¿ç”¨å››æ¬¡æ–¹å‡½æ•°çš„æ—¶å€™,10-fold CV error rateä¹Ÿè¾¾åˆ°äº†æœ€ä½å€¼,è€Œä¸”å’Œä¸‰æ¬¡æ–¹æ—¶å€™çš„true test error rateç›¸å·®ä¸å¤š</li>
<li>ç»¼åˆèµ·æ¥,ä½¿ç”¨å››æ¬¡æ–¹å‡½æ•°æœ€å¥½,é¦–å…ˆ10-fold CV error rateåœ¨å››æ¬¡æ–¹è·å¾—æœ€å°å€¼,å…¶æ¬¡true test error
rateè™½ç„¶åœ¨ä¸‰æ¬¡æ–¹å¾—åˆ°æœ€å°å€¼,ä½†æ˜¯åœ¨å››æ¬¡æ–¹çš„æ—¶å€™true test error rateä¹Ÿå°±æ˜¯å¤§ä¸€ç‚¹ç‚¹</li>
</ol></li>
<li>å³è¾¹çš„å›¾ä½¿ç”¨modelæ˜¯KNN(ä½¿ç”¨ä¸åŒæ•°ç›®çš„K):
<ol class="org-ol">
<li>true test error ä½¿ç”¨é»„è‰²æ ‡è¯†</li>
<li>training errorä½¿ç”¨è“è‰²æ ‡è¯†</li>
<li>10-fold CV errorä½¿ç”¨é»‘è‰²æ ‡è¯†</li>
</ol></li>
<li>å³è¾¹çš„å›¾ä¾ç„¶å¯ä»¥çœ‹å‡º, training error rateä¹Ÿæ˜¯éšç€methodçš„flexibilityçš„æé«˜è€Œé™ä½,è¿™ä¹Ÿå°±æ„å‘³ç€
æˆ‘ä»¬ä¸èƒ½é€šè¿‡training error rateæ¥é€‰æ‹©æœ€ä¼˜åŒ–çš„K</li>
<li>å³å›¾å¯ä»¥çœ‹å‡º,æˆ‘ä»¬çš„cross-validation errorè¿˜æ˜¯å¾ˆå¥½çš„æ¨¡æ‹Ÿäº†true test error rate çš„å›¾å½¢(è™½ç„¶æ•°å€¼æœ‰äº›ä½ä¼°)</li>
<li>å³å›¾å¯ä»¥çœ‹å‡º,cross-validation çš„æœ€å°å€¼ä¹Ÿå’Œtrue error rateçš„æœ€å°å€¼æ¥è¿‘. æ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä½¿ç”¨cross-validation
çš„ç»“æœæ¥é€‰æ‹©æœ€ä¼˜çš„K(true error rateæ˜¯æœ€ç†æƒ³çš„é€‰æ‹©Kçš„æ–¹æ³•,ä½†æ˜¯å®é™…æƒ…å†µä¸‹,true error rateæœªçŸ¥)</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org1b78f4d" class="outline-3">
<h3 id="org1b78f4d"><span class="section-number-3">5.2.</span> Bootstrap</h3>
<div class="outline-text-3" id="text-5-2">
</div>
</div>
</div>
<div id="outline-container-orgc44a234" class="outline-2">
<h2 id="orgc44a234"><span class="section-number-2">6.</span> Chapter 6: Linear Model Selection and Regularization</h2>
<div class="outline-text-2" id="text-6">
<ul class="org-ul">
<li><p>
åœ¨regressionä¸­,å¦‚ä¸‹çš„standard linear modelä¼šè¢«å¹¿æ³›ä½¿ç”¨åœ¨response Yå’Œvariable \(X_1,X_2,\cdot\cdot\cdot,X_p\)
</p>
\begin{equation}
Y = \beta_0 + \beta_1X_1 + \cdot\cdot\cdot + \beta_pX_p + \varepsilon\tag{6.1}
\end{equation}</li>
<li>æˆ‘ä»¬å¯ä»¥ä½¿ç”¨least squareæ¥åŒ¹é…è¿™ä¸ªmodel</li>
<li>æœ¬ç« ä¼šä»‹ç»æ–°çš„fitting procedureæ¥æ›¿ä»£least square,æ–°çš„fitting procedureæœ‰å¦‚ä¸‹ä¼˜ç‚¹:
<ul class="org-ul">
<li>Prediction Accuracy:
<ol class="org-ol">
<li>å‡è®¾true relationshipå°±æ˜¯linearçš„,least squareçš„estimateä¼šæœ‰low bias</li>
<li>å¦‚æœn(observationæ•°ç›®)è¿œå¤§äºp(variableä¸ªæ•°),é‚£ä¹ˆ,least squareçš„estimateè¿˜ä¼šæœ‰low variance,
ä»è€Œä¼šåœ¨test observationä¸Šæœ‰å¥½çš„è¡¨ç°</li>
<li>ä½†æ˜¯å¦‚æœnæ¯”på¤§çš„ä¸å¤š,é‚£ä¹ˆleast square fitå°±ä¼šæœ‰å¾ˆå¤švariability,ä¼šå¯¼è‡´overfitting,å¹¶ä¸”åœ¨åç»­
predictionçš„æ—¶å€™è¡¨ç°ç³Ÿç³•</li>
<li>æç«¯æƒ…å†µä¸‹,å¦‚æœnå°äºp,é‚£ä¹ˆå°±ä¸å­˜åœ¨unique lest square coefficient estimate,æ¢å¥è¯è¯´å°±æ˜¯variance
æ˜¯infiniteçš„,é‚£ä¹ˆè¿™ä¸ªleaset square methodå°±æ ¹æœ¬æ²¡æ³•ç”¨</li>
<li>æˆ‘ä»¬å¯ä»¥é€šè¿‡å‡å°‘å¾…è¯„ä¼°coefficientçš„æ–¹æ³•æ¥é™ä½variance,ä»£ä»·æ˜¯æé«˜bias</li>
</ol></li>
<li>Model Interpretability:
<ol class="org-ol">
<li>ä¸€ä¸ªæ™®éç°è±¡å°±æ˜¯regression modelé‡Œé¢çš„variableå¾ˆå¤šéƒ½æ˜¯æ²¡æœ‰ç”¨çš„:åŒ…å«è¿™äº›irrelevant variableä¼š
å¯¼è‡´æ¨¡å‹unnecessry complexity</li>
<li>ä¸Šè¿°é—®é¢˜å¯ä»¥é€šè¿‡è®¾ç½®irrelevant variableå¯¹åº”çš„coefficientä¸º0æ¥è§£å†³</li>
<li>ä½†æ˜¯é—®é¢˜åœ¨äºleast squreéå¤„ä¸å¯èƒ½æŠŠæŸä¸ªcoefficientè®¾ç½®ä¸º0</li>
<li>æœ¬ç« ä¼šæœ‰äº›approachå°±æ˜¯ç”¨æ¥å¸®åŠ©regression modelæ¥å»é™¤irrelevant variableçš„(è¿™ä¸ªè¿‡ç¨‹ä¹Ÿå«variable
selectionæˆ–è€…feature selection)</li>
</ol></li>
</ul></li>
<li>æœ¬ç« ä¼šä»‹ç»least squareçš„æ›¿ä»£è€…ç”¨æ¥fit å…¬å¼6-1,è¿™äº›approachåŒ…æ‹¬:
<ul class="org-ul">
<li>Subset Selection: è¿™ä¸ªapproaché‡ç‚¹æ˜¯æŠŠpä¸ªpredictorä¸­çœŸæ­£æœ‰ç”¨çš„xä¸ªpredictorç»™è¯†åˆ«å‡ºæ¥,ç„¶åç”¨è¿™ä¸ª
xä¸ªpredictoræ¥åŒ¹é…least square</li>
<li>Shrinkage: è¿™ä¸ªapproachä¼šä½¿ç”¨å…¨éƒ¨pä¸ªpredictor,ä½†æ˜¯è¿™ä¸ªpä¸ªpredictorä¼šæœ0çš„æ–¹å‘è¿›è¡Œç¼©å‡(æˆ–è€…å«æ­£
åˆ™åŒ–),ç”±äºcoefficientå¯èƒ½ä¼šç¼©å°åˆ°zero,æ‰€ä»¥Shrinkageä¹Ÿå¯ä»¥ç”¨æ¥åšvariable selection</li>
<li>Dimension Reduction: è¿™é‡Œçš„ç­–ç•¥æ˜¯é€šè¿‡æŠ•å°„(projecting),æŠŠpä¸ªpredictorç¼©å°åˆ°Mä¸ª(M&lt;p). åŸç†æ˜¯é€šè¿‡
æ’åˆ—ç»„åˆ,ä»pä¸ªpredictoré‡Œé¢é€‰æ‹©Mä¸ªpredictor,ç„¶åç”¨è¿™ä¸ªMä¸ªpredictoré€‚é…least square</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org68214c6" class="outline-3">
<h3 id="org68214c6"><span class="section-number-3">6.1.</span> Subset Selection</h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>æœ¬èŠ‚æˆ‘ä»¬ä¼šä»‹ç»é€‰å–predictorçš„ä¸€éƒ¨åˆ†çš„æ–¹æ³•,åŒ…æ‹¬:
<ul class="org-ul">
<li>best subset</li>
<li>stepwise model selection</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org801cd93" class="outline-4">
<h4 id="org801cd93"><span class="section-number-4">6.1.1.</span> Best Subset Selection</h4>
<div class="outline-text-4" id="text-6-1-1">
<ul class="org-ul">
<li>è¿™ä¸ªè¿‡ç¨‹æ¯”è¾ƒå¤æ‚,å‡è®¾æˆ‘ä»¬æ€»å…±æœ‰pä¸ªpredictor:
<ul class="org-ul">
<li>æˆ‘ä»¬æ¯1ä¸ªpredictorä½œä¸ºinput,äº§ç”Ÿpä¸ªmodel</li>
<li>æˆ‘ä»¬æ¯2ä¸ªpredictorä½œä¸ºinput,äº§ç”Ÿp/2ä¸ªmodel</li>
<li>æˆ‘ä»¬æ¯xä¸ªpredictorä½œä¸ºinput,äº§ç”Ÿp/xä¸ªmodel</li>
</ul></li>
<li>è¿™ä¸ªæ–¹æ³•æ€»å…±ä¼šäº§ç”Ÿ \(2^p\) ä¸ªmodel,ç„¶åé€‰æ‹©æœ€å¥½çš„model,å½“ç„¶é€‰æ‹©æœ€å¥½çš„è¿‡ç¨‹æœ‰äº›å¤æ‚.æˆ‘ä»¬æ•´ç†ä¸ºAlgorithm-6.1</li>
<li>Algorithm-6.1 Best subset selection:
<ol class="org-ol">
<li>è®© \(M_0\) ä»£è¡¨null model,è¿™ä¸ªmodelæ²¡æœ‰predictor,è¿™ä¸ªmodelçš„predictçš„ç»“æœæ˜¯æ¯ä¸ªobservationçš„sample mean</li>
<li>å¯¹äºk=1,2,&#x2026;pçš„æƒ…å†µ:
<ul class="org-ul">
<li>é¦–å…ˆæ¯kä¸ªpredictorç»„æˆä¸€ä¸ªpredictor,é‚£ä¹ˆä¼šæœ‰ \(\binom{p}{k}\) ç§ç»„åˆ,ä¹Ÿå°±æœ‰ \(\binom{p}{k}\) ç§model</li>
<li>ä»è¿™ \(\binom{p}{k}\) ä¸ªmodelé‡Œé¢,é€‰æ‹©æœ€å¥½çš„ä¸€ä¸ªmodel,èµ·åå«åš \(M_k\), è¿™é‡Œçš„æœ€å¥½çš„å®šä¹‰æ˜¯æ‹¥æœ‰æœ€ä½çš„RSS</li>
</ul></li>
<li>ä» \(M_0,\cdot\cdot\cdot,M_p\) é‡Œé¢é€šè¿‡cross-validated prediction error, \(C_p(AIC)\), BIC, æˆ–è€… adjusted \(R^2\) é€‰æ‹©æœ€å¥½çš„model</li>
</ol></li>
<li>ä¸Šé¢ç®—æ³•çš„ç¬¬2æ­¥å…¶å®å°±æ˜¯é€‰æ‹©å¥½äº†p+1ä¸ªpossibleçš„å€™é€‰model</li>
<li>ä¸ºäº†é€‰æ‹©æœ€ä½³model,æˆ‘ä»¬å…¶å®å°±æ˜¯åœ¨è¿™p+1ä¸ªå€™é€‰modelé‡Œé¢é€‰æ‹©.è¿™ä¸ªtaskéœ€è¦éå¸¸å°å¿ƒ:
<ul class="org-ul">
<li>éšç€predictorä¸ªæ•°çš„å¢å¤š,RSSä¼šå•è°ƒé€’å‡,$R^2$ä¼šå•è°ƒé€’å¢.æ‰€ä»¥,æˆ‘ä»¬ä¸èƒ½ä½¿ç”¨è¿™äº›å‚æ•°æ¥é€‰æ‹©model,å¦
åˆ™predictoræœ€å¤šçš„è‚¯å®šæ˜¯æœ€åçš„èƒœåˆ©è€…</li>
<li>å…¶ä¸­çš„åŸå› åœ¨äºLow RSSæˆ–è€… High \(R^2\) ä»£è¡¨çš„æ˜¯low training error,è€Œæˆ‘ä»¬é€‰çš„bestçš„å®šä¹‰æ˜¯lowest
test error</li>
<li>ç¬¬ä¸‰æ­¥æˆ‘ä»¬å°±ä½¿ç”¨èƒ½å¤Ÿåˆ¤æ–­å‡ºtest erroré«˜ä½çš„æ–¹æ³•å•¦,æ¯”å¦‚:cross-validated prediction error, \(C_p(AIC)\),
BIC, æˆ–è€… adjusted \(R^2\)</li>
</ul></li>
<li>è™½ç„¶best subset selectionçœ‹ä¸Šå»ç®€å•,å¹¶ä¸”æ–¹æ³•æœ‰æ„ŸæŸ“åŠ›,ä½†æ˜¯ç”±äºå…¶è®¡ç®—é‡è¿‡å¤§,ä½¿ç”¨çš„æ—¶å€™è¿˜æ˜¯æœ‰å¾ˆå¤šé™åˆ¶</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org3571fbb" class="outline-2">
<h2 id="org3571fbb"><span class="section-number-2">7.</span> Chapter 8: Tree-Based Methods</h2>
<div class="outline-text-2" id="text-7">
<ul class="org-ul">
<li>æœ¬ç« æˆ‘ä»¬æè¿°ä¸ºregressionå’Œclassificationå‡†å¤‡çš„tree-based method,è¿™ä¸ªmethodçš„åŸç†,å°±æ˜¯æŠŠpredictor
spaceç»™åˆ†æˆä¸åŒçš„region(è¿™ä¸ªè¿‡ç¨‹å«åšstratifyingæˆ–è€…segmenting)</li>
<li>ç”¨æ¥spliting segmentçš„è§„åˆ™å¯ä»¥æ€»ç»“ä¸ºä¸€æ£µæ ‘,æ‰€ä»¥è¿™ç±»approachè¢«å«åšdecision tree</li>
<li>tree-base methodåœ¨å‡†ç¡®æ€§æ–¹é¢å¹¶ä¸æ“…é•¿,å…¶ç‰¹ç‚¹æ˜¯å®¹æ˜“è§£é‡Š(useful for interpretation)</li>
<li>ä¸ºäº†æé«˜å‡†ç¡®æ€§(åŒæ—¶ä¹Ÿä¼šä¸¢å¤±ä¸€å®šçš„è§£é‡Šæ€§),æˆ‘ä»¬ä¼šæŠŠå¤šä¸ªtreeåˆ›é€ å‡ºæ¥,ç”¨æ¥é¢„æµ‹ä¸€ä¸ªæ•°æ®é›†.è¿™äº›æ–¹æ³•æœ‰:
<ul class="org-ul">
<li>bagging</li>
<li>random forests</li>
<li>boosting</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org6a084ee" class="outline-3">
<h3 id="org6a084ee"><span class="section-number-3">7.1.</span> The Basics of Decision Trees</h3>
<div class="outline-text-3" id="text-7-1">
<ul class="org-ul">
<li>decision treeå¯ä»¥åœ¨regressionå’Œclassificationä¸Šé¢ä½¿ç”¨,æˆ‘ä»¬å…ˆçœ‹regressionä¸Šçš„ä¾‹å­,ç„¶åçœ‹classification
çš„ä¾‹å­</li>
</ul>
</div>
<div id="outline-container-orgd8da673" class="outline-4">
<h4 id="orgd8da673"><span class="section-number-4">7.1.1.</span> Regression Trees</h4>
<div class="outline-text-4" id="text-7-1-1">
</div>
<ol class="org-ol">
<li><a id="org7fcaeee"></a>Predicting Baseball Players' Salaries Using Regression Trees<br />
<div class="outline-text-5" id="text-7-1-1-1">
<ul class="org-ul">
<li>æˆ‘ä»¬ä½¿ç”¨Hitters data setæ¥é¢„æµ‹çƒå‘˜çš„å·¥èµ„,æ ¹æ®:
<ul class="org-ul">
<li>Years: å…¥è¡Œå¹´é™</li>
<li>Hits: å»å¹´å‡»æ‰“æ•°ç›®</li>
</ul></li>
<li>æˆ‘ä»¬é¦–å…ˆå¤„ç†æ²¡æœ‰Salaryçš„æ•°æ®</li>
<li>ç„¶åæˆ‘ä»¬å¤„ç†ä¸‹Salary(å¼€æ ¹å·),å› ä¸ºSalaryæ•°ç›®å¤ªå¤§</li>
<li>ä¸‹é¢å°±æ˜¯æˆ‘ä»¬æˆåŠŸç®—å‡ºæ¥çš„modelçš„æ•ˆæœ(æ¨å¯¼modelçš„è¿‡ç¨‹åœ¨åé¢):
<ul class="org-ul">
<li><p>
å›¾8-1
</p>

<div id="org40915b9" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/8-1.png" alt="8-1.png" />
</p>
<p><span class="figure-number">Figure 36: </span>isl/8-1.png</p>
</div></li>
<li>ä¸Šå›¾å°±æ˜¯ä¸€ä¸ªç”¨regression treeæ¥fit dataçš„ä¾‹å­</li>
<li>treeçš„æœ€å¼€å§‹æ˜¯ä¸€ä¸ªåˆ†æ”¯:
<ol class="org-ol">
<li>å·¥ä½œå°äº4.5å¹´çš„è¢«åˆ†åœ¨å·¦åˆ†æ”¯</li>
<li>å·¥ä½œå¤§äº4.5å¹´çš„è¢«åˆ†åœ¨å³åˆ†æ”¯</li>
</ol></li>
<li>å¯¹äºYear&lt;4.5çš„çƒå‘˜,å…¶å¹³å‡å·¥èµ„(å¼€æ ¹å·å)æ˜¯5.107,æ‰€ä»¥æˆ‘ä»¬çš„é¢„æµ‹å€¼æ˜¯ \(e^{5.107} k\) ç¾å…ƒ,ä¹Ÿå°±æ˜¯
165,174ç¾å…ƒ</li>
<li>å¯¹äºYear&gt;4.5çš„çƒå‘˜,æˆ‘ä»¬è¢«åˆ†åˆ°äº†å³å­æ ‘</li>
<li>å³å­æ ‘åˆä¼šåˆ†æˆä¸¤ä¸ªéƒ¨åˆ†,æ ¹æ®Hitçš„æ•°ç›®åˆåˆ†æˆä¸¤ä¸ªå­æ ‘</li>
<li>ç»è¿‡å¦‚ä¸Šçš„ä¸¤æ¬¡åˆ†æ”¯,æœ€ç»ˆåˆ†æˆäº†ä¸‰ä¸ªregion:
<ol class="org-ol">
<li>R1 = {X| Years&lt;4.5}</li>
<li>R2 = {X| Years&gt;=4.5,Hits&lt;117.5}</li>
<li>R3 = {X| Years&gt;=4.5,Hits&gt;=117.5}</li>
</ol></li>
</ul></li>
<li>å¦‚å›¾
<ul class="org-ul">
<li><p>
å›¾8-2
</p>

<div id="orgc60813d" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/8-2.png" alt="8-2.png" />
</p>
<p><span class="figure-number">Figure 37: </span>isl/8-2.png</p>
</div></li>
<li>ä¸Šå›¾å¯ä»¥çœ‹æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨ä¸¤æ¡çº¿æŠŠè¿™ä¸¤æ¬¡ä¸ªbranchç»™è¡¨ç¤ºå‡ºæ¥</li>
<li>R1, R2, R3çš„è–ªæ°´å¦‚ä¸‹:
<ol class="org-ol">
<li>R1 \(e^{5.107}\)</li>
<li>R2 \(e^{5.999}\)</li>
<li>R1 \(e^{6.740}\)</li>
</ol></li>
</ul></li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org691844f" class="outline-2">
<h2 id="org691844f"><span class="section-number-2">8.</span> Chapter 9: Suppport Vector Machines</h2>
<div class="outline-text-2" id="text-8">
<ul class="org-ul">
<li>æœ¬ç« æˆ‘ä»¬è®¨è®ºSVM(support vector machine),è¿™æ˜¯ä¸€ä¸ªç”¨æ¥è¿›è¡Œåˆ†ç±»çš„approach,äº1990å¹´ä»£åœ¨è®¡ç®—æœºç•Œå‘æ˜</li>
<li>SVMåœ¨å¤šé¡¹æŒ‡æ ‡ä¸­è¡¨ç°éƒ½å¾ˆå¥½,è¢«è®¤ä¸ºæ˜¯éå¸¸æœ‰åˆ›æ„çš„classifier</li>
<li>SVMä¸æ˜¯ä¸€ä¸‹æƒ³å‡ºæ¥çš„,è€Œæ˜¯ç»è¿‡å¦‚ä¸‹å‡ ä¸ªè¿‡ç¨‹è¿­ä»£è¿‡æ¥çš„:
<ul class="org-ul">
<li>maximal margin classifier,æ˜¯ä¸€ä¸ªç®€å•çš„,ç›´è§‰ä¸Šå°±èƒ½æƒ³å‡ºæ¥çš„åˆ†ç±»å™¨,è™½ç„¶ä¼˜é›…è€Œåˆç®€å•,ä½†æ˜¯è¿™ä¸ªclassifier
ä¸èƒ½åº”ç”¨åˆ°å¤§éƒ¨åˆ†çš„data set,å› ä¸ºä»–éœ€è¦classå¿…é¡»ä½¿ç”¨linear boundaryæ¥åŒºåˆ†</li>
<li>é’ˆå¯¹maximal margin classifierçš„ç¼ºç‚¹,è¯ç”Ÿäº†support vector classifier,å®ƒèƒ½å¤Ÿåº”ç”¨åˆ°æ›´å¹¿æ³›çš„caseä¸Š
è¦æ±‚å¿…é¡»ä»¥linear boundaryæ¥åŒºåˆ†</li>
<li>å¯¹support vector classifierè¿›è¡Œæ”¹è¿›å,è¯ç”Ÿäº†support vector machine,å…¶å¯¹boundaryçš„è¦æ±‚ä¸å†æ˜¯linear
çš„äº†.å½“ç„¶æœ€å¼€å§‹support vector machineåªèƒ½åˆ†ä¸¤ç±»</li>
<li>åé¢ä»‹ç»çš„å¯¹support vector machineçš„extension,æ˜¯å¯ä»¥åˆ†æˆå¤šäºä¸¤ç±»çš„</li>
<li>æœ€åæˆ‘ä»¬ä¼šè®¨è®ºsupport vector machineå’Œå…¶ä»–çš„statistical method(æ¯”å¦‚logistic regression)ä¹‹é—´çš„ç´§å¯†è”ç³»</li>
</ul></li>
<li>å¾ˆå¤šäººä¼šæŠŠå¦‚ä¸‹ä¸‰ä¸ªæ¦‚å¿µç»Ÿç§°ä¸ºSVM,ä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯ä¼šç»†è‡´çš„åŒºåˆ†å®ƒä»¬:
<ul class="org-ul">
<li>maximal margin classifier</li>
<li>support vector classifier</li>
<li>support vector machine</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orge58dcf1" class="outline-3">
<h3 id="orge58dcf1"><span class="section-number-3">8.1.</span> Maximal Margin Classifier</h3>
<div class="outline-text-3" id="text-8-1">
</div>
<div id="outline-container-org673f552" class="outline-4">
<h4 id="org673f552"><span class="section-number-4">8.1.1.</span> What is a Hyperplane?</h4>
<div class="outline-text-4" id="text-8-1-1">
<ul class="org-ul">
<li>è¶…å¹³é¢(hyprplane)æ˜¯ä¸ºäº†på¾ˆå¤§çš„pç»´ç©ºé—´ä¸Šé¢,æˆ‘ä»¬æè¿°p-1ç»´äº‹ç‰©æ–¹ä¾¿è€Œè®¾è®¡çš„æ¦‚å¿µ:
<ul class="org-ul">
<li>å¯¹åº”äºŒç»´ç©ºé—´æ¥è¯´,å®ƒçš„è¶…å¹³é¢å°±æ˜¯ä¸€æ¡ç›´çº¿(ç›´çº¿åªæœ‰ä¸€ç»´)</li>
<li>å¯¹äºä¸‰ç»´ç©ºé—´æ¥è¯´,å®ƒçš„è¶…å¹³é¢å°±æ˜¯ä¸€ä¸ªå¹³é¢(å¹³é¢åªæœ‰ä¸¤ç»´)</li>
<li>å¯¹äºpç»´ç©ºé—´æ¥è¯´,ä»–çš„è¶…å¹³é¢å°±æ˜¯ä¸€ä¸ªp-1ç»´çš„äº‹ç‰©,äººç±»ä¸å¤ªå®¹æ˜“æƒ³è±¡</li>
</ul></li>
<li><p>
å¯¹äºè¶…å¹³é¢çš„æ•°å­¦è¡¨ç¤ºæˆ‘ä»¬å¯ä»¥å…ˆçœ‹ä¸€ä¸ªä¸€ç»´çš„æƒ…å†µ(ä¹Ÿå°±æ˜¯ç›´çº¿)
</p>
\begin{equation}
\beta_0 + \beta_1X_1 + \beta_2X_2 = 0,\tag{9.1}
\end{equation}</li>
<li><p>
ä½¿å¾—å…¬å¼9-1æˆç«‹çš„ä»»æ„ \(X=(X_1,X_2)^T\) (æ³¨æ„,æˆ‘ä»¬çš„Xæ— è®ºæˆå‘˜å¤šå°‘,éƒ½æ˜¯ä¸€ä¸ªvector,ä¹Ÿå°±æ˜¯ä¸€ä¸ªåˆ—å‘é‡,
æ‰€ä»¥ç”¨åˆ°Tæ¥è¡¨ç¤ºå¯¹è¡Œå‘é‡è¿›è¡Œè½¬ç½®)éƒ½æ˜¯è¶…å¹³é¢ä¸Šçš„ä¸€ä¸ªç‚¹!,è¿™ä¸ªç†å¿µå¯¹äºç†è§£è¶…å¹³é¢éå¸¸é‡è¦
</p>
<pre class="example" id="orgfe2293b">
When we say that 9.1 "efines" the hyperplane, we mean that any
X = (X1,X2) for whith 9.1 holds is a point on the hyperplane
</pre></li>
<li>æ³¨æ„,è¿™é‡Œè™½ç„¶æ˜¯X1, X2,å…¶å®ä½ å¯ä»¥çœ‹æˆx, y,è¿™æ ·å°±å®¹æ˜“ç†è§£äº†</li>
<li><p>
ä»ç›´çº¿ç†è§£äº†è¶…å¹³é¢ä¹‹å,æˆ‘ä»¬å¾ˆå®¹æ˜“æŠŠå…¬å¼9-1æ‰©å±•æˆå…¬å¼9-2,å¦‚ä¸‹
</p>
\begin{equation}
\beta_0 + \beta_1X_1 + \beta_2X_2 + \cdot\cdot\cdot + \beta_pX_p = 0,\tag{9.2}
\end{equation}</li>
<li>æˆ‘ä»¬è¿˜å¯ä»¥æ‰©å±•å¦‚ä¸‹ä¸¤ä¸ªå…¬å¼:
<ul class="org-ul">
<li><p>
å¦‚æœ \(X = (X_1,X_2,\cdot\cdot\cdot,X_p)^T\) åœ¨è¶…å¹³é¢çš„ä¸€ä¾§,å¯ä»¥å¾—åˆ°
</p>
\begin{equation}
\beta_0 + \beta_1X_1 + \beta_2X_2 + \cdot\cdot\cdot + \beta_pX_p > 0,\tag{9.3}
\end{equation}</li>
<li><p>
å¦‚æœ \(X = (X_1,X_2,\cdot\cdot\cdot,X_p)^T\) åœ¨è¶…å¹³é¢çš„å¦å¤–ä¸€ä¾§,å¯ä»¥å¾—åˆ°
</p>
\begin{equation}
\beta_0 + \beta_1X_1 + \beta_2X_2 + \cdot\cdot\cdot + \beta_pX_p < 0,\tag{9.4}
\end{equation}</li>
</ul></li>
<li>ä¹Ÿå°±æ˜¯è¯´,è¶…å¹³é¢æŠŠæ•´ä¸ªp-ç»´ç©ºé—´åˆ†æˆäº†ä¸¤éƒ¨åˆ†,æŠŠX(Xæ˜¯p-1ä¸ªçš„åˆ—å‘é‡)å¸¦å…¥å…¬å¼9-2,å¯ä»¥çŸ¥é“,è¿™
ä¸ªpointæ˜¯åœ¨è¶…å¹³é¢çš„å“ªä¸€ä¾§(è¿˜æ˜¯å°±åœ¨è¶…å¹³é¢ä¸Š)</li>
</ul>
</div>
</div>
<div id="outline-container-org2351863" class="outline-4">
<h4 id="org2351863"><span class="section-number-4">8.1.2.</span> Classification Using a Separating Hyperplane</h4>
<div class="outline-text-4" id="text-8-1-2">
<ul class="org-ul">
<li>å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ª \(n \times p\) çš„çŸ©é˜µ,åŒ…å«nä¸ªtraining observation,æ¯ä¸ªobservationé‡Œé¢æœ‰ä¸€ä¸ªp-dimensional
space(pä¸ªå‚æ•°)</li>
<li>ç„¶åè¿™äº›observationsä¼šæœ‰ä¸¤ç§ç»“æœ:
<ul class="org-ul">
<li>-1,è¡¨ç¤ºclass</li>
<li>1è¡¨ç¤ºå¦å¤–ä¸€ä¸ªclass</li>
</ul></li>
<li>æˆ‘ä»¬åŒæ—¶ä¹Ÿæœ‰test observation,æ˜¯ä¸€ä¸ªp-vector \(x^* = (x_1^* \cdot\cdot\cdot x_p^*)^T\)</li>
<li>æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ ¹æ®training dataå¼€å‘ä¸€ä¸ªclassifier,èƒ½å¤Ÿæ­£ç¡®çš„å§test observationåˆ†ç±»æˆåŠŸ.è¿™ç§ä¾é è¶…
å¹³é¢æ¥è¿›è¡Œåˆ†ç±»çš„æ–¹æ³•,å«åšseparating hyperplane</li>
<li><p>
å¦‚å›¾
</p>

<div id="org83f09ca" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/9-2.png" alt="9-2.png" />
</p>
<p><span class="figure-number">Figure 38: </span>isl/9-2.png</p>
</div>
<ul class="org-ul">
<li>ä¸Šå›¾ä¸­æœ‰ä¸‰æ¡çº¿,éƒ½èƒ½æˆåŠŸæŠŠæ•°æ®åˆ†æˆä¸¤ä¸ªéƒ¨åˆ†</li>
<li>æˆ‘ä»¬åªéœ€è¦è®¡ç®— \(f(x^*) = \beta_0 + \beta_1x^*_1+ \beta_2x^*_2+ \cdot\cdot\cdot+\beta_px^*_p\)  ,å°±å¯ä»¥é€šè¿‡ç»“æœçš„æ­£è´Ÿå€¼æ¥ç¡®è®¤test observationçš„é¢„æµ‹å€¼æ˜¯è“è‰²è¿˜æ˜¯ç²‰è‰²</li>
<li>\(f(x^*)\) çš„å¤§å°ä¹Ÿå¾ˆé‡è¦,å¦‚æœ \(f(x^*)\) è¶Šå¤§,é‚£ä¹ˆæˆ‘ä»¬å¯¹æˆ‘ä»¬çš„åˆ†ç±»ç»“æœå°±è¶Šè‡ªä¿¡</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgd92b146" class="outline-4">
<h4 id="orgd92b146"><span class="section-number-4">8.1.3.</span> The Maximal Margin Classifier</h4>
<div class="outline-text-4" id="text-8-1-3">
<ul class="org-ul">
<li>æ€»ä½“ä¸Šæ¥è¯´,å¦‚æœå­˜åœ¨ä¸€ä¸ªèƒ½å¤Ÿå®Œç¾åŒºåˆ†å½“å‰ç©ºé—´çš„è¶…å¹³é¢,é‚£ä¹ˆå®é™…ä¸Šä¼šå­˜åœ¨æ— ç©·å¤šä¸ªè¿™ç§è¶…å¹³é¢,æ¯”å¦‚å›¾9-2
é‡Œé¢å°±ç”»å‡ºæ¥ä¸‰ä¸ª,ä½†å…¶å®ç¨å¾®ç§»åŠ¨ä¸€ä¸‹ç›´çº¿(åˆä¸æ”¹å˜åˆ†ç±»ç»“æœ),å°±ä¼šæœ‰æ–°çš„ç›´çº¿</li>
<li>æˆ‘ä»¬å¿…é¡»è¦æœ‰ä¸€ä¸ªåŠæ³•æ¥ç¡®å®š,å¦‚ä½•åœ¨è¿™infiniteä¸ªå¯èƒ½çš„è¶…å¹³é¢é‡Œé¢,ç¡®å®šä¸€ä¸ªæœ€å¥½çš„è¶…å¹³é¢æ˜¯æˆ‘ä»¬ä¸‹é¢è¦ç ”ç©¶çš„</li>
<li>ä¸€ä¸ªå¾ˆè‡ªç„¶çš„æƒ³æ³•,å°±æ˜¯maximal margin hyperplane:
<ul class="org-ul">
<li>æ‰€è°“margin,æ˜¯training seté‡Œé¢å•ä¸ªpointåˆ°è¶…å¹³é¢çš„æœ€çŸ­è·ç¦»</li>
<li>å¯¹äºç‰¹å®šçš„è¶…å¹³é¢, æˆ‘ä»¬è®¡ç®—æ‰€æœ‰trainig seté‡Œé¢æ¯ä¸ªpointçš„marginçš„å’Œ.</li>
<li>å¦‚æœæŸä¸ªè¶…å¹³é¢æ‹¥æœ€å¤§çš„marginå’Œ,é‚£ä¹ˆè¿™ä¸ªè¶…å¹³é¢å°±æ˜¯æœ€å¥½çš„é€‰æ‹©</li>
<li>æˆ‘ä»¬ä¼šä½¿ç”¨å¾—åˆ°çš„maximal margin hyperplaneæ¥å¯¹test setè¿›è¡Œé¢„æµ‹.ç»å¤§å¤šæ•°æ—¶å€™,æ•ˆæœéƒ½æ˜¯ä¸é”™çš„,ä½†
æ˜¯å¯¹äºpå¾ˆå¤§çš„æƒ…å†µ,maximal margin hyperplaneä¼šæœ‰è¿‡æ‹Ÿåˆ(overfitting)çš„æƒ…å†µ</li>
</ul></li>
<li>å¦‚æœ \(\beta_0,\beta_1,\cdot\cdot\cdot,\beta_p\) æ˜¯maximal margin hyperplaneçš„coefficient,é‚£ä¹ˆå¯¹
äºæ–°çš„test observation \(x^*\) , æˆ‘ä»¬å°±ä½¿ç”¨å¦‚ä¸‹çš„è®¡ç®—æ–¹æ³•åˆ¤æ–­å…¶ç±»å‹ \(f(x^*) = \beta_0 + \beta_1x^*_1 + \cdot\cdot\cdot + \beta_2x^*_p\)</li>
<li>å¦‚å›¾
<ul class="org-ul">
<li><p>
å›¾9-3
</p>

<div id="org09e5c03" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/9-3.png" alt="9-3.png" />
</p>
<p><span class="figure-number">Figure 39: </span>isl/9-3.png</p>
</div></li>
<li>ä¸Šå›¾å±•ç¤ºçš„æ˜¯, å›¾9-2çš„æ•°æ®å¾—æ¥çš„maximal margin hyperplane</li>
<li>ä»å›¾ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°(å…¶å®ä¹Ÿå¯ä»¥æƒ³åˆ°),æˆ‘ä»¬çš„è¶…å¹³é¢æ˜¯ä¸€ä¸ª"å¹³æ¿"çš„"ä¸­çº¿"(å› ä¸ºä¸­çº¿èƒ½å¤Ÿä¿è¯å’Œä¸¤ä¸ªè¾¹
çš„è·ç¦»æœ€å¤§),è¿™ä¸ª"å¹³æ¿"æ˜¯èƒ½å¤Ÿæ’å…¥ä¸¤ä¸ªç±»ä¸­é—´çš„,æœ€å¤§çš„"å¹³æ¿"</li>
<li>è§‚å¯Ÿä¸Šå›¾,æˆ‘ä»¬ä¼šå‘ç°ä¸‰ä¸ªç‚¹åˆšå¥½è½åœ¨è™šçº¿ä¸Š,è¿™ä¸ªè™šçº¿å°±æ˜¯æœ€å¤§"å¹³æ¿"çš„è¾¹ç•Œ. è¿™ç§è½åœ¨æœ€å¤§"å¹³æ¿"è¾¹ç•Œ
çš„observationå«åšsupport vectors</li>
<li>support vectorçš„åå­—æ¥æºäº:
<ol class="org-ol">
<li>é¦–å…ˆä»–ä»¬æ˜¯vector(è¿™é‡Œæ˜¯äºŒç»´å‘é‡)</li>
<li>å…¶æ¬¡,ä»–ä»¬æ˜¯supportæ•´ä¸ªmaximal margin hyperplaneçš„,å› ä¸ºä»–ä»¬ç¨å¾®åŠ¨ä¸€ä¸‹,maximal margin hyperplane
å°±éœ€è¦æ”¹å˜!è€Œå…¶ä»–çš„vectorè½»å¾®åŠ¨ä¸€ä¸‹(åªè¦ä¸è¶Šè¿‡è™šçº¿),ä¸å½±å“maximal margin hyperplane</li>
</ol></li>
</ul></li>
<li>maximal margin hyperplaneå…¶å®åªå—ä¸€å°éƒ¨åˆ†observationå½±å“,æ˜¯å…¶é‡è¦ç‰¹æ€§,æˆ‘ä»¬åé¢ä¼šè®²åˆ°</li>
</ul>
</div>
</div>
<div id="outline-container-orgf04de60" class="outline-4">
<h4 id="orgf04de60"><span class="section-number-4">8.1.4.</span> Construction of the Maximal Margin Classifier</h4>
<div class="outline-text-4" id="text-8-1-4">
<ul class="org-ul">
<li>æˆ‘ä»¬ç°åœ¨è€ƒè™‘å¦‚ä½•è®¡ç®—maximal margin hyperplane,æœ‰å¦‚ä¸‹æ•°æ®:
<ul class="org-ul">
<li>nä¸ªtrainig observation: \(x_1, \cdot\cdot\cdot, x_n \in \Re^p\)</li>
<li>pä¸ªå¯¹åº”çš„label: \(y_1,\cdot\cdot\cdot,y_n \in \{-1, 1\}\)</li>
</ul></li>
<li>æ ¹æ®ä»¥ä¸Šæ•°æ®,è®¡ç®—å¾—åˆ°ä¸‹é¢å…¬å¼çš„æœ€ä¼˜åŒ–è§£,å°±æ˜¯maximal margin classifier:
<ul class="org-ul">
<li>å…¬å¼9-9</li>
<li>å…¬å¼9-10</li>
<li>å…¬å¼9-11</li>
</ul></li>
<li>å¦‚ä½•è®¡ç®—è¿™ä¸‰ä¸ªå…¬å¼çš„æœ€ä¼˜è§£ä¸æ˜¯æœ¬ä¹¦è®¨è®ºçš„èŒƒç•´,æ•…æ­¤å¤„ä¸å†è®²è§£</li>
</ul>
</div>
</div>
<div id="outline-container-orga5df7f8" class="outline-4">
<h4 id="orga5df7f8"><span class="section-number-4">8.1.5.</span> The Non-separable Case</h4>
<div class="outline-text-4" id="text-8-1-5">
<ul class="org-ul">
<li>åœ¨separating hyperplane å­˜åœ¨çš„æƒ…å†µä¸‹,maximal margin classifieræ˜¯ä¸€ä¸ªéå¸¸è‡ªç„¶çš„é€‰æ‹©.</li>
<li>ä½†æ˜¯æœ‰å¾ˆå¤šç§æƒ…å†µä¸‹,æ²¡æœ‰separating hyperplaneå­˜åœ¨,ä¹Ÿå°±æ²¡æœ‰maximal margin classifier. åœ¨è¿™ç§æƒ…å†µ
ä¸‹, æœ€ä¼˜è§£é—®é¢˜(å…¬å¼9.9-å…¬å¼9.11)æ²¡æœ‰M&gt;0çš„è§£</li>
<li>ä¸‹å›¾å°±æ˜¯æ²¡æœ‰separateä¸¤ä¸ªclassçš„æƒ…å†µ
<ul class="org-ul">
<li><p>
å›¾9-4
</p>

<div id="org787443b" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/isl/9-4.png" alt="9-4.png" />
</p>
<p><span class="figure-number">Figure 40: </span>isl/9-4.png</p>
</div></li>
</ul></li>
<li>ä¸‹ä¸€èŠ‚,æˆ‘ä»¬ä¼šæ‰©å±•separating hyperplaneçš„æ¦‚å¿µ,æ‰¾åˆ°almost separate classçš„hyperplane,ä½¿ç”¨soft
marginçš„æ¦‚å¿µ</li>
<li>æŠŠmaximal margin classifieræ‰©å±•åˆ°non-separable caseçš„æƒ…å½¢,å°±å«åšsupport vector classifier</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgb858ba5" class="outline-3">
<h3 id="orgb858ba5"><span class="section-number-3">8.2.</span> Support Vector Classifiers</h3>
<div class="outline-text-3" id="text-8-2">
</div>
<div id="outline-container-org603c340" class="outline-4">
<h4 id="org603c340"><span class="section-number-4">8.2.1.</span> Overview of the Support Vector Classifier</h4>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: harrifeng@outlook.com</p>
<p class="date">Created: 2023-08-29 ÖÜ¶ş 20:44</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
